[{"title":"FIFA","content":"  The F\u00e9d\u00e9ration internationale de football association (French for 'International Association Football Federation';[3] abbreviated as FIFA and pronounced in English as \/\u02c8fi\u02d0f\u0259\/ FEE-f\u0259) is an international self-regulatory governing body of association football, beach soccer, and futsal. It was founded in 1904[4] to oversee international competition among the national associations of Belgium, Denmark, France, Germany, the Netherlands, Spain (represented by the Madrid Football Club), Sweden, and Switzerland. Headquartered in Z\u00fcrich, Switzerland, its membership now comprises 211 national associations. These national associations must also be members of one of the six regional confederations into which the world is divided: CAF (Africa), AFC (Asia and Australia), UEFA (Europe), CONCACAF (North & Central America and the Caribbean), OFC (Oceania), and CONMEBOL (South America).  FIFA outlines several objectives in its organizational statutes, including growing association football internationally, providing efforts to ensure it is accessible to everyone, and advocating for integrity and fair play.[5] It is responsible for the organization and promotion of association football's major international tournaments, notably the World Cup which commenced in 1930, and the Women's World Cup which began in 1991. Although FIFA does not solely set the laws of the game, that being the responsibility of the International Football Association Board of which FIFA is a member, it applies and enforces the rules across all FIFA competitions.[6] All FIFA tournaments generate revenue from sponsorships; in 2022, FIFA had revenues of over US $5.8\u00a0billion, ending the 2019\u20132022 cycle with a net positive of US$1.2\u00a0billion, and cash reserves of over US$3.9\u00a0billion.[7]  Reports by investigative journalists have linked FIFA leadership with corruption, bribery, and vote-rigging related to the election of FIFA president Sepp Blatter and the organization's decision to award the 2018 and 2022 World Cups to Russia and Qatar, respectively. These allegations led to the indictments of nine high-ranking FIFA officials and five corporate executives by the U.S. Department of Justice on charges including racketeering, wire fraud, and money laundering. On 27 May 2015, several of these officials were arrested by Swiss authorities, who launched a simultaneous but separate criminal investigation into how the organization awarded the 2018 and 2022 World Cups. Those among these officials who were also indicted in the U.S. are expected to be extradited to face charges there as well.[8][9][10]  Many officials were suspended by FIFA's ethics committee including Sepp Blatter[11] and Michel Platini.[12] In early 2017, reports became public about FIFA president Gianni Infantino attempting to prevent the re-elections[13] of both chairmen of the ethics committee, Cornel Borb\u00e9ly and Hans-Joachim Eckert, during the FIFA congress in May 2017.[14][15] On 9 May 2017, following Infantino's proposal,[16] FIFA Council decided not to renew the mandates of Borb\u00e9ly and Eckert.[16] Together with the chairmen, 11 of 13 committee members were removed. FIFA has been suspected of corruption regarding the Qatar 2022 FIFA World Cup.[17]  The need for a single body to oversee association football became increasingly apparent at the beginning of the 20th century with the increasing popularity of international fixtures. The F\u00e9d\u00e9ration Internationale de Football Association (FIFA) was founded in the rear of the headquarters of the Union des Soci\u00e9t\u00e9s Fran\u00e7aises de Sports Athl\u00e9tiques (USFSA) at the Rue Saint Honor\u00e9 229 in Paris on 21 May 1904.[18] The French name and acronym are universally adopted outside French-speaking countries. The founding members were the national associations of Belgium, Denmark, France, the Netherlands, Spain (represented by then-Real Madrid CF; the Royal Spanish Football Federation was not created until 1913), Sweden and Switzerland.  On the same day, the German Football Association (DFB) declared its intention to affiliate through a telegram.[1]  The first president of FIFA was Robert Gu\u00e9rin. Gu\u00e9rin was replaced in 1906 by Daniel Burley Woolfall from England, by then a member of the association. The first tournament FIFA staged, the association football competition for the 1908 Olympics in London was more successful than its Olympic predecessors, despite the presence of professional footballers, contrary to the founding principles of FIFA.[19][20][21][22]  Membership of FIFA expanded beyond Europe with the application of South Africa in 1909, Argentina in 1912, Canada and Chile in 1913, and the United States in 1914.[23]  The 1912 Spalding Athletic Library \"Official Guide\" includes information on the 1912 Olympics (scores and stories), AAFA, and FIFA. The 1912 FIFA President was Dan B Woolfall.[24] Daniel Burley Woolfall was president from 1906 to 1918.[25]  During World War I, with many players sent off to war and the possibility of travel for international fixtures severely limited, the organization's survival was in doubt. Post-war, following the death of Woolfall, the organization was run by Dutchman Carl Hirschmann. It was saved from extinction but at the cost of the withdrawal of the Home Nations (of the United Kingdom), who cited an unwillingness to participate in international competitions with their World War enemies. The Home Nations later resumed their membership. The FIFA collection is held by the National Football Museum at Urbis in Manchester, England.[26] The first World Cup was held in 1930 in Montevideo, Uruguay.[26]  The FIFA flag is blue, with the organization's wordmark logo in the middle. The current FIFA flag was first flown during the 2018 FIFA World Cup opening ceremony in Moscow, Russia.[27]  Akin to the UEFA Champions League, FIFA has adopted an anthem composed by the German composer Franz Lambert since the 1994 FIFA World Cup. It has been re-arranged and produced by Rob May and Simon Hill.[28][29] The FIFA Anthem is played at the beginning of official FIFA sanctioned matches and tournaments such as international friendlies, the FIFA World Cup, FIFA Women's World Cup, FIFA U-20 World Cup, FIFA U-17 World Cup, Football at the Summer Olympics, FIFA U-20 Women's World Cup, FIFA Women's U-17 World Cup, FIFA Futsal World Cup, FIFA Beach Soccer World Cup and FIFA Club World Cup.[30]  Since 2007, FIFA has also required most of its broadcast partners to use short sequences including the anthem at the beginning and end of FIFA event coverage and for break bumpers to help promote FIFA's sponsors. This emulates practices long used by international football events, such as the UEFA Champions League. Exceptions may be made for specific circumstances; for example, an original piece of African music was used for bumpers during the 2010 FIFA World Cup.[31]    Besides its worldwide institutions, there are six confederations recognized by FIFA which oversee the game in the different continents and regions of the world. National associations, and not the continental confederations, are members of FIFA. The continental confederations are provided for in FIFA's statutes, and membership of a union is a prerequisite to FIFA membership.  In total, FIFA recognizes 211 national associations and their associated men's national teams as well as 129 women's national teams; see the list of national football teams and their respective country codes. The number of FIFA member associations is higher than the number of UN member states as FIFA has admitted associations from 23 non-sovereign entities as members in their own right, such as the four Home Nations within the United Kingdom and the two special administrative regions of China: Hong Kong and Macau.  On 28 February 2022, FIFA suspended Russia from all competitions due to controversy surrounding Russia's invasion of Ukraine.[32]  FIFA can suspend countries due to numerous multifaceted issues. Common reasons include governance interference, corruption, and financial irregularities. Doping or the misappropriation of drugs is also a consideration for expulsion.  The FIFA Men's World Rankings are updated monthly and rank each team based on their performance in international competitions, qualifiers, and friendly matches. There is also a world ranking for women's football, amended on a quarterly schedule.  FIFA's headquarters is in Z\u00fcrich, and it is an association established under the law of Switzerland.  FIFA's supreme body is the FIFA Congress, an assembly of representatives from each affiliated member association. Each national football association has one vote, regardless of size or footballing strength. The Congress assembles in ordinary sessions once every year, and extraordinary sessions have been held once a year since 1998. Congress makes decisions relating to FIFA's governing statutes and their method of implementation and application. Only Congress can pass changes to FIFA's statutes. The congress approves the annual report and decides on the acceptance of new national associations, and holds elections. Congress elects the President of FIFA, its general secretary, and the other members of the FIFA Council in the year following the FIFA World Cup.[33]  FIFA Council \u2013 formerly called the FIFA Executive Committee and chaired by the president \u2013 is the organization's main decision-making body in the intervals of Congress. The council comprises 37 people: the president; 8 vice-presidents; and 28 members from the confederations, with at least one of them being a woman. The executive committee is the body that decides which country will host the World Cup.  The president and the general secretary are the main office holders of FIFA and are in charge of its daily administration, carried in by the general secretariat, with its staff of approximately 280 members. Gianni Infantino is the current president, elected on 26 February 2016 at an extraordinary FIFA Congress session after former president Sepp Blatter was suspended pending a corruption investigation.[34][35]  FIFA's worldwide organizational structure also consists of several other bodies under the authority of the FIFA Council or created by Congress as standing committees. Among those bodies are the FIFA Emergency Committee, the FIFA Ethics Committee, the Finance Committee, the Disciplinary Committee, and the Referees Committee.  The FIFA Emergency Committee deals with all matters requiring immediate settlement in the time frame between the regular meetings of the FIFA Council.[36][37] The Emergency Committee consists of the FIFA president as well as one member from each confederation.[38] Emergency Committee decisions made are immediately put into legal effect, although they need to be ratified at the next Executive Committee meeting.[39]  FIFA publishes its results according to International Financial Reporting Standards. The total compensation for the management committee in 2011 was 30 million for 35 people. Blatter, the only full-time person on the committee, earned approximately two million Swiss francs, 1.2 million in salary, and the rest in bonuses.[40][41][42] A report in London's The Sunday Times in June 2014 said the members of the committee had their salaries doubled from $100,000 to $200,000 during the year. The report also said leaked documents had indicated $4.4 million in secret bonuses had been paid to the committee members following the 2010 FIFA World Cup in South Africa.[43]  The laws that govern football known officially as the Laws of the Game, are not solely the responsibility of FIFA; they are maintained by a body called the International Football Association Board (IFAB). FIFA has members on its board (four representatives); the other four are provided by the football associations of the United Kingdom: England, Scotland, Wales, and Northern Ireland, who jointly established IFAB in 1882 and are recognized for the creation and history of the game. Changes to the Laws of the Game must be agreed upon by at least six delegates.  The FIFA Statutes form the overarching document guiding FIFA's governing system. The governing system is divided into separate bodies with the appropriate powers to create a system of checks and balances. It consists of four general bodies: the Congress, the executive committee, the general Secretariat, and standing and ad hoc committees.[44]  FIFA frequently takes active roles in the running of the sport and developing the game around the world. One of its sanctions is to suspend teams and associated members from international competition when a government interferes in the running of FIFA's associate member organizations or if the associate is not functioning correctly.  A 2007 FIFA ruling that a player can be registered with a maximum of three clubs and appear in official matches for a maximum of two in a year measured from 1 July to 30 June has led to controversy, especially in those countries whose seasons cross that date barrier, as in the case of two former Ireland internationals. As a direct result of this controversy, FIFA modified this ruling the following year to accommodate transfers between leagues with out-of-phase seasons.  FIFA now permits the use of video evidence during matches, as well as for subsequent sanctions. However, for most of FIFA's history it stood opposed to its use.[45] The 1970 meeting of the International Football Association Board \"agreed to request the television authorities to refrain from any slow-motion play-back which reflected, or might reflect, adversely on any decision of the referee\".[46] As recently as 2008 FIFA president Sepp Blatter said: \"Let it be as it is and let's leave [football] with errors. The television companies will have the right to say [the referee] was right or wrong, but still, the referee makes the decision \u2013 a man, not a machine.\"[47] This stance was finally overturned on 3 March 2018, when the IFAB wrote video assistant referees (also known as VARs) into the Laws of the Game permanently.[48] Their use remains optional for competitions.  In early July 2012 FIFA sanctioned the use of goal-line technology, subject to rules specified by the International Football Association Board (IFAB), who had officially approved its use by amending the Laws of the Game to permit (but not require) its use.[49][50] This followed a high-profile incident during a second-round game in the 2010 FIFA World Cup between England and Germany, where a shot by Englishman Frank Lampard, which would have levelled the scores at 2\u20132 in a match that ultimately ended in a 4\u20131 German victory, crossed the line but was not seen to do so by the match officials, which led FIFA officials to declare that they would re-examine the use of goal-line technology.[51]  On 28 February 2022, due to the 2022 Russian invasion of Ukraine and by a recommendation by the International Olympic Committee (IOC), FIFA suspended the participation of Russia.[52][53]  The Russian Football Union unsuccessfully appealed the FIFA ban to the Court of Arbitration for Sport, which upheld the ban.[54] Some observers, while approving of the boycott of Russia, have pointed out that FIFA did not boycott Saddam Hussein's Iraq as an aggressor during the Iran\u2013Iraq War,[55] Saudi Arabia for its military intervention in Yemen,[56] Qatar for its human rights violations,[57][58] or the United States for the actions of the U.S. military during the Iraq War.[59] However, this full ban was partially lifted in October 2023 when it was decided that their men's and women's U-17 teams were allowed to return to international competitions.   FIFA previously banned Indonesia due to government intervention within the team. FIFA requires members to play \"with no influence from third parties\".[60]  FIFA holds an annual awards ceremony, The Best FIFA Football Awards since 2016, which recognizes both individual and team achievements in international association football. Individually, the top men's player is awarded The Best FIFA Men's Player, and the top women's player is The Best FIFA Women's Player. Other prominent awards are The Best FIFA Football Coach and FIFA FIFPro World11.  In 2000, FIFA presented two awards, FIFA Club of the Century and FIFA Player of the Century, to decide the greatest football club and player of the 20th century. Real Madrid was the club winner, while Diego Maradona and Pel\u00e9 were the joint player's winners.  Men's  Women's  Men's  Women's  Individual  Team    (Paulo Henrique Chaves)(Pedro Henrique Soares)(Paulo Neto)  (Levi de Weerd)(Manuel Bachoore)(Emre Yilmaz)  The following table has the Top 20 ranked men's football countries worldwide.[71]  The following table has the Top 20 ranked women's football countries in the world.[73]    In April 2022 FIFA launched FIFA+,[82] an OTT service providing up to 40,000 live matches per year, including 11,000 women's matches.[83] It was also confirmed that FIFA would make available archival content, including every FIFA World Cup and FIFA Women's World Cup match recorded on camera,[84] together with original documentary content.[85] Eleven Sports was later reported to be responsible for populating the FIFA+ platform with live matches.[86]  FIFA+ showed the 2023 FIFA Women's World Cup live in selected regions such as Japan, Brazil, Indonesia, and Thailand.[87]  FIFA+ have the rights to competitions in Oceania including the OFC Champions League and the OFC Women's Olympic Qualifying Tournament.[88][89][90] They also have rights to the New Zealand domestic competitions and national teams.[91][92]  2021-23 Members:  In May 2006, British investigative reporter Andrew Jennings' book Foul! The Secret World of FIFA: Bribes, Vote-Rigging, and Ticket Scandals (HarperCollins) caused controversy within the football world by detailing an alleged international cash-for-contracts scandal following the collapse of FIFA's marketing partner International Sport and Leisure (ISL) and revealed how some football officials had been urged to secretly repay the sweeteners they received. The book also alleged that vote-rigging had occurred in the fight for Sepp Blatter's continued control of FIFA as the organization's president. Shortly after the release of Foul! a BBC Panorama expos\u00e9 by Jennings and BBC producer Roger Corke, screened on 11 June 2006, reported that Blatter was being investigated by Swiss police over his role in a secret deal to repay more than \u00a31m worth of bribes pocketed by football officials. Lord Triesman, the former chairman of the English Football Association, described FIFA as an organization that \"behaves like a mafia family,\" highlighting the organization's \"decades-long traditions of bribes, bungs, and corruption\".[96]  All testimonies offered in the Panorama expos\u00e9 were provided through a disguised voice, appearance, or both, save one: Mel Brennan, a former CONCACAF official, became the first high-level football insider to go public with substantial allegations of corruption, nonfeasance, and malfeasance by CONCACAF and FIFA leadership. Brennan\u2014the highest-level African-American in the history of world football governance\u2014joined Jennings, Trinidadian journalist Lisana Liburd, and many others in exposing allegedly inappropriate allocations of money by CONCACAF and drew connections between ostensible CONCACAF criminality and similar behaviours at FIFA. Since then, and in the light of fresh allegations of corruption by FIFA in late 2010,[97] both Jennings and Brennan remain highly critical of FIFA. Brennan has called directly for an alternative to FIFA to be considered by the stakeholders of the sport worldwide.[98]  In a further Panorama expos\u00e9 broadcast on 29 November 2010, Jennings alleged that three senior FIFA officials, Nicolas Leoz, Issa Hayatou and Ricardo Teixeira, had been paid huge bribes by ISL between 1989 and 1999, which FIFA had failed to investigate. Jennings claimed they appeared on a list of 175 bribes paid by ISL, totalling about $100 million. A former ISL executive said there were suspicions within the company that they were only awarded the marketing contract for successive World Cups by paying bribes to FIFA officials. The program also alleged that another current official, Jack Warner, has been repeatedly involved in reselling World Cup tickets to touts; Blatter said that FIFA had not investigated the allegation because it had not been told about it via 'official channels.'  Panorama also alleged that FIFA requires nations bidding to host the World Cup to agree to implement special laws, including a blanket tax exemption for FIFA and its corporate sponsors and limitation of workers rights. Contrary to FIFA's demands, these conditions were revealed by the Dutch government, resulting in them being told by FIFA that their bid could be adversely affected. Following Jennings' earlier investigations, he was banned from all FIFA press conferences for reasons he claimed had not been made clear. The accused officials failed to answer questions about his latest allegations verbally or by letter.  Prime Minister David Cameron and Andy Anson, head of England's World Cup bid, criticized the timing of the broadcast three days before FIFA decided on the host for the 2018 FIFA World Cup, because it might damage England's bid; the voters included officials accused by the program.[99][100]  In June 2011, it came to light that the International Olympic Committee had started inquiry proceedings against FIFA honorary president Jo\u00e3o Havelange into claims of bribery. Panorama alleged that Havelange accepted a $1\u00a0million 'bung' in 1997 from ISL. The IOC stated that it \"takes all allegations of corruption very seriously, and we would always ask for any evidence of wrongdoing involving any IOC members to be passed to our ethics commission\".[101]  In a 2014 interview, American sportswriter Dave Zirin said that corruption is endemic to FIFA leadership and that the organization should be abolished for the game's good. He said that currently, FIFA is in charge of both monitoring corruption in association football matches and marketing and selling the sport, but that two \"separate\" organizational bodies are needed: an organizational body that monitors corruption and match-fixing and the like and an organization that's responsible for marketing and sponsorships and selling the sport. Zirin said the idea of having a single organization responsible for both seems highly ineffective and detrimental to the sport.[102]  In May 2015, 14 people were arrested, including nine FIFA officials, after being accused of corruption.[103]  In the 2022 World Cup bid, Qatar was honoured to host the World Cup.  Since then it has been discovered that Qatar paid as much as 200 billion dollars to host the World Cup. This information was discovered by the Tass news agency in Russia.[104]  Between 2013 and 2015 four individuals, and two sports television rights corporations pleaded guilty to United States financial misconduct charges. The pleas of Chuck Blazer, Jos\u00e9 Hawilla, Daryan Warner, Darrell Warner, Traffic Group and Traffic Sports USA were unsealed in May 2015.[9] In another 2015 case, Singapore also imposed a 6-year \"harshest sentence ever received for match-fixing\" on match-fixer Eric Ding who had bribed three Lebanese FIFA football officials with prostitutes as an inducement to fix future matches that they would officiate, as well as perverting the course of justice.[105]  Fourteen FIFA officials and marketing executives were indicted by the United States Department of Justice in May 2015. The officials were arrested in Switzerland and are in the process of extradition to the US. Specific charges (brought under the RICO act) include wire fraud, racketeering, and money laundering.[106]  \"Swiss authorities say they have also opened a separate criminal investigation into FIFA's operations pertaining to the 2018 and 2022 World Cup bids\".[107]  FIFA's top officials were arrested at a hotel in Switzerland on suspicion of receiving bribes totalling $100m (\u00a365m). The US Department of Justice stated that nine FIFA officials and four executives of sports management companies were arrested and accused of over $150m in bribes.[108] The UK Shadow Home Secretary and Labour Member of Parliament, Andy Burnham, stated in May 2015 that England should boycott the 2018 World Cup against corruption in FIFA and military aggression by Russia.[109]  FIFA's choice to award the 2018 World Cup to Russia and the 2022 World Cup to Qatar has been widely criticized by media.[110][111][112][113] It has been alleged that some FIFA inside sources insist that the Russian kickbacks of cash and gifts given to FIFA executive members were enough to secure the Russian 2018 bid weeks before the result was announced.[114] Sepp Blatter was widely criticized in the media for giving a warning about the \"evils of the media\" in a speech to FIFA executive committee members shortly before they voted on the hosting of the 2018 World Cup, a reference to The Sunday Times expos\u00e9s,[115] and the Panorama investigation.[116]  Two members of FIFA's executive committee were banned from all football-related activity in November 2010 for allegedly offering to sell their votes to undercover newspaper reporters. In early May 2011, a British parliamentary inquiry into why England failed to secure the 2018 finals was told by a member of parliament, Damian Collins, that there was evidence from The Sunday Times newspaper that Issa Hayatou of Cameroon and Jacques Anouma of Ivory Coast were paid by Qatar. Qatar has categorically denied the allegations, as have Hayatou and Anouma.[117]  FIFA president Blatter said, as of 23\u00a0May\u00a02011[update], that the British newspaper The Sunday Times has agreed to bring its whistle-blowing source to meet senior FIFA officials, who will decide whether to order a new investigation into alleged World Cup bidding corruption. \"[The Sunday Times] are happy, they agreed that they will bring this whistleblower here to Z\u00fcrich and then we will have a discussion, an investigation of this\", Blatter said.  Specifically, the whistle-blower claims that FIFA executive committee members Issa Hayatou and Jacques Anouma were paid $1.5\u00a0million to vote for Qatar.[118][119] The emirate's bid beat the United States in a final round of voting last December. Blatter did not rule out reopening the 2022 vote if corruption could be proved, but urged taking the matter \"step by step\". The FIFA president said his organization is \"anxiously awaiting\" more evidence before asking its ethics committee to examine allegations made in Britain's Parliament in early May 2011.  Hayatou, who is from Cameroon, leads the Confederation of African Football and is a FIFA vice-president. Anouma is president of Ivorian Football Federation. The whistle-blower said Qatar agreed to pay a third African voter, Amos Adamu, for his support. The Nigerian was later suspended from voting after a FIFA ethics court ruled he solicited bribes from undercover Sunday Times reporters posing as lobbyists. Blatter said the newspaper and its whistle-blower would meet with FIFA secretary general, J\u00e9r\u00f4me Valcke, and legal director, Marco Villiger.  Allegations against FIFA officials have also been made to the UK Parliament by David Triesman, the former head of England's bid and the English Football Association. Triesman told the lawmakers that four long-standing FIFA executive committee members\u2014Jack Warner, Nicol\u00e1s Leoz, Ricardo Teixeira and Worawi Makudi\u2014engaged in \"improper and unethical\" conduct in the 2018 bidding, which was won by Russia. All six FIFA voters have denied wrongdoing.[120]  On 28 September 2015, Sepp Blatter suggested that the 2018 World Cup being awarded to Russia was planned before the voting, and that the 2022 World Cup would have then been awarded to the United States. However, this plan changed after the election ballot, and the 2022 World Cup was awarded to Qatar instead of the U.S.[121][122]  According to leaked documents seen by The Sunday Times, Qatari state-run television channel Al Jazeera secretly offered $400\u00a0million to FIFA, for broadcasting rights, just 21 days before FIFA announced that Qatar would hold the 2022 World Cup.[123][124]  On 17 July 2012, in the wake of announced anti-corruption reforms by Sepp Blatter, the president of the FIFA,[125] the organization appointed U.S. lawyer Michael J. Garcia as the chairman of the investigative chamber of FIFA Ethics Committee, while German judge Hans-Joachim Eckert was appointed as the chairman of the Ethics Committee's adjudication chamber.[126]  In August 2012, Garcia declared his intention to investigate the bidding process and decision to respectively award the right to host the 2018 and 2022 FIFA World Cup to Russia and Qatar by the FIFA Executive Committee.[127] Garcia delivered his subsequent 350-page report in September 2014, and Eckert then announced that it would not be made public for legal reasons.[128]  On 13 November 2014, Eckert released a 42-page summary of his findings after reviewing Garcia's report. The summary cleared both Russia and Qatar of any wrongdoing during the bidding for the 2018 and 2022 World Cups,[129] leaving Russia and Qatar free to stage their respective World Cups.[130]  FIFA welcomed \"the fact that a degree of closure has been reached\", while the Associated Press wrote that the Eckert summary \"was denounced by critics as a whitewash\".[130] Hours after the Eckert summary was released, Garcia himself criticized it for being \"materially incomplete\" with \"erroneous representations of the facts and conclusions\", while declaring his intention to appeal to FIFA's Appeal Committee.[129] On 16 December 2014, FIFA's Appeal Committee dismissed Garcia's appeal against the Eckert summary as \"not admissible\". FIFA also stated that Eckert's summary was \"neither legally binding nor appealable\".[131] A day later, Garcia resigned from his role as FIFA ethics investigator in protest of FIFA's conduct, citing a \"lack of leadership\" and lost confidence in the independence of Eckert from FIFA.[132] In June 2015, Swiss authorities claimed the report was of \"little value\".[133]  In November 2022, the FIFA officials told players not to get involved in politics but focus on sports when they are in Qatar.[134] A few weeks earlier, the football associations and players of Denmark and Australia criticized Qatar for this.[135][136]  FIFA announced on 25 May 2011 that it had opened the investigation to examine the conduct of four officials\u2014Mohamed Bin Hammam and Jack Warner, along with Caribbean Football Union (CFU) officials Debbie Minguell and Jason Sylvester\u2014in relation to claims made by executive committee member, Chuck Blazer.[137][138][139] Blazer, who was at the time, the general secretary of the CONCACAF confederation, has alleged that violations were committed under the FIFA code of ethics during a meeting organized by Bin Hammam and Warner on 10 and 11 May\u2014the same time Lord Triesman had accused Warner of demanding money for a World Cup 2018 vote\u2014in relation to the 2011 FIFA presidential election,[140] in which Bin Hammam, who also played a key role in the Qatar 2022 FIFA World Cup bid, allegedly offered financial incentives for votes cast in his favour during the presidential election.  As a result of the investigation both Bin Hammam and Warner were suspended.[141] Warner reacted to his suspension by questioning Blatter's conduct and adding that FIFA secretary general, J\u00e9r\u00f4me Valcke, had told him via e-mail that Qatar had bought the 2022 World Cup.[142][143] Valcke subsequently issued a statement denying he had suggested it was bribery, saying instead that the country had \"used its financial muscle to lobby for support\". Qatar officials denied any impropriety.[144] Bin Hammam also responded by writing to FIFA, protesting unfair treatment in suspension by the FIFA Ethics Committee and FIFA administration.[145]  Further evidence emerged of alleged corruption. On 30 May 2011, Fred Lunn, vice-president of the Bahamas Football Association, said that he was given $40,000 in cash[146] as an incitement to vote for FIFA presidential candidate, Mohamed bin Hammam. In addition, on 11 June 2011 Louis Giskus, president of the Surinamese Football Association, alleged that he was given $40,000 in cash for \"development projects\" as an incentive to vote for Bin Hammam.[147]  After being re-elected as president of FIFA, Sepp Blatter responded to the allegations by promising to reform FIFA in wake of the bribery scandal, with Danny Jordaan, CEO of the 2010 FIFA World Cup in South Africa, saying there is great expectation for reform.[148] Former US Secretary of State Henry Kissinger is being tipped for a role on the newly proposed 'Solutions Committee', and former Netherlands national football team player Johan Cruyff was also being linked with a role.[143][149]  UEFA secretary-general Gianni Infantino said he hopes for \"concrete\" measures to be taken by the world game's authority. Saying that \"the UEFA executive committee has taken note of the will of FIFA to take concrete and effective measures for good governance ... [and is] following the situation closely.\"[150]  IOC president Jacques Rogge commented on the situation by saying that he believes FIFA \"can emerge stronger\" from its worst-ever crisis, stating that \"I will not point a finger and lecture ... I am sure FIFA can emerge stronger and from within\".[151]  Several of FIFA's partners and sponsors have raised concerns about the allegations of corruption, including Coca-Cola, Adidas, Emirates and Visa.[152][153][154] Coca-Cola raised concerns by saying \"the current allegations being raised are distressing and bad for the sport\"; with Adidas saying \"the negative tenor of the public debate around Fifa at the moment is neither good for football nor for Fifa and its partners\"; moreover Emirates raised its concerns by saying \"we hope that these issues will be resolved as soon as possible\"; and Visa adding \"the current situation is clearly not good for the game and we ask that Fifa take all necessary steps to resolve the concerns that have been raised.\"[152]  Australian Sports Minister Mark Arbib said it was clear FIFA needed to change, saying \"there is no doubt there needs to be reform of FIFA. This is something that we're hearing worldwide\", with Australian Senator Nick Xenophon accusing FIFA of \"scamming\" the country out of the A$46\u00a0million (US$35\u00a0million) it spent on the Australia 2022 FIFA World Cup bid, saying that \"until the investigation into FIFA has been completed, Australia must hold off spending any more taxpayers' money on any future World Cup bids.\"[155]  Theo Zwanziger, president of the German Football Association, also called on FIFA to re-examine the awarding of the 2022 World Cup to Qatar.[156]  Transparency International, which had called on FIFA to postpone the election pending a full independent investigation, renewed its call on FIFA to change its governance structure.[157]  Moreover, former Argentine football player Diego Maradona was critical of FIFA in light of the corruption scandal, comparing members of the board to dinosaurs. He said \"Fifa is a big museum. They are dinosaurs who do not want to relinquish power. It's always going to be the same.\"[158] In October 2011, Dick Pound criticized the organization, saying, \"FIFA has fallen far short of a credible demonstration that it recognizes the many problems it faces, that it has the will to solve them, that it is willing to be transparent about what it is doing and what it finds, and that its conduct in the future will be such that the public can be confident in the governance of the sport.\"[159]  In 2018, FIFA revised its code of ethics to remove corruption as one of the enumerated bases of ethical violations.[160] It retained bribery, misappropriation of funds and manipulation of competitions as offences, but added a statute of limitation clause that those offences could not be pursued after a ten-year period.[160]  The revision also made it an offence to make public statements of a defamatory nature against FIFA.[160] Alexandra Wrage, a former member of the FIFA governance committee and an expert in anti-bribery compliance, said that of the revision that \"the real value to FIFA is the chilling effect this will have on critics\".[160] "},{"title":"Baseball","content":"  Baseball is a bat-and-ball sport played between two teams of nine players each, taking turns batting and fielding. The game occurs over the course of several plays, with each play generally beginning when a player on the fielding team, called the pitcher, throws a ball that a player on the batting team, called the batter, tries to hit with a bat. The objective of the offensive team (batting team) is to hit the ball into the field of play, away from the other team's players, allowing its players to run the bases, having them advance counter-clockwise around four bases to score what are called \"runs\". The objective of the defensive team (referred to as the fielding team) is to prevent batters from becoming runners, and to prevent runners' advance around the bases.[2] A run is scored when a runner legally advances around the bases in order and touches home plate (the place where the player started as a batter).  The initial objective of the batting team is to have a player reach first base safely; this generally occurs either when the batter hits the ball and reaches first base before an opponent retrieves the ball and touches the base, or when the pitcher persists in throwing the ball out of the batter's reach. Players on the batting team who reach first base without being called \"out\" can attempt to advance to subsequent bases as a runner, either immediately or during teammates' turns batting. The fielding team tries to prevent runs by getting batters or runners \"out\", which forces them out of the field of play. The pitcher can get the batter out by throwing three pitches which result in strikes, while fielders can get the batter out by catching a batted ball before it touches the ground, and can get a runner out by tagging them with the ball while the runner is not touching a base.  The opposing teams switch back and forth between batting and fielding; the batting team's turn to bat is over once the fielding team records three outs. One turn batting for each team constitutes an inning. A game is usually composed of nine innings, and the team with the greater number of runs at the end of the game wins. Most games end after the ninth inning, but if scores are tied at that point, extra innings are usually played. Baseball has no game clock, though some competitions feature pace-of-play regulations such as the pitch clock to shorten game time.  Baseball evolved from older bat-and-ball games already being played in England by the mid-18th century. This game was brought by immigrants to North America, where the modern version developed. Baseball's American origins, as well as its reputation as a source of escapism during troubled points in American history such as the American Civil War and the Great Depression, have led the sport to receive the moniker of \"America's Pastime\"; since the late 19th century, it has been unofficially recognized as the national sport of the United States, though in modern times is considered less popular than other sports, such as American football. In addition to North America, baseball is considered the most popular sport in parts of Central and South America, the Caribbean, and East Asia, particularly in Japan, South Korea, and Taiwan.  In Major League Baseball (MLB), the highest level of professional baseball in the United States and Canada, teams are divided into the National League (NL) and American League (AL), each with three divisions: East, West, and Central. The MLB champion is determined by playoffs that culminate in the World Series. The top level of play is similarly split in Japan between the Central and Pacific Leagues and in Cuba between the West League and East League. The World Baseball Classic, organized by the World Baseball Softball Confederation, is the major international competition of the sport and attracts the top national teams from around the world. Baseball was played at the Olympic Games from 1992 to 2008, and was reinstated in 2020.  A baseball game is played between two teams, each usually composed of nine players, that take turns playing offense (batting and baserunning) and defense (pitching and fielding). A pair of turns, one at bat and one in the field, by each team constitutes an inning. A game consists of nine innings (seven innings at the high school level and in doubleheaders in college, Minor League Baseball and, since the 2020 season, Major League Baseball; and six innings at the Little League level).[3] One team\u2014customarily the visiting team\u2014bats in the top, or first half, of every inning. The other team\u2014customarily the home team\u2014bats in the bottom, or second half, of every inning. The goal of the game is to score more points (runs) than the other team. The players on the team at bat attempt to score runs by touching all four bases, in order, set at the corners of the square-shaped baseball diamond. A player bats at home plate and must attempt to safely reach a base before proceeding, counterclockwise, from first base, to second base, third base, and back home to score a run. The team in the field attempts to prevent runs from scoring by recording outs, which remove opposing players from offensive action, until their next turn at bat comes up again. When three outs are recorded, the teams switch roles for the next half-inning. If the score of the game is tied after nine innings, extra innings are played to resolve the contest. Many amateur games, particularly unorganized ones, involve different numbers of players and innings.[4]  The game is played on a field whose primary boundaries, the foul lines, extend forward from home plate at 45-degree angles. The 90-degree area within the foul lines is referred to as fair territory; the 270-degree area outside them is foul territory. The part of the field enclosed by the bases and several yards beyond them is the infield; the area farther beyond the infield is the outfield. In the middle of the infield is a raised pitcher's mound, with a rectangular rubber plate (the rubber) at its center. The outer boundary of the outfield is typically demarcated by a raised fence, which may be of any material and height. The fair territory between home plate and the outfield boundary is baseball's field of play, though significant events can take place in foul territory, as well.[5]  There are three basic tools of baseball: the ball, the bat, and the glove or mitt:  Protective helmets are also standard equipment for all batters.[9]  At the beginning of each half-inning, the nine players of the fielding team arrange themselves around the field. One of them, the pitcher, stands on the pitcher's mound. The pitcher begins the pitching delivery with one foot on the rubber, pushing off it to gain velocity when throwing toward home plate. Another fielding team player, the catcher, squats on the far side of home plate, facing the pitcher. The rest of the fielding team faces home plate, typically arranged as four infielders\u2014who set up along or within a few yards outside the imaginary lines (basepaths) between first, second, and third base\u2014and three outfielders. In the standard arrangement, there is a first baseman positioned several steps to the left of first base, a second baseman to the right of second base, a shortstop to the left of second base, and a third baseman to the right of third base. The basic outfield positions are left fielder, center fielder, and right fielder. With the exception of the catcher, all fielders are required to be in fair territory when the pitch is delivered. A neutral umpire sets up behind the catcher.[10] Other umpires will be distributed around the field as well.[11]  Play starts with a member of the batting team, the batter, standing in either of the two batter's boxes next to home plate, holding a bat.[12] The batter waits for the pitcher to throw a pitch (the ball) toward home plate, and attempts to hit the ball[13] with the bat.[12] The catcher catches pitches that the batter does not hit\u2014as a result of either electing not to swing or failing to connect\u2014and returns them to the pitcher. A batter who hits the ball into the field of play must drop the bat and begin running toward first base, at which point the player is referred to as a runner (or, until the play is over, a batter-runner). A batter-runner who reaches first base without being put out is said to be safe and is on base. A batter-runner may choose to remain at first base or attempt to advance to second base or even beyond\u2014however far the player believes can be reached safely. A player who reaches base despite proper play by the fielders has recorded a hit. A player who reaches first base safely on a hit is credited with a single. If a player makes it to second base safely as a direct result of a hit, it is a double; third base, a triple. If the ball is hit in the air within the foul lines over the entire outfield (and outfield fence, if there is one), or if the batter-runner otherwise safely circles all the bases, it is a home run: the batter and any runners on base may all freely circle the bases, each scoring a run. This is the most desirable result for the batter. The ultimate and most desirable result possible for a batter would be to hit a home run while all three bases are occupied or \"loaded\", thus scoring four runs on a single hit. This is called a grand slam. A player who reaches base due to a fielding mistake is not credited with a hit\u2014instead, the responsible fielder is charged with an error.[12]  Any runners already on base may attempt to advance on batted balls that land, or contact the ground, in fair territory, before or after the ball lands. A runner on first base must attempt to advance if a ball lands in play, as only one runner may occupy a base at any given time. If a ball hit into play rolls foul before passing through the infield, it becomes dead and any runners must return to the base they occupied when the play began. If the ball is hit in the air and caught before it lands, the batter has flied out and any runners on base may attempt to advance only if they tag up (contact the base they occupied when the play began, as or after the ball is caught). Runners may also attempt to advance to the next base while the pitcher is in the process of delivering the ball to home plate; a successful effort is a stolen base.[14]  A pitch that is not hit into the field of play is called either a strike or a ball. A batter against whom three strikes are recorded strikes out. A batter against whom four balls are recorded is awarded a base on balls or walk, a free advance to first base. (A batter may also freely advance to first base if the batter's body or uniform is struck by a pitch outside the strike zone, provided the batter does not swing and attempts to avoid being hit.)[15] Crucial to determining balls and strikes is the umpire's judgment as to whether a pitch has passed through the strike zone, a conceptual area above home plate extending from the midpoint between the batter's shoulders and belt down to the hollow of the knee.[16] Any pitch which does not pass through the strike zone is called a ball, unless the batter either swings and misses at the pitch, or hits the pitch into foul territory; an exception generally occurs if the ball is hit into foul territory when the batter already has two strikes, in which case neither a ball nor a strike is called.  While the team at bat is trying to score runs, the team in the field is attempting to record outs. In addition to the strikeout and flyout, common ways a member of the batting team may be put out include the ground out, force out, and tag out. These occur either when a runner is forced to advance to a base, and a fielder with possession of the ball reaches that base before the runner does, or the runner is touched by the ball, held in a fielder's hand, while not on a base. (The batter-runner is always forced to advance to first base, and any other runners must advance to the next base if a teammate is forced to advance to their base.) It is possible to record two outs in the course of the same play. This is called a double play. Three outs in one play, a triple play, is possible, though rare. Players put out or retired must leave the field, returning to their team's dugout or bench. A runner may be stranded on base when a third out is recorded against another player on the team. Stranded runners do not benefit the team in its next turn at bat as every half-inning begins with the bases empty.[17]  An individual player's turn batting or plate appearance is complete when the player reaches base, hits a home run, makes an out, or hits a ball that results in the team's third out, even if it is recorded against a teammate. On rare occasions, a batter may be at the plate when, without the batter's hitting the ball, a third out is recorded against a teammate\u2014for instance, a runner getting caught stealing (tagged out attempting to steal a base). A batter with this sort of incomplete plate appearance starts off the team's next turn batting; any balls or strikes recorded against the batter the previous inning are erased. A runner may circle the bases only once per plate appearance and thus can score at most a single run per batting turn. Once a player has completed a plate appearance, that player may not bat again until the eight other members of the player's team have all taken their turn at bat in the batting order. The batting order is set before the game begins, and may not be altered except for substitutions. Once a player has been removed for a substitute, that player may not reenter the game. Children's games often have more lenient rules, such as Little League rules, which allow players to be substituted back into the same game.[3][18]  If the designated hitter (DH) rule is in effect, each team has a tenth player whose sole responsibility is to bat (and run). The DH takes the place of another player\u2014almost invariably the pitcher\u2014in the batting order, but does not field. Thus, even with the DH, each team still has a batting order of nine players and a fielding arrangement of nine players.[19]  The number of players on a baseball roster, or squad, varies by league and by the level of organized play. A Major League Baseball (MLB) team has a roster of 26 players with specific roles. A typical roster features the following players:[20]  Most baseball leagues worldwide have the DH rule, including MLB, Japan's Pacific League, and Caribbean professional leagues, along with major American amateur organizations.[21] The Central League in Japan does not have the rule and high-level minor league clubs connected to National League teams are not required to field a DH.[22] In leagues that apply the designated hitter rule, a typical team has nine offensive regulars (including the DH), five starting pitchers,[23] seven or eight relievers, a backup catcher, and two or three other reserve players.[24][25]  The manager, or head coach, oversees the team's major strategic decisions, such as establishing the starting rotation, setting the lineup, or batting order, before each game, and making substitutions during games\u2014in particular, bringing in relief pitchers. Managers are typically assisted by two or more coaches; they may have specialized responsibilities, such as working with players on hitting, fielding, pitching, or strength and conditioning. At most levels of organized play, two coaches are stationed on the field when the team is at bat: the first base coach and third base coach, who occupy designated coaches' boxes, just outside the foul lines. These coaches assist in the direction of baserunners, when the ball is in play, and relay tactical signals from the manager to batters and runners, during pauses in play.[26] In contrast to many other team sports, baseball managers and coaches generally wear their team's uniforms; coaches must be in uniform to be allowed on the field to confer with players during a game.[27]  Any baseball game involves one or more umpires, who make rulings on the outcome of each play. At a minimum, one umpire will stand behind the catcher, to have a good view of the strike zone, and call balls and strikes. Additional umpires may be stationed near the other bases, thus making it easier to judge plays such as attempted force outs and tag outs. In MLB, four umpires are used for each game, one near each base. In the playoffs, six umpires are used: one at each base and two in the outfield along the foul lines.[28]  Many of the pre-game and in-game strategic decisions in baseball revolve around a fundamental fact: in general, right-handed batters tend to be more successful against left-handed pitchers and, to an even greater degree, left-handed batters tend to be more successful against right-handed pitchers.[29] A manager with several left-handed batters in the regular lineup, who knows the team will be facing a left-handed starting pitcher, may respond by starting one or more of the right-handed backups on the team's roster. During the late innings of a game, as relief pitchers and pinch hitters are brought in, the opposing managers will often go back and forth trying to create favorable matchups with their substitutions. The manager of the fielding team trying to arrange same-handed pitcher-batter matchups and the manager of the batting team trying to arrange opposite-handed matchups. With a team that has the lead in the late innings, a manager may remove a starting position player\u2014especially one whose turn at bat is not likely to come up again\u2014for a more skillful fielder (known as a defensive substitution).[30]  The tactical decision that precedes almost every play in a baseball game involves pitch selection.[31] By gripping and then releasing the baseball in a certain manner, and by throwing it at a certain speed, pitchers can cause the baseball to break to either side, or downward, as it approaches the batter, thus creating differing pitches that can be selected.[32] Among the resulting wide variety of pitches that may be thrown, the four basic types are the fastball, the changeup (or off-speed pitch), and two breaking balls\u2014the curveball and the slider.[33] Pitchers have different repertoires of pitches they are skillful at throwing. Conventionally, before each pitch, the catcher signals the pitcher what type of pitch to throw, as well as its general vertical or horizontal location.[34] If there is disagreement on the selection, the pitcher may shake off the sign and the catcher will call for a different pitch.  With a runner on base and taking a lead, the pitcher may attempt a pickoff, a quick throw to a fielder covering the base to keep the runner's lead in check or, optimally, effect a tag out.[35] Pickoff attempts, however, are subject to rules that severely restrict the pitcher's movements before and during the pickoff attempt. Violation of any one of these rules could result in the umpire calling a balk against the pitcher, which permits any runners on base to advance one base with impunity.[36] If an attempted stolen base is anticipated, the catcher may call for a pitchout, a ball thrown deliberately off the plate, allowing the catcher to catch it while standing and throw quickly to a base.[37] Facing a batter with a strong tendency to hit to one side of the field, the fielding team may employ a shift, with most or all of the fielders moving to the left or right of their usual positions. With a runner on third base, the infielders may play in, moving closer to home plate to improve the odds of throwing out the runner on a ground ball, though a sharply hit grounder is more likely to carry through a drawn-in infield.[38]  Several basic offensive tactics come into play with a runner on first base, including the fundamental choice of whether to attempt a steal of second base. The hit and run is sometimes employed, with a skillful contact hitter, the runner takes off with the pitch, drawing the shortstop or second baseman over to second base, creating a gap in the infield for the batter to poke the ball through.[39] The sacrifice bunt, calls for the batter to focus on making soft contact with the ball, so that it rolls a short distance into the infield, allowing the runner to advance into scoring position as the batter is thrown out at first. A batter, particularly one who is a fast runner, may also attempt to bunt for a hit. A sacrifice bunt employed with a runner on third base, aimed at bringing that runner home, is known as a squeeze play.[40] With a runner on third and fewer than two outs, a batter may instead concentrate on hitting a fly ball that, even if it is caught, will be deep enough to allow the runner to tag up and score\u2014a successful batter, in this case, gets credit for a sacrifice fly.[38] In order to increase the chance of advancing a batter to first base via a walk, the manager will sometimes signal a batter who is ahead in the count (i.e., has more balls than strikes) to take, or not swing at, the next pitch. The batter's potential reward of reaching base (via a walk) exceeds the disadvantage if the next pitch is a strike.[41]  The evolution of baseball from older bat-and-ball games is difficult to trace with precision. Consensus once held that today's baseball is a North American development from the older game rounders, popular among children in Great Britain and Ireland.[42][43][44] American baseball historian David Block suggests that the game originated in England; recently uncovered historical evidence supports this position. Block argues that rounders and early baseball were actually regional variants of each other, and that the game's most direct antecedents are the English games of stoolball and \"tut-ball\".[42] The earliest known reference to baseball is in a 1744 British publication, A Little Pretty Pocket-Book, by John Newbery.[45] Block discovered that the first recorded game of \"Bass-Ball\" took place in 1749 in Surrey, and featured the Prince of Wales as a player.[46] This early form of the game was apparently brought to Canada by English immigrants.[47]  By the early 1830s, there were reports of a variety of uncodified bat-and-ball games recognizable as early forms of baseball being played around North America.[48] The first officially recorded baseball game in North America was played in Beachville, Ontario, Canada, on June 4, 1838.[49] In 1845, Alexander Cartwright, a member of New York City's Knickerbocker Club, led the codification of the so-called Knickerbocker Rules,[50] which in turn were based on rules developed in 1837 by William R. Wheaton of the Gotham Club.[51] While there are reports that the New York Knickerbockers played games in 1845, the contest long recognized as the first officially recorded baseball game in U.S. history took place on June 19, 1846, in Hoboken, New Jersey: the \"New York Nine\" defeated the Knickerbockers, 23\u20131, in four innings.[52] With the Knickerbocker code as the basis, the rules of modern baseball continued to evolve over the next half-century.[53] By the time of the Civil War, baseball had begun to overtake its fellow bat-and-ball sport cricket in popularity within the United States, due in part to baseball being of a much shorter duration than the form of cricket played at the time, as well as the fact that troops during the Civil War did not need a specialized playing surface to play baseball, as they would have required for cricket.[54][55]  In the mid-1850s, a baseball craze hit the New York metropolitan area,[56] and by 1856, local journals were referring to baseball as the \"national pastime\" or \"national game\".[57] A year later, the sport's first governing body, the National Association of Base Ball Players, was formed. In 1867, it barred participation by African Americans.[58] The more formally structured National League was founded in 1876.[59] Professional Negro leagues formed, but quickly folded.[60] In 1887, softball, under the name of indoor baseball or indoor-outdoor, was invented as a winter version of the parent game.[61] The National League's first successful counterpart, the American League, which evolved from the minor Western League, was established in 1893, and virtually all of the modern baseball rules were in place by then.[62][63]  The National Agreement of 1903 formalized relations both between the two major leagues and between them and the National Association of Professional Base Ball Leagues, representing most of the country's minor professional leagues.[64] The World Series, pitting the two major league champions against each other, was inaugurated that fall.[65]  The Black Sox Scandal of the 1919 World Series led to the formation of the office of the Commissioner of Baseball.[66] The first commissioner, Kenesaw Mountain Landis, was elected in 1920. That year also saw the founding of the Negro National League; the first significant Negro league, it would operate until 1931. For part of the 1920s, it was joined by the Eastern Colored League.[67]  Compared with the present, professional baseball in the early 20th century was lower-scoring, and pitchers were more dominant.[68] The so-called dead-ball era ended in the early 1920s with several changes in rule and circumstance that were advantageous to hitters. Strict new regulations governed the ball's size, shape and composition, along with a new rule officially banning the spitball and other pitches that depended on the ball being treated or roughed-up with foreign substances, resulted in a ball that traveled farther when hit.[69] The rise of the legendary player Babe Ruth, the first great power hitter of the new era, helped permanently alter the nature of the game.[70] In the late 1920s and early 1930s, St. Louis Cardinals general manager Branch Rickey invested in several minor league clubs and developed the first modern farm system.[71] A new Negro National League was organized in 1933; four years later, it was joined by the Negro American League. The first elections to the National Baseball Hall of Fame took place in 1936. In 1939, Little League Baseball was founded in Pennsylvania.[72]  A large number of minor league teams disbanded when World War II led to a player shortage. Chicago Cubs owner Philip K. Wrigley led the formation of the All-American Girls Professional Baseball League to help keep the game in the public eye.[73] The first crack in the unwritten agreement barring blacks from white-controlled professional ball occurred in 1945: Jackie Robinson was signed by the National League's Brooklyn Dodgers and began playing for their minor league team in Montreal.[74] In 1947, Robinson broke the major leagues' color barrier when he debuted with the Dodgers.[75] Latin-American players, largely overlooked before, also started entering the majors in greater numbers. In 1951, two Chicago White Sox, Venezuelan-born Chico Carrasquel and black Cuban-born Minnie Mi\u00f1oso, became the first Hispanic All-Stars.[76][77] Integration proceeded slowly: by 1953, only six of the 16 major league teams had a black player on the roster.[76]  In 1975, the union's power\u2014and players' salaries\u2014began to increase greatly when the reserve clause was effectively struck down, leading to the free agency system.[78] Significant work stoppages occurred in 1981 and 1994, the latter forcing the cancellation of the World Series for the first time in 90 years.[79] Attendance had been growing steadily since the mid-1970s and in 1994, before the stoppage, the majors were setting their all-time record for per-game attendance.[80][81] After play resumed in 1995, non-division-winning wild card teams became a permanent fixture of the post-season. Regular-season interleague play was introduced in 1997 and the second-highest attendance mark for a full season was set.[82] In 2000, the National and American Leagues were dissolved as legal entities. While their identities were maintained for scheduling purposes (and the designated hitter distinction), the regulations and other functions\u2014such as player discipline and umpire supervision\u2014they had administered separately were consolidated under the rubric of MLB.[83]  In 2001, Barry Bonds established the current record of 73 home runs in a single season. There had long been suspicions that the dramatic increase in power hitting was fueled in large part by the abuse of illegal steroids (as well as by the dilution of pitching talent due to expansion), but the issue only began attracting significant media attention in 2002 and there was no penalty for the use of performance-enhancing drugs before 2004.[84] In 2007, Bonds became MLB's all-time home run leader, surpassing Hank Aaron, as total major league and minor league attendance both reached all-time highs.[85][86]  With the historic popular moniker as \"America's national pastime\", baseball is well-established in several other countries as well. As early as 1877, a professional league, the International Association, featured teams from both Canada and the United States.[87] While baseball is widely played in Canada and many minor league teams have been based in the country,[88][89] the American major leagues did not include a Canadian club until 1969, when the Montreal Expos joined the National League as an expansion team. In 1977, the expansion Toronto Blue Jays joined the American League.[90]  In 1847, American soldiers played what may have been the first baseball game in Mexico at Parque Los Berros in Xalapa, Veracruz.[91] The first formal baseball league outside of the United States and Canada was founded in 1878 in Cuba, which maintains a rich baseball tradition. The Dominican Republic held its first islandwide championship tournament in 1912.[92] Professional baseball tournaments and leagues began to form in other countries between the world wars, including the Netherlands (formed in 1922), Australia (1934), Japan (1936), Mexico (1937), and Puerto Rico (1938).[93] The Japanese major leagues have long been considered the highest quality professional circuits outside of the United States.[94]  After World War II, professional leagues were founded in many Latin American countries, most prominently Venezuela (1946) and the Dominican Republic (1955).[96] Since the early 1970s, the annual Caribbean Series has matched the championship clubs from the four leading Latin American winter leagues: the Dominican Professional Baseball League, Mexican Pacific League, Puerto Rican Professional Baseball League, and Venezuelan Professional Baseball League. In Asia, South Korea (1982), Taiwan (1990) and China (2003) all have professional leagues.[97]  The English football club, Aston Villa, were the first British baseball champions winning the 1890 National League of Baseball of Great Britain.[98][99] The 2020 National Champions were the London Mets. Other European countries have seen professional leagues; the most successful, other than the Dutch league, is the Italian league, founded in 1948.[100] In 2004, Australia won a surprise silver medal at the Olympic Games.[101] The Conf\u00e9d\u00e9ration Europ\u00e9ene de Baseball (European Baseball Confederation), founded in 1953, organizes a number of competitions between clubs from different countries. Other competitions between national teams, such as the Baseball World Cup and the Olympic baseball tournament, were administered by the International Baseball Federation (IBAF) from its formation in 1938 until its 2013 merger with the International Softball Federation to create the current joint governing body for both sports, the World Baseball Softball Confederation (WBSC).[102] Women's baseball is played on an organized amateur basis in numerous countries.[103]  After being admitted to the Olympics as a medal sport beginning with the 1992 Games, baseball was dropped from the 2012 Summer Olympic Games at the 2005 International Olympic Committee meeting. It remained part of the 2008 Games.[104] While the sport's lack of a following in much of the world was a factor,[105] more important was MLB's reluctance to allow its players to participate during the major league season.[106] MLB initiated the World Baseball Classic, scheduled to precede its season, partly as a replacement, high-profile international tournament. The inaugural Classic, held in March 2006, was the first tournament involving national teams to feature a significant number of MLB participants.[107][108] The Baseball World Cup was discontinued after its 2011 edition in favor of an expanded World Baseball Classic.[109]  Baseball has certain attributes that set it apart from the other popular team sports in the countries where it has a following. All of these sports use a clock,[110] play is less individual,[111] and the variation between playing fields is not as substantial or important.[112] The comparison between cricket and baseball demonstrates that many of baseball's distinctive elements are shared in various ways with its cousin sports.[113]  In clock-limited sports, games often end with a team that holds the lead killing the clock rather than competing aggressively against the opposing team. In contrast, baseball has no clock, thus a team cannot win without getting the last batter out and rallies are not constrained by time. At almost any turn in any baseball game, the most advantageous strategy is some form of aggressive strategy.[114] Whereas, in the case of multi-day Test and first-class cricket, the possibility of a draw (which occurs because of the restrictions on time, which like in baseball, originally did not exist[115]) often encourages a team that is batting last and well behind, to bat defensively and run out the clock, giving up any faint chance at a win, to avoid an overall loss.[116]  While nine innings has been the standard since the beginning of professional baseball, the duration of the average major league game has increased steadily through the years. At the turn of the 20th century, games typically took an hour and a half to play. In the 1920s, they averaged just less than two hours, which eventually ballooned to 2:38 in 1960.[117] By 1997, the average American League game lasted 2:57 (National League games were about 10 minutes shorter\u2014pitchers at the plate making for quicker outs than designated hitters).[118] In 2004, Major League Baseball declared that its goal was an average game of 2:45.[117] By 2014, though, the average MLB game took over three hours to complete.[119] The lengthening of games is attributed to longer breaks between half-innings for television commercials, increased offense, more pitching changes, and a slower pace of play, with pitchers taking more time between each delivery, and batters stepping out of the box more frequently.[117][118] Other leagues have experienced similar issues. In 2008, Nippon Professional Baseball took steps aimed at shortening games by 12 minutes from the preceding decade's average of 3:18.[120]  In 2016, the average nine-inning playoff game in Major League baseball was 3 hours and 35 minutes. This was up 10 minutes from 2015 and 21 minutes from 2014.[121] In response to the lengthening of the game, MLB decided from the 2023 season onward to institute a pitch clock rule to penalize batters and pitchers who take too much time between pitches; this had the effect of shortening 2023 regular season games by 24 minutes on average.[122][123]  Although baseball is a team sport, individual players are often placed under scrutiny and pressure. While rewarding, it has sometimes been described as \"ruthless\" due to the pressure on the individual player.[124] In 1915, a baseball instructional manual pointed out that every single pitch, of which there are often more than two hundred in a game, involves an individual, one-on-one contest: \"the pitcher and the batter in a battle of wits\".[125] Pitcher, batter, and fielder all act essentially independent of each other. While coaching staffs can signal pitcher or batter to pursue certain tactics, the execution of the play itself is a series of solitary acts. If the batter hits a line drive, the outfielder is solely responsible for deciding to try to catch it or play it on the bounce and for succeeding or failing. The statistical precision of baseball is both facilitated by this isolation and reinforces it.  Cricket is more similar to baseball than many other team sports in this regard: while the individual focus in cricket is mitigated by the importance of the batting partnership and the practicalities of tandem running, it is enhanced by the fact that a batsman may occupy the wicket for an hour or much more.[126] There is no statistical equivalent in cricket for the fielding error and thus less emphasis on personal responsibility in this area of play.[127]  Unlike those of most sports, baseball playing fields can vary significantly in size and shape. While the dimensions of the infield are specifically regulated, the only constraint on outfield size and shape for professional teams, following the rules of MLB and Minor League Baseball, is that fields built or remodeled since June 1, 1958, must have a minimum distance of 325 feet (99\u00a0m) from home plate to the fences in left and right field and 400 feet (122\u00a0m) to center.[128] Major league teams often skirt even this rule. For example, at Minute Maid Park, which became the home of the Houston Astros in 2000, the Crawford Boxes in left field are only 315 feet (96\u00a0m) from home plate.[129] There are no rules at all that address the height of fences or other structures at the edge of the outfield. The most famously idiosyncratic outfield boundary is the left-field wall at Boston's Fenway Park, in use since 1912: the Green Monster is 310 feet (94\u00a0m) from home plate down the line and 37 feet (11\u00a0m) tall.[130]  Similarly, there are no regulations at all concerning the dimensions of foul territory. Thus a foul fly ball may be entirely out of play in a park with little space between the foul lines and the stands, but a foulout in a park with more expansive foul ground.[131] A fence in foul territory that is close to the outfield line will tend to direct balls that strike it back toward the fielders, while one that is farther away may actually prompt more collisions, as outfielders run full speed to field balls deep in the corner. These variations can make the difference between a double and a triple or inside-the-park home run.[132] The surface of the field is also unregulated. While the adjacent image shows a traditional field surfacing arrangement (and the one used by virtually all MLB teams with naturally surfaced fields), teams are free to decide what areas will be grassed or bare.[133] Some fields\u2014including several in MLB\u2014use artificial turf. Surface variations can have a significant effect on how ground balls behave and are fielded as well as on baserunning. Similarly, the presence of a roof (seven major league teams play in stadiums with permanent or retractable roofs) can greatly affect how fly balls are played.[134] While football and soccer players deal with similar variations of field surface and stadium covering, the size and shape of their fields are much more standardized. The area out-of-bounds on a football or soccer field does not affect play the way foul territory in baseball does, so variations in that regard are largely insignificant.[135]  These physical variations create a distinctive set of playing conditions at each ballpark. Other local factors, such as altitude and climate, can also significantly affect play. A given stadium may acquire a reputation as a pitcher's park or a hitter's park, if one or the other discipline notably benefits from its unique mix of elements. The most exceptional park in this regard is Coors Field, home of the Colorado Rockies. Its high altitude\u20145,282 feet (1,610\u00a0m) above sea level\u2014is partly responsible for giving it the strongest hitter's park effect in the major leagues due to the low air pressure.[136] Wrigley Field, home of the Chicago Cubs, is known for its fickle disposition: a pitcher's park when the strong winds off Lake Michigan are blowing in, it becomes more of a hitter's park when they are blowing out.[137] The absence of a standardized field affects not only how particular games play out, but the nature of team rosters and players' statistical records. For example, hitting a fly ball 330 feet (100\u00a0m) into right field might result in an easy catch on the warning track at one park, and a home run at another. A team that plays in a park with a relatively short right field, such as the New York Yankees, will tend to stock its roster with left-handed pull hitters, who can best exploit it. On the individual level, a player who spends most of his career with a team that plays in a hitter's park will gain an advantage in batting statistics over time\u2014even more so if his talents are especially suited to the park.[138]  Organized baseball lends itself to statistics to a greater degree than many other sports. Each play is discrete and has a relatively small number of possible outcomes. In the late 19th century, a former cricket player, English-born Henry Chadwick of Brooklyn, was responsible for the \"development of the box score, tabular standings, the annual baseball guide, the batting average, and most of the common statistics and tables used to describe baseball.\"[139] The statistical record is so central to the game's \"historical essence\" that Chadwick came to be known as Father Baseball.[139] In the 1920s, American newspapers began devoting more and more attention to baseball statistics, initiating what journalist and historian Alan Schwarz describes as a \"tectonic shift in sports, as intrigue that once focused mostly on teams began to go to individual players and their statistics lines.\"[140]  The Official Baseball Rules administered by MLB require the official scorer to categorize each baseball play unambiguously. The rules provide detailed criteria to promote consistency. The score report is the official basis for both the box score of the game and the relevant statistical records.[141] General managers, managers, and baseball scouts use statistics to evaluate players and make strategic decisions.  Certain traditional statistics are familiar to most baseball fans. The basic batting statistics include:[142]  The basic baserunning statistics include:[143]  The basic pitching statistics include:[144]  The basic fielding statistics include:[145]  Among the many other statistics that are kept are those collectively known as situational statistics. For example, statistics can indicate which specific pitchers a certain batter performs best against. If a given situation statistically favors a certain batter, the manager of the fielding team may be more likely to change pitchers or have the pitcher intentionally walk the batter in order to face one who is less likely to succeed.[146]  Sabermetrics refers to the field of baseball statistical study and the development of new statistics and analytical tools. The term is also used to refer directly to new statistics themselves. The term was coined around 1980 by one of the field's leading proponents, Bill James, and derives from the Society for American Baseball Research (SABR).[147]  The growing popularity of sabermetrics since the early 1980s has brought more attention to two batting statistics that sabermetricians argue are much better gauges of a batter's skill than batting average:[148]  Some of the new statistics devised by sabermetricians have gained wide use:  Writing in 1919, philosopher Morris Raphael Cohen described baseball as the national religion of the US.[154] In the words of sports columnist Jayson Stark, baseball has long been \"a unique paragon of American culture\"\u2014a status he sees as devastated by the steroid abuse scandal.[155] Baseball has an important place in other national cultures as well: Scholar Peter Bjarkman describes \"how deeply the sport is ingrained in the history and culture of a nation such as Cuba, [and] how thoroughly it was radically reshaped and nativized in Japan.\"[156]  The major league game in the United States was originally targeted toward a middle-class, white-collar audience: relative to other spectator pastimes, the National League's set ticket price of 50 cents in 1876 was high, while the location of playing fields outside the inner city and the workweek daytime scheduling of games were also obstacles to a blue-collar audience.[157] A century later, the situation was very different. With the rise in popularity of other team sports with much higher average ticket prices\u2014football, basketball, and hockey\u2014professional baseball had become among the most popular blue-collar-oriented American spectator sports.[158]  Overall, baseball has a large following in the United States; a 2006 poll found that nearly half of Americans are fans.[159] This led to baseball being granted the title of \"America's favorite pastime\" by many American baseball fans.[160] In the late 1900s and early 2000s, baseball's position compared to football in the United States moved in contradictory directions. In 2008, MLB set a revenue record of $6.5\u00a0billion, matching the NFL's revenue for the first time in decades.[161] A new MLB revenue record of more than $10\u00a0billion was set in 2017.[162] On the other hand, the percentage of American sports fans polled who named baseball as their favorite sport was 9%, compared to pro football at 37%.[163] In 1985, the respective figures were pro football 24%, baseball 23%.[164] Because there are so many more major league games played, there is no comparison in overall attendance.[165] In 2008, total attendance at major league games was the second-highest in history: 78.6\u00a0million, 0.7% off the record set the previous year.[85] The following year, amid the U.S. recession, attendance fell by 6.6% to 73.4\u00a0million.[166] Eight years later, it dropped under 73\u00a0million.[167] Attendance at games held under the Minor League Baseball umbrella set a record in 2008, with 43.3\u00a0million.[168] While MLB games have not drawn the same national TV viewership as football games, MLB games are dominant in teams' local markets and regularly lead all programs in primetime in their markets during the summer.[169]  Since the early 1980s, the Dominican Republic, in particular the city of San Pedro de Macor\u00eds, has been the major leagues' primary source of foreign talent.[170] In 2017, 83 of the 868 players on MLB Opening Day rosters (and disabled lists) were from the country. Among other Caribbean countries and territories, a combined 97 MLB players were born in Venezuela, Cuba, and Puerto Rico.[171] Hall-of-Famer Roberto Clemente remains one of the greatest national heroes in Puerto Rico's history.[172] While baseball has long been the island's primary athletic pastime, its once well-attended professional winter league has declined in popularity since 1990, when young Puerto Rican players began to be included in the major leagues' annual first-year player draft.[173] In Cuba, where baseball is by every reckoning the national sport,[174] the national team overshadows the city and provincial teams that play in the top-level domestic leagues.[175]  In Asia, baseball is among the most popular sports in Japan and South Korea.[176] In Japan, where baseball is inarguably the leading spectator team sport, combined revenue for the twelve teams in Nippon Professional Baseball (NPB), the body that oversees both the Central and Pacific Leagues, was estimated at $1\u00a0billion in 2007. Total NPB attendance for the year was approximately 20\u00a0million. While in the preceding two decades, MLB attendance grew by 50 percent and revenue nearly tripled, the comparable NPB figures were stagnant. There are concerns that MLB's growing interest in acquiring star Japanese players will hurt the game in their home country.[177] Revenue figures are not released for the country's amateur system. Similarly, according to one official pronouncement, the sport's governing authority \"has never taken into account attendance\u00a0... because its greatest interest has always been the development of athletes\".[178] In Taiwan, baseball is one of the most widely spectated sports, with the origins dating back to Japanese rule.[179]  As of 2018[update], Little League Baseball oversees leagues with close to 2.4\u00a0million participants in over 80 countries.[180] The number of players has fallen since the 1990s, when 3\u00a0million children took part in Little League Baseball annually.[181] Babe Ruth League teams have over 1\u00a0million participants.[182] According to the president of the International Baseball Federation, between 300,000 and 500,000 women and girls play baseball around the world, including Little League and the introductory game of Tee Ball.[183]  A varsity baseball team is an established part of physical education departments at most high schools and colleges in the United States.[184] In 2015, nearly half a million high schoolers and over 34,000 collegians played on their schools' baseball teams.[185] By early in the 20th century, intercollegiate baseball was Japan's leading sport. Today, high school baseball in particular is immensely popular there.[186] The final rounds of the two annual tournaments\u2014the National High School Baseball Invitational Tournament in the spring, and the even more important National High School Baseball Championship in the summer\u2014are broadcast around the country. The tournaments are known, respectively, as Spring Koshien and Summer Koshien after the 55,000-capacity stadium where they are played.[187] In Cuba, baseball is a mandatory part of the state system of physical education, which begins at age six. Talented children as young as seven are sent to special district schools for more intensive training\u2014the first step on a ladder whose acme is the national baseball team.[175]  Baseball has had a broad impact on popular culture, both in the United States and elsewhere. Dozens of English-language idioms have been derived from baseball; in particular, the game is the source of a number of widely used sexual euphemisms.[189] The first networked radio broadcasts in North America were of the 1922 World Series: famed sportswriter Grantland Rice announced play-by-play from New York City's Polo Grounds on WJZ\u2013Newark, New Jersey, which was connected by wire to WGY\u2013Schenectady, New York, and WBZ\u2013Springfield, Massachusetts.[190] The baseball cap has become a ubiquitous fashion item not only in the United States and Japan, but also in countries where the sport itself is not particularly popular, such as the United Kingdom.[191]  Baseball has inspired many works of art and entertainment. One of the first major examples, Ernest Thayer's poem \"Casey at the Bat\", appeared in 1888. A wry description of the failure of a star player in what would now be called a \"clutch situation\", the poem became the source of vaudeville and other staged performances, audio recordings, film adaptations, and an opera, as well as a host of sequels and parodies in various media. There have been many baseball movies, including the Academy Award\u2013winning The Pride of the Yankees (1942) and the Oscar nominees The Natural (1984) and Field of Dreams (1989). The American Film Institute's selection of the ten best sports movies includes The Pride of the Yankees at number 3 and Bull Durham (1988) at number 5.[192] Baseball has provided thematic material for hits on both stage\u2014the Adler\u2013Ross musical Damn Yankees\u2014and record\u2014George J. Gaskin's \"Slide, Kelly, Slide\", Simon and Garfunkel's \"Mrs. Robinson\", and John Fogerty's \"Centerfield\".[193] The baseball-inspired comedic sketch \"Who's on First?\", popularized by Abbott and Costello in 1938, quickly became famous. Six decades later, Time named it the best comedy routine of the 20th century.[194]  Literary works connected to the game include the short fiction of Ring Lardner and novels such as Bernard Malamud's The Natural (the source for the movie), Robert Coover's The Universal Baseball Association, Inc., J. Henry Waugh, Prop., John Grisham's Calico Joe and W. P. Kinsella's Shoeless Joe (the source for Field of Dreams). Baseball's literary canon also includes the beat reportage of Damon Runyon; the columns of Grantland Rice, Red Smith, Dick Young, and Peter Gammons; and the essays of Roger Angell. Among the celebrated nonfiction books in the field are Lawrence S. Ritter's The Glory of Their Times, Roger Kahn's The Boys of Summer, and Michael Lewis's Moneyball. The 1970 publication of major league pitcher Jim Bouton's tell-all chronicle Ball Four is considered a turning point in the reporting of professional sports.[195]  Baseball has also inspired the creation of new cultural forms. Baseball cards were introduced in the late 19th century as trade cards. A typical example featured an image of a baseball player on one side and advertising for a business on the other. In the early 1900s they were produced widely as promotional items by tobacco and confectionery companies. The 1930s saw the popularization of the modern style of baseball card, with a player photograph accompanied on the rear by statistics and biographical data. Baseball cards\u2014many of which are now prized collectibles\u2014are the source of the much broader trading card industry, involving similar products for different sports and non-sports-related fields.[196]  Modern fantasy sports began in 1980 with the invention of Rotisserie League Baseball by New York writer Daniel Okrent and several friends. Participants in a Rotisserie league draft notional teams from the list of active MLB players and play out an entire imaginary season with game outcomes based on the players' latest real-world statistics. Rotisserie-style play quickly became a phenomenon. Now known more generically as fantasy baseball, it has inspired similar games based on an array of different sports.[197] The field boomed with increasing Internet access and new fantasy sports-related websites. By 2008, 29.9\u00a0million people in the United States and Canada were playing fantasy sports, spending $800\u00a0million on the hobby.[198] The burgeoning popularity of fantasy baseball is also credited with the increasing attention paid to sabermetrics\u2014first among fans, only later among baseball professionals.[199]  Informal variations of baseball have popped up over time, with games like corkball reflecting local traditions and allowing the game to be played in diverse environments.[200] Two variations of baseball, softball and Baseball5, are internationally governed alongside baseball by the World Baseball Softball Confederation.[201]  American professional baseball teams toured Britain in 1874 and 1889, and had a great effect on similar sports in Britain. In Wales and Merseyside, a strong community game had already developed with skills and plays more in keeping with the American game and the Welsh began to informally adopt the name \"baseball\" (P\u00eal Fas), to reflect the American style. By the 1890s, calls were made to follow the success of other working class sports (like Rugby in Wales and Soccer in Merseyside) and adopt a distinct set of rules and bureaucracy.[202] During the 1892 season rules for the game of \"baseball\" were agreed and the game was officially codified.[203]  Finnish baseball, also known as pes\u00e4pallo, is a combination of traditional ball-batting team games and North American baseball, invented by Lauri \"Tahko\" Pihkala in the 1920s.[204] The basic idea of pes\u00e4pallo is similar to that of baseball: the offense tries to score by hitting the ball successfully and running through the bases, while the defense tries to put the batter and runners out. One of the most important differences between pes\u00e4pallo and baseball is that the ball is pitched vertically, which makes hitting the ball, as well as controlling the power and direction of the hit, much easier. This gives the offensive game more variety, speed, and tactical aspects compared to baseball.[204] "},{"title":"Gunpowder","content":"Gunpowder, also commonly known as black powder to distinguish it from modern smokeless powder, is the earliest known chemical explosive. It consists of a mixture of sulfur, carbon (in the form of charcoal), and potassium nitrate (saltpeter). The sulfur and carbon act as fuels while the saltpeter is an oxidizer.[1][2] Gunpowder has been widely used as a propellant in firearms, artillery, rocketry, and pyrotechnics, including use as a blasting agent for explosives in quarrying, mining, building pipelines, tunnels,[3] and roads.  Gunpowder is classified as a low explosive because of its relatively slow decomposition rate and consequently low brisance. Low explosives deflagrate (i.e., burn at subsonic speeds), whereas high explosives detonate, producing a supersonic shockwave. Ignition of gunpowder packed behind a projectile generates enough pressure to force the shot from the muzzle at high speed, but usually not enough force to rupture the gun barrel. It thus makes a good propellant but is less suitable for shattering rock or fortifications with its low-yield explosive power. Nonetheless, it was widely used to fill fused artillery shells (and used in mining and civil engineering projects) until the second half of the 19th century, when the first high explosives were put into use.  Gunpowder is one of the Four Great Inventions of China.[4] Originally developed by Taoists for medicinal purposes, it was first used for warfare around AD 904.[5] Its use in weapons has declined due to smokeless powder replacing it, and it is no longer used for industrial purposes due to its relative inefficiency compared to newer alternatives such as dynamite and ammonium nitrate\/fuel oil.[6]  Gunpowder is a low explosive: it does not detonate, but rather deflagrates (burns quickly). This is an advantage in a propellant device, where one does not desire a shock that would shatter the gun and potentially harm the operator; however, it is a drawback when an explosion is desired. In that case, the propellant (and most importantly, gases produced by its burning) must be confined. Since it contains its own oxidizer and additionally burns faster under pressure, its combustion is capable of bursting containers such as a shell, grenade, or improvised \"pipe bomb\" or \"pressure cooker\" casings to form shrapnel.  In quarrying, high explosives are generally preferred for shattering rock. However, because of its low brisance, gunpowder causes fewer fractures and results in more usable stone compared to other explosives, making it useful for blasting slate, which is fragile,[7] or monumental stone such as granite and marble. Gunpowder is well suited for blank rounds, signal flares, burst charges, and rescue-line launches. It is also used in fireworks for lifting shells, in rockets as fuel, and in certain special effects.  Combustion converts less than half the mass of gunpowder to gas; most of it turns into particulate matter. Some of it is ejected, wasting propelling power, fouling the air, and generally being a nuisance (giving away a soldier's position, generating fog that hinders vision, etc.). Some of it ends up as a thick layer of soot inside the barrel, where it also is a nuisance for subsequent shots, and a cause of jamming an automatic weapon. Moreover, this residue is hygroscopic, and with the addition of moisture absorbed from the air forms a corrosive substance. The soot contains potassium oxide or sodium oxide that turns into potassium hydroxide, or sodium hydroxide, which corrodes wrought iron or steel gun barrels. Gunpowder arms therefore require thorough and regular cleaning to remove the residue.[8]  Gunpowder loads can be used in modern firearms as long as they are not gas-operated.[Footnote 1] The most compatible modern guns are smoothbore-barreled shotguns that are long-recoil operated. Combined with chrome-plated essential parts such as barrels and bores, these elements heavily reduce fouling and corrosion; the combination of these factors makes the shotgun easier to clean.[15]  The first confirmed reference to what can be considered gunpowder in China occurred in the 9th century AD during the Tang dynasty, first in a formula contained in the Taishang Shengzu Jindan Mijue (\u592a\u4e0a\u8056\u7956\u91d1\u4e39\u79d8\u8a23) in 808, and then about 50 years later in a Taoist text known as the Zhenyuan miaodao yaol\u00fce (\u771f\u5143\u5999\u9053\u8981\u7565).[16] The Taishang Shengzu Jindan Mijue mentions a formula composed of six parts sulfur to six parts saltpeter to one part birthwort herb.[16] According to the Zhenyuan miaodao yaol\u00fce, \"Some have heated together sulfur, realgar and saltpeter with honey; smoke and flames result, so that their hands and faces have been burnt, and even the whole house where they were working burned down.\"[17] Based on these Taoist texts, the invention of gunpowder by Chinese alchemists was likely an accidental byproduct from experiments seeking to create the elixir of life.[18] This experimental medicine origin is reflected in its Chinese name huoyao (Chinese: \u706b\u836f\/\u706b\u85e5; pinyin: hu\u01d2 y\u00e0o\/xuo y\u0251\u028a\/), which means \"fire medicine\".[19] Saltpeter was known to the Chinese by the mid-1st century AD and was primarily produced in the provinces of Sichuan, Shanxi, and Shandong.[20] There is strong evidence of the use of saltpeter and sulfur in various medicinal combinations.[21] A Chinese alchemical text dated 492 noted saltpeter burnt with a purple flame, providing a practical and reliable means of distinguishing it from other inorganic salts, thus enabling alchemists to evaluate and compare purification techniques; the earliest Latin accounts of saltpeter purification are dated after 1200.[22]  The earliest chemical formula for gunpowder appeared in the 11th century Song dynasty text, Wujing Zongyao (Complete Essentials from the Military Classics), written by Zeng Gongliang between 1040 and 1044.[23] The Wujing Zongyao provides encyclopedia references to a variety of mixtures that included petrochemicals\u2014as well as garlic and honey. A slow match for flame-throwing mechanisms using the siphon principle and for fireworks and rockets is mentioned. The mixture formulas in this book contain at most 50% saltpeter\u2009\u2014\u2009not enough to create an explosion, they produce an incendiary instead.[23] The Essentials was written by a Song dynasty court bureaucrat and there is little evidence that it had any immediate impact on warfare; there is no mention of its use in the chronicles of the wars against the Tanguts in the 11th century, and China was otherwise mostly at peace during this century. However, it had already been used for fire arrows since at least the 10th century. Its first recorded military application dates its use to the year 904 in the form of incendiary projectiles.[5] In the following centuries various gunpowder weapons such as bombs, fire lances, and the gun appeared in China.[24][25] Explosive weapons such as bombs have been discovered in a shipwreck off the shore of Japan dated from 1281, during the Mongol invasions of Japan.[26]  By 1083 the Song court was producing hundreds of thousands of fire arrows for their garrisons.[27] Bombs and the first proto-guns, known as \"fire lances\", became prominent during the 12th century and were used by the Song during the Jin-Song Wars. Fire lances were first recorded to have been used at the Siege of De'an in 1132 by Song forces against the Jin.[28] In the early 13th century the Jin used iron-casing bombs.[29] Projectiles were added to fire lances, and re-usable fire lance barrels were developed, first out of hardened paper, and then metal. By 1257 some fire lances were firing wads of bullets.[30][31] In the late 13th-century metal fire lances became 'eruptors', proto-cannons firing co-viative projectiles (mixed with the propellant, rather than seated over it with a wad), and by 1287 at the latest, had become true guns, the hand cannon.[32]  According to Iqtidar Alam Khan, it was invading Mongols who introduced gunpowder to the Islamic world.[33] The Muslims acquired knowledge of gunpowder sometime between 1240 and 1280, by which point the Syrian Hasan al-Rammah had written recipes, instructions for the purification of saltpeter, and descriptions of gunpowder incendiaries. It is implied by al-Rammah's usage of \"terms that suggested he derived his knowledge from Chinese sources\" and his references to saltpeter as \"Chinese snow\" (Arabic: \u062b\u0644\u062c \u0627\u0644\u0635\u064a\u0646 thalj al-\u1e63\u012bn), fireworks as \"Chinese flowers\", and rockets as \"Chinese arrows\" that knowledge of gunpowder arrived from China.[34] However, because al-Rammah attributes his material to \"his father and forefathers\", al-Hassan argues that gunpowder became prevalent in Syria and Egypt by \"the end of the twelfth century or the beginning of the thirteenth\".[35] In Persia saltpeter was known as \"Chinese salt\" (Persian: \u0646\u0645\u06a9 \u0686\u06cc\u0646\u06cc) namak-i ch\u012bn\u012b)[36][37] or \"salt from Chinese salt marshes\" (\u0646\u0645\u06a9 \u0634\u0648\u0631\u0647 \u0686\u06cc\u0646\u06cc namak-i sh\u016bra-yi ch\u012bn\u012b).[38][39]  Hasan al-Rammah included 107 gunpowder recipes in his text al-Furusiyyah wa al-Manasib al-Harbiyya (The Book of Military Horsemanship and Ingenious War Devices), 22 of which are for rockets. If one takes the median of 17 of these 22 compositions for rockets (75% nitrates, 9.06% sulfur, and 15.94% charcoal), it is nearly identical to the modern reported ideal recipe of 75% potassium nitrate, 10% sulfur, and 15% charcoal.[35] The text also mentions fuses, incendiary bombs, naphtha pots, fire lances, and an illustration and description of the earliest torpedo. The torpedo was called the \"egg which moves itself and burns\".[40] Two iron sheets were fastened together and tightened using felt. The flattened pear-shaped vessel was filled with gunpowder, metal filings, \"good mixtures\", two rods, and a large rocket for propulsion. Judging by the illustration, it was evidently supposed to glide across the water.[40][41][42] Fire lances were used in battles between the Muslims and Mongols in 1299 and 1303.[43]  Al-Hassan claims that in the Battle of Ain Jalut of 1260, the Mamluks used against the Mongols, in \"the first cannon in history\", formula with near-identical ideal composition ratios for explosive gunpowder.[35] Other historians urge caution regarding claims of Islamic firearms use in the 1204\u20131324 period as late medieval Arabic texts used the same word for gunpowder, naft, that they used for an earlier incendiary, naphtha.[44][45]  The earliest surviving documentary evidence for cannons in the Islamic world is from an Arabic manuscript dated to the early 14th century.[46][47] The author's name is uncertain but may have been Shams al-Din Muhammad, who died in 1350.[40] Dating from around 1320-1350, the illustrations show gunpowder weapons such as gunpowder arrows, bombs, fire tubes, and fire lances or proto-guns.[42] The manuscript describes a type of gunpowder weapon called a midfa which uses gunpowder to shoot projectiles out of a tube at the end of a stock.[48] Some consider this to be a cannon while others do not. The problem with identifying cannons in early 14th century Arabic texts is the term midfa, which appears from 1342 to 1352 but cannot be proven to be true hand-guns or bombards. Contemporary accounts of a metal-barrel cannon in the Islamic world do not occur until 1365.[49] Needham believes that in its original form the term midfa refers to the tube or cylinder of a naphtha projector (flamethrower), then after the invention of gunpowder it meant the tube of fire lances, and eventually it applied to the cylinder of hand-gun and cannon.[50]  According to Paul E. J. Hammer, the Mamluks certainly used cannons by 1342.[51] According to J. Lavin, cannons were used by Moors at the siege of Algeciras in 1343. A metal cannon firing an iron ball was described by Shihab al-Din Abu al-Abbas al-Qalqashandi between 1365 and 1376.[49]  The musket appeared in the Ottoman Empire by 1465.[52] In 1598, Chinese writer Zhao Shizhen described Turkish muskets as being superior to European muskets.[53] The Chinese military book Wu Pei Chih (1621) later described Turkish muskets that used a rack-and-pinion mechanism, which was not known to have been used in European or Chinese firearms at the time.[54]  The state-controlled manufacture of gunpowder by the Ottoman Empire through early supply chains to obtain nitre, sulfur and high-quality charcoal from oaks in Anatolia contributed significantly to its expansion between the 15th and 18th century. It was not until later in the 19th century when the syndicalist production of Turkish gunpowder was greatly reduced, which coincided with the decline of its military might.[55]  The earliest Western accounts of gunpowder appears in texts written by English philosopher Roger Bacon in 1267 called Opus Majus and Opus Tertium.[56] The oldest written recipes in continental Europe were recorded under the name Marcus Graecus or Mark the Greek between 1280 and 1300 in the Liber Ignium, or Book of Fires.[57]  Some sources mention possible gunpowder weapons being deployed by the Mongols against European forces at the Battle of Mohi in 1241.[58][59][60] Professor Kenneth Warren Chase credits the Mongols for introducing into Europe gunpowder and its associated weaponry.[61] However, there is no clear route of transmission,[62] and while the Mongols are often pointed to as the likeliest vector, Timothy May points out that \"there is no concrete evidence that the Mongols used gunpowder weapons on a regular basis outside of China.\"[63] May also states, \"however [, ...] the Mongols used the gunpowder weapon in their wars against the Jin, the Song and in their invasions of Japan.\"[63]  Records show that, in England, gunpowder was being made in 1346 at the Tower of London; a powder house existed at the Tower in 1461, and in 1515 three King's gunpowder makers worked there.[64] Gunpowder was also being made or stored at other royal castles, such as Portchester.[65] The English Civil War (1642\u20131645) led to an expansion of the gunpowder industry, with the repeal of the Royal Patent in August 1641.[64]  In late 14th century Europe, gunpowder was improved by corning, the practice of drying it into small clumps to improve combustion and consistency.[66] During this time, European manufacturers also began regularly purifying saltpeter, using wood ashes containing potassium carbonate to precipitate calcium from their dung liquor, and using ox blood, alum, and slices of turnip to clarify the solution.[66]  During the Renaissance, two European schools of pyrotechnic thought emerged, one in Italy and the other at Nuremberg, Germany.[67] In Italy, Vannoccio Biringuccio, born in 1480, was a member of the guild Fraternita di Santa Barbara but broke with the tradition of secrecy by setting down everything he knew in a book titled De la pirotechnia, written in vernacular.  It was published posthumously in 1540, with 9 editions over 138 years, and also reprinted by MIT Press in 1966.[66]  By the mid-17th century fireworks were used for entertainment on an unprecedented scale in Europe, being popular even at resorts and public gardens.[68] With the publication of Deutliche Anweisung zur Feuerwerkerey (1748), methods for creating fireworks were sufficiently well-known and well-described that \"Firework making has become an exact science.\"[69] In 1774 Louis XVI ascended to the throne of France at age 20.  After he discovered that France was not self-sufficient in gunpowder, a Gunpowder Administration was established; to head it, the lawyer Antoine Lavoisier was appointed. Although from a bourgeois family, after his degree in law Lavoisier became wealthy from a company set up to collect taxes for the Crown; this allowed him to pursue experimental natural science as a hobby.[70]  Without access to cheap saltpeter (controlled by the British), for hundreds of years France had relied on saltpetremen with royal warrants, the droit de fouille or \"right to dig\", to seize nitrous-containing soil and demolish walls of barnyards, without compensation to the owners.[71] This caused farmers, the wealthy, or entire villages to bribe the petermen and the associated bureaucracy to leave their buildings alone and the saltpeter uncollected.  Lavoisier instituted a crash program to increase saltpeter production, revised (and later eliminated) the droit de fouille, researched best refining and powder manufacturing methods, instituted management and record-keeping, and established pricing that encouraged private investment in works.  Although saltpeter from new Prussian-style putrefaction works had not been produced yet (the process taking about 18 months), in only a year France had gunpowder to export. A chief beneficiary of this surplus was the American Revolution.  By careful testing and adjusting the proportions and grinding time, powder from mills such as at Essonne outside Paris became the best in the world by 1788, and inexpensive.[71][72]  Two British physicists, Andrew Noble and Frederick Abel, worked to improve the properties of gunpowder during the late 19th century. This formed the basis for the Noble-Abel gas equation for internal ballistics.[73]  The introduction of smokeless powder in the late 19th century led to a contraction of the gunpowder industry. After the end of World War I, the majority of the British gunpowder manufacturers merged into a single company, \"Explosives Trades limited\", and a number of sites were closed down, including those in Ireland. This company became Nobel Industries Limited, and in 1926 became a founding member of Imperial Chemical Industries. The Home Office removed gunpowder from its list of Permitted Explosives. Shortly afterwards, on 31 December 1931, the former Curtis & Harvey's Glynneath gunpowder factory at Pontneddfechan in Wales closed down. The factory was demolished by fire in 1932.[74] The last remaining gunpowder mill at the Royal Gunpowder Factory, Waltham Abbey was damaged by a German parachute mine in 1941 and it never reopened.[64] This was followed by the closure and demolition of the gunpowder section at the Royal Ordnance Factory, ROF Chorley, at the end of World War II, and of ICI Nobel's Roslin gunpowder factory which closed in 1954.[64][75] This left ICI Nobel's Ardeer site in Scotland, which included a gunpowder factory, as the only factory in Great Britain producing gunpowder. The gunpowder area of the Ardeer site closed in October 1976.[64]  Gunpowder and gunpowder weapons were transmitted to India through the Mongol invasions of India.[76][77] The Mongols were defeated by Alauddin Khalji of the Delhi Sultanate, and some of the Mongol soldiers remained in northern India after their conversion to Islam.[77] It was written in the Tarikh-i Firishta (1606\u20131607) that Nasiruddin Mahmud the ruler of the Delhi Sultanate presented the envoy of the Mongol ruler Hulegu Khan with a dazzling pyrotechnics display upon his arrival in Delhi in 1258. Nasiruddin Mahmud tried to express his strength as a ruler and tried to ward off any Mongol attempt similar to the Siege of Baghdad (1258).[78] Firearms known as top-o-tufak also existed in many Muslim kingdoms in India by as early as 1366.[78] From then on the employment of gunpowder warfare in India was prevalent, with events such as the \"Siege of Belgaum\" in 1473 by Sultan Muhammad Shah Bahmani.[79]  The shipwrecked Ottoman Admiral Seydi Ali Reis is known to have introduced the earliest type of matchlock weapons, which the Ottomans used against the Portuguese during the Siege of Diu (1531). After that, a diverse variety of firearms, large guns in particular, became visible in Tanjore, Dacca, Bijapur, and Murshidabad.[80] Guns made of bronze were recovered from Calicut (1504)- the former capital of the Zamorins[81]  The Mughal emperor Akbar mass-produced matchlocks for the Mughal Army. Akbar is personally known to have shot a leading Rajput commander during the Siege of Chittorgarh.[82] The Mughals began to use bamboo rockets (mainly for signalling) and employ sappers: special units that undermined heavy stone fortifications to plant gunpowder charges.  The Mughal Emperor Shah Jahan is known to have introduced much more advanced matchlocks, their designs were a combination of Ottoman and Mughal designs. Shah Jahan also countered the British and other Europeans in his province of Gujar\u0101t, which supplied Europe saltpeter for use in gunpowder warfare during the 17th century.[83] Bengal and M\u0101lwa participated in saltpeter production.[83] The Dutch, French, Portuguese, and English used Chhapra as a center of saltpeter refining.[83]  Ever since the founding of the Sultanate of Mysore by Hyder Ali, French military officers were employed to train the Mysore Army. Hyder Ali and his son Tipu Sultan were the first to introduce modern cannons and muskets, their army was also the first in India to have official uniforms. During the Second Anglo-Mysore War Hyder Ali and his son Tipu Sultan unleashed the Mysorean rockets at their British opponents effectively defeating them on various occasions. The Mysorean rockets inspired the development of the Congreve rocket, which the British widely used during the Napoleonic Wars and the War of 1812.[84]  Cannons were introduced to Majapahit when Kublai Khan's Chinese army under the leadership of Ike Mese sought to invade Java in 1293. History of Yuan mentioned that the Mongol used cannons (Chinese: \u70ae\u2014P\u00e0o) against Daha forces.[85]:\u200a1\u20132\u200a[86][87]:\u200a220\u200a Cannons were used by the Ayutthaya Kingdom in 1352 during its invasion of the Khmer Empire.[88] Within a decade large quantities of gunpowder could be found in the Khmer Empire.[88] By the end of the century firearms were also used by the Tr\u1ea7n dynasty.[89]  Even though the knowledge of making gunpowder-based weapon has been known after the failed Mongol invasion of Java, and the predecessor of firearms, the pole gun (bedil tombak), was recorded as being used by Java in 1413,[90][91]:\u200a245\u200a the knowledge of making \"true\" firearms came much later, after the middle of the 15th century. It was brought by the Islamic nations of West Asia, most probably the Arabs. The precise year of introduction is unknown, but it may be safely concluded to be no earlier than 1460.[92]:\u200a23\u200a Before the arrival of the Portuguese in Southeast Asia, the natives already possessed primitive firearms, the Java arquebus.[93] Portuguese influence to local weaponry after the capture of Malacca (1511) resulted in a new type of hybrid tradition matchlock firearm, the istinggar.[94][95]:\u200a53\u200a  When the Portuguese came to the archipelago, they referred to the breech-loading swivel gun as ber\u00e7o, while the Spaniards call it verso.[96]:\u200a151\u200a By the early 16th century, the Javanese already locally producing large guns, some of them still survived until the present day and dubbed as \"sacred cannon\" or \"holy cannon\". These cannons varied between 180- and 260-pounders, weighing anywhere between 3 and 8 tons, length of them between 3 and 6\u00a0m.[97]  Saltpeter harvesting was recorded by Dutch and German travelers as being common in even the smallest villages and was collected from the decomposition process of large dung hills specifically piled for the purpose. The Dutch punishment for possession of non-permitted gunpowder appears to have been amputation.[98]:\u200a180\u2013181\u200a Ownership and manufacture of gunpowder was later prohibited by the colonial Dutch occupiers.[99] According to colonel McKenzie quoted in Sir Thomas Stamford Raffles', The History of Java (1817), the purest sulfur was supplied from a crater from a mountain near the straits of Bali.[98]:\u200a180\u2013181\u200a  On the origins of gunpowder technology, historian Tonio Andrade remarked, \"Scholars today overwhelmingly concur that the gun was invented in China.\"[100] Gunpowder and the gun are widely believed by historians to have originated from China due to the large body of evidence that documents the evolution of gunpowder from a medicine to an incendiary and explosive, and the evolution of the gun from the fire lance to a metal gun, whereas similar records do not exist elsewhere.[101] As Andrade explains, the large amount of variation in gunpowder recipes in China relative to Europe is \"evidence of experimentation in China, where gunpowder was at first used as an incendiary and only later became an explosive and a propellant... in contrast, formulas in Europe diverged only very slightly from the ideal proportions for use as an explosive and a propellant, suggesting that gunpowder was introduced as a mature technology.\"[62]  However, the history of gunpowder is not without controversy. A major problem confronting the study of early gunpowder history is ready access to sources close to the events described. Often the first records potentially describing use of gunpowder in warfare were written several centuries after the fact, and may well have been colored by the contemporary experiences of the chronicler.[102] Translation difficulties have led to errors or loose interpretations bordering on artistic licence. Ambiguous language can make it difficult to distinguish gunpowder weapons from similar technologies that do not rely on gunpowder. A commonly cited example is a report of the Battle of Mohi in Eastern Europe that mentions a \"long lance\" sending forth \"evil-smelling vapors and smoke\", which has been variously interpreted by different historians as the \"first-gas attack upon European soil\" using gunpowder, \"the first use of cannon in Europe\", or merely a \"toxic gas\" with no evidence of gunpowder.[103] It is difficult to accurately translate original Chinese alchemical texts, which tend to explain phenomena through metaphor, into modern scientific language with rigidly defined terminology in English. [34] Early texts potentially mentioning gunpowder are sometimes marked by a linguistic process where semantic change occurred.[104] For instance, the Arabic word naft transitioned from denoting naphtha to denoting gunpowder, and the Chinese word p\u00e0o changed in meaning from trebuchet to a cannon.[105] This has led to arguments on the exact origins of gunpowder based on etymological foundations. Science and technology historian Bert S. Hall makes the observation that, \"It goes without saying, however, that historians bent on special pleading, or simply with axes of their own to grind, can find rich material in these terminological thickets.\"[104]  Another major area of contention in modern studies of the history of gunpowder is regarding the transmission of gunpowder. While the literary and archaeological evidence supports a Chinese origin for gunpowder and guns, the manner in which gunpowder technology was transferred from China to the West is still under debate.[100] It is unknown why the rapid spread of gunpowder technology across Eurasia took place over several decades whereas other technologies such as paper, the compass, and printing did not reach Europe until centuries after they were invented in China.[62]  Gunpowder is a granular mixture of:  Potassium nitrate is the most important ingredient in terms of both bulk and function because the combustion process releases oxygen from the potassium nitrate, promoting the rapid burning of the other ingredients.[106] To reduce the likelihood of accidental ignition by static electricity, the granules of modern gunpowder are typically coated with graphite, which prevents the build-up of electrostatic charge.  Charcoal does not consist of pure carbon; rather, it consists of partially pyrolyzed cellulose, in which the wood is not completely decomposed. Carbon differs from ordinary charcoal. Whereas charcoal's autoignition temperature is relatively low, carbon's is much greater. Thus, a gunpowder composition containing pure carbon would burn similarly to a match head, at best.[107]  The current standard composition for the gunpowder manufactured by pyrotechnicians was adopted as long ago as 1780. Proportions by weight are 75% potassium nitrate (known as saltpeter or saltpetre), 15% softwood charcoal, and 10% sulfur.[108] These ratios have varied over the centuries and by country, and can be altered somewhat depending on the purpose of the powder. For instance, power grades of black powder, unsuitable for use in firearms but adequate for blasting rock in quarrying operations, are called blasting powder rather than gunpowder with standard proportions of 70% nitrate, 14% charcoal, and 16% sulfur; blasting powder may be made with the cheaper sodium nitrate substituted for potassium nitrate and proportions may be as low as 40% nitrate, 30% charcoal, and 30% sulfur.[109] In 1857, Lammot du Pont solved the main problem of using cheaper sodium nitrate formulations when he patented DuPont \"B\" blasting powder. After manufacturing grains from press-cake in the usual way, his process tumbled the powder with graphite dust for 12 hours. This formed a graphite coating on each grain that reduced its ability to absorb moisture.[110]  Neither the use of graphite nor sodium nitrate was new. Glossing gunpowder corns with graphite was already an accepted technique in 1839,[111] and sodium nitrate-based blasting powder had been made in Peru for many years using the sodium nitrate mined at Tarapac\u00e1 (now in Chile).[112] Also, in 1846, two plants were built in south-west England to make blasting powder using this sodium nitrate.[113] The idea may well have been brought from Peru by Cornish miners returning home after completing their contracts. Another suggestion is that it was William Lobb, the plant collector, who recognised the possibilities of sodium nitrate during his travels in South America. Lammot du Pont would have known about the use of graphite and probably also knew about the plants in south-west England. In his patent he was careful to state that his claim was for the combination of graphite with sodium nitrate-based powder, rather than for either of the two individual technologies.  French war powder in 1879 used the ratio 75% saltpeter, 12.5% charcoal, 12.5% sulfur. English war powder in 1879 used the ratio 75% saltpeter, 15% charcoal, 10% sulfur.[114] The British Congreve rockets used 62.4% saltpeter, 23.2% charcoal and 14.4% sulfur, but the British Mark VII gunpowder was changed to 65% saltpeter, 20% charcoal and 15% sulfur.[citation needed] The explanation for the wide variety in formulation relates to usage. Powder used for rocketry can use a slower burn rate since it accelerates the projectile for a much longer time\u2014whereas powders for weapons such as flintlocks, cap-locks, or matchlocks need a higher burn rate to accelerate the projectile in a much shorter distance. Cannons usually used lower burn-rate powders, because most would burst with higher burn-rate powders.  Besides black powder, there are other historically important types of gunpowder. \"Brown gunpowder\" is cited as composed of 79% nitre, 3% sulfur, and 18% charcoal per 100 of dry powder, with about 2% moisture. Prismatic Brown Powder is a large-grained product the Rottweil Company introduced in 1884 in Germany, which was adopted by the British Royal Navy shortly thereafter. The French navy adopted a fine, 3.1 millimeter, not prismatic grained product called Slow Burning Cocoa (SBC) or \"cocoa powder\". These brown powders reduced burning rate even further by using as little as 2 percent sulfur and using charcoal made from rye straw that had not been completely charred, hence the brown color.[115]  Lesmok powder was a product developed by DuPont in 1911,[116] one of several semi-smokeless products in the industry containing a mixture of black and nitrocellulose powder. It was sold to Winchester and others primarily for .22 and .32 small calibers. Its advantage was that it was believed at the time to be less corrosive than smokeless powders then in use.  It was not understood in the U.S. until the 1920s that the actual source of corrosion was the potassium chloride residue from potassium chlorate sensitized primers.  The bulkier black powder fouling better disperses primer residue.  Failure to mitigate primer corrosion by dispersion caused the false impression that nitrocellulose-based powder caused corrosion.[117] Lesmok had some of the bulk of black powder for dispersing primer residue, but somewhat less total bulk than straight black powder, thus requiring less frequent bore cleaning.[118] It was last sold by Winchester in 1947.  The development of smokeless powders, such as cordite, in the late 19th century created the need for a spark-sensitive priming charge, such as gunpowder. However, the sulfur content of traditional gunpowders caused corrosion problems with Cordite Mk I and this led to the introduction of a range of sulfur-free gunpowders, of varying grain sizes.[64] They typically contain 70.5 parts of saltpeter and 29.5 parts of charcoal.[64] Like black powder, they were produced in different grain sizes. In the United Kingdom, the finest grain was known as sulfur-free mealed powder (SMP). Coarser grains were numbered as sulfur-free gunpowder (SFG n): 'SFG 12', 'SFG 20', 'SFG 40' and 'SFG 90', for example where the number represents the smallest BSS sieve mesh size, which retained no grains.  Sulfur's main role in gunpowder is to decrease the ignition temperature. A sample reaction for sulfur-free gunpowder would be:  The term black powder was coined in the late 19th century, primarily in the United States, to distinguish prior gunpowder formulations from the new smokeless powders and semi-smokeless powders. Semi-smokeless powders featured bulk volume properties that approximated black powder, but had significantly reduced amounts of smoke and combustion products. Smokeless powder has different burning properties (pressure vs. time) and can generate higher pressures and work per gram. This can rupture older weapons designed for black powder. Smokeless powders ranged in color from brownish tan to yellow to white. Most of the bulk semi-smokeless powders ceased to be manufactured in the 1920s.[119][118][120]  The original dry-compounded powder used in 15th-century Europe was known as \"Serpentine\", either a reference to Satan[37] or to a common artillery piece that used it.[121] The ingredients were ground together with a mortar and pestle, perhaps for 24 hours,[121] resulting in a fine flour.  Vibration during transportation could cause the components to separate again, requiring remixing in the field. Also if the quality of the saltpeter was low (for instance if it was contaminated with highly hygroscopic calcium nitrate), or if the powder was simply old (due to the mildly hygroscopic nature of potassium nitrate), in humid weather it would need to be re-dried. The dust from \"repairing\" powder in the field was a major hazard.  Loading cannons or bombards before the powder-making advances of the Renaissance was a skilled art. Fine powder loaded haphazardly or too tightly would burn incompletely or too slowly. Typically, the breech-loading powder chamber in the rear of the piece was filled only about half full, the serpentine powder neither too compressed nor too loose, a wooden bung pounded in to seal the chamber from the barrel when assembled, and the projectile placed on.  A carefully determined empty space was necessary for the charge to burn effectively. When the cannon was fired through the touchhole, turbulence from the initial surface combustion caused the rest of the powder to be rapidly exposed to the flame.[121]  The advent of much more powerful and easy to use corned powder changed this procedure, but serpentine was used with older guns into the 17th century.[122]  For propellants to oxidize and burn rapidly and effectively, the combustible ingredients must be reduced to the smallest possible particle sizes, and be as thoroughly mixed as possible. Once mixed, however, for better results in a gun, makers discovered that the final product should be in the form of individual dense grains that spread the fire quickly from grain to grain, much as straw or twigs catch fire more quickly than a pile of sawdust.  In late 14th century Europe and China,[123] gunpowder was improved by wet grinding; liquid such as distilled spirits[66] were added during the grinding-together of the ingredients and the moist paste dried afterwards. The principle of wet mixing to prevent the separation of dry ingredients, invented for gunpowder, is used today in the pharmaceutical industry.[124] It was discovered that if the paste was rolled into balls before drying the resulting gunpowder absorbed less water from the air during storage and traveled better. The balls were then crushed in a mortar by the gunner immediately before use, with the old problem of uneven particle size and packing causing unpredictable results. If the right size particles were chosen, however, the result was a great improvement in power.  Forming the damp paste into corn-sized clumps by hand or with the use of a sieve instead of larger balls produced a product after drying that loaded much better, as each tiny piece provided its own surrounding air space that allowed much more rapid combustion than a fine powder.  This \"corned\" gunpowder was from 30% to 300% more powerful. An example is cited where 15 kilograms (34\u00a0lb) of serpentine was needed to shoot a 21-kilogram (47\u00a0lb) ball, but only 8.2 kilograms (18\u00a0lb) of corned powder.[66]  Because the dry powdered ingredients must be mixed and bonded together for extrusion and cut into grains to maintain the blend, size reduction and mixing is done while the ingredients are damp, usually with water. After 1800, instead of forming grains by hand or with sieves, the damp mill-cake was pressed in molds to increase its density and extract the liquid, forming press-cake. The pressing took varying amounts of time, depending on conditions such as atmospheric humidity.  The hard, dense product was broken again into tiny pieces, which were separated with sieves to produce a uniform product for each purpose: coarse powders for cannons, finer grained powders for muskets, and the finest for small hand guns and priming.[122] Inappropriately fine-grained powder often caused cannons to burst before the projectile could move down the barrel, due to the high initial spike in pressure.[125] Mammoth powder with large grains, made for Rodman's 15-inch cannon, reduced the pressure to only 20 percent as high as ordinary cannon powder would have produced.[126]  In the mid-19th century, measurements were made determining that the burning rate within a grain of black powder (or a tightly packed mass) is about 6\u00a0cm\/s (0.20 feet\/s), while the rate of ignition propagation from grain to grain is around 9\u00a0m\/s (30 feet\/s), over two orders of magnitude faster.[122]  Modern corning first compresses the fine black powder meal into blocks with a fixed density (1.7\u00a0g\/cm3).[127] In the United States, gunpowder grains were designated F (for fine) or C (for coarse). Grain diameter decreased with a larger number of Fs and increased with a larger number of Cs, ranging from about 2\u00a0mm (1\u204416\u00a0in) for 7F to 15\u00a0mm (9\u204416\u00a0in) for 7C. Even larger grains were produced for artillery bore diameters greater than about 17\u00a0cm (6.7\u00a0in). The standard DuPont Mammoth powder developed by Thomas Rodman and Lammot du Pont for use during the American Civil War had grains averaging 15\u00a0mm (0.6\u00a0in) in diameter with edges rounded in a glazing barrel.[126] Other versions had grains the size of golf and tennis balls for use in 20-inch (51\u00a0cm) Rodman guns.[128] In 1875 DuPont introduced Hexagonal powder for large artillery, which was pressed using shaped plates with a small center core\u2014about 38\u00a0mm (1+1\u20442\u00a0in) diameter, like a wagon wheel nut, the center hole widened as the grain burned.[115] By 1882 German makers also produced hexagonal grained powders of a similar size for artillery.[115]  By the late 19th century manufacturing focused on standard grades of black powder from Fg used in large bore rifles and shotguns, through FFg (medium and small-bore arms such as muskets and fusils), FFFg (small-bore rifles and pistols), and FFFFg (extreme small bore, short pistols and most commonly for priming flintlocks).[129] A coarser grade for use in military artillery blanks was designated A-1. These grades were sorted on a system of screens with oversize retained on a mesh of 6 wires per inch, A-1 retained on 10 wires per inch, Fg retained on 14, FFg on 24, FFFg on 46, and FFFFg on 60. Fines designated FFFFFg were usually reprocessed to minimize explosive dust hazards.[130] In the United Kingdom, the main service gunpowders were classified RFG (rifle grained fine) with diameter of one or two millimeters and RLG (rifle grained large) for grain diameters between two and six millimeters.[128] Gunpowder grains can alternatively be categorized by mesh size: the BSS sieve mesh size, being the smallest mesh size, which retains no grains. Recognized grain sizes are Gunpowder G 7, G 20, G 40, and G 90.  Owing to the large market of antique and replica black-powder firearms in the US, modern black powder substitutes like Pyrodex, Triple Seven and Black Mag3[118] pellets have been developed since the 1970s. These products, which should not be confused with smokeless powders, aim to produce less fouling (solid residue), while maintaining the traditional volumetric measurement system for charges. Claims of less corrosiveness of these products have been controversial however. New cleaning products for black-powder guns have also been developed for this market.[129]  A simple, commonly cited, chemical equation for the combustion of gunpowder is:  A balanced, but still simplified, equation is:[131]  The exact percentages of ingredients varied greatly through the medieval period as the recipes were developed by trial and error, and needed to be updated for changing military technology.[132]  Gunpowder does not burn as a single reaction, so the byproducts are not easily predicted. One study[133] showed that it produced (in order of descending quantities) 55.91% solid products: potassium carbonate, potassium sulfate, potassium sulfide, sulfur, potassium nitrate, potassium thiocyanate, carbon, ammonium carbonate and 42.98% gaseous products: carbon dioxide, nitrogen, carbon monoxide, hydrogen sulfide, hydrogen, methane, 1.11% water.  Gunpowder made with less-expensive and more plentiful sodium nitrate instead of potassium nitrate (in appropriate proportions) works just as well. However, it is more hygroscopic than powders made from potassium nitrate. Muzzleloaders have been known to fire after hanging on a wall for decades in a loaded state, provided they remained dry. By contrast, gunpowder made with sodium nitrate must be kept sealed to remain stable.[original research?] Gunpowder releases 3 megajoules per kilogram and contains its own oxidant.[citation needed] This is less than TNT (4.7 megajoules per kilogram), or gasoline (47.2 megajoules per kilogram in combustion, but gasoline requires an oxidant; for instance, an optimized gasoline and O2 mixture releases 10.4 megajoules per kilogram, taking into account the mass of the oxygen).  Gunpowder also has a low energy density[how much?] compared to modern \"smokeless\" powders, and thus to achieve high energy loadings, large amounts are needed with heavy projectiles.[134]  For the most powerful black powder, meal powder, a wood charcoal is used. The best wood for the purpose is Pacific willow,[135] but others such as alder or buckthorn can be used. In Great Britain between the 15th and 19th centuries charcoal from alder buckthorn was greatly prized for gunpowder manufacture; cottonwood was used by the American Confederate States.[136] The ingredients are reduced in particle size and mixed as intimately as possible. Originally, this was with a mortar-and-pestle or a similarly operating stamping-mill, using copper, bronze or other non-sparking materials, until supplanted by the rotating ball mill principle with non-sparking bronze or lead. Historically, a marble or limestone edge runner mill, running on a limestone bed, was used in Great Britain; however, by the mid 19th century this had changed to either an iron-shod stone wheel or a cast iron wheel running on an iron bed.[108] The mix was dampened with alcohol or water during grinding to prevent accidental ignition. This also helps the extremely soluble saltpeter to mix into the microscopic pores of the very high surface-area charcoal.  Around the late 14th century, European powdermakers first began adding liquid during grinding to improve mixing, reduce dust, and with it the risk of explosion.[137] The powder-makers would then shape the resulting paste of dampened gunpowder, known as mill cake, into corns, or grains, to dry. Not only did corned powder keep better because of its reduced surface area, gunners also found that it was more powerful and easier to load into guns. Before long, powder-makers standardized the process by forcing mill cake through sieves instead of corning powder by hand.  The improvement was based on reducing the surface area of a higher density composition. At the beginning of the 19th century, makers increased density further by static pressing. They shoveled damp mill cake into a two-foot square box, placed this beneath a screw press and reduced it to half its volume. \"Press cake\" had the hardness of slate. They broke the dried slabs with hammers or rollers, and sorted the granules with sieves into different grades.  In the United States, Eleuthere Irenee du Pont, who had learned the trade from Lavoisier, tumbled the dried grains in rotating barrels to round the edges and increase durability during shipping and handling. (Sharp grains rounded off in transport, producing fine \"meal dust\" that changed the burning properties.)  Another advance was the manufacture of kiln charcoal by distilling wood in heated iron retorts instead of burning it in earthen pits. Controlling the temperature influenced the power and consistency of the finished gunpowder.  In 1863, in response to high prices for Indian saltpeter, DuPont chemists developed a process using potash or mined potassium chloride to convert plentiful Chilean sodium nitrate to potassium nitrate.[138]  The following year (1864) the Gatebeck Low Gunpowder Works in Cumbria (Great Britain) started a plant to manufacture potassium nitrate by essentially the same chemical process.[139] This is nowadays called the 'Wakefield Process', after the owners of the company. It would have used potassium chloride from the Sta\u00dffurt mines, near Magdeburg, Germany, which had recently become available in industrial quantities.[140]  During the 18th century, gunpowder factories became increasingly dependent on mechanical energy.[141] Despite mechanization, production difficulties related to humidity control, especially during the pressing, were still present in the late 19th century. A paper from 1885 laments that \"Gunpowder is such a nervous and sensitive spirit, that in almost every process of manufacture it changes under our hands as the weather changes.\" Pressing times to the desired density could vary by a factor of three depending on the atmospheric humidity.[142]  The United Nations Model Regulations on the Transportation of Dangerous Goods and national transportation authorities, such as United States Department of Transportation, have classified gunpowder (black powder) as a Group A: Primary explosive substance for shipment because it ignites so easily. Complete manufactured devices containing black powder are usually classified as Group D: Secondary detonating substance, or black powder, or article containing secondary detonating substance, such as firework, class D model rocket engine, etc., for shipment because they are harder to ignite than loose powder. As explosives, they all fall into the category of Class 1.  Besides its use as a propellant in firearms and artillery, black powder's other main use has been as a blasting powder in quarrying, mining, and road construction (including railroad construction). During the 19th century, outside of war emergencies such as the Crimean War or the American Civil War, more black powder was used in these industrial uses than in firearms and artillery. Dynamite gradually replaced it for those uses. Today, industrial explosives for such uses are still a huge market, but most of the market is in newer explosives rather than black powder.  Beginning in the 1930s, gunpowder or smokeless powder was used in rivet guns, stun guns for animals, cable splicers and other industrial construction tools.[143] The \"stud gun\", a powder-actuated tool, drove nails or screws into solid concrete, a function not possible with hydraulic tools, and today is still an important part of various industries, but the cartridges usually use smokeless powders. Industrial shotguns have been used to eliminate persistent material rings in operating rotary kilns (such as those for cement, lime, phosphate, etc.) and clinker in operating furnaces, and commercial tools make the method more reliable.[144]  Gunpowder has occasionally been employed for other purposes besides weapons, mining, fireworks and construction:       "},{"title":"United States Soccer Federation","content":"  The United States Soccer Federation (USSF), commonly referred to as U.S. Soccer, is a 501(c)(3) nonprofit organization and the official governing body of the sport of soccer in the United States. Headquartered in Chicago, the federation is a full member of FIFA and governs American soccer at the international, professional, and amateur levels, including: the men's and women's national teams, Major League Soccer, National Women's Soccer League, youth organizations, beach soccer, futsal, Paralympic, and deaf national teams. U.S. Soccer sanctions referees and soccer tournaments for most soccer leagues in the United States. The U.S. Soccer Federation also administers and operates the U.S. Open Cup and the SheBelieves Cup.  U.S. Soccer was originally known as the United States Football Association. It formed on April 5, 1913, at the Astor House Hotel in Lower Manhattan,[3] and on August 15 of that year was accepted as one of the earliest member organizations of FIFA and the first from North and Central America. The affiliation was originally provisional[4] but during FIFA Congress in Oslo, Norway on June 24, 1914, the USFA, as it was abbreviated at the time, was accepted as a full FIFA member.[5] The governing body of the sport in the United States added the word soccer to its name in 1945, when it became the United States Soccer Football Association; by this point, football as a standalone word had come to define a totally different sport in the U.S. It dropped the word football from its name in 1974 to become known as the United States Soccer Federation.[6]  U.S. Soccer has hosted several global soccer tournaments, including the 1994 FIFA World Cup, the 1999 and 2003 FIFA Women's World Cup, and the Summer Olympic football tournaments in 1984 and 1996.  Originally based in Colorado Springs, Colorado, U.S. Soccer headquarters were moved to Chicago in 1991 under the leadership of former Secretary General, Hank Steinbrecher[7][8] Called U.S. Soccer House, it is currently located in two refurbished mansions at 1801 South Prairie Avenue in Chicago.[9]  In 2003, U.S. Soccer opened their National Training Center at Dignity Health Sports Park (then named Home Depot Center) in Carson, California. The $130\u00a0million facility includes a soccer-specific stadium, home to the MLS team Los Angeles Galaxy. Additionally, four grass soccer fields, a FieldTurf soccer field and a general training area are specifically dedicated to U.S. Soccer. Both the senior and youth men's and women's U.S. national teams hold regular camps at Dignity Health Sports Park.[10]  U.S. Soccer was also exploring a possibility of building the National Training and Coaching Development Center in Kansas City, Kansas.[11] On April 9, 2015, the Development Center received final approval from the local governments. U.S. Soccer agreed to a 20-year lease, with the project set to break ground in 2016 and finishing some time in 2017.[12][13]  In September 2023, U.S. Soccer announced they were moving from Chicago to a new headquarters and training center near Atlanta, which will be partially funded by Arthur Blank, cofounder of The Home Depot and owner of the NFL\u2019s Atlanta Falcons and the MLS\u2019s Atlanta United.[14] In December 2023, U.S. Soccer announced they had chosen a site for the new national training center in Fayette County, Georgia. The 200-acre (81\u00a0ha) site is scheduled to be developed and opened prior to the 2026 FIFA World Cup; it is near the headquarters of Coca-Cola, one of the founding partners for the training center.[15]  U.S. Soccer is governed by a board of directors that administers the affairs of U.S. Soccer.[16] Cindy Parlow Cone, former 1999 FIFA Women's World Cup champion and long-time U.S. Soccer administrator, became president in March 2020 following the resignation of Carlos Cordeiro.[17] JT Batson was named chief executive officer and secretary general in September 2022.[18]  U.S. Soccer members are individuals and affiliate organizations. The national council is the representative membership body of the federation. It elects the president and vice president, amends the bylaws, approves the budgets, decides on policies adopted by the board, and affirms actions of the Board.[citation needed] The non-profit organization is a member of the worldwide soccer body FIFA and the North American soccer body CONCACAF, and also has a relationship with the U.S. Olympic Committee and the International Olympic Committee.[19]  The federation convenes an annual meeting, usually held in February. Every four years, the annual meeting's attendees hold an election for the federation's president and vice president.[20]  USSF recognizes the following members:[21]  The United States men's national team was assembled in 1885 to play Canada in the first international match held outside the United Kingdom.[22] The team was invited to the inaugural FIFA World Cup in 1930 and qualified for the World Cup in 1934, finishing third place (semifinals) in 1930 out of 13 teams participating. In 1950 the United States scored one of its most surprising victories with a 1\u20130 win over heavily favored England, who were amongst the world's best sides at the time. The United States did not reach another World Cup until an upstart team qualified for the 1990 World Cup with the \"goal heard around the world\" scored by Paul Caligiuri against Trinidad and Tobago, which started the modern era of soccer in the United States.  The United States hosted the 1994 FIFA World Cup, setting total and average attendance records that still stand, including drawing 94,194 fans to the final.[23] The United States made a surprising run to the second round in 1994, but finished last among the 32 teams in the 1998 World Cup. The tournament was marred by poor team chemistry and leadership, which led head coach Steve Sampson to resign.[24] Sampson was replaced by Bruce Arena, a two-time MLS Cup winner with D.C. United, in 1998.[25] Arena led a mix of veterans and youth players to a quarterfinal appearance in the 2002 World Cup, defeating rivals Mexico in the Round of 16 before losing to eventual runners-up Germany.[26][27]  At the 2006 edition of the tournament, the U.S. failed to qualify for a knockout round with two losses and a draw in the group stage.[28] Arena's contract was not renewed following the tournament; former assistant Bob Bradley was hired as head coach in 2007.[29] The U.S. qualified for the 2010 FIFA World Cup in South Africa by winning the CONCACAF qualifying tournament.[30] At the World Cup, the Americans were undefeated in the group stage but were eliminated in the round of 16 by a loss to Ghana. Bradley was dismissed following the 2011 Gold Cup, which the United States lost 4\u20132 to Mexico in the final.[31]  The U.S. entered the 2014 FIFA World Cup under J\u00fcrgen Klinsmann, who had led Germany to third place in the 2006 World Cup and had lived in the United States for several years. Klinsmann recruited dual national players, particularly Germans with American heritage, and favored youth in his rosters; this included his exclusion of Landon Donovan from the World Cup roster.[32] The U.S. finished second in the \"Group of Death\" (eventual champion Germany, Ghana, and Portugal) and advanced to the round of 16, where they lost to Belgium in extra time after goalkeeper Tim Howard's 16 saves set a World Cup record.[32][33] Klinsmann was retained as head coach for the 2018 World Cup qualifying cycle, but was fired in November 2016 after the team had lost the opening two matches of the final qualifying round.[34] Bruce Arena was hired to replace Klinsmann, but the United States finished fifth and were unable to qualify for the 2018 FIFA World Cup. It was the first time the U.S. had failed to qualify for the World Cup since 1986.[35]  Arena resigned following the qualification campaign and was replaced by Dave Sarachan, who was interim coach during the search for a permanent head coach. Sarachan's year-long tenure included the introduction of several young players to replace veterans who had resigned following the 2018 qualification cycle.[36] Columbus Crew coach Gregg Berhalter was selected and hired as head coach in December 2018; his rosters rely mostly on younger players who had played in MLS academies or were developed by teams in Europe. During qualification for the 2022 FIFA World Cup, the United States had rosters with an average age of under 24 years old; the team finished 7\u20133\u20134 during the final round and qualified for the World Cup.[37] Berhalter used the second-youngest roster at the World Cup with only DeAndre Yedlin retained from a previous World Cup team. The United States finished second in their group with a win against Iran and ties with England and Wales. The team were eliminated in the round of 16 by the Netherlands.[38]  Berhalter's contract was renewed in June 2023 following an investigation by U.S. Soccer into allegations of domestic abuse from a 1991 incident. During his absence from the team, two assistant coaches served as interim coaches.[39][40] B.J. Callaghan, the second interim coach, led the United States to a second CONCACAF Nations League title but failed to reach the final of the 2023 CONCACAF Gold Cup.[41][42]  The United States will co-host the 2026 FIFA World Cup alongside Canada and Mexico after their joint bid was selected over Morocco by FIFA in 2018. The tournament will be the first World Cup to feature 48 teams.[43] The United States will also host the 2024 Copa Am\u00e9rica, the championship of South American teams; it will be the second Copa Am\u00e9rica to be played in the United States following the Copa Am\u00e9rica Centenario in 2016.[44] The United States did not automatically qualify as hosts,[45] but earned a spot through their performance in the 2023\u201324 CONCACAF Nations League.[44]  Having won four FIFA Women's World Cup tournaments\u20141991, 1999, 2015, and 2019\u2014the United States is considered the most successful in international women's soccer. The team finished second in 2011 and third in 1995, 2003, and 2007. It has won Olympic gold medals at the 1996, 2004, 2008, and 2012 Summer Olympics.[46] In addition, it has won ten titles at the Algarve Cup and nine at the CONCACAF Women's Championship, the qualifying tournament for the FIFA Women's World Cup.[47][48][49]  The inaugural FIFA Women's World Cup was held in 1991 in China. The U.S. women's national team was the first team to win the prize after beating Norway in the final.[50]  In 1999, the United States hosted the FIFA Women's World Cup for the first time. During their tournament run, the women's national team established a new level of popularity for the women's game, culminating in a final against China that drew 90,185 fans, an all-time attendance record for a women's sports event, to a sold-out Rose Bowl. After neither team scored in regulation or extra time, the final went to a penalty shootout, which the United States won 5\u20134. The celebration by Brandi Chastain after she converted the winning penalty, in which she took off her shirt, is one of the more famous images in U.S. women's sports.  U.S. Soccer Federation oversees and promotes the development of 14 youth national teams:[51]  U.S. Soccer Federation had ceased operations on its youth national team programming with the exception of the U-23, U-20, and U-17 teams on the men's side and the U-20 and U-17 teams on the women's side due to the COVID-19 pandemic in April 2020.[52][53]  As of March 2023, U.S. Soccer Federation supervises nine extended national teams across the disciplines of beach soccer, CP soccer, deaf soccer, futsal, and power soccer.[54]  Men's coaches    Women's coaches    Extended teams' coaches    Technical staff    Referee programs staff  Referee development staff  Despite the growth of men's and women's professional soccer in the United States in the last few decades, by far the largest category of soccer in the United States, at least in terms of participation, is youth soccer.[citation needed] Though organized locally by organizations all over the United States, there are two main youth soccer organizations working nationwide through affiliated local associations. The United States Youth Soccer Association boasts over three million players between the ages of five and 19, while American Youth Soccer Organization has more than 300,000 players between the ages of four and 19. This makes soccer one of the most played sports by children in the United States.[79]  The professional first-division league in North America is Major League Soccer, which as of the 2023 season has 26 teams in the U.S. and 3 in Canada. The league began an aggressive expansion in 2017, with the goal of adding at least eight clubs. That effort has resulted in the addition of the following nine clubs: Atlanta United FC (2017), Minnesota United FC (2017), Los Angeles FC (2018), FC Cincinnati (2019), Inter Miami CF (2020), Nashville SC (2020), Austin FC (2021), Charlotte FC (2022), and St. Louis City SC (2023). The league operates as a single-entity league, which means MLS, and not the individual teams, holds the contracts on players.[80]  The one sanctioned second-division men's outdoor soccer league is the USL Championship (USLC). Previously, the second North American Soccer League had second-division status, sharing it with the USL in the 2017 season, but the NASL was denied second-division sanctioning for 2018 due to considerable instability in the league;[81] the league effectively folded at that time.  The USLC was sanctioned as the United States' lone Division II men's outdoor soccer league in 2018. Formed in 2010 as a result of the merger of the former USL First Division and USL Second Division, the USL Championship was sanctioned as Division III league from 2011 to 2016 before becoming provisionally sanctioned as a Division II league for 2017,[82] and receiving full Division II sanctioning in 2018.[83]  The USL Championship has expanded almost three-fold since its first season in 2011 to include 35 teams in the 2020 season, with the league divided into two conferences, Eastern and Western. The USLC is the world's largest Division II professional league by number of teams. Since 2014, valuation of USL Championship clubs have increased five-fold. In revenue, 2018 Championship clubs saw a 28% increase over 2017 numbers on an average of ticketing, sponsorship, merchandise, and ancillary revenue generation.[citation needed]  The USLC also holds a broadcast agreement with ESPN that sees 20 regular season games televised nationally on ESPN2, ESPNews and ESPN Deportes[84] in addition to national broadcast of the USL Championship Final, which in 2019 was aired on both ESPN2 and ESPN Deportes. The league's remaining regular season games are broadcast nationally on ESPN+, with 22 of the Championship's clubs also holding local broadcast agreements. The USL Championship's broadcast agreement was made possible in large part by a major investment by USL with league technology partner Vista Worldlink[85] to establish a USL Broadcast Center out of Fort Lauderdale, Fla.[86]  The second NASL had no official tie to the former NASL that operated from 1968 to 1984, although some of the teams shared names with their historic counterparts. Unlike MLS that is a single-entity operation, the second NASL, like the old NASL, had no salary cap and players were contracted by the individual teams.[87] The season was a split format (similar to that of many leagues in Latin America) that features seven teams, including one Puerto Rican team. Previous to the reorganization of the NASL in 2009, the USL First Division operated as the professional second-division league in the United States. However, a dispute among its teams and ownership led to the creation of the NASL which applied for and was awarded by USSF second division status. The 2010 season was played as a combined USL\/NASL league format before NASL officially separated in 2011.[88]  USL League One is sanctioned at the Men's Division III level. In March 2017, United Soccer League, administrator of the USL Championship and USL League Two, announced following the successful sanctioning of the USL Championship as a Division II league it would start a new tier in its professional structure, which became USL League One, and seek Division III certification for the 2019 season.[89] The league received sanctioning in December 2018 and conducted a successful first season in 2019 that saw 10 teams compete in a single-table format and North Texas SC claim its inaugural league title. The seven independent clubs averaged 2,496 fans per match in 2019, placing League One in the top three of Division III leagues globally, and the league has expanded to include 12 teams for its second season in 2020, with further expansion expected prior to the 2021 season.  National Independent Soccer Association (NISA) led by former Chicago Fire general manager Peter Wilt plans on fielding 8\u201310 teams in 2018 and has stated that it will seek third-division certification.[90]  A fourth-division league in the United States is the USL League Two, which as of 2015 is expected to have 58 U.S. teams, and six Canadian teams. Though League Two does have some paid players, it also has many teams that are made up entirely or almost entirely of college soccer players who use the league as an opportunity to play competitive soccer in front of professional scouts during the summer, while retaining amateur status and NCAA eligibility. Other fourth-division leagues in the United States are the United Premier Soccer League, National Premier Soccer League and Ligas Unidas.[citation needed]  In addition to MLS and the USL, the United States Adult Soccer Association governs amateur soccer competition for adults throughout the United States, which is effectively the amateur fifth-division of soccer in the United States. The USASA sanctions regional tournaments that allow entry into the U.S. Open Cup, the oldest continuous national soccer competition in the United States. Since 1914, the competition has been open to all U.S. Soccer affiliated clubs, and currently pits teams from all five levels of the American soccer pyramid against each other each year, similarly to England's FA Cup.[91]  The National Women's Soccer League (NWSL) is the professional, top-division league in North America and as of 2020, is composed of nine teams based in the U.S.[92] The league has announced expansion plans for Racing Louisville FC in 2021[93] and Los Angeles' Angel City FC in 2022.[94] Two professional, top-division leagues preceded the NWSL: the Women's United Soccer Association (WUSA), which featured many players from the 1999 FIFA Women's Cup-winning team (as well as other national teams), ran from 2001 to 2003 and Women's Professional Soccer (WPS) ran from 2009 to 2011.[95]  Two second-division leagues currently exist: United Women's Soccer began play in May 2016 and as of 2020 features 30 teams in five conferences[96] and the Women's Premier Soccer League (WPSL), started in 1997, features over 115 teams across the United States and Canada (the largest women's soccer league in the world as of 2020).[97] Previously, the USL W-League was a semi-professional league that ran from 1995 to 2015 and featured a mix of college students and international players.[98]  On November 21, 2012, U.S. Soccer, in conjunction with the Canadian Soccer Association (CSA) and Mexican Football Federation (FMF), announced the formation of a new professional league for the 2013 season.[99] The league, unnamed at the time of the initial announcement but later unveiled as the National Women's Soccer League (NWSL), launched in April 2013 with eight teams.[99] Like WUSA and WPS, NWSL teams are privately owned with some owned by existing MLS teams.[100] The American and Canadian federations pay the salaries for many of their respective national team members. U.S. Soccer initially committed to funding up to 24 national team members, with the CSA committing to paying 16 players and FMF pledging support for at least 12 and possibly as many as 16.[100][101] In addition, U.S. Soccer housed the league's front office for the first four years, and scheduled matches to avoid any possible conflict with international tournaments.[100] Four of the league's charter teams had WPS ties\u2014the Boston Breakers, Chicago Red Stars, Sky Blue FC, and the Western New York Flash. The other four initial teams were located in the Kansas City, Portland, Seattle, and Washington, D.C. markets with the Portland team run by the Portland Timbers of MLS.[100] The NWSL expanded to nine teams for 2014 by adding the Houston Dash, run by the Houston Dynamo of MLS. In 2016, it expanded to 10 with the addition of another MLS-backed team, the Orlando Pride. Ahead of the 2017 season, A&E Networks announced it had taken an equity stake in the league and Lifetime would begin broadcasting games to a national television audience.[102] As of 2017[update], additional expansion teams were being discussed by Los Angeles FC, Vancouver Whitecaps FC, and FC Barcelona,[103][104][105] but none of these have yet materialized.  Several league changes occurred in advance of the 2017 season. First, FMF and U.S. Soccer amicably ended their partnership following FMF's establishment of its own women's professional league, Liga MX Femenil. The Western New York Flash ceased fully professional operations (though retaining its youth and, for a time, semi-pro operations), selling its NWSL franchise rights to Steve Malik, owner of then-NASL and current USLC side North Carolina FC. Malik relocated the NWSL team to NCFC's home of the Research Triangle and rebranded it as the North Carolina Courage. Both the Boston Breakers and FC Kansas City folded, with FCKC's player contracts transferred to Utah Royals FC, a new side owned and operated by Real Salt Lake.  The Seattle franchise went through two major changes in subsequent years. First, the team moved from Seattle to Tacoma and rebranded as Reign FC before the 2019 season. Then, in January 2020, the team was purchased by the parent company of French Ligue 1 power Olympique Lyonnais and rebranded again as OL Reign.  The league's next expansion was announced in November 2019, with a Louisville franchise granted to the ownership group of USLC side Louisville City FC, The Louisville side, which began play as Racing Louisville FC in 2021, is the first NWSL team whose entry into the league was announced more than 5 months before it started play.  The second professional league, Women's Professional Soccer (WPS), was founded in 2009. The inaugural season champion was Sky Blue FC, based in the New York\u2013New Jersey area. The team defeated the Los Angeles Sol 1\u20130 at The Home Depot Center in Carson, California. The WPS launched with seven teams, all based in the United States. The Sol folded after the league's inaugural season, and two new teams joined for 2010, bringing WPS to eight teams. However, the 2010 season saw considerable instability, with another charter team, Saint Louis Athletica, folding during the season, champions FC Gold Pride folding after the season, and the Chicago Red Stars deciding to regroup in the second-tier Women's Premier Soccer League (WPSL). The 2011 season, in which six teams based along the East Coast played, was marked by low attendance for most of the season and conflict with Dan Borislow, who had purchased the former Washington Freedom, moved the team to South Florida, and renamed it magicJack. The dispute between WPS and Borislow led the league to suspend the magicJack franchise, with Borislow responding by suing. The legal battle led WPS to suspend its 2012 season, with hopes of returning in 2013, but WPS soon decided to fold completely.  The Women's United Soccer Association (WUSA) was founded in 2001.  Headlined by the stars of the 1999 FIFA Women's World Cup-winning team, $30\u00a0million was initially invested by numerous cable TV networks and owners.[106] The league's inaugural match was held between the Washington Freedom featuring Mia Hamm and the Bay Area CyberRays (featuring Brandi Chastain) at RFK Stadium in Washington, D.C. In addition to the 34,148 fans in attendance being greater than any MLS game that weekend, the Turner Network Television (TNT) broadcast reached 393,087 households: more than two MLS games broadcast on ESPN and ESPN2.[107] The league folded in 2003.  United Women's Soccer (UWS) began play in May 2016 and as of 2020 features 30 teams in five conferences across the United States.[96]  Women's Premier Soccer League (WPSL), started in 1997, features over 115 teams across the United States and Canada (the largest women's soccer league in the world as of 2020).[97]  The USL W-League was a semi-professional league that ran from 1995 to 2015 and featured a mix of college students and international players.[98] A second pre-professional league named the USL W League began play in May 2022 with 44 teams organized into seven regional divisions.[108]  USL also plans to launch a professional league, the USL Super League, in 2024 with an application for first-division sanctioning.[109]  In 2014, parents and former players filed a class action lawsuit against the United States Soccer Federation, FIFA, and other soccer organizations for failure to create policies that would prevent, evaluate and manage concussion injuries.[110] Soccer is second only to American football in the number of concussion injuries per year.[111]  The USSF has been accused by representatives of the North American Soccer League, among others, of unfairly protecting MLS's leading role in American professional soccer. Among their concerns is that the USSF benefits from financial dealings with MLS that it does not have with other leagues, giving it an apparent incentive to protect MLS from competition.[112] This includes the contract that the USSF has with MLS's Soccer United Marketing (SUM) subsidiary in which most USSF sponsorship, television licensing and royalty revenues (outside of its apparel deal with Nike, Inc.) are paid through SUM. The USSF reported $15,433,754 in revenues through the SUM relationship in its 2014 audited financial report.[113]  In 2015, the NASL took issue with proposed USSF rule changes reportedly making it harder to gain co-equal \"Division 1\" status with MLS that would increase the NASL's influence within the USSF as well as presumably allow more access to international competition and larger media and sponsorship contracts, calling the draft proposal \"...an anti-competitive bait and switch, with the purpose of entrenching MLS's monopoly position at the very time when the NASL is threatening to become a significant competitor.\"[114] Seats on the USSF's Professional Council governing committee are also based proportionally on pyramid level, giving MLS more votes when choosing the two professional league representatives on the USSF's board of directors. In 2015, those representatives are MLS Commissioner Don Garber and Alec Papadakis, CEO of the United Soccer League that announced an affiliation with MLS in 2015.  High-profile international soccer figures including former USMNT Head Coach J\u00fcrgen Klinsmann,[115] former LA Galaxy head coach and USMNT Head Coach Bruce Arena[116] and Manchester City coach and former FIFA World Coach of the Year Pep Guardiola,[117] have expressed beliefs that the top-down structure of soccer developed and managed by the USSF in the United States, including pressure to have the best American players in MLS rather than higher-quality leagues in other countries, is hampering the nation's competitiveness in international soccer.  Conversely, Klinsmann has been criticized in turn by MLS representatives for recommending that American players leave MLS development systems to pursue professional careers in Europe in order to test themselves against higher levels of players in preparation for international competition. In 2015, MLS Commissioner Don Garber said, \"I do believe our national team coach has a short-term objective. That's what he's hired to do. That doesn't mean next week, but it's to win the Gold Cup, it's to have the best possible team in 2018. And our goals and objectives are broader than that, and that's why we agree on some things but don't agree on others.\"[118]  On March 8, 2019, all members of the U.S. women's national team collectively filed a gender discrimination lawsuit against the U.S. Soccer Federation in a district court in Los Angeles. The lawsuit was filed due to claims that the athletes were being treated differently on the basis of gender, affecting their paychecks, the facilities they were offered, and even the medical treatment they received.[119] Women on the team have previously filed complaints about pay disparity, including in 2016 when five members of the women's team filed a complaint with the Equal Employment Opportunity Commission.[120][121]  On May 1, 2020, the district court dismissed the team's unequal and discriminatory pay claim, however preserving the players' claims about unequal treatment in areas like travel, hotel accommodations and team staffing. A trial on those issues is scheduled to begin June 16.[122]  Judge R. Gary Klausner of the United States District Court for the Central District of California, granted the federation's motion for summary judgment. In his ruling, he dismissed the players' arguments that they were systematically underpaid by U.S. Soccer in comparison with the men's national team. According to Klausner, U.S. Soccer had substantiated its argument that the women's team had actually earned more \"on both a cumulative and an average per-game basis\" than the men's team during the years at issue in the lawsuit.[123]  On February 22, 2022, the U.S. Soccer Federation agreed settle the lawsuit for $24 million, with a proposed $22 million going the players in the case and an additional $2 million to benefit USWNT players post-career goals and also charitable efforts related to women's soccer. The settlement also requires both male and female soccer players to paid equally for friendlies, and tournaments including the World Cup.[124][125]   In July 2023, 103 current and former U.S. Soccer senior men's and women's teams and youth squad players wrote in a letter to members of the U.S. Senate and House of Representatives that \"SafeSport is failing in what it was meant to achieve.\"[126][127] For one thing, they wrote that SafeSport's use of administrative closures and exclusive jurisdiction was leaving athletes vulnerable to abuse or revictimizing them.[127] They opined that: \"SafeSport should be expected to properly investigate claims and be held accountable for taking action based on those investigations.\"[127] They also took to task SafeSport's appeals process, which uses \"merits arbitration\" instead of a simple re-examination of the case for errors.[127][128] They wrote:  The arbitration process can be damaging and retraumatizing for victims of abuse who have already participated in the process and shared their stories in full, only to have to do it all over again. If the victim decides not to go through the whole process again on appeal, the decision is automatically overturned, and the perpetrator is free to enter back into the sport. The appeals process harms victims in other ways, including by affording alleged perpetrators rights that victims do not have. Victims cannot appeal a decision that finds their alleged abuser was not culpable. And SafeSport does not turn over records to the victim so that they can be sure that justice was done.[127] On July 17, 2012, in the wake of announced anti-corruption reforms by Sepp Blatter, the president of the world soccer governing body FIFA,[129] the organization appointed U.S. lawyer Michael J. Garcia as the chairman of the investigative chamber of FIFA Ethics Committee, while German judge Hans-Joachim Eckert was appointed as the chairman of the Ethics Committee's adjudication chamber.[130]  In August 2012, Garcia declared his intention to investigate the bidding process and decision to respectively award the right to host the 2018 and 2022 FIFA World Cup to Russia and Qatar by the FIFA Executive Committee.[131] Garcia delivered his subsequent 350-page report in September 2014, and Eckert then announced that it would not be made public for legal reasons.[132]  On November 13, 2014, Eckert released a 42-page summary of his findings after reviewing Garcia's report. The summary cleared both Russia and Qatar of any wrongdoing during the bidding for the 2018 and 2022 World Cups,[133] leaving Russia and Qatar free to stage their respective World Cups.[134]  FIFA welcomed \"the fact that a degree of closure has been reached,\" while the Associated Press wrote that the Eckert summary \"was denounced by critics as a whitewash.\"[134] Hours after the Eckert summary was released, Garcia himself criticized it for being \"materially incomplete\" with \"erroneous representations of the facts and conclusions,\" while declaring his intention to appeal to FIFA's Appeal Committee.[133] On December 16, 2014, FIFA's Appeal Committee dismissed Garcia's appeal against the Eckert summary as \"not admissible.\" FIFA also stated that Eckert's summary was \"neither legally binding nor appealable.\"[135] A day later, Garcia resigned from his role as FIFA ethics investigator in protest of FIFA's conduct, citing a \"lack of leadership\" and lost confidence in the independence of Eckert from FIFA.[136]  In June 2015, Swiss authorities claimed the report was of \"little value\".[137]  On October 3, 2022, the U.S. Soccer Federation publicly released the 173-page Yates Report, officially titled Report of the Independent Investigation to the U.S. Soccer Federation Concerning Allegations of Abusive Behavior and Sexual Misconduct in Women's Professional Soccer, the official report documenting the findings and conclusions concerning abusive behavior and sexual misconduct in women's professional soccer. The report is named for Sally Yates, the lawyer who led the investigation, a former Acting United States Attorney General.[138]  As of March\u00a08, 2024[update][139]  Chris Ahrens (paralympian national team player) Nelson Akwari (former MLS and USL player)[142] Sean Boyle (paralympian national team player) Lori Lindsey (former national team, WPS, and NWSL player; current NWSL, MLS, USL broadcast analyst)[143] Danielle Slaton (former national team, WPS, and NWSL player) Whitney Engen (former national team and NWSL player) Cassidy Leake  Jessica Berman (NWSL Commissioner) Don Garber (MLS Commissioner and CEO of Soccer United Marketing)[144] Amanda Vandervort (President of USL Super League)[145]  Fritz Marth(Vice President of United States Adult Soccer Association) John Motta(President of the United States Adult Soccer Association)  Mike Cullina(CEO\/Executive Director of US Club Soccer) Michael Karon(National President of American Youth Soccer Organization) Todd Lockhart Pete Zopfi (trauma surgeon and chair of the board United States Youth Soccer Association)[146]  Lisa Carnoy (banking executive)[147] Patti Hart (former gaming executive and Yahoo board member) Juan Uro (former NBA executive)[148]  United States Soccer Football Association (until 1974)  United States Soccer Federation (1974\u2013present)  41\u00b051\u203228\u2033N 87\u00b037\u203214\u2033W\ufeff \/ \ufeff41.8578\u00b0N 87.6205\u00b0W\ufeff \/ 41.8578; -87.6205 "},{"title":"National Collegiate Athletic Association","content":"  The National Collegiate Athletic Association (NCAA)[b] is a nonprofit organization that regulates student athletics among about 1,100 schools in the United States, and one in Canada.[3] It also organizes the athletic programs of colleges and helps over 500,000 college student athletes who compete annually in college sports.[3] The organization is headquartered in Indianapolis, Indiana.  Until 1957, the NCAA was a single division for all schools. That year, the NCAA split into the University Division and the College Division.[4] In August 1973, the current three-division system of Division I, Division II, and Division III was adopted by the NCAA membership in a special convention. Under NCAA rules, Division I and Division II schools can offer scholarships to athletes for playing a sport. Division III schools may not offer any athletic scholarships. Generally, larger schools compete in Division I and smaller schools in II and III. Division I football was further divided into I-A and I-AA in 1978, while Division I programs that did not have football teams were known as I-AAA. In 2006, Divisions I-A and I-AA were respectively renamed the Football Bowl Subdivision (FBS) and Football Championship Subdivision (FCS). In its 2022\u201323 fiscal year, the NCAA generated $1.28\u00a0billion in revenue, $945\u00a0million (74%) of which came from airing rights to the Division I men's basketball tournament.[5]  Controversially, the NCAA substantially restricts the kinds of benefits and compensation (including paid salary) that collegiate athletes could receive from their schools. The consensus among economists is these caps for men's basketball and football players benefit the athletes' schools (through rent-seeking) at the expense of the athletes.[6][7][8] Economists have subsequently characterized the NCAA as a cartel.[9][10][11] In 2021, the Supreme Court of the United States unanimously ruled that some of these NCAA restrictions on student athletes are in violation of US antitrust law.[12]  Intercollegiate sports began in the United States in 1852 when crews from Harvard and Yale universities met in a challenge race in the sport of rowing.[13] As rowing remained the preeminent sport in the country into the late-1800s, many of the initial debates about collegiate athletic eligibility and purpose were settled through organizations like the Rowing Association of American Colleges and the Intercollegiate Rowing Association. As other sports emerged, notably football and basketball, many of these same concepts and standards were adopted. Football, in particular, began to emerge as a marquee sport, but the rules of the game itself were in constant flux and often had to be adapted for each contest.  The NCAA dates its formation to two White House conferences convened by President Theodore Roosevelt in the early 20th century in response to repeated injuries and deaths in college football which had \"prompted many college and universities to discontinue the sport.\"[1] Following those White House meetings and the reforms which had resulted, Chancellor Henry MacCracken of New York University organized a meeting of 13 colleges and universities to initiate changes in football playing rules; at a follow-on meeting on December 28, 1905, in New York, 62 higher-education institutions became charter members of the Intercollegiate Athletic Association of the United States (IAAUS).[1] The IAAUS was officially established on March 31, 1906, and took its present name, the NCAA, in 1910.[1]  For several years, the NCAA was a discussion group and rules-making body, but in 1921, the first NCAA national championship was conducted: the National Collegiate Track and Field Championships. Gradually, more rules committees were formed and more championships were created, including a basketball championship in 1939.[14]  A series of crises brought the NCAA to a crossroads after World War II. The \"Sanity Code\" \u2013 adopted to establish guidelines for recruiting and financial aid \u2013 failed to curb abuses, and the Association needed to find more effective ways to curtail its membership.[15] Postseason football games were multiplying with little control, and member schools were increasingly concerned about how the new medium of television would affect football attendance.[14]  The NCAA engaged in a bitter power struggle with the Amateur Athletic Union (AAU).[16][17] The complexity of those problems and the growth in membership and championships demonstrated the need for full-time professional leadership.  Walter Byers, previously an assistant sports information director, was named executive director in 1951.[14] The Harvard Crimson described Byers as \"power-mad,\" The New York Times said that Byers was \"secretive, despotic, stubborn and ruthless,\" The Washington Post described him as a dictator, and others described him as a \"petty tyrant.\"[16][18][19][20]\u201d[21][22][verification needed][23]  Byers wasted no time placing his stamp on the Association, and a national headquarters was established in Kansas City, Missouri, in 1952.[14] A program to control live television of football games was approved, the annual Convention delegated enforcement powers to the Association's Council, and legislation was adopted governing postseason bowl games.[14]  As college athletics grew, the scope of the nation's athletics programs diverged, forcing the NCAA to create a structure that recognized varying levels of emphasis. In 1973, the association's membership was divided into three legislative and competitive divisions \u2013 I, II, and III.[24] Five years later in 1978, Division I members voted to create subdivisions I-A and I-AA (renamed the Football Bowl Subdivision and the Football Championship Subdivision in 2006) in football.[14]  Until the 1980s, the association did not govern women's athletics. Instead, the Association for Intercollegiate Athletics for Women (AIAW), with nearly 1,000 member schools, governed women's collegiate sports in the United States. The AIAW was in a vulnerable position that precipitated conflicts with the NCAA in the early-1980s. Following a one-year overlap in which both organizations staged women's championships, the AIAW discontinued operation, and most member schools continued their women's athletics programs under the governance of the NCAA.[25] By 1982 all divisions of the NCAA offered national championship events for women's athletics. A year later in 1983, the 75th Convention approved an expansion to plan women's athletic program services and pushed for a women's championship program.[14]  Proposals at every NCAA Convention are voted on by the institutional members of the NCAA. Each institutional member has one representative: the president\/CEO or a representative designated by him\/her.[26] Attendance by the actual president\/CEO was low; less than 30%.[26] Southern Methodist University President A. Kenneth Pye commented, \"In too many cases, presidents have not only delegated responsibility, they have abdicated it.\"[26] Many presidents designated their athletic director as the institutional representative, something Pye compared to \"entrusting a chicken coop to the supervision of a wolf and a fox.\"[26] Beginning around 1980, a group of college presidents thought there was a crisis of integrity in collegiate sports and discussed ways to  transform athletics to match the academic model. The American Council on Education (ACE) proposed a presidential board empowered to veto NCAA membership actions, while the NCAA Council, whose membership was mostly athletic officials, suggested a presidential commission with advisory powers. The Council's proposal may have been intended to block the presidential effort to gain control of the NCAA. The two proposals were voted on by the membership at the NCAA Convention in January 1984. The ACE proposal was defeated by a vote of 313 to 328. The Council proposal passed on a voice vote without ballots.[26] Publicly, the Presidents' Commission (PC) was responsible for establishing an agenda for the NCAA, but the actual language of the proposal stated that their role was to be a presidential forum and to provide the NCAA with the president's position on major policy issues. The PC could study issues and urge action, call special meetings and sponsor legislation. Their one real power was to veto the selection of Executive Director.[26][27] The composition of the commission was 22 CEOs from Division I and 11 CEOs each from Divisions II and III.[28]  The true intent of the PC was to shift control of intercollegiate athletics back to CEOs. Graduation rates were an important metric to chancellors and presidents and became a focus of the PC.[29][30]  In June 1985 a special convention was held to review legislative proposals including academic integrity, academic-reporting requirements, differences in \"major\" and \"secondary\" violations including the \"death penalty\" and requiring an annual financial audit of athletic departments. All proposals passed overwhelmingly. Many presidents who did not attend sent a vice-president rather than their athletic director.[26] University of Florida President Marshall Criser stated that \"the ultimate responsibility must be assumed by the CEOs because we don't have enough NCAA cops to solve all of the problems.\"[26]  The regular NCAA meeting in January 1986 presented proposals in regard to college eligibility, drug testing, and basketball competition limits. All passed but matters regarding acceptable academic progress, special-admissions and booster club activities were ignored. Many presidents did not attend and it appeared that athletic directors controlled the meeting. A survey of 138 Division I presidents indicated that athletic directors did control collegiate sports. Despite a moratorium on extending the season of any sport in 1985, the extension of basketball and hockey seasons were approved. Indiana University president John W. Ryan, outgoing chairman of the PC commented, \"If the moratorium is vacated, it's being vacated not by the commission, but by this convention.\"[26] Following the vote, a delegate was quoted, \"A lot of Athletic Directors figure they've successfully waited out the presidents...unless the presidents fight back, NCAA reform is flat-ass dead in the water.\"[26]  The PC proposed just one legislative issue at the January 1987 meeting: applying the minimum academic standards in Division I to Division II. It narrowly passed.[26]  The PC attempted to again push the reform of college athletics by calling another special convention which was held in June 1987 to discuss cost-cutting measures and to address the overemphasis on athletics in colleges and universities. John Slaughter, Chancellor of the University of Maryland served as chairman. He stated, \"This represents the second major thrust since our commission was formed three years ago. The first involved academics and infractions. This will be equally momentous and more sweeping. We want to achieve a balance between athletics and other institutional programs.\"[28] Cost-cutting measures proposed included reductions in athletic financial aid, coaching staff sizes, and length of practice\/playing seasons. A resolution was also floated that opposed coaches receiving outside financial compensation if outside activities interfere with regular duties.[28] All the PC proposals were defeated, and two basketball scholarships were restored that were eliminated at the meeting in January. It was apparent that there was an open conflict between college presidents.[26] The president of the Carnegie Foundation for the Advancement of Teaching Ernest L. Boyer summarized the situation: \"There are presidents whose institutions are so deeply involved in athletics that their own institutional and personal futures hang in the balance. They feel they must resist such change because athletics are bigger than they are.\"[26]  The PC sponsored no legislation at the January 1988 annual meeting, and there was not a vote of confidence.[26]  However, a year later at the annual meeting, financial aid restrictions were proposed for specific Division I and II sports. Following extensive discussions, the measure was withdrawn and a Special Committee on Cost Reductions was formed to study the issue. Once again, a proposal from the PC was circumvented.[26]  The Presidents' Commission met in October 1989 to prepare for the 1990 NCAA annual meeting. Proposals were developed to shorten spring football and the basketball season; grant financial aid based on need to academically deficient athletes; and reporting of graduation rates. Chancellor Martin Massengale of the University of Nebraska was then chairman of the PC insisted that graduation rate data was needed to preclude \"further need for federal legislation\" that was being proposed by Representative Tom McMillen and Senator Bill Bradley.[26] The proposals demonstrated that the PC was intent on regaining control of college athletics and the opposition was immediate. Commissioner of the Big Ten Conference Jim Delany responded, \"They tend to want quick answers and you don't solve the complexities of intercollegiate athletics. Yes, presidents are involved, but the truth is, they really don't have time to be involved.\"[26] Bo Schembechler was blunt, \"Unfortunately, you're dealing with people who don't understand. We're trying to straddle the fence here because you still want me to put 100,000 (fans) in the stadium and the reason you want me to do it is because you're not going to help me financially at all.\"[26] In 1990, the University of Michigan head football coach and athletic director resigned his college job to become president of the Major League Baseball Detroit Tigers. Upon his departure, he predicted, \"In the next five years, school presidents will completely confuse intercollegiate athletics directors, then they'll dump it back to athletics directors and say, 'You straighten this out.' About 2000, it may be back on track.\"[26]  Presidential turnout for the January 1990 meeting was good and many who did not attend sent a delegate to vote for the PC. The graduation reporting proposal passed overwhelmingly, and the proposal for need-based non-athletic aid passed easily. The final proposal to shorten basketball and spring football generated fierce debate. There was a motion to defer the proposal for study that failed 383\u2013363, but the many PC members relaxed, confident of victory. PC Chairman Massengale left the meeting for other business, but during lunch, council members began lobbying and twisting arms to change votes. When the session resumed, council members began criticizing the PC and quickly executed a parliamentary maneuver to refer the proposal to the NCAA Council. Many PC members were still at lunch when a roll call vote passed 170\u2013150. University of Texas women's athletic director Donna Lopiano complained, \"The Presidents' Commission needs to do what it does best, and that is to macro-manage. Leave the micro-management to the various expert groups. We will bring back solutions.\"[26] Numerous presidents were shocked, upset and angry, but the remaining PC members began their own lobbying and arm-twisting. An hour later, there was a sense that representatives who had voted against the direction of their respective presidents had reconsidered, and a motion was made to reconsider by Lattie F. Coor, president of Arizona State University. West Point Lieutenant General Dave Richard Palmer urged the vote, stating the NCAA needed \"to make a mark on the wall...delay is the deadliest form of denial.\" [26] Following discussion, compromise and voting on minor issues, the reconsideration motion passed, and the third proposal was adopted with a vote of 165\u2013156.[26]  The Presidents Commission held hearings beginning on May 9, 1991, to develop stronger academic standards.[31]  The Presidents Commission lasted for 13 years and pushed through initiatives such as restricting the size of coaching staffs; limiting how much time student-athletes can spend on their sports; and setting more demanding academic standards for Divisions I and II.[32] By the 1980s, televised college football had become a larger source of income for the NCAA. In September 1981, the Board of Regents of the University of Oklahoma and the University of Georgia Athletic Association filed suit against the NCAA in district court in Oklahoma. The plaintiffs stated that the NCAA's football television plan constituted price fixing, output restraints, boycott, and monopolizing, all of which were illegal under the Sherman Act. The NCAA argued that its pro-competitive and non-commercial justifications for the plan \u2013 protection of live gate, maintenance of competitive balance among NCAA member institutions, and the creation of a more attractive \"product\" to compete with other forms of entertainment \u2013 combined to make the plan reasonable. In September 1982, the district court found in favor of the plaintiffs, ruling that the plan violated antitrust laws. It enjoined the association from enforcing the contract. The NCAA appealed all the way to the United States Supreme Court, but lost in 1984 in a 7\u20132 ruling NCAA v. Board of Regents of the University of Oklahoma.[33] (If the television contracts the NCAA had with ABC, CBS, and ESPN had remained in effect for the 1984 season, they would have generated some $73.6\u00a0million for the association and its members.)  In 1999, the NCAA was sued for discriminating against female athletes under Title IX for systematically giving men in graduate school more waivers than a woman to participate in college sports. In National Collegiate Athletic Association v. Smith, 525 U.S. 459 (1999) the U.S. Supreme Court ruled that the NCAA was not subject to that law, without reviewing the merits of the discrimination claim.[34]  Over the last two decades recruiting international athletes has become a growing trend among NCAA institutions. For example, most German athletes outside of Germany are based at US universities. For many European athletes, the American universities are the only option to pursue an academic and athletic career at the same time. Many of these students come to the US with high academic expectations and aspirations.[35]  In 2009, Simon Fraser University in Burnaby, British Columbia, Canada, became the NCAA's first non-US member institution, joining Division II.[36][37] In 2018, Division II membership approved allowing schools from Mexico to apply for membership; CETYS of Tijuana, Baja California expressed significant interest in joining at the time.[38][39]  In 2014, the NCAA set a record high of $989 million in net revenue. Just shy of $1 billion, it is among the highest of all large sports organizations.[citation needed]  During the NCAA's 2022 annual convention, the membership ratified a new version of the organization's constitution. The new constitution dramatically simplifies a rulebook that many college sports leaders saw as increasingly bloated.  It also reduces the size of the NCAA Board of Governors from 20 to 9, and guarantees that current and former athletes have voting representation on both the NCAA board and the governing bodies of each NCAA division. The new constitution was the first step in a reorganization process in which each division will have the right to set its own rules, with no approval needed from the rest of the NCAA membership.[40][41]  The modern era of the NCAA began in July 1955 when its executive director, Kansas City, Missouri native Walter Byers, moved the organization's headquarters from the LaSalle Hotel in Chicago (where its offices were shared by the headquarters of the Big Ten Conference) to the Fairfax Building in Downtown Kansas City. The move was intended to separate the NCAA from the direct influence of any individual conference and keep it centrally located.  The Fairfax was a block from Municipal Auditorium which had hosted men's basketball Final Four games in 1940, 1941, and 1942. After Byers moved the headquarters to Kansas City, the championships would be held in Municipal Auditorium in 1953, 1954, 1955, 1957, 1961, and 1964. The Fairfax office consisted of three rooms with no air conditioning. Byers' staff consisted of four people: an assistant, two secretaries, and a bookkeeper.[57]  In 1964, the NCAA moved three blocks away to offices in the Midland Theatre, moving again in 1973 to a $1.2\u00a0million building on 3.4 acres (14,000\u00a0m2) on Shawnee Mission Parkway in suburban Mission, Kansas. In 1989, the organization moved 6 miles (9.7\u00a0km) farther south to Overland Park, Kansas. The new building was on 11.35 acres (45,900\u00a0m2) and had 130,000 square feet (12,000\u00a0m2) of space.[58]  The NCAA was dissatisfied with its Johnson County, Kansas suburban location, noting that its location on the southern edges of the Kansas City suburbs was more than 40 minutes from Kansas City International Airport. They also noted that the suburban location was not drawing visitors to its new visitors' center.[59]  In 1997, it asked for bids for a new headquarters. Various cities competed for a new headquarters with the two finalists being Kansas City and Indianapolis. Kansas City proposed to relocate the NCAA back downtown near the Crown Center complex and would locate the visitors' center in Union Station. However Kansas City's main sports venue Kemper Arena was nearly 23 years old.[59] Indianapolis argued that it was in fact more central than Kansas City in that two-thirds of the members are east of the Mississippi River.[59] The 50,000-seat RCA Dome far eclipsed 19,500-seat Kemper Arena. In 1999, the NCAA moved its 300-member staff to its new headquarters in the White River State Park in a four-story 140,000-square-foot (13,000\u00a0m2) facility on the west edge of downtown Indianapolis, Indiana. Adjacent to the headquarters is the 35,000-square-foot (3,300\u00a0m2) NCAA Hall of Champions.[60]  The NCAA's Board of Governors (formerly known as the Executive Committee) is the main body within the NCAA. This body elects the NCAA's president.[61]  The NCAA's legislative structure is broken down into cabinets and committees, consisting of various representatives of its member schools.[citation needed] These may be broken down further into sub-committees. The legislation is then passed on to the Management Council, which oversees all the cabinets and committees, and also includes representatives from the schools, such as athletic directors and faculty advisers. Management Council legislation goes on to the Board of Directors, which consists of school presidents, for final approval. The NCAA national office staff provides support by acting as guides, liaisons, researchers, and by managing public and media relations.  The NCAA runs the officiating software company ArbiterSports, based in Sandy, Utah, a joint venture between two subsidiaries of the NCAA, Arbiter LLC and eOfficials LLC. The NCAA's stated objective for the venture is to help improve the fairness, quality, and consistency of officiating across amateur athletics.[62][63]  The NCAA had no full-time administrator until 1951, when Walter Byers was appointed executive director.[1] In 1998, the title was changed to president.[64]  In 2013, the NCAA hired Brian Hainline as its first chief medical officer.[68]  Before 1957, all NCAA sports used a single division of competition. In 1957 the NCAA split into two divisions for men's basketball only, with major programs making up the University Division and smaller programs making up the College Division.[4] The names could be confusing, as some schools with \"University\" in their name still competed in the College Division while some with \"College\" in their name competed in the University Division. The split gradually took hold in other sports as well. Records from before the split were inherited by the University Division.  In 1973 the College Division split up between teams that wanted to grant athletic scholarships (becoming Division II, which inherited the College Division's records and history) and teams that did not (becoming Division III), and the University Division was renamed to Division I. Division I split into two subdivisions for football only in 1978 (though both still under the Division I name), with Division I-A consisting of major teams who would continue to compete in bowl games and use various polls to decide its champion and Division I-AA consisting of smaller teams who would compete in the new NCAA Football Tournament to decide its champion.[69] Division I schools without football teams were known as Division I-AAA. In 2006, Division I-A became the Football Bowl Subdivision (FBS), Division I-AA became the Football Championship Subdivision (FCS), and Division I-AAA became Division I non-football. The changes were in name only with no significant structural differences to the organization.  For some less-popular sports, the NCAA does not separate teams into their usual divisions and instead holds only one tournament to decide a single national champion between all three divisions (except for women's ice hockey and men's indoor volleyball, where the National Collegiate championship only features teams from Division I and Division II and a separate championship is contested for only Division III). The 11 sports which use the National Collegiate format, also called the single-division format, are women's bowling, fencing, men's gymnastics, women's gymnastics, women's ice hockey, rifle, skiing, men's indoor volleyball, women's beach volleyball, men's water polo, and women's water polo.[70] The NCAA considers a National Collegiate title equivalent to a Division I title even if the champion is primarily a member of Division II or III.[71] These championships are largely dominated by teams that are otherwise members of Division I, but current non-Division I teams have won 40 National Collegiate championships since the University Division\/College Division split as of 2022 (2 in bowling, 20 in fencing, 8 in women's ice hockey, and 10 in rifle).[71] Division III schools are allowed to grant athletic scholarships to students who compete in National Collegiate sports, though most do not.  Men's ice hockey uses a similar but not identical \"National Collegiate\" format as women's ice hockey and men's indoor volleyball (Division III has its own championship but several Division III teams compete in Division I for men's ice hockey), but its top-level championship is branded as a \"Division I\" championship. While the NCAA has not explained why it is the only sport with this distinction, the NCAA held a separate Division II championship from 1978 to 1984 and again from 1993 to 1999. As of 2023, 12 Division I men's ice hockey championships have been won by current non-Division I teams since the University Division\/College Division split. Like with National Collegiate sports, schools that are otherwise members of Division III who compete in Division I for men's ice hockey are allowed to grant athletic scholarships for the sport.  All sports used the National Collegiate format until 1957, when the NCAA was split into the University Division and College Division (which itself was split into Divisions II and III in 1973).[4] The only sport that immediately saw a change after the 1957 split was basketball; all other sports continued to use the National Collegiate format for at least one season, and usually many more. Some sports that began after the split once used the format and no longer do. This include men's and women's lacrosse, women's rowing, women's soccer, and men's and women's indoor track & field.  Some sports, including men's and women's golf, men's ice hockey, men's lacrosse, and men's and women's soccer used to have a combined championship between Divisions II and III, but these were known as a \"Division II\/III championship\" in most cases. The NCAA considered these titles equivalent to a Division II title.[71] No sport currently uses this format.  The NCAA requires all of its athletes to be amateurs. All incoming athletes must be certified as amateurs. To remain eligible, athletes must not sign contract with sports clubs, earn a salary playing a sport, try out for professional sports, or enter into agreements with agents.[72]  To participate in college athletics in their freshman year, the NCAA requires that students meet three criteria: having graduated from high school, be completing the minimum required academic courses, and having qualifying grade-point average (GPA).[73]  The 16 academic credits are four courses in English, two courses in math, two classes in social science, two in natural or physical science, and one additional course in English, math, natural or physical science, or another academic course such as a foreign language.[74]  To meet the Division I requirements for grade point average, the lowest possible high school GPA a student may have to be eligible with to play in their freshman year is a 2.30 (2.20 for Division II or III), but they are allowed to play beginning in their second year with a GPA of 2.00.[75]  As of the 2017\u201318 school year, a high school student may sign a letter of intent to enter and play football for a Division I or Division II college in either of two periods.[c] The first, introduced in 2017\u201318, is a three-day period in mid-December, coinciding with the first three days of the previously existing signing period for junior college players.[77] The second period, which before 2017 was the only one allowed for signings of high school players, starts on the first Wednesday in February.[78] In August 2011, the NCAA announced plans to raise academic requirements for postseason competition, including its two most prominent competitions, football's now-defunct Bowl Championship Series (replaced in 2014 by the College Football Playoff) and the Division I men's basketball tournament; the new requirement, which are based on an \"Academic Progress Rate\" (APR) that measures retention and graduation rates, and is calculated on a four-year, rolling basis.[79] The changes raise the rate from 900 to 930, which represents a 50% graduation rate.[79]  Student-athletes can accept prize money from tournaments or competitions if they do not exceed the total expenses from the event. For example, during high school, D1 tennis players may take up to $10,000 in total prize money. If the student surpassed the amount of $10,000 of prize money in a calendar year, they would lose eligibility.[80]  Students are generally allowed to compete athletically for four years. Athletes are allowed to sit out a year while still attending school but not lose a year of eligibility by redshirting. In other words, a student has five years from the time they begin college to play four seasons.  The NCAA currently awards 90 national championships yearly \u2013 46 women's, 41 men's, and 3 coed championships for fencing, rifle, and skiing. Sports sanctioned by the NCAA include the following: basketball, baseball (men), beach volleyball (women), softball (women), football (men), cross country, field hockey (women), bowling (women), golf, fencing (coeducational), lacrosse, soccer, gymnastics, rowing (women), volleyball, ice hockey, water polo, rifle (coeducational), tennis, skiing (coeducational), track and field, swimming and diving, and wrestling (men).  The newest sport to be officially sanctioned is beach volleyball, which held its first championship in spring 2016.[81] The NCAA had called the sport \"sand volleyball\" until June 23, 2015, when it announced that it would use the internationally recognized name of \"beach volleyball\".[82]  The Football Bowl Subdivision of Division I determines its own champion separately from the NCAA via the College Football Playoff; this is not an official NCAA championship (see below).  The NCAA awards championships in the sports listed below. For the three coeducational championships, women's dates reflect the first championship that was open to women.  The number of teams (school programs) that compete in each sport in their respective division as of the 2021\u201322 academic year are as follows:[84]      Notes:  In addition to the above sports, the NCAA recognizes Emerging Sports for Women. These sports have scholarship limitations for each sport, but do not currently have officially sanctioned NCAA championships. A member institution may use these sports to meet the required level of sports sponsorship for its division. An \"Emerging Sport\" must gain championship status (minimum 40 varsity programs for team sports, except 28 for Division III) within 10 years, or show steady progress toward that goal to remain on the list.[85] Until then, it is under the auspices of the NCAA and its respective institutions. Emerging Sport status allows for competition to include club teams to satisfy the minimum number of competitions bylaw established by the NCAA.  The six sports currently designated as Emerging Sports for Women are:  The popularity of each of these sports programs has changed over time. Between 1988\u201389 and 2010\u201311, NCAA schools had net additions of 510 men's teams and 2,703 women's teams.[86]  The following tables show the changes over time in the number of NCAA schools across all three divisions combined sponsoring each of the men's and women's team sports.  The men's sports with the biggest net gains during the 1988\/89 to 2010\/11 period were indoor track and field, lacrosse, and cross country (each with more than 100 net gains). The men's sports with the biggest losses were wrestling (\u2212104 teams), tennis, and rifle; the men's team sport with the most net losses was water polo.[86] Other reports show that 355 college wrestling programs have been eliminated since 2000; 212 men's gymnastics programs have been eliminated since 1969 with only 17 programs remaining as of 2013.[87]  Additionally, eight NCAA sports\u2014all men's sports\u2014were sponsored by fewer Division I schools in 2020 than in 1990, despite the D-I membership having increased by nearly 60 schools during that period. Four of these sports, namely wrestling, swimming & diving, gymnastics, and tennis, lost more than 20 net teams during that timeframe. As a proportion of D-I membership, men's tennis took the greatest hit; 71.5% of D-I members had men's tennis in 2020, compared to 93.2% in 1990.[88]  The following table lists the men's individual DI sports with at least 5,000 participating athletes. Sports are ranked by number of athletes.  The women's sports with the biggest net gains during the 1988\u201389 to 2010\u201311 period were soccer (+599 teams), golf, and indoor track and field; no women's sports programs experienced double-digit net losses.[86]  The following table lists the women's individual NCAA sports with at least 1,000 participating athletes. Sports are ranked by number of athletes.  For every NCAA sanctioned sport other than Division I FBS football, the NCAA awards trophies with gold, silver, and bronze plating for the first-, second-, and third-place teams respectively.[citation needed] In the case of the NCAA basketball tournaments, both semifinalists who did not make the championship game receive bronze plated trophies for third place (prior to 1982 the teams played a \"consolation\" game to determine third place).[citation needed] Similar trophies are awarded to both semifinalists in the NCAA football tournaments (which are conducted in Division I FCS and both lower divisions), which have never had a third-place game. Winning teams maintain permanent possession of these trophies unless it is later found that they were won via serious rules violations.  Starting with the 2001\u201302 season, and again in the 2007\u201308 season, the trophies were changed.[citation needed] Starting in the 2006 basketball season, teams that make the Final Four in the Division I tournament receive bronze-plated \"regional championship\" trophies upon winning their Regional Championship which state the region they won and have the Final Four logo. The teams that make the National Championship game receive an additional trophy that is gold-plated for the winner. Starting in the mid-1990s, the National Champions in men's and women's basketball receive an elaborate trophy with a black marble base and crystal \"neck\" with a removable crystal basketball following the presentation of the standard NCAA Championship trophy.  As of May 30, 2022,[91] Stanford, UCLA, and Southern California (USC) have the most NCAA championships. Stanford has won 131 and UCLA has won 119 NCAA team championships in men's and women's sports, while USC is third with 111.  The NCAA has never sanctioned an official championship for its highest level of football, now known as Division I FBS. Instead, several outside bodies award their own titles. The NCAA does not hold a championship tournament or game for Division I FBS football. In the past, teams that placed first in any of a number of season-ending media polls, most notable the AP Poll of writers and the Coaches Poll, were said to have won the \"national championship\".  From 2014 through 2023, the College Football Playoff \u2013 a consortium of the conferences and independent schools that compete in Division I FBS and six bowl games \u2013 has arranged to place the top four teams (based on a thirteen-member committee that selects and seeds the teams) into two semifinal games, with the winners advancing to compete in the College Football Playoff National Championship, which is not officially sanctioned or recognized by the NCAA. The winner of the game receives a trophy; since the NCAA awards no national championship for Division I FBS football, this trophy does not denote NCAA as other NCAA college sports national championship trophies do. The playoff will expand to 12 teams starting in 2024.  The NCAA is divided into three levels of conferences, Division I, Division II, and Division III, organized in declining program size, as well as numerous sub-divisions. Most schools belong to a primary \"multisport conference\" for most of their sports. Schools may belong to different conferences for different sports.  The Division I, Division II, and Division III \"Independents\" listed below are not conferences per se; it is a designation used for schools that do not belong to a conference for a particular sport. These schools may still have conference memberships for other sports. For example, Notre Dame primarily belongs to the Atlantic Coast Conference for most sports, but its ice hockey team competes in the Big Ten Conference and its football team is an independent.  Among the NCAA regulations, each Division I conference defined as a \"multisport conference\" must have at least seven active Division I member institutions. These conferences must sponsor at least 12 sports, including six sports for men and six for women. At least seven active members in a multisport conference must sponsor both men's and women's basketball. However, a conference may operate for up to 2 years with fewer active members under a hardship rule. For non-football conferences, they must sponsor at least two men's team sports other than basketball. Teams that consist of both men and women are counted as men's teams for sports sponsorship purposes.[92]  For all institutions in the Division I Football Bowl Subdivision, they have additional requirements. Among them, they must participate in conference play in at least six men's and eight women's sports, including football, men's and women's basketball, and at least two other women's team sports.[93][94] In 2023, the NCAA added new requirements for FBS membership, set to take effect in 2027\u201328. At that time, FBS institutions must fund the equivalent of 210 full scholarships across all of their NCAA sports; must spend at least $6 million annually on said scholarships; and must provide at least 90% of the required number of full scholarships across 16 sports (as chosen by the institution), including football.[95]  Division I ice hockey has a different conference structure than the above multisport conferences. These schools have memberships in other conferences for other sports.  Among the NCAA regulations, Division II institutions must sponsor at least five sports for men and five for women (or four for men and six for women), with two team sports for each sex, and each playing season represented by each sex. Teams that consist of both men and women are counted as men's teams for sports sponsorship purposes.[96]  Unlike the other two divisions, Division III institutions cannot offer athletic scholarships. Among the other NCAA Division III requirements, all institutions, regardless of enrollment, must sponsor at least three team sports for each sex\/gender, and each playing season represented by each sex\/gender.[97] Furthermore, a sports sponsorship rule unique to Division III is that the total number of sports that must be sponsored differs by a school's full-time undergraduate enrollment: schools with an enrollment of 1,000 or fewer must sponsor at least five sports for men and five for women; those with larger enrollments must sponsor six men's and six women's sports. As in the other divisions, teams that include both men and women are treated as men's sports for the purpose of these regulations.[98]  The NCAA has current media rights contracts with CBS Sports, CBS Sports Network, ESPN, ESPN+, TNT Sports and Golf Channel for coverage of its 88 championships. According to the official NCAA website,[99] ESPN and its associated networks have rights to 21 championships, CBS to 65, TNT Sports to one and NBC's Golf Channel to two. The following are the most prominent championships and rights holders until the 2023\u201324 season:  Westwood One has exclusive radio rights to the men's and women's basketball Final Fours and the Men's College World Series (baseball).  From 1998 to 2013, Electronic Arts had a license to develop college sports video games with the NCAA's branding, which included its NCAA Football, NCAA Basketball (formerly NCAA March Madness) and MVP Baseball series. The NCAA's licensing was not required to produce the games, as rights to use teams are not licensed through the NCAA, but through entities such as individual schools and the Collegiate Licensing Company. EA only acquired the license so that it could officially incorporate the Division I men's basketball tournament into its college basketball game series. The NCAA withdrew EA's license due to uncertainties surrounding a series of lawsuits, most notably O'Bannon v. NCAA, involving the use of player likenesses in college sports video games.[100][101]  The week-long program took place October 1\u20135, 2018. The aim was to utilize social media platforms in order to promote diversity and inclusion within intercollegiate athletics. Throughout the NCAA's history, there has been controversy as to the levels of diversity present within intercollegiate athletics, and this campaign is the NCAA's most straightforward approach to combatting these issues.[51]  As a core value, the NCAA believes in and is committed to diversity, inclusion and gender equity among its student-athletes, coaches and administrators. It seeks to establish and maintain an inclusive culture that fosters equitable participation for student-athletes and career opportunities for coaches and administrators from diverse backgrounds. Diversity and inclusion improve the learning environment for all student-athletes and enhance excellence within the Association.[51]  The Office of Inclusion will provide or enable programming and education, which sustains foundations of a diverse and inclusive culture across dimensions of diversity including but not limited to age, race, sex, class, national origin, creed, educational background, religion, gender identity, disability, gender expression, geographical location, income, marital status, parental status, sexual orientation and work experiences.  This statement was adopted by the NCAA Executive Committee in April 2010, and amended by the NCAA Board of Governors in April 2017.[51]  While no concrete criteria are given as to a state of gender equity on campuses, an athletics program is considered gender equitable when both women's and men's sports programs reach a consensus.[102]  The basis of Title IX, when amended in 1972 to the 1964 Civil Rights Act, criminalized discrimination on the basis of sex.[103] This plays into intercollegiate athletics in that it helps to maintain gender equity and inclusion in intercollegiate athletics. The NCAA provides many resources to provide information and enforce this amendment.  The NCAA has kept these core values central to its decisions regarding the allocation of championship bids. In April 2016, the Board of Governors announced new requirements for host cities that include protection against discrimination based on sexual orientation or gender identity for all people involved in the event. This decision was prompted by several states passing laws that permit discrimination based on sexual orientation or gender identity in accordance with religious beliefs.[104]  The LGBTQ community has been under scrutiny and controversy in the public eye of collegiate athletics, but the NCAA has gradually liberalised its policy on them. The NCAA provides many resources concerning the education of the college community on this topic and policies in order to foster diversity.[105] Title IX protects the transgender community within intercollegiate athletics and on college campuses.  On January 19, 2022, the NCAA approved a new policy for transgender athletes, effective immediately, and this replaced their previous policy, which was in place since 2011.[106] Now, the participation of transgender athletes in a particular sport is generally to be governed by the rules of the sport's national governing body, international federation policy, or IOC policy criteria (though an NCAA committee may provide its own recommendation).[107] This action prompted immediate critique from LGBTQ advocates, including Athlete Ally and former NCAA LGBTQ OneTeam facilitator Rhea Debussy.[108][109]  Previously, the NCAA used testosterone levels to qualify transgender athletes for participation. A transgender male student-athlete was not allowed to compete on a male sports team unless they had undergone medical treatment of testosterone for gender transition, and a transgender female student-athlete was not allowed to compete on a women's sports team until completing one calendar year of testosterone suppression treatment. Under this policy, transgender males were ineligible to compete on a women's team, and transgender females were ineligible to compete on a men's team, without changing the team's status to be a mixed team.[110] In December 2021, John Lohn, the editor-in-chief of Swimming World, criticised NCAA policy; writing about transgender swimmer Lia Thomas, he argued that the \"one-year suppressant requirement is not nearly stringent enough to create a level playing field between Thomas and the biological females against whom she is racing\".[111]  In 2010, the NCAA Executive Committee announced its support and commitment to diversity, inclusion, and gender equality among its student-athletes, coaches, and administrators. The statement included the NCAA's commitment to ensuring that all students have equal opportunities to achieve their academic goals, and coaches and administrators have equal opportunities for career development in a climate of respect.[105] In 2012, the LGBTQ Subcommittee of the NCAA association-wide Committee on Women's Athletics and the Minority Opportunities and Interests Committee commissioned Champions of Respect, a document that provides resources and advocacy that promotes inclusion and equality for LGBTQ student-athletes, coaches, administrators and all others associated with intercollegiate athletics. This resource uses guides from the Women's Sports Foundation It Takes a Team! project for addressing issues related to LGBTQ equality in intercollegiate athletics.[112] The document provides information on specific issues LGBTQ sportspeople face, similarities and differences of these issues on women's and men's teams, policy recommendations and best practices, and legal resources and court cases.[113]  The NCAA expressed concern over Indiana's Religious Freedom Restoration Act that allows businesses to discriminate against people based on their sexual orientation. This bill was proposed just before Indianapolis was set to host the 2015 Men's Basketball Final Four tournament.[114] The bill clashed with the NCAA core values of inclusion and equality, and forced the NCAA to consider moving events out of Indiana. Under pressure from across the nation and fearing the economic loss of being banned from hosting NCAA events, the governor of Indiana, Mike Pence, revised the bill so that businesses could not discriminate based on sexual orientation, race, religion, or disability. The NCAA accepted the revised bill and continues to host events in Indiana.[115] The bill was enacted into law on July 1, 2015.[115]  On September 12, 2016, the NCAA announced that it would pull all seven planned championship events out of North Carolina for the 2016\u20132017 academic year.[116] This decision was a response to the state passing the Public Facilities Privacy and Security Act (H.B. 2) on March 23, 2016. This law requires people to use public restrooms that correspond with their sex assigned at birth and stops cities from passing laws that protect against discrimination towards gay and transgender people.[citation needed] The NCAA Board of Governors determined that this law would make ensuring an inclusive atmosphere in the host communities challenging, and relocating these championship events best reflects the association's commitment to maintaining an environment that is consistent with its core values.[116] North Carolina has lost the opportunity to host the 2018 Final Four Tournament which was scheduled to be in Charlotte, but is relocated to San Antonio. If H.B. 2 is not repealed, North Carolina could be barred from bidding for events from 2019 to 2022.[117]  Racial\/Ethnic minority groups in the NCAA are protected by inclusion and diversity policies put in place to increase sensitivity and awareness to the issues and challenges faced across intercollegiate athletics. The NCAA provides a demographics database that can be openly viewed by the public.[51]  Historically, the NCAA has used its authority in deciding on host cities to promote its core values. The Association also prohibits championship events in states that display the Confederate flag, and at member schools that have abusive or offensive nicknames or mascots based on Native American imagery. Board members wish to ensure that anyone associated with an NCAA championship event will be treated with fairness and respect.[104]  The NCAA defines a disability as a current impairment that has a substantial educational impact on a student's academic performance and requires accommodation. Student-Athletes with disabilities are given education accommodations along with an adapted sports model. The NCAA hosts adapted sports championships for both track and field and swimming and diving as of 2015.[105]  Over the last two decades recruiting international athletes has become a growing trend among NCAA institutions. For example, most German athletes outside of Germany are based at US universities. For many European athletes, the American universities are the only option to pursue an academic and athletic career at the same time. Many of these students come to the US with high academic expectations and aspirations.[105]  As of 2018, there has been a continuation of changing school mascots that are said by some to be based on racist or offensive stereotypes. Universities under NCAA policy are under scrutiny for specifically Native American-inspired mascots. While many colleges have changed their mascots, some have gotten legal permission from the tribe represented and will continue to bear the mascot. This Native American mascot controversy has not been completely settled; however, many issues have been resolved.[118]  Here is a list of notable colleges that changed Native American mascots and\/or nicknames in recent history:  Others:  Of note: Utah (Utes), Central Michigan (Chippewas), Florida State (Seminoles) and Mississippi College (Choctaws) all appealed successfully to the NCAA after being deemed \"hostile and offensive.\" Each cited positive relationships with neighboring tribes in appeal. UNC Pembroke (Braves), an institution originally created to educate Native Americans and enjoying close ties to the local Lumbee tribe, was approved to continue the use of native-derived imagery without needing an appeal.  Member schools pledge to follow the rules promulgated by the NCAA. Creation of a mechanism to enforce the NCAA's legislation occurred in 1952 after careful consideration by the membership.  Allegations of rules violations are referred to the NCAA's enforcement staff, who monitor information about potential violations, investigate and process violations, provide notice of alleged violations, and bring cases before the NCAA's Committees on Infractions.[120] A preliminary investigation is initiated to determine if an official inquiry is warranted and to categorize any resultant violations as secondary or major. If several violations are found, the NCAA may determine that the school as a whole has exhibited a \"lack of institutional control.\" The institution involved is notified promptly and may appear on its own behalf before the NCAA Committee on Infractions.  Findings of the Committee on Infractions and the resultant sanctions in major cases are reported to the institution. Sanctions will generally include having the institution placed on \"probation\" for a period of time, in addition to other penalties. The institution may appeal the findings or sanctions to an appeals committee. After considering written reports and oral presentations by representatives of the Committee on Infractions and the institution, the committee acts on the appeal. Action may include accepting the infractions committee's findings and penalty, altering either, or making its own findings and imposing an appropriate penalty.[120]  In cases of particularly egregious misconduct, the NCAA has the power to ban a school from participating in a particular sport, a penalty known as the \"Death Penalty\". Since 1985, any school that commits major violations during the probationary period can be banned from the sport involved for up to two years. However, when the NCAA opts not to issue a death penalty for a repeat violation, it must explain why it did not do so. This penalty has only been imposed three times in its modern form, most notably when Southern Methodist University's (SMU) football team had its 1987 season canceled due to massive rules violations dating back more than a decade. SMU opted not to field a team in 1988 as well due to the aftershocks from the sanctions, and the program has never recovered. The Mustangs did not post a winning season until 1997, did not appear in their next bowl game until 2009, did not post consecutive winning seasons until 2011 and 2012, did not return to the national rankings until 2019, and did not win a conference title again until 2023. The devastating effect the death penalty had on SMU has reportedly made the NCAA skittish about issuing another one. Since the SMU case, there are only three instances where the NCAA has seriously considered imposing it against a Division I school; it imposed it against Division II Morehouse College's men's soccer team in 2003 and Division III MacMurray College's men's tennis team in 2005. In addition to these cases, the most recent Division I school to be considered was Penn State. This was because of the Jerry Sandusky Incident that consequently almost landed Penn State on the hook for the death penalty. They received a $60\u00a0million fine, in addition to forfeited seasons and other sanctions as well. The NCAA later reversed itself by restoring all forfeited seasons and overturning the remaining sanctions.  Additionally, in particularly egregious cases of rules violations, coaches, athletic directors, and athletic support staff can be barred from working for any NCAA member school without permission from the NCAA. This procedure is known as a \"show-cause penalty\" (not to be confused with an order to show cause in the legal sense).[121] Theoretically, a school can hire someone with a \"show cause\" on their record during the time the show cause order is in effect only with permission from the NCAA Infractions Committee. The school assumes the risks and stigma of hiring such a person. It may then end up being sanctioned by the NCAA and the Infractions Committee for their choice, possibly losing athletic scholarships, revenue from schools who would not want to compete with that other school, and the ability for their games to be televised, along with restrictions on recruitment and practicing times. As a result, a show-cause order essentially has the effect of blackballing individuals from being hired for the duration of the order.  One of the most famous scandals in NCAA history involved Heisman Trophy-winning quarterback Cam Newton of the Auburn Tigers in 2011. As a direct effect of not being compensated for his college athletics, Cam Newton's family allegedly sought upwards of $100,000 for him to instead play at Mississippi State. This was revealed days before the conference SEC championship game; however, Cam Newton was later reinstated as there was insufficient evidence against him.[122]  The NCAA has a two-tier sponsorship division. AT&T, Coca-Cola, and Capital One are NCAA Corporate Champions, all others are NCAA Corporate Partners.[123]  As a governing body for amateur sports the NCAA is classified as a tax-exempt not-for-profit organization.[124] As such, it is not required to pay most taxes on income that for-profit private and public corporations are subject to. The NCAA's business model of prohibiting salaries for collegial athletes has been challenged in court, but a 2015 case was struck down.[125] As of 2014 the NCAA reported that it had over $600\u00a0million in unrestricted net assets in its annual report.[126] During 2014 the NCAA also reported almost a billion dollars of revenue, contributing to a \"budget surplus\" \u2013 revenues in excess of disbursements for that year \u2013 of over $80\u00a0million.[126] Over $700\u00a0million of that revenue total was from licensing TV rights to its sporting events.[126] In addition, the NCAA also earns money through investment growth of its endowment fund. Established in 2004 with $45\u00a0million, the fund has grown to over $380\u00a0million in 2014.[127]  According to the NCAA, it receives most of its annual revenue from two sources: Division I Men's Basketball television and marketing rights, and championships ticket sales. According to the NCAA, \"that money is distributed in more than a dozen ways \u2013 almost all of which directly support NCAA schools, conferences and nearly half a million student-athletes.\"[128]  In 2017 total NCAA revenues were in excess of $1.06\u00a0billion.[129] Division I basketball television and marketing rights generated $821.4\u00a0million, and \"championships ticket sales\" totaled $129.4\u00a0million. Other \"smaller streams of revenue, such as membership dues\" contributed an unspecified amount.[128]  The NCAA provided a breakdown of how those revenues were in turn spent, organizing pay-outs and expenses into some 14 basic categories. By far the largest went to Sports Scholarship and Sponsorship Funds, funding for sports and student scholarships under the Division I Basketball Performance Fund, expenses incurred in producing Division I Championships (including team food, travel, and lodging), the Student Assistance Fund, and Student Athlete Services. Together these top five recipients accounted for 65% of all NCAA expenditures. General and Administrative expenses for running the NCAA day-to-day operations totaled approximately 4% of monies paid out, and other association-wide expenses, including legal services, communications, and business insurance totaled 8%.[128]  The categories:  According to the NCAA, the 2017 fiscal year was the first in which its revenues topped $1.0\u00a0billion. The increase in revenue from 2016 came from hikes in television and marketing fees, plus greater monies generated from championship events and investment income.[129]  An ESPN critique of the organization's 2017 financials indicated some $560.3\u00a0million of the total $956\u00a0million paid out went back to its roughly 1,100 member institutions in 24 sports in all three divisions, as well as $200\u00a0million for a one-time payment the NCAA made to schools to fund additional programs.[130]  The Division I basketball tournament alone generated some $761\u00a0million, with another $60\u00a0million in 2016\u201317 marketing rights. With increases in rights fees it is estimated the basketball tournament will generate some $869\u00a0million for the 2018 championship.[130]  The NCAA has limited the amount of compensation that individual players can receive to scholarships equal to school tuition and related expenses. This rule has generated controversy, in light of the large amounts of revenues that schools earn from sports from TV contracts, ticket sales, and licensing and merchandise. Several commentators have discussed whether the NCAA limit on player compensation violates antitrust laws. There is a consensus among economists that the NCAA's compensation caps for men's basketball and football players benefit the athletes' schools (through rent-seeking) at the expense of the athletes.[6] Economists have subsequently characterized the NCAA as a cartel and collusive monopsony.[9][11][10][131][132]  Pro-rating payouts to Division I basketball players in proportion to the size of revenues its championship tournament generates relative to the NCAA's total annual revenues would be one possible approach, but will open the door to litigation by students and schools adversely affected by such a formula.  According to a national study by the National College Players Association (NCPA) and the Drexel University Sport Management Department, the average FBS \"full\" athletic scholarship falls short of the full cost of attending each school by an average of $3285 during 2011\u201312 school year, and leaves the vast majority of full scholarship players living below the federal poverty line.  [133]  In 2020, the NCAA Board of Governors announced that they supported rule changes that would permit players to receive athletics-related endorsements from third-parties.[134] All divisions were expected to adopt new rules relating to the use of players' names, images, and likenesses before the 2021\u20132022 academic year begins.  On May 6, 2021, Governor Brian Kemp signed Bill 617 into law, giving collegiate athletes the ability to profit off their Name, Image and Likeness. The University of Georgia have said they will immediately compensate their student athletes, while Georgia Tech and Georgia State University have not set anything yet.[135]  On June 21, 2021, the U.S. Supreme Court held unanimously in National Collegiate Athletic Association v. Alston that the NCAA's restrictions on education-related payments were unlawfully in violation of Sherman Act's anti-trust and trade regulations.[136][137] Though this holding did not address restrictions on direct compensation payment to athletes, it also opened the door for the possibly of future court cases concerning this matter.[138][136]  The NCAA announced on July 1, 2021, that as a result of O'Bannon and numerous state laws giving college players the ability to manage their publicity, the board had agreed to new rules that removed restrictions on college athletes from entering paid endorsements and other sponsorship deals, and from using agents to manage their publicity. Students would still be required to inform the school of all such activities, with the school to make determinations if those activities violate state and local laws.[139]  On the first day of effect for the NIL rule change (July 1), athletes such as D'Eriq King (Miami (FL) quarterback), Justyn Ross (Clemson wide receiver), Bo Nix (Auburn quarterback), Antwan Owen (Jackson State defensive end), McKenzie Milton (Florida State quarterback), Malik Cunningham (Louisville quarterback), Michael Penix Jr. (Indiana quarterback), Spencer Rattler (Oklahoma quarterback), Lexi Sun (Nebraska volleyball), Paige Bueckers (UConn basketball) and twins Haley & Hanna Cavinder (Fresno State basketball), all signed deals and\/or unveiled trademarks to profit off of their names, images, and likenesses. As of day one, LSU gymnast Olivia Dunne was projected to be the highest earning college athlete of 2021\u201322, out of both men's and women's sports.[140]  The new NIL agreement has given student athletes big time deals and opportunities to put themselves out there and gain profit using their name, image, and likeness. For example, Ga'Quincy McKinstry, a cornerback from Alabama known since childhood as \"Kool-Aid\", signed a deal with Kool-Aid. Not only can they partner up with companies, student athletes can get paid for other talents (i.e. singing).  Russell Steinberg in 2021 says, \"In addition to his prowess on the football field, where he has a shot at tying the school record for most starts, Marshall's Will Ulmer is a talented musician who wasn't able to earn money using his own name \u2014 until now. He had been going by \"Lucky Bill\" to avoid running afoul of NCAA regulations, but now says he is ready to book shows using his real name\" (Steinberg 2021).[141] The NIL has allowed Ulmer great opportunities to further pursue his football and musician career.  Some companies have partnered up with multiple athletes and created a team of their own. Degree, the deodorant brand, started a team of 14 student athletes to help promote their brand. Degree calls this team Breaking Limits. \"The Unilever-owned antiperspirant brand has committed $5 million over the next five years to inspire people to break limits. The first group of athletes that Degree has selected represent a diverse range of backgrounds regarding race, gender, and sport, and their stories will be unveiled on Instagram. These athletes will also have the chance to participate in events to help their local communities\" (Steinberg 2021).[141]  The NCAA presents a number of different individual awards,[143] including:  In previous years, the NCAA has presented the following awards at its NCAA Honors event: Astronaut Salute, Business Leader Salute, Congressional Medal of Honor Salute, Governor Salute, Olympians Salute, Performing Arts Salute, Presidents Cabinet Salute, Prominent National Media Salute, Special Recognition Awards, U.S. House of Representatives Salute, and U.S. Senate Salute.[144]  The NCAA is the dominant, but not the only, collegiate athletic organization in the United States. Several other such collegiate athletic organizations exist. "},{"title":"Australian rules football","content":"  Australian rules football, also called Australian football or Aussie rules,[2] or more simply football or footy, is a contact sport played between two teams of 18 players on an oval field, often a modified cricket ground. Points are scored by kicking the oval ball between the central goal posts (worth six points), or between a central and outer post (worth one point, otherwise known as a \"behind\").  During general play, players may position themselves anywhere on the field and use any part of their bodies to move the ball. The primary methods are kicking, handballing and running with the ball. There are rules on how the ball can be handled; for example, players running with the ball must intermittently bounce or touch it on the ground. Throwing the ball is not allowed, and players must not get caught holding the ball. A distinctive feature of the game is the mark, where players anywhere on the field who catch the ball from a kick (with specific conditions) are awarded unimpeded possession.[3] Possession of the ball is in dispute at all times except when a free kick or mark is paid. Players can tackle using their hands or use their whole body to obstruct opponents. Dangerous physical contact (such as pushing an opponent in the back), interference when marking, and deliberately slowing the play are discouraged with free kicks, distance penalties, or suspension for a certain number of matches depending on the severity of the infringement. The game features frequent physical contests, spectacular marking, fast movement of both players and the ball, and high scoring.  The sport's origins can be traced to football matches played in Melbourne, Victoria, in 1858, inspired by English public school football games. Seeking to develop a game more suited to adults and Australian conditions, the Melbourne Football Club published the first laws of Australian football in May 1859.[4][5]  Australian football has the highest spectator attendance and television viewership of all sports in Australia,[6][7] while the Australian Football League (AFL), the sport's only fully professional competition, is the nation's wealthiest sporting body.[8] The AFL Grand Final, held annually at the Melbourne Cricket Ground, is the second-highest-attended club championship event in the world. The sport is also played at amateur level in many countries and in several variations. Its rules are governed by the AFL Commission with the advice of the AFL's Laws of the Game Committee.  Australian rules football is known by several nicknames, including Aussie rules, football and footy.[9] In some regions, where other codes of football are more popular, the sport is usually called AFL after the Australian Football League, while the league itself also uses this name for local competitions in some areas.[10]  Primitive forms of football were played sporadically in the Australian colonies in the first half of the 19th century. Compared to cricket and horse racing, football was considered a mere \"amusement\" by colonists at the time, and while little is known about these early one-off games, evidence does not support a causal link with Australian football.[12] In Melbourne, Victoria, in 1858, in a move that would help to shape Australian football in its formative years, private schools (then termed \"public schools\" in accordance with nomenclature in England) began organising football games inspired by precedents at English public schools.[13] The earliest match, held on 15 June, was between Melbourne Grammar and St Kilda Grammar.[14]  On 10 July 1858, the Melbourne-based Bell's Life in Victoria and Sporting Chronicle published a letter by Tom Wills, captain of the Victoria cricket team, calling for the formation of a \"foot-ball club\" with a \"code of laws\" to keep cricketers fit during winter.[15] Born in Australia, Wills played a nascent form of rugby football whilst a pupil at Rugby School in England, and returned to his homeland a star athlete and cricketer. Two weeks later, Wills' friend, cricketer Jerry Bryant, posted an advertisement for a scratch match at the Richmond Paddock adjoining the Melbourne Cricket Ground (MCG).[16] This was the first of several \"kickabouts\" held that year involving members of the Melbourne Cricket Club, including Wills, Bryant, W. J. Hammersley and J. B. Thompson. Trees were used as goalposts and play typically lasted an entire afternoon. Without an agreed-upon code of laws, some players were guided by rules they had learned in the British Isles, \"others by no rules at all\".[17] Another milestone in 1858 was a 40-a-side match played under experimental rules between Melbourne Grammar and Scotch College, held at the Richmond Paddock. Umpired by Wills and teacher John Macadam, it began on 7 August and continued over two subsequent Saturdays, ending in a draw with each side kicking one goal.[18] It is commemorated with a statue outside the MCG, and the two schools have since competed annually in the Cordner\u2013Eggleston Cup, the world's oldest continuous football competition.[19]  Since the 1920s, it has been suggested that Australian football may have been derived from the Irish sport of Gaelic football.[20] However, there is no archival evidence in favour of a Gaelic influence, and the style of play shared between the two modern codes appeared in Australia long before the Irish game evolved in a similar direction.[21][22] Another theory, first proposed in 1983, posits that Wills, having grown up amongst Aboriginals in Victoria, may have seen or played the Aboriginal ball game of Marn Grook, and incorporated some of its features into early Australian football. There is only circumstantial evidence that he knew of the game, and according to biographer Greg de Moore's research, Wills was \"almost solely influenced by his experience at Rugby School\".[23]  A loosely organised Melbourne side, captained by Wills, played against other football enthusiasts in the winter and spring of 1858.[24] The following year, on 14 May, the Melbourne Football Club was officially established, making it one of the world's oldest football clubs. Three days later, Wills, Hammersley, Thompson and teacher Thomas H. Smith met near the MCG at the Parade Hotel, owned by Bryant, and drafted ten rules: \"The Rules of the Melbourne Football Club\". These are the laws from which Australian football evolved.[25] The club aimed to create a simple code suited to the hard playing surfaces around Melbourne, and to eliminate the roughest aspects of English school games\u2014such as \"hacking\" (shin-kicking) in Rugby School football\u2014to reduce the risk of injuries to working men.[26] In another significant departure from English public school football, the Melbourne rules omitted any offside law.[27] \"The new code was as much a reaction against the school games as influenced by them\", writes Mark Pennings.[28] The rules were distributed throughout the colony; Thompson in particular did much to promote the new code in his capacity as a journalist.[29]  Following Melbourne's lead, Geelong and Melbourne University also formed football clubs in 1859.[31] While many early Victorian teams participated in one-off matches, most had not yet formed clubs for regular competition. A South Yarra club devised its own rules.[32] To ensure the supremacy of the Melbourne rules, the first-club level competition in Australia, the Caledonian Society's Challenge Cup (1861\u201364), stipulated that only the Melbourne rules were to be used.[33] This law was reinforced by the Athletic Sports Committee (ASC), which ran a variation of the Challenge Cup in 1865\u201366.[34] With input from other clubs, the rules underwent several minor revisions, establishing a uniform code known as \"Victorian rules\".[35] In 1866, the \"first distinctively Victorian rule\", the running bounce, was formalised at a meeting of club delegates chaired by H. C. A. Harrison,[36] an influential pioneer who took up football in 1859 at the invitation of Wills, his cousin.[37]  The game around this time was defensive and low-scoring, played low to the ground in congested rugby-style scrimmages. The typical match was a 20-per-side affair, played with a ball that was roughly spherical, and lasted until a team scored two goals.[27] The shape of the playing field was not standardised; matches often took place in rough, tree-spotted public parks, most notably the Richmond Paddock (Yarra Park), known colloquially as the Melbourne Football Ground.[38] Wills argued that the turf of cricket fields would benefit from being trampled upon by footballers in winter,[39] and, as early as 1859, football was allowed on the MCG.[40] However, cricket authorities frequently prohibited football on their grounds until the 1870s, when they saw an opportunity to capitalise on the sport's growing popularity. Football gradually adapted to an oval-shaped field, and most grounds in Victoria expanded to accommodate the dual purpose\u2014a situation that continues to this day.[40]  Football became organised in South Australia in 1860 with the formation of the Adelaide Football Club, the oldest football club in Australia outside Victoria.[41] It devised its own rules, and, along with other Adelaide-based clubs, played a variety of codes until 1876, when they uniformly adopted most of the Victorian rules, with South Australian football pioneer Charles Kingston noting their similarity to \"the old Adelaide rules\".[42] Similarly, Tasmanian clubs quarrelled over different rules until they adopted a slightly modified version of the Victorian game in 1879.[43] The South Australian Football Association (SAFA), the sport's first governing body, formed on 30 April 1877, firmly establishing Victorian rules as the preferred code in that colony.[44] The Victorian Football Association (VFA) formed the following month.  Clubs began touring the colonies in the late 1870s, and in 1879 the first intercolonial match took place in Melbourne between Victoria and South Australia.[45] In order to standardise the sport across Australia, delegates representing the football associations of South Australia, Tasmania, Victoria and Queensland met in 1883 and updated the code.[43] New rules such as holding the ball led to a \"golden era\" of fast, long-kicking and high-marking football in the 1880s, a time which also saw players such as George Coulthard achieve superstardom, as well as the rise of professionalism, particularly in Victoria and Western Australia, where the code took hold during a series of gold rushes.[46] Likewise, when New Zealand experienced a gold rush, the sport arrived with a rapid influx of Australian miners. Now known as Australian rules or Australasian rules, the sport became the first football code to develop mass spectator appeal,[45] attracting world record attendances for sports viewing and gaining a reputation as \"the people's game\".[46]  Australian rules football reached Queensland and New South Wales as early as 1866;[47] the sport experienced a period of dominance in the former,[48] and in the latter, several regions remain strongholds of Australian rules, such as the Riverina. However, by the late 1880s, rugby football had become the dominant code in both colonies, as well as in New Zealand. This shift was largely due to rugby's spread with British migration, regional rivalries and the lack of strong local governing bodies. In the case of Sydney, denial of access to grounds, the influence of university headmasters from Britain who favoured rugby, and the loss of players to other codes inhibited the game's growth.[49]  In 1896, delegates from six of the wealthiest VFA clubs\u2014Carlton, Essendon, Fitzroy, Geelong, Melbourne and South Melbourne\u2014met to discuss the formation of a breakaway professional competition.[50] Later joined by Collingwood and St Kilda, the clubs formed the Victorian Football League (VFL), which held its inaugural season in 1897. The VFL's popularity grew rapidly as it made several innovations, such as instituting a finals system, reducing teams from 20 to 18 players, and introducing the behind as a score.[51] Richmond and University joined the VFL in 1908, and by 1925, with the addition of Hawthorn, Footscray and North Melbourne, it had become the preeminent league in the country and would take a leading role in many aspects of the sport.  The time around the federation of the Australian colonies in 1901 saw Australian rules undergo a revival in New South Wales, New Zealand and Queensland. In 1903, both the Queensland Australian Football League and the NSW Australian Football Association were established, and in New Zealand, as it moved towards becoming a dominion, leagues were also established in the major cities. This renewed popularity helped encourage the formation of the Australasian Football Council, which in 1908 in Melbourne staged the first national interstate competition, the Jubilee Australasian Football Carnival, with teams representing each state and New Zealand.[52]  The game was also established early on in the new territories. In the new national capital Canberra both soccer and rugby had a head start, but following the first matches in 1911, Australian rules football in the Australian Capital Territory became a major participation sport. By 1981 it had become much neglected and quickly lagged behind the other football codes. Australian rules football in the Northern Territory began shortly after the outbreak of the war in 1916 with the first match in Darwin. The game went on to become the most popular sport in the Territory and build the highest participation rate for the sport nationally.  Both World War I and World War II had a devastating effect on Australian football and on Australian sport in general. While scratch matches were played by Australian \"diggers\" in remote locations around the world, the game lost many of its great players to wartime service. Some clubs and competitions never fully recovered. Between 1914 and 1915, a proposed hybrid code of Australian football and rugby league, the predominant code of football in New South Wales and Queensland, was trialled without success.[53][54] In Queensland, the state league went into recess for the duration of the war. VFL club University left the league and went into recess due to severe casualties. The WAFL lost two clubs and the SANFL was suspended for one year in 1916 due to heavy club losses. The Anzac Day match, the annual game between Essendon and Collingwood on Anzac Day, is one example of how the war continues to be remembered in the football community.  The role of the Australian National Football Council (ANFC) was primarily to govern the game at a national level and to facilitate interstate representative and club competition. In 1968, the ANFC revived the Championship of Australia, a competition first held in 1888 between the premiers of the VFA and SAFA. Although clubs from other states were at times invited, the final was almost always between the premiers from the two strongest state competitions of the time\u2014South Australia and Victoria\u2014with Adelaide hosting most of the matches at the request of the SAFA\/SANFL. The last match took place in 1976, with North Adelaide being the last non-Victorian winner in 1972. Between 1976 and 1987, the ANFC, and later the Australian Football Championships (AFC) ran a night series, which invited clubs and representative sides from around the country to participate in a knock-out tournament parallel to the premiership seasons, which Victorian sides still dominated.  With the lack of international competition, state representative matches were regarded with great importance. Due in part to the VFL poaching talent from other states, Victoria dominated interstate matches for three-quarters of a century. State of Origin rules, introduced in 1977, stipulated that rather than representing the state of their adopted club, players would return to play for the state they were first recruited in. This instantly broke Victoria's stranglehold over state titles and Western Australia and South Australia began to win more of their games against Victoria. Both New South Wales and Tasmania scored surprise victories at home against Victoria in 1990.  The term \"Barassi Line\", named after VFL star Ron Barassi, was coined by scholar Ian Turner in 1978 to describe the \"fictitious geographical barrier\" separating the rugby-following parts of New South Wales and Queensland from the rest of the country, where Australian football reigned.[56] It became a reference point for the expansion of Australian football and for establishing a national league.[57]  The way the game was played had changed dramatically due to innovative coaching tactics, with the phasing out of many of the game's kicking styles and the increasing use of handball; while presentation was influenced by television.[58]  In 1982, in a move that heralded big changes within the sport, one of the original VFL clubs, South Melbourne, relocated to Sydney and became known as the Sydney Swans. In the late 1980s, due to the poor financial standing of many of the Victorian clubs, and a similar situation existing in Western Australia in the sport, the VFL pursued a more national competition. Two more non-Victorian clubs, West Coast and Brisbane, joined the league in 1987 generating more than $8 million in license revenue for the Victorian clubs and increasing broadcast revenues which helped the Victorian clubs survive.[59] In their early years, the Sydney and Brisbane clubs struggled both on and off-field because the substantial TV revenues they generated by playing on a Sunday went to the VFL.[citation needed] To protect these revenues the VFL granted significant draft concessions and financial aid to keep the expansion clubs competitive.  The VFL changed its name to the Australian Football League (AFL) for the 1990 season, and over the next decade, three non-Victorian clubs gained entry: Adelaide (1991), Fremantle (1995) and the SANFL's Port Adelaide (1997), the only pre-existing club outside Victoria to join the league.[59] In 2011 and 2012, respectively, two new non-Victorian clubs were added to the competition: Gold Coast and Greater Western Sydney.[60] The AFL, currently with 18 member clubs, is the sport's elite competition and most powerful body. Following the emergence of the AFL, state leagues were quickly relegated to a second-tier status. The VFA merged with the former VFL reserves competition in 1998, adopting the VFL name. State of Origin also declined in importance, especially after an increasing number of player withdrawals. The AFL turned its focus to the annual International Rules Series against Ireland in 1998 before abolishing State of Origin the following year. State and territorial leagues still contest interstate matches, as do AFL Women players.[61]  In the 2010s, the AFL signalled further attempts at expanding into markets outside Australian football's traditional heartlands by hosting home-and-away matches in New Zealand,[62] followed by China.[63] After several failed bids since the early 1990s for a Tasmania-based AFL team, the Tasmania Football Club secured the 19th AFL license in 2023, and is set to compete by 2028.[64]  In a standard match, a team may consist of anywhere between 14 and 18 players who may be permitted on the playing surface at any given time. Each team may have up to four interchange (reserve) players who may be swapped for those on the field at any time during the game.[65] Although some leagues in less populated areas may utilise as few as 12 players.[66]  In addition, some leagues notably including the AFL, have each team designate one additional player as a substitute who can be used to make a single permanent exchange of players during a game for either medical or tactical reasons.[67]  Players on the playing surface can be swapped with those on the interchange bench at any time. They must though pass through a designated \"Interchange Area\".[68] In the event a player fails to pass through this area correctly, or if too many players from one team are found to be on the ground at a time, a free kick will be awarded to the opposing side.[68][69]  While there is no set uniform, the basic equipment for Australian football consists of a guernsey, shorts, socks and boots, with additional pieces of apparel such as headbands and gloves additionally being permitted.[70] Players may wear certain pieces of protective equipment, such as helmets or arm guards, if approved by the relevant controlling body.[71] Mouthguards are strongly recommended for all players.[72][73]  Players are not permitted to wear jewellery, or other materials which the field umpire has deemed to be either potentially dangerous or increase the risk of injury to other players.[71]  Australian rules football is played with an ellipsoid ball, between 72 and 73\u00a0cm (28 and 29\u00a0in) in long circumference, and 54.5 and 55.5\u00a0cm (21.5 and 21.9\u00a0in) in short circumference.[75] For women's competitions, a smaller ball size of 69 and 53\u00a0cm (27 and 21\u00a0in) is used.[76] The ball must be inflated to a pressure of 69 kilopascals (10.0 pounds per square inch).[75] There are no defined laws regarding what material a ball must be made from, but standard AFL match-used balls are produced by Sherrin using cowhide leather.[77]  While there is no standard colour of the ball, red and yellow are most common and the only colours used at AFL level. Yellow is used for games beginning after 3pm or in an enclosed stadium, due to its greater visibility, and to assist score reviews.[78][75]  Unlike other forms of football which are played on rectangular fields, Australian rules football playing fields are oval-shaped, and are between 135 and 185 metres (148 and 202\u00a0yd) long and 110 and 155 metres (120 and 170\u00a0yd) wide.[79]  At either end of the field, two sets of posts are erected in a straight line to indicate the scoring areas on the field, each with two kinds of posts, named the goal posts and the behind posts respectively. The goal posts are placed first, located 6.4 metres (7.0\u00a0yd) apart from each other, with a behind post being placed a further 6.4 metres to the side of each goal post. The name for the field line between two goal posts is known as the Goal Line.[79]  Around the perimeter of the field, two white lines are drawn between the set of behind posts in an arc-shape, marking the field of play.[79]  Other field markings include:[79]  The 50m arcs, centre square, centre circle and goal square are utilised at the beginning of each quarter or after each goal. With each team  permitted a maximum of six players in each 50m arc, with one in the goal square and four players in the centre square with one in the centre circle. If this is breached, a free kick is awarded.[80]  A game lasts for 80 minutes, split into four quarters consisting of 20 minutes playing time, with the clock being stopped for stoppages in play such as scores,  or at the umpire's discretion, e.g. for serious injury.[81] Leagues may choose to employ shorter quarters of play at their discretion, such as the AFLW using 17 minutes per quarter.[82]  For any given match, two timekeepers are appointed to officiate the duration. The timekeepers record all relevant match for the match, such as total quarter duration and score by each team. Additionally timekeepers are required to sound a siren prior to and at the conclusion of each quarter until such time they are acknowledged by the field umpires. In order to stop and recommence the clock, the field umpires are required to signal to the timekeepers to indicate when the clock should be stopped or restarted.[81]  Between each quarter, a break is observed to allow players a rest period. Two six-minute breaks are observed between the first and second quarters, and the third and fourth quarters. A longer 20 minute break is observed between the second and third quarter, commonly known as half-time.[81][83]  Each game is officiated by at least five match officials, known as an umpire.[84] These match officials are placed into three categories based upon their roles and responsibilities, with varying minimum numbers of Umpires required depending on position:  At AFL level, a video score review system is utilised. Only umpires are permitted to request a review, and only scoring shots and potential scoring shots are permitted to be reviewed.[86]  An Australian rules football may only be propelled forward in a select few ways as defined by the Laws of Australian Football, published by the AFL. The ball can be propelled in any direction by way of a kick or a clenched fist (called a handball)\u2014deemed a correct disposal.[87] Failure to dispose of the ball in one of these two methods will result in a free kick to the opposing team.[88] If the ball is not currently in possession of a player, it can be moved legally through the usage of other means, such as punching.[87] While in possession of the ball, players may run with the ball, but are required to either bounce or touch the ball on the ground at least once every 15 metres (16\u00a0yd).[88]  Tackling is a technique employed by players used to force opposition players to dispose of the ball when they are in possession. Failure to dispose of the ball when legally tackled may see the player penalised for 'holding the ball', except if the umpire deems there was a lack of prior opportunity to do so.[89]  The ball carrier may only be tackled between the shoulders and knees from the front or side.[87] If the player forcefully contacts the opposing in the back while performing a tackle, the opposition player will be penalised for a push in the back. If the opposition tackles the player with possession below the knees (a low tackle or a trip) or above the shoulders (a high tackle), the team with possession of the football gets a free kick.[90] Furthermore, tackles deemed to be dangerous by the umpire and those conducted from front-on whilst an opposition player has their head over the football are deemed to be prohibited contact, and will incur a free kick against the offending player.[90][91]  Additionally, players may perform a technique known shepherding when the ball is within 5 metres (5.5\u00a0yd) of an opposition player. Shepherding involves the use of a player's body to push, bump or otherwise block an opposition player, providing they do not have possession of the ball.[87]  If a player takes possession of the ball  that has travelled more than 15 metres (16\u00a0yd) from another player's kick, by way of a catch within the field of play, it is deemed as a mark.[92] Upon a mark being taken, one opposition player may choose to stand on the point on the field where the mark was taken, known as \"the mark\". When a mark is taken, a small protected zone is established on the field, extending 10 metres (11\u00a0yd) either side of \"the mark\" and the player who marked the ball, with a small protected corridor between \"the mark\" and the player. The opposition player is permitted to jump, but is not allowed to move from their position on \"the mark\". Any other movements result in a free kick.[93] The player who was awarded the mark may then choose to either dispose of the ball over \"the mark\" or may choose to attempt disposal via a different method, in which case the field umpire will call \"play on\"\u2014a verbal instruction to continue play.[93][87] \"Play on\" may also be called if the umpire deems the player awarded the mark to be taking an unreasonable amount of time to dispose of the football.[93]  Once the player has disposed of the ball, or \"play on\" is called, normal play resumes.[93]  In the event a player breaks a rule, a free kick is awarded to the opposing team, from the location that the misconduct occurred, or the ball's current location\u2014whichever is closer to the team's scoring zone.[94] As when a mark is taken, this location is called \"the mark\", and the same protections regarding the space apply.[93]  In the event a player engages in unsportsmanlike conduct after a free kick has been awarded or a mark has been paid to the opposing team, the umpire may instead award a 50 metre penalty. When imposed, the field umpire will advance \"the mark\" an additional 50 metres (55\u00a0yd) down the field or to the goal line, whichever is closer. Additional 50 metre penalties may be awarded if the behaviour continues after the initial penalty.[95]  The laws of the game allow umpires to send off players for egregious foul play, although this law does not apply to the AFL and is largely only utilised at the local level.[96]  There are two types of scoring shots in Australian football: goals and behinds. A goal is worth six points, and is scored when the football is propelled between the goal posts and across the goal line at any height by way of a kick from the attacking team. It may touch the ground, but must not have been touched by any player from either team or a goalpost prior to crossing the goal line.[97]  A behind is worth one point and is scored when:[97]  A behind is also awarded to the team if the ball touches any part of an opposition player, including a foot, before passing across their goal or behind line.[97] A free kick is awarded against any player who is deemed to have deliberately rushes a behind.[98][99]  The team that has scored the most points at the end of play wins the game. If the scores are level on points at the end of play, then the game is a draw; extra time applies only during finals matches in some competitions.[100][101]  As an example of a score report, consider a match between Sydney and Geelong with the former as the home team. Sydney's score of 17 goals and 5 behinds equates to 107 points. Geelong's score of 10 goals and 17 behinds equates to a 77-point tally. Sydney wins the match by a margin of 30 points. Such a result would be written as:  And spoken as:  Additionally, it can be said that:  The home team is typically listed first and the visiting side is listed second.  A draw would be written as:  The football season proper is from March to August (early autumn to late winter in Australia) with finals being held in September and October.[103] In the tropics, the game is sometimes played in the wet season (October to March).[104]  The AFL is recognised by the Australian Sports Commission as being the National Sporting Organisation for Australian football.[105] There are also seven state\/territory-based organisations in Australia, all of which are affiliated with the AFL.[106] These state leagues hold annual semi-professional club competitions, with some also overseeing more than one league. Local semi-professional or amateur organisations and competitions are often affiliated to their state organisations.[107]  In 2002, the AFL became the de facto world governing body for Australian football when it pushed for the closure of the International Australian Football Council. There are also a number of affiliated organisations governing amateur clubs and competitions around the world.[108]  For almost all Australian football club competitions, the aim is to win the Premiership. The premiership is typically decided by a finals series. The teams that occupy the highest positions on the ladder after the home-and-away season play off in a \"semi-knockout\" finals series, culminating in a single Grand Final match to determine the premiers. Between four and eight teams contest a finals series, typically using the AFL final eight system[109] or a variation of the McIntyre system.[110][111] The team which finishes first on the ladder after the home-and-away season is referred to as a \"minor premier\", but this usually holds little stand-alone significance, other than receiving a better draw in the finals.[112]  Some metropolitan leagues have several tiered divisions, with promotion of the lower division premiers and relegation of the upper division's last placed team at the end of each year.[113]  The high level of interest shown by women in Australian football is considered unique among the world's football codes.[114] It was the case in the 19th century, as it is in modern times, that women made up approximately half of total attendances at Australian football matches\u2014a far greater proportion than, for example, the estimated 10 per cent of women that comprise British soccer crowds.[115] This has been attributed in part to the egalitarian character of Australian football's early years in public parks where women could mingle freely and support the game in various ways.[116]  In terms of participation, there are occasional 19th-century references to women playing the sport, but it was not until the 1910s that the first organised women's teams and competitions appeared.[117] Women's state leagues emerged in the 1980s,[118] and in 2013, the AFL announced plans to establish a nationally televised women's competition.[119] Amidst a surge in viewing interest and participation in women's football, the AFL pushed the founding date of the competition, named AFL Women's, to 2017.[120] Eight AFL clubs won licences to field sides in its inaugural season.[121] By the seventh season, which began in August 2022, all 18 clubs fielded a women's side.  Many related games have emerged from Australian football, mainly with variations of contact to encourage greater participation. These include Auskick (played by children aged between 5 and 12), kick-to-kick (and its variants end-to-end footy and marks up), rec footy, 9-a-side footy, masters Australian football, handball and longest-kick competitions. Players outside Australia sometimes engage in related games adapted to available fields, like metro footy (played on gridiron fields) and Samoa rules (played on rugby fields). One such prominent example in use since 2018 is AFLX, a shortened variation of the game with seven players a side, played on a soccer-sized pitch.[122]  The similarities between Australian football and the Irish sport of Gaelic football have allowed for the creation of a hybrid code known as international rules football. The first international rules matches were contested in Ireland during the 1967 Australian Football World Tour. Since then, various sets of compromise rules have been trialed, and in 1984 the International Rules Series commenced with national representative sides selected by Australia's state leagues (later by the AFL) and the Gaelic Athletic Association (GAA). The competition became an annual event in 1998, but was postponed indefinitely in 2007 when the GAA pulled out due to Australia's severe and aggressive style of play.[123] It resumed in Australia in 2008 under new rules to protect the player with the ball.  During the colonial period, Australian rules was sometimes referred to as Australasian rules, reflecting its popularity in New Zealand. The game was played outside Australasia as early as 1888 when Australians studying at Edinburgh University and London University formed teams and competed in London.[124] By the early 20th century, it had spread with the Australian diaspora to South Africa, the United States and other parts of the Anglosphere; however this growth went into rapid decline during and after World War I, leading also to a decades long hiatus in New Zealand. After World War II, it experienced growth in the Pacific region, particularly in Papua New Guinea and Nauru, where Australian football is now the national sport.[125]  Today, the sport is played at an amateur level in various countries throughout the world. 23 countries have participated in the International Cup, the highest level of international competition, held triennially in Australia since 2002. 9 countries have also participated in the AFL Europe Championship with both competitions prohibiting Australian players. A fan of the sport since attending school in Victoria, King Charles is the Patron of AFL Europe. In 2013, participation across AFL Europe's 21 member nations was more than 5,000 players, the majority of which are European nationals rather than Australian expats.[126] The sport also has a growing presence in India.[127] Over 20 countries have either affiliation or working agreements with the AFL.[128]  Most present-day international amateur clubs and leagues are based in North America, Europe and Asia, with the oldest typically having originated in the 1980s. That decade, the sport developed a cult following in the United States when matches were broadcast on the fledgling ESPN network.[129] Growing international interest has been assisted by exhibition matches, players switching between football codes, and Australia's multicultural makeup. Many VFL\/AFL players were born overseas, with a growing number recruited through various initiatives. One notable example is the Irish experiment, which, since the 1980s, has seen many Gaelic footballers leave the amateur GAA to play Australian rules professionally.  Although Australian rules football is not an Olympic sport, it was showcased at the MCG as part of the 1956 Summer Olympics, held in Melbourne. In addition, when Brisbane hosted the 1982 Commonwealth Games, an exhibition match was held at the Gabba.[130]  Australian football has attracted more overall interest among Australians than any other football code,[131] and, when compared with all sports throughout the nation, has consistently ranked first in the winter reports, and third behind cricket and swimming in summer.[132] Over 1,057,572 fans were paying members of AFL clubs in 2019.[133]  The 2021 AFL Grand Final was the year's most-watched television broadcast in Australia, with an in-home audience of up to 4.11 million.[134][135]  In 2019, there were 1,716,276 registered participants in Australia[133] including 586,422 females (34 per cent of the overall total) and more than 177,000 registered outside Australia including 79,000 females (45 per cent of the overall total).[133]  Australian football has inspired many literary works,[136] from poems by C. J. Dennis and Peter Goldsworthy, to the fiction of Frank Hardy and Kerry Greenwood. Historians Manning Clarke and Geoffrey Blainey have also written extensively on the sport. Slang within Australian football has impacted Australian English more broadly, with a number of expressions taking on new meanings in non-sporting contexts, e.g., to \"get a guernsey\" is to gain recognition or approval, while \"shirt-fronting\" someone is to accost them.[137]  In 1889, Australian impressionist painter Arthur Streeton captured football games en plein air for the 9 by 5 Impression Exhibition, titling one work The National Game.[138] Paintings by Sidney Nolan (Footballer, 1946) and John Brack (Three of the Players, 1953) helped to establish Australian football as a serious subject for modernists,[139] and many Aboriginal artists have explored the game, often fusing it with the mythology of their region.[140][141] In cartooning, WEG's VFL\/AFL premiership posters\u2014inaugurated in 1954\u2014have achieved iconic status among Australian football fans.[142] Australian football statues can be found throughout the country, some based on famous photographs, among them Haydn Bunton Sr.'s leap, Jack Dyer's charge and Nicky Winmar lifting his jumper.[143] In the 1980s, a group of postmodern architects based in Melbourne began incorporating references to Australian football into their buildings, an example being Building 8 by Edmond and Corrigan.[144][145]  Dance sequences based on Australian football feature heavily in Robert Helpmann's 1964 ballet The Display, his first and most famous work for the Australian Ballet.[146] The game has also inspired well-known plays such as And the Big Men Fly (1963) by Alan Hopgood and David Williamson's The Club (1977), which was adapted into a 1980 film, directed by Bruce Beresford. Mike Brady's 1979 hit \"Up There Cazaly\" is considered an Australian football anthem, and references to the sport can be found in works by popular musicians, from singer-songwriter Paul Kelly to the alternative rock band TISM.[147] Many Australian football video games have been released, most notably the AFL series.  For the centenary of the VFL\/AFL in 1996, the Australian Football Hall of Fame was established. That year, 136 significant figures across the various competitions were inducted into the Hall of Fame. An additional 115 inductees have been added since the creation of the Hall of Fame, resulting in a total number of 251 inductees.[148]  In addition to the Hall of Fame, select members are chosen to receive the elite Legend status. Due to restrictions limiting the number of Legend status players to 10% of the total number of Hall of Fame inductees, there are currently 25 players with the status in the Hall of Fame.[148] "},{"title":"Canada","content":"  Canada is a country in North America. Its ten provinces and three territories extend from the Atlantic Ocean to the Pacific Ocean and northward into the Arctic Ocean, making it the world's second-largest country by total area, with the world's longest coastline. Its border with the United States is the world's longest international land border. The country is characterized by a wide range of both meteorologic and geological regions. It is a sparsely inhabited country of 40\u00a0million people, the vast majority residing south of the 55th parallel in urban areas. Canada's capital is Ottawa and its three largest metropolitan areas are Toronto, Montreal, and Vancouver.  Indigenous peoples have continuously inhabited what is now Canada for thousands of years. Beginning in the 16th century, British and French expeditions explored and later settled along the Atlantic coast. As a consequence of various armed conflicts, France ceded nearly all of its colonies in North America in 1763. In 1867, with the union of three British North American colonies through Confederation, Canada was formed as a federal dominion of four provinces. This began an accretion of provinces and territories and a process of increasing autonomy from the United Kingdom, highlighted by the Statute of Westminster, 1931, and culminating in the Canada Act 1982, which severed the vestiges of legal dependence on the Parliament of the United Kingdom.  Canada is a parliamentary democracy and a constitutional monarchy in the Westminster tradition. The country's head of government is the prime minister, who holds office by virtue of their ability to command the confidence of the elected House of Commons and is \"called upon\" by the governor general, representing the monarch of Canada, the ceremonial head of state. The country is a Commonwealth realm and is officially bilingual (English and French) in the federal jurisdiction. It is very highly ranked in international measurements of government transparency, quality of life, economic competitiveness, innovation, education and gender equality. It is one of the world's most ethnically diverse and multicultural nations, the product of large-scale immigration. Canada's long and complex relationship with the United States has had a significant impact on its history, economy, and culture.  A developed country, Canada has a high nominal per capita income globally and its advanced economy ranks among the largest in the world, relying chiefly upon its abundant natural resources and well-developed international trade networks. It is recognized as a middle power for its role in international affairs, with a tendency to pursue multilateral and international solutions. Canada's peacekeeping role during the 20th century has had a significant influence on its global image. Canada is part of multiple international organizations and forums.  While a variety of theories have been postulated for the etymological origins of Canada, the name is now accepted as coming from the St. Lawrence Iroquoian word kanata, meaning \"village\" or \"settlement\".[8] In 1535, Indigenous inhabitants of the present-day Quebec City region used the word to direct French explorer Jacques Cartier to the village of Stadacona.[9] Cartier later used the word Canada to refer not only to that particular village but to the entire area subject to Donnacona (the chief at Stadacona);[9] by 1545, European books and maps had begun referring to this small region along the Saint Lawrence River as Canada.[9]  From the 16th to the early 18th century, \"Canada\" referred to the part of New France that lay along the Saint Lawrence River.[10] In 1791, the area became two British colonies called Upper Canada and Lower Canada. These two colonies were collectively named the Canadas until their union as the British Province of Canada in 1841.[11]  Upon Confederation in 1867, Canada was adopted as the legal name for the new country at the London Conference and the word dominion was conferred as the country's title.[12] By the 1950s, the term Dominion of Canada was no longer used by the United Kingdom, which considered Canada a \"realm of the Commonwealth\".[13]  The Canada Act 1982, which brought the Constitution of Canada fully under Canadian control, referred only to Canada. Later that year, the name of the national holiday was changed from Dominion Day to Canada Day.[14] The term Dominion was used to distinguish the federal government from the provinces, though after the Second World War the term federal had replaced dominion.[15]   The first inhabitants of North America are generally hypothesized to have migrated from Siberia by way of the Bering land bridge and arrived at least 14,000 years ago.[16][17] The Paleo-Indian archeological sites at Old Crow Flats and Bluefish Caves are two of the oldest sites of human habitation in Canada.[18] The characteristics of Indigenous societies included permanent settlements, agriculture, complex societal hierarchies, and trading networks.[19][20] Some of these cultures had collapsed by the time European explorers arrived in the late 15th and early 16th centuries and have only been discovered through archeological investigations.[21] Indigenous peoples in present-day Canada include the First Nations, Inuit, and M\u00e9tis,[22] the last being of mixed descent who originated in the mid-17th century when First Nations people married European settlers and subsequently developed their own identity.[22] The Indigenous population at the time of the first European settlements is estimated to have been between 200,000[24] and two million,[25] with a figure of 500,000 accepted by Canada's Royal Commission on Aboriginal Peoples.[26] As a consequence of European colonization, the Indigenous population declined by forty to eighty percent and several First Nations, such as the Beothuk, disappeared.[27] The decline is attributed to several causes, including the transfer of European diseases, such as influenza, measles, and smallpox, to which they had no natural immunity,[24][28] conflicts over the fur trade, conflicts with the colonial authorities and settlers, and the loss of Indigenous lands to settlers and the subsequent collapse of several nations' self-sufficiency.[29][30]  Although not without conflict, European Canadians' early interactions with First Nations and Inuit populations were relatively peaceful.[31] First Nations and M\u00e9tis peoples played a critical part in the development of European colonies in Canada, particularly for their role in assisting European coureurs des bois and voyageurs in their explorations of the continent during the North American fur trade.[32] These early European interactions with First Nations would change from friendship and peace treaties to the dispossession of Indigenous lands through treaties.[33][34] From the late 18th century, European Canadians forced Indigenous peoples to assimilate into a western Canadian society.[35] These attempts reached a climax in the late 19th and early 20th centuries with forced integration through state-funded boarding schools,[36] health-care segregation,[37] and displacement.[38] A period of redress began with the formation of the Truth and Reconciliation Commission of Canada by the Government of Canada in 2008.[39] This included recognition of past colonial injustices and settlement agreements and betterment of racial discrimination issues, such as addressing the plight of missing and murdered Indigenous women.[39][40]  It is believed that the first documented European to explore the east coast of Canada was Norse explorer Leif Erikson.[42][43] In approximately 1000 AD, the Norse built a small short-lived encampment that was occupied sporadically for perhaps 20 years at L'Anse aux Meadows on the northern tip of Newfoundland.[44] No further European exploration occurred until 1497, when seafarer John Cabot explored and claimed Canada's Atlantic coast in the name of Henry VII of England.[45] In 1534, French explorer Jacques Cartier explored the Gulf of Saint Lawrence where, on July 24, he planted a 10-metre (33\u00a0ft) cross bearing the words, \"long live the King of France\", and took possession of the territory New France in the name of King Francis I.[46] The early 16th century saw European mariners with navigational techniques pioneered by the Basque and Portuguese establish seasonal whaling and fishing outposts along the Atlantic coast.[47] In general, early settlements during the Age of Discovery appear to have been short-lived due to a combination of the harsh climate, problems with navigating trade routes and competing outputs in Scandinavia.[48][49]  In 1583, Sir Humphrey Gilbert, by the royal prerogative of Queen Elizabeth I, founded St John's, Newfoundland, as the first North American English seasonal camp.[50] In 1600, the French established their first seasonal trading post at Tadoussac along the Saint Lawrence.[44] French explorer Samuel de Champlain arrived in 1603 and established the first permanent year-round European settlements at Port Royal (in 1605) and Quebec City (in 1608).[51] Among the colonists of New France, Canadiens extensively settled the Saint Lawrence River valley and Acadians settled the present-day Maritimes, while fur traders and Catholic missionaries explored the Great Lakes, Hudson Bay, and the Mississippi watershed to Louisiana.[52] The Beaver Wars broke out in the mid-17th century over control of the North American fur trade.[53]  The English established additional settlements in Newfoundland in 1610 along with settlements in the Thirteen Colonies to the south.[54][55] A series of four wars erupted in colonial North America between 1689 and 1763; the later wars of the period constituted the North American theatre of the Seven Years' War.[56] Mainland Nova Scotia came under British rule with the 1713 Treaty of Utrecht and Canada and most of New France came under British rule in 1763 after the Seven Years' War.[57]  The Royal Proclamation of 1763 established First Nation treaty rights, created the Province of Quebec out of New France, and annexed Cape Breton Island to Nova Scotia.[14] St John's Island (now Prince Edward Island) became a separate colony in 1769.[59] To avert conflict in Quebec, the British Parliament passed the Quebec Act 1774, expanding Quebec's territory to the Great Lakes and Ohio Valley.[60] More importantly, the Quebec Act afforded Quebec special autonomy and rights of self-administration at a time when the Thirteen Colonies were increasingly agitating against British rule.[61] It re-established the French language, Catholic faith, and French civil law there, staving off the growth of an independence movement in contrast to the Thirteen Colonies.[62] The Proclamation and the Quebec Act in turn angered many residents of the Thirteen Colonies, further fuelling anti-British sentiment in the years prior to the American Revolution.[14]  After the successful American War of Independence, the 1783 Treaty of Paris recognized the independence of the newly formed United States and set the terms of peace, ceding British North American territories south of the Great Lakes and east of the Mississippi River to the new country.[63] The American war of independence also caused a large out-migration of Loyalists, the settlers who had fought against American independence. Many moved to Canada, particularly Atlantic Canada, where their arrival changed the demographic distribution of the existing territories. New Brunswick was in turn split from Nova Scotia as part of a reorganization of Loyalist settlements in the Maritimes, which led to the incorporation of Saint John, New Brunswick, as Canada's first city.[64] To accommodate the influx of English-speaking Loyalists in Central Canada, the Constitutional Act of 1791 divided the province of Canada into French-speaking Lower Canada (later Quebec) and English-speaking Upper Canada (later Ontario), granting each its own elected legislative assembly.[65]  The Canadas were the main front in the War of 1812 between the United States and the United Kingdom. Peace came in 1815; no boundaries were changed.[67] Immigration resumed at a higher level, with over 960,000 arrivals from Britain between 1815 and 1850.[68] New arrivals included refugees escaping the Great Irish Famine as well as Gaelic-speaking Scots displaced by the Highland Clearances.[69] Infectious diseases killed between 25 and 33 percent of Europeans who immigrated to Canada before 1891.[24]  The desire for responsible government resulted in the abortive Rebellions of 1837.[70] The Durham Report subsequently recommended responsible government and the assimilation of French Canadians into English culture.[14] The Act of Union 1840 merged the Canadas into a united Province of Canada and responsible government was established for all provinces of British North America east of Lake Superior by 1855.[71] The signing of the Oregon Treaty by Britain and the United States in 1846 ended the Oregon boundary dispute, extending the border westward along the 49th parallel. This paved the way for British colonies on Vancouver Island (1849) and in British Columbia (1858).[72] The Anglo-Russian Treaty of Saint Petersburg (1825) established the border along the Pacific coast, but, even after the US Alaska Purchase of 1867, disputes continued about the exact demarcation of the Alaska\u2013Yukon and Alaska\u2013BC border.[73]  Following three constitutional conferences, the British North America Act, 1867 officially proclaimed Canadian Confederation on July 1, 1867, initially with four provinces: Ontario, Quebec, Nova Scotia, and New Brunswick.[75][76] Canada assumed control of Rupert's Land and the North-Western Territory to form the Northwest Territories, where the M\u00e9tis' grievances ignited the Red River Rebellion and the creation of the province of Manitoba in July 1870.[77] British Columbia and Vancouver Island (which had been united in 1866) joined the confederation in 1871 on the promise of a transcontinental railway extending to Victoria in the province within 10 years,[78] while Prince Edward Island joined in 1873.[79] In 1898, during the Klondike Gold Rush in the Northwest Territories, Parliament created the Yukon Territory. Alberta and Saskatchewan became provinces in 1905.[79] Between 1871 and 1896, almost one quarter of the Canadian population emigrated south to the US.[80]  To open the West and encourage European immigration, the Government of Canada sponsored the construction of three transcontinental railways (including the Canadian Pacific Railway), passed the Dominion Lands Act to regulate settlement and established the North-West Mounted Police to assert authority over the territory.[81][82] This period of westward expansion and nation building resulted in the displacement of many Indigenous peoples of the Canadian Prairies to \"Indian reserves\",[83] clearing the way for ethnic European block settlements.[84] This caused the collapse of the Plains Bison in western Canada and the introduction of European cattle farms and wheat fields dominating the land.[85] The Indigenous peoples saw widespread famine and disease due to the loss of the bison and their traditional hunting lands.[86] The federal government did provide emergency relief, on condition of the Indigenous peoples moving to the reserves.[87] During this time, Canada introduced the Indian Act extending its control over the First Nations to education, government and legal rights.[88]  Because Britain still maintained control of Canada's foreign affairs under the British North America Act, 1867, its declaration of war in 1914 automatically brought Canada into the First World War.[89] Volunteers sent to the Western Front later became part of the Canadian Corps, which played a substantial role in the Battle of Vimy Ridge and other major engagements of the war.[90] Out of approximately 625,000 Canadians who served in the First World War, some 60,000 were killed and another 172,000 were wounded.[91] The Conscription Crisis of 1917 erupted when the Unionist Cabinet's proposal to augment the military's dwindling number of active members with conscription was met with vehement objections from French-speaking Quebecers.[92] The Military Service Act brought in compulsory military service, though it, coupled with disputes over French language schools outside Quebec, deeply alienated Francophone Canadians and temporarily split the Liberal Party.[92] In 1919, Canada joined the League of Nations independently of Britain,[90] and the Statute of Westminster, 1931, affirmed Canada's independence.[93]  The Great Depression in Canada during the early 1930s saw an economic downturn, leading to hardship across the country.[94] In response to the downturn, the Co-operative Commonwealth Federation (CCF) in Saskatchewan introduced many elements of a welfare state (as pioneered by Tommy Douglas) in the 1940s and 1950s.[95] On the advice of Prime Minister William Lyon Mackenzie King, war with Germany was declared effective September 10, 1939, by King George VI, seven days after the United Kingdom. The delay underscored Canada's independence.[90]  The first Canadian Army units arrived in Britain in December 1939. In all, over a million Canadians served in the armed forces during the Second World War and approximately 42,000 were killed and another 55,000 were wounded.[96] Canadian troops played important roles in many key battles of the war, including the failed 1942 Dieppe Raid, the Allied invasion of Italy, the Normandy landings, the Battle of Normandy, and the Battle of the Scheldt in 1944.[90] Canada provided asylum for the Dutch monarchy while that country was occupied and is credited by the Netherlands for major contributions to its liberation from Nazi Germany.[97]  The Canadian economy boomed during the war as its industries manufactured military materiel for Canada, Britain, China, and the Soviet Union.[90] Despite another Conscription Crisis in Quebec in 1944, Canada finished the war with a large army and strong economy.[98]  The financial crisis of the Great Depression led the Dominion of Newfoundland to relinquish responsible government in 1934 and become a Crown colony ruled by a British governor.[99] After two referendums, Newfoundlanders voted to join Canada in 1949 as a province.[100]  Canada's post-war economic growth, combined with the policies of successive Liberal governments, led to the emergence of a new Canadian identity, marked by the adoption of the maple leaf flag in 1965,[101] the implementation of official bilingualism (English and French) in 1969,[102] and the institution of official multiculturalism in 1971.[103] Socially democratic programs were also instituted, such as Medicare, the Canada Pension Plan, and Canada Student Loans; though, provincial governments, particularly Quebec and Alberta, opposed many of these as incursions into their jurisdictions.[104]  Finally, another series of constitutional conferences resulted in the Canada Act 1982, the patriation of Canada's constitution from the United Kingdom, concurrent with the creation of the Canadian Charter of Rights and Freedoms.[106][107][108] Canada had established complete sovereignty as an independent country under its own monarchy.[109][110] In 1999, Nunavut became Canada's third territory after a series of negotiations with the federal government.[111]  At the same time, Quebec underwent profound social and economic changes through the Quiet Revolution of the 1960s, giving birth to a secular nationalist movement.[112] The radical Front de lib\u00e9ration du Qu\u00e9bec (FLQ) ignited the October Crisis with a series of bombings and kidnappings in 1970,[113] and the sovereigntist Parti Qu\u00e9b\u00e9cois was elected in 1976, organizing an unsuccessful referendum on sovereignty-association in 1980. Attempts to accommodate Quebec nationalism constitutionally through the Meech Lake Accord failed in 1990.[114] This led to the formation of the Bloc Qu\u00e9b\u00e9cois in Quebec and the invigoration of the Reform Party of Canada in the West.[115][116] A second referendum followed in 1995, in which sovereignty was rejected by a slimmer margin of 50.6 to 49.4 percent.[117] In 1997, the Supreme Court ruled unilateral secession by a province would be unconstitutional, and the Clarity Act was passed by Parliament, outlining the terms of a negotiated departure from Confederation.[114]  In addition to the issues of Quebec sovereignty, a number of crises shook Canadian society in the late 1980s and early 1990s. These included the explosion of Air India Flight 182 in 1985, the largest mass murder in Canadian history;[118] the \u00c9cole Polytechnique massacre in 1989, a university shooting targeting female students;[119] and the Oka Crisis of 1990,[120] the first of a number of violent confrontations between provincial governments and Indigenous groups.[121] Canada also joined the Gulf War in 1990 as part of a United States\u2013led coalition force and was active in several peacekeeping missions in the 1990s, including the UNPROFOR mission in the former Yugoslavia.[122] Canada sent troops to Afghanistan in 2001 but declined to join the United States\u2013led invasion of Iraq in 2003.[123]  In 2011, Canadian forces participated in the NATO-led intervention into the Libyan Civil War[124] and also became involved in battling the Islamic State insurgency in Iraq in the mid-2010s.[125] The country celebrated its sesquicentennial in 2017, three years before the COVID-19 pandemic in Canada began on January 27, 2020, with widespread social and economic disruption.[126] In 2021, the possible graves of hundreds of Indigenous people were discovered near the former sites of Canadian Indian residential schools.[127] Administered by various Christian churches and funded by the Canadian government from 1828 to 1997, these boarding schools attempted to assimilate Indigenous children into Euro-Canadian culture.[36]  By total area (including its waters), Canada is the second-largest country in the world, after Russia.[128] By land area alone, Canada ranks fourth, due to having the world's largest area of fresh water lakes.[129] Stretching from the Atlantic Ocean in the east, along the Arctic Ocean to the north, and to the Pacific Ocean in the west, the country encompasses 9,984,670\u00a0km2 (3,855,100\u00a0sq\u00a0mi) of territory.[130] Canada also has vast maritime terrain, with the world's longest coastline of 243,042 kilometres (151,019\u00a0mi).[131][132] In addition to sharing the world's largest land border with the United States\u2014spanning 8,891\u00a0km (5,525\u00a0mi)[a]\u2014Canada shares a land border with Greenland (and hence the Kingdom of Denmark) to the northeast, on Hans Island,[133] and a maritime boundary with France's overseas collectivity of Saint Pierre and Miquelon to the southeast.[134] Canada is also home to the world's northernmost settlement, Canadian Forces Station Alert, on the northern tip of Ellesmere Island\u2014latitude 82.5\u00b0N\u2014which lies 817 kilometres (508\u00a0mi) from the North Pole.[135]  Canada can be divided into seven physiographic regions: the Canadian Shield, the interior plains, the Great Lakes-St. Lawrence Lowlands, the Appalachian region, the Western Cordillera, Hudson Bay Lowlands, and the Arctic Archipelago.[136] Boreal forests prevail throughout the country, ice is prominent in northern Arctic regions and through the Rocky Mountains, and the relatively flat Canadian Prairies in the southwest facilitate productive agriculture.[130] The Great Lakes feed the St. Lawrence River (in the southeast) where the lowlands host much of Canada's economic output.[130] Canada has over 2,000,000 lakes\u2014563 of which are larger than 100\u00a0km2 (39\u00a0sq\u00a0mi)\u2014containing much of the world's fresh water.[137][138] There are also fresh-water glaciers in the Canadian Rockies, the Coast Mountains, and the Arctic Cordillera.[139] Canada is geologically active, having many earthquakes and potentially active volcanoes, notably Mount Meager massif, Mount Garibaldi, Mount Cayley, and the Mount Edziza volcanic complex.[140]  Average winter and summer high temperatures across Canada vary from region to region. Winters can be harsh in many parts of the country, particularly in the interior and Prairie provinces, which experience a continental climate, where daily average temperatures are near \u221215\u00a0\u00b0C (5\u00a0\u00b0F), but can drop below \u221240\u00a0\u00b0C (\u221240\u00a0\u00b0F) with severe wind chills.[141] In non-coastal regions, snow can cover the ground for almost six months of the year, while in parts of the north snow can persist year-round. Coastal British Columbia has a temperate climate, with a mild and rainy winter. On the east and west coasts, average high temperatures are generally in the low 20s \u00b0C (70s \u00b0F), while between the coasts, the average summer high temperature ranges from 25 to 30\u00a0\u00b0C (77 to 86\u00a0\u00b0F), with temperatures in some interior locations occasionally exceeding 40\u00a0\u00b0C (104\u00a0\u00b0F).[142]  Much of Northern Canada is covered by ice and permafrost. The future of the permafrost is uncertain because the Arctic has been warming at three times the global average as a result of climate change in Canada.[143] Canada's annual average temperature over land has risen by 1.7\u00a0\u00b0C (3.1\u00a0\u00b0F), with changes ranging from 1.1 to 2.3\u00a0\u00b0C (2.0 to 4.1\u00a0\u00b0F) in various regions, since 1948.[130] The rate of warming has been higher across the North and in the Prairies.[144] In the southern regions of Canada, air pollution from both Canada and the United States\u2014caused by metal smelting, burning coal to power utilities, and vehicle emissions\u2014has resulted in acid rain, which has severely impacted waterways, forest growth, and agricultural productivity in Canada.[145]  Canada is divided into 15 terrestrial and five marine ecozones.[147] These ecozones encompass over 80,000 classified species of Canadian wildlife, with an equal number yet to be formally recognized or discovered.[148] Although Canada has a low percentage of endemic species compared to other countries,[149] due to human activities, invasive species, and environmental issues in the country, there are currently more than 800 species at risk of being lost.[150] About 65 percent of Canada's resident species are considered \"Secure\".[151] Over half of Canada's landscape is intact and relatively free of human development.[152] The boreal forest of Canada is considered to be the largest intact forest on Earth, with approximately 3,000,000\u00a0km2 (1,200,000\u00a0sq\u00a0mi) undisturbed by roads, cities or industry.[153] Since the end of the last glacial period, Canada has consisted of eight distinct forest regions,[154] with 42 percent of its land area covered by forests (approximately 8 percent of the world's forested land).[155]  Approximately 12.1 percent of the nation's landmass and freshwater are conservation areas, including 11.4 percent designated as protected areas.[156] Approximately 13.8 percent of its territorial waters are conserved, including 8.9 percent designated as protected areas.[156] Canada's first National Park, Banff National Park established in 1885, spans 6,641 square kilometres (2,564\u00a0sq\u00a0mi)[157] of mountainous terrain, with many glaciers and ice fields, dense coniferous forest, and alpine landscapes.[158] Canada's oldest provincial park, Algonquin Provincial Park, established in 1893, covers an area of 7,653.45 square kilometres (2,955.01\u00a0sq\u00a0mi). It is dominated by old-growth forest with over 2,400 lakes and 1,200 kilometres of streams and rivers.[159] Lake Superior National Marine Conservation Area is the world's largest freshwater protected area, spanning roughly 10,000 square kilometres (3,900\u00a0sq\u00a0mi) of lakebed, its overlaying freshwater, and associated shoreline on 60 square kilometres (23\u00a0sq\u00a0mi) of islands and mainland.[160] Canada's largest national wildlife region is the Scott Islands Marine National Wildlife Area, which spans 11,570.65 square kilometres (4,467.45\u00a0sq\u00a0mi)[161] and protects critical breeding and nesting habitat for over 40 percent of British Columbia's seabirds.[162] Canada's 18 UNESCO Biosphere Reserves cover a total area of 235,000 square kilometres (91,000\u00a0sq\u00a0mi).[163]  Canada is described as a \"full democracy\",[164] with a tradition of liberalism,[165] and an egalitarian,[166] moderate political ideology.[167] An emphasis on social justice has been a distinguishing element of Canada's political culture.[168][169] Peace, order, and good government, alongside an Implied Bill of Rights, are founding principles of the Canadian government.[170][171]  At the federal level, Canada has been dominated by two relatively centrist parties practising \"brokerage politics\":[b] the centre-left leaning Liberal Party of Canada[178][179] and the centre-right leaning Conservative Party of Canada (or its predecessors).[180] The historically predominant Liberals position themselves at the centre of the political scale.[180] Five parties had representatives elected to the Parliament in the 2021 election\u2014the Liberals, who formed a minority government; the Conservatives, who became the Official Opposition; the New Democratic Party (occupying the left[181][182]); the Bloc Qu\u00e9b\u00e9cois; and the Green Party of Canada.[183] Far-right and far-left politics have never been a prominent force in Canadian society.[184][185][186]  Canada has a parliamentary system within the context of a constitutional monarchy\u2014the monarchy of Canada being the foundation of the executive, legislative, and judicial branches.[187][188][189][190] The reigning monarch is also monarch of 14 other Commonwealth countries (though, all are sovereign of one another[191]) and each of Canada's 10 provinces. To carry out most of their federal royal duties in Canada, the monarch appoints a representative, the governor general, on the advice of the prime minister.[192][193]  The monarchy is the source of sovereignty and authority in Canada.[190][194][195] However, while the governor general or monarch may exercise their power without ministerial advice in certain rare crisis situations,[194] the use of the executive powers (or royal prerogative) is otherwise always directed by the Cabinet, a committee of ministers of the Crown responsible to the elected House of Commons and chosen and headed by the prime minister,[196] the head of government. To ensure the stability of government, the governor general will usually appoint as prime minister the individual who is the current leader of the political party that can obtain the confidence of a majority of members in the House of Commons.[197] The Prime Minister's Office (PMO) is thus one of the most powerful institutions in government, initiating most legislation for parliamentary approval and selecting for appointment by the Crown, besides the aforementioned, the governor general, lieutenant governors, senators, federal court judges, and heads of Crown corporations and government agencies.[194] The leader of the party with the second-most seats usually becomes the leader of the Official Opposition and is part of an adversarial parliamentary system intended to keep the government in check.[198]  The Parliament of Canada passes all statute laws within the federal sphere. It comprises the monarch, the House of Commons, and the Senate. While Canada inherited the British concept of parliamentary supremacy, this was later, with the enactment of the Constitution Act, 1982, all but completely superseded by the American notion of the supremacy of the law.[200]  Each of the 338 members of Parliament in the House of Commons is elected by simple plurality in an electoral district or riding. The Constitution Act, 1982, requires that no more than five years pass between elections, although the Canada Elections Act limits this to four years with a \"fixed\" election date in October; general elections still must be called by the governor general and can be triggered by either the advice of the prime minister or a lost confidence vote in the House.[201][202] The 105 members of the Senate, whose seats are apportioned on a regional basis, serve until age 75.[203]  Canadian federalism divides government responsibilities between the federal government and the 10 provinces. Provincial legislatures are unicameral and operate in parliamentary fashion similar to the House of Commons.[195] Canada's three territories also have legislatures; but, these are not sovereign and have fewer constitutional responsibilities than the provinces.[204] The territorial legislatures also differ structurally from their provincial counterparts.[205]  The Bank of Canada is the central bank of the country.[206] The minister of finance and minister of innovation, science, and industry use the Statistics Canada agency for financial planning and economic policy development.[207] The Bank of Canada is the sole authority authorized to issue currency in the form of Canadian bank notes.[208] The bank does not issue Canadian coins; they are issued by the Royal Canadian Mint.[209]  The Constitution of Canada is the supreme law of the country and consists of written text and unwritten conventions.[210] The Constitution Act, 1867 (known as the British North America Act, 1867 prior to 1982), affirmed governance based on parliamentary precedent and divided powers between the federal and provincial governments.[211] The Statute of Westminster, 1931, granted full autonomy, and the Constitution Act, 1982, ended all legislative ties to Britain, as well as adding a constitutional amending formula and the Canadian Charter of Rights and Freedoms.[212] The Charter guarantees basic rights and freedoms that usually cannot be over-ridden by any government; though, a notwithstanding clause allows Parliament and the provincial legislatures to override certain sections of the Charter for a period of five years.[213]  Canada's judiciary plays an important role in interpreting laws and has the power to strike down acts of Parliament that violate the constitution. The Supreme Court of Canada is the highest court, final arbiter, and has been led since December 18, 2017, by Richard Wagner, the Chief Justice of Canada.[214] The governor general appoints the court's nine members on the advice of the prime minister and minister of justice.[215] The federal Cabinet also appoints justices to superior courts in the provincial and territorial jurisdictions.[216]  Common law prevails everywhere, except in Quebec, where civil law predominates.[217] Criminal law is solely a federal responsibility and is uniform throughout Canada.[218] Law enforcement, including criminal courts, is officially a provincial responsibility, conducted by provincial and municipal police forces.[219] In most rural and some urban areas, policing responsibilities are contracted to the federal Royal Canadian Mounted Police.[220]  Canadian Aboriginal law provides certain constitutionally recognized rights to land and traditional practices for Indigenous groups in Canada.[221] Various treaties and case laws were established to mediate relations between Europeans and many Indigenous peoples.[222] Most notably, a series of 11 treaties, known as the Numbered Treaties, were signed between the Indigenous peoples and the reigning monarch of Canada between 1871 and 1921.[223] These treaties are agreements between the Canadian Crown-in-Council, with the duty to consult and accommodate.[224] The role of Aboriginal law and the rights they support were reaffirmed by section 35 of the Constitution Act, 1982.[222] These rights may include provision of services, such as healthcare through the Indian Health Transfer Policy, and exemption from taxation.[225]  Canada is recognized as a middle power for its role in global affairs with a tendency to pursue multilateral and international solutions.[227][228][229] Canada's foreign policy based on international peacekeeping and security is carried out through coalitions, international organizations, and the work of numerous federal institutions.[230][231] The strategy of the Canadian government's foreign aid policy reflects an emphasis to meet the Sustainable Development Goals, while also providing assistance in response to foreign humanitarian crises.[232] The Canadian Security Intelligence Service (CSIS) is tasked with gathering and analyzing intelligence to prevent threats such as terrorism, espionage, and foreign interference,[233] while the Communications Security Establishment (CSE) is focused on cyber security and protecting Canada's digital infrastructure.[233]  Canada and the United States have a long, complex, and intertwined relationship;[234][235] they are close allies, co-operating regularly on military campaigns and humanitarian efforts.[236][237] Canada also maintains historic and traditional ties to the United Kingdom and to France,[238] along with both countries' former colonies through its membership in the Commonwealth of Nations and the Organisation internationale de la Francophonie.[239] Canada is noted for having a positive relationship with the Netherlands, owing, in part, to its contribution to the Dutch liberation during the Second World War.[97] Canada has diplomatic and consular offices in over 270 locations in approximately 180 foreign countries.[226]  Canada's peacekeeping role during the 20th century has played a major role in its positive global image.[240][241] The Suez Crisis of 1956, saw future prime minister Lester B. Pearson eased tensions by proposing the inception of the United Nations Peacekeeping Force, for which he was awarded the 1957 Nobel Peace Prize.[242] Canada has served in over 50 peacekeeping missions providing the greatest amount of peacekeepers during the Cold War.[243] Since the 21st century, Canadian direct participation in UN peacekeeping efforts has greatly declined.[244] The large decrease was a result of Canada directing its participation to UN-sanctioned military operations through NATO, rather than directly through the UN.[245] Canada has also faced controversy over its involvement in some foreign countries, notably the 1993 Somalia affair.[246]  As of 2024, Canada's military had over 3000 personnel deployed overseas in multiple operations.[248] The unified Canadian Forces (CF) comprise the Royal Canadian Navy, Canadian Army, and Royal Canadian Air Force. The nation employs a professional, volunteer force of approximately 68,000 active personnel and 27,000 reserve personnel\u2014increasing to 71,500 and 30,000 respectively under \"Strong, Secure, Engaged\"[249]\u2014with a sub-component of approximately 5,000 Canadian Rangers.[250][c] In 2022, Canada's military expenditure totalled approximately $26.9\u00a0billion, or around 1.2\u00a0percent of the country's gross domestic product (GDP)\u00a0\u2013 placing it 14th for military expenditure by country.[252]  Canada is a member of various international organizations and forums.[253] Canada was a founding member of the United Nations in 1945 and formed the North American Aerospace Defense Command together with the United States in 1958.[254] The country has membership in the World Trade Organization, the Five Eyes, the G7 and the Organisation for Economic Co-operation and Development (OECD).[227] The country joined the Organization of American States (OAS) in 1990,[255] and seeks to expand its ties to Pacific Rim economies through membership in the Asia-Pacific Economic Cooperation forum (APEC).[256] Canada ratified the Universal Declaration of Human Rights in 1948, and seven principal UN human rights conventions and covenants since then.[257]  Canada is a federation composed of 10 federated states, called provinces, and three federal territories. In turn, these may be grouped into four main regions: Western Canada, Central Canada, Atlantic Canada, and Northern Canada (Eastern Canada refers to Central Canada and Atlantic Canada together).[259] Provinces and territories have responsibility for social programs such as healthcare, education, and welfare,[260] as well as administration of justice (but not criminal law). Together, the provinces collect more revenue than the federal government, a rarity among other federations in the world. Using its spending powers, the federal government can initiate national policies in provincial areas such as health and child care; the provinces can opt out of these cost-share programs but rarely do so in practice. Equalization payments are made by the federal government to ensure reasonably uniform standards of services and taxation are kept between the richer and poorer provinces.[261]  The major difference between a Canadian province and a territory is that provinces receive their sovereignty from the Crown[262] and power and authority from the Constitution Act, 1867, whereas territorial governments have powers delegated to them by the Parliament of Canada[263] and the commissioners represent the King in his federal Council,[264] rather than the monarch directly. The powers flowing from the Constitution Act, 1867, are divided between the federal government and the provincial governments to exercise exclusively[265] and any changes to that arrangement require a constitutional amendment, while changes to the roles and powers of the territories may be performed unilaterally by the Parliament of Canada.[266]  Canada has a highly developed mixed-market economy,[268][269] with the world's ninth-largest economy as of 2023[update], and a nominal GDP of approximately US$2.221\u00a0trillion.[270] It is one of the world's largest trading nations, with a highly globalized economy.[271] In 2021, Canadian trade in goods and services reached $2.016\u00a0trillion.[272] Canada's exports totalled over $637\u00a0billion, while its imported goods were worth over $631\u00a0billion, of which approximately $391\u00a0billion originated from the United States.[272] In 2018, Canada had a trade deficit in goods of $22\u00a0billion and a trade deficit in services of $25\u00a0billion.[272] The Toronto Stock Exchange is the ninth-largest stock exchange in the world by market capitalization, listing over 1,500 companies with a combined market capitalization of over US$2\u00a0trillion.[273]  Canada has a strong cooperative banking sector, with the world's highest per-capita membership in credit unions.[274] It ranks low in the Corruption Perceptions Index (14th in 2023)[275] and \"is widely regarded as among the least corrupt countries of the world\".[276] It ranks high in the Global Competitiveness Report (14th in 2019)[277] and Global Innovation Index (15th in 2023).[278] Canada's economy ranks above most Western nations on The Heritage Foundation's Index of Economic Freedom[279] and experiences a relatively low level of income disparity.[280] The country's average household disposable income per capita is \"well above\" the OECD average.[281] Canada ranks among the lowest of the most developed countries for housing affordability[282][283] and foreign direct investment.[284][283]  Since the early 20th century, the growth of Canada's manufacturing, mining, and service sectors has transformed the nation from a largely rural economy to an urbanized, industrial one.[285] Like many other developed countries, the Canadian economy is dominated by the service industry, which employs about three-quarters of the country's workforce.[286] Among developed countries, Canada has an unusually important primary sector, of which the forestry and petroleum industries are the most prominent components.[287] Many towns in northern Canada, where agriculture is difficult, are sustained by nearby mines or sources of timber.[288]  Canada's economic integration with the United States has increased significantly since the Second World War.[290] The Automotive Products Trade Agreement of 1965 opened Canada's borders to trade in the automobile manufacturing industry.[291] The Canada\u00a0\u2013 United States Free Trade Agreement (FTA) of 1988 eliminated tariffs between the two countries, while the North American Free Trade Agreement (NAFTA) expanded the free-trade zone to include Mexico in 1994 (later replaced by the Canada\u2013United States\u2013Mexico Agreement).[292] As of 2023, Canada is a signatory to 15 free trade agreements with 51 different countries.[289]  Canada is one of the few developed nations that are net exporters of energy.[287][293] Atlantic Canada possess vast offshore deposits of natural gas,[294] and Alberta hosts the fourth-largest oil reserves in the world.[295] The vast Athabasca oil sands and other oil reserves give Canada 13\u00a0percent of global oil reserves, constituting the world's third or fourth-largest.[296] Canada is additionally one of the world's largest suppliers of agricultural products; the Canadian Prairies region is one of the most important global producers of wheat, canola, and other grains.[297] The country is a leading exporter of zinc, uranium, gold, nickel, platinoids, aluminum, steel, iron ore, coking coal, lead, copper, molybdenum, cobalt, and cadmium.[298][299] Canada has a sizeable manufacturing sector centred in southern Ontario and Quebec, with automobiles and aeronautics representing particularly important industries.[300] The fishing industry is also a key contributor to the economy.[301]  In 2020, Canada spent approximately $41.9\u00a0billion on domestic research and development, with supplementary estimates for 2022 at $43.2\u00a0billion.[302] As of 2023[update], the country has produced 15 Nobel laureates in physics, chemistry, and medicine.[303] The country ranks seventh in the worldwide share of articles published in scientific journals, according to the Nature Index,[304] and is home to the headquarters of a number of global technology firms.[305] Canada has one of the highest levels of Internet access in the world, with over 33\u00a0million users, equivalent to around 94 percent of its total population.[306]  Canada's developments in science and technology include the creation of the modern alkaline battery,[308] the discovery of insulin,[309] the development of the polio vaccine,[310] and discoveries about the interior structure of the atomic nucleus.[311] Other major Canadian scientific contributions include the artificial cardiac pacemaker, mapping the visual cortex,[312][313] the development of the electron microscope,[314][315] plate tectonics, deep learning, multi-touch technology, and the identification of the first black hole, Cygnus X-1.[316] Canada has a long history of discovery in genetics, which include stem cells, site-directed mutagenesis, T-cell receptor, and the identification of the genes that cause Fanconi anemia, cystic fibrosis, and early-onset Alzheimer's disease, among numerous other diseases.[313][317]  The Canadian Space Agency operates a highly active space program, conducting deep-space, planetary, and aviation research and developing rockets and satellites.[318] Canada was the third country to design and construct a satellite after the Soviet Union and the United States, with the 1962 Alouette 1 launch.[319] Canada is a participant in the International Space Station (ISS), and is a pioneer in space robotics, having constructed the Canadarm, Canadarm2, Canadarm3 and Dextre robotic manipulators for the ISS and NASA's Space Shuttle.[320] Since the 1960s, Canada's aerospace industry has designed and built numerous marques of satellite, including Radarsat-1 and 2, ISIS, and MOST.[321] Canada has also produced one of the world's most successful and widely used sounding rockets, the Black Brant.[322]  The 2021 Canadian census enumerated a total population of 36,991,981, an increase of around 5.2 percent over the 2016 figure.[324] It is estimated that Canada's population surpassed 40,000,000 in 2023.[325] The main drivers of population growth are immigration and, to a lesser extent, natural growth.[326] Canada has one of the highest per-capita immigration rates in the world,[327] driven mainly by economic policy and also family reunification.[328][329] A record 405,000 immigrants were admitted to Canada in 2021.[330] Canada leads the world in refugee resettlement; it resettled more than 28,000 in 2018.[331] New immigrants settle mostly in major urban areas in the country, such as Toronto, Montreal, and Vancouver.[332]  Canada's population density, at 4.2 inhabitants per square kilometre (11\/sq\u00a0mi), is among the lowest in the world.[324] Canada spans latitudinally from the 83rd parallel north to the 41st parallel north and approximately 95\u00a0percent of the population is found south of the 55th parallel north.[333] About 80 percent of the population lives within 150 kilometres (93\u00a0mi) of the border with the contiguous United States.[334] Canada is highly urbanized, with over 80 percent of the population living urban centres.[335] The most densely populated part of the country, accounting for nearly 50 percent, is the Quebec City\u2013Windsor Corridor in Southern Quebec and Southern Ontario along the Great Lakes and the St. Lawrence River.[336][333]  The majority of Canadians (81.1\u00a0percent) live in family households, 12.1\u00a0percent report living alone, and those living with other relatives or unrelated persons reported at 6.8\u00a0percent.[337] Fifty-one\u00a0percent of households are couples with or without children, 8.7\u00a0percent are single-parent households, 2.9\u00a0percent are multigenerational households, and 29.3\u00a0percent are single-person households.[337]   According to the 2021 Canadian census, over 450 \"ethnic or cultural origins\" were self-reported by Canadians.[339] The major panethnic groups chosen were: European (52.5\u00a0percent), North American (22.9\u00a0percent), Asian (19.3\u00a0percent), North American Indigenous (6.1\u00a0percent), African (3.8\u00a0percent), Latin, Central and South American (2.5\u00a0percent), Caribbean (2.1\u00a0percent), Oceanian (0.3\u00a0percent), and other (6\u00a0percent).[339][340] Over 60 percent of Canadians reported a single origin, and 36 percent of Canadians reported having multiple ethnic origins, thus the overall total is greater than 100\u00a0percent.[339]  The country's ten largest self-reported specific ethnic or cultural origins in 2021 were Canadian[d] (accounting for 15.6\u00a0percent of the population), followed by English (14.7\u00a0percent), Irish (12.1\u00a0percent), Scottish (12.1\u00a0percent), French (11.0\u00a0percent), German (8.1\u00a0percent), Chinese (4.7\u00a0percent), Italian (4.3\u00a0percent), Indian (3.7\u00a0percent), and Ukrainian (3.5\u00a0percent).[345]  Of the 36.3 million people enumerated in 2021, approximately 25.4 million reported being \"White\", representing 69.8\u00a0percent of the population.[346] The Indigenous population representing 5\u00a0percent or 1.8 million individuals, grew by 9.4\u00a0percent compared to the non-Indigenous population, which grew by 5.3\u00a0percent from 2016 to 2021.[346] One out of every four Canadians or 26.5\u00a0percent of the population belonged to a non-White and non-Indigenous visible minority,[347][e] the largest of which in 2021 were South Asian (2.6 million people; 7.1\u00a0percent), Chinese (1.7 million; 4.7\u00a0percent), and Black (1.5 million; 4.3\u00a0percent).[349]  Between 2011 and 2016, the visible minority population rose by 18.4\u00a0percent.[350] In 1961, about 300,000 people, less than two percent of Canada's population, were members of visible minority groups.[351] The 2021 census indicated that 8.3\u00a0million people, or almost one-quarter (23.0\u00a0percent) of the population, reported themselves as being or having been a landed immigrant or permanent resident in Canada\u2014above the 1921 census previous record of 22.3\u00a0percent.[352] In 2021, India, China, and the Philippines were the top three countries of origin for immigrants moving to Canada.[353]  A multitude of languages are used by Canadians, with English and French (the official languages) being the mother tongues of approximately 54\u00a0percent and 19\u00a0percent of Canadians, respectively.[337] As of the 2021 census, just over 7.8\u00a0million Canadians listed a non-official language as their mother tongue. Some of the most common non-official first languages include Mandarin (679,255 first-language speakers), Punjabi (666,585), Cantonese (553,380), Spanish (538,870), Arabic (508,410), Tagalog (461,150), Italian (319,505), German (272,865), and Tamil (237,890).[337] Canada's federal government practises official bilingualism, which is applied by the commissioner of official languages in consonance with section 16 of the Canadian Charter of Rights and Freedoms and the federal Official Languages Act. English and French have equal status in federal courts, Parliament, and in all federal institutions. Citizens have the right, where there is sufficient demand, to receive federal government services in either English or French and official-language minorities are guaranteed their own schools in all provinces and territories.[355]  Quebec's 1974 Official Language Act established French as the only official language of the province.[356] Although more than 82 percent of French-speaking Canadians live in Quebec, there are substantial Francophone populations in New Brunswick, Alberta, and Manitoba; Ontario has the largest French-speaking population outside Quebec.[357] New Brunswick, the only officially bilingual province, has a French-speaking Acadian minority constituting 33 percent of the population.[358] There are also clusters of Acadians in southwestern Nova Scotia, on Cape Breton Island, and in central and western Prince Edward Island.[359]  Other provinces have no official languages as such, but French is used as a language of instruction, in courts, and for other government services, in addition to English. Manitoba, Ontario, and Quebec allow for both English and French to be spoken in the provincial legislatures and laws are enacted in both languages. In Ontario, French has some legal status, but is not fully co-official.[360] There are 11 Indigenous language groups, composed of more than 65 distinct languages and dialects.[361] Several Indigenous languages have official status in the Northwest Territories.[362] Inuktitut is the majority language in Nunavut and is one of three official languages in the territory.[363]  Additionally, Canada is home to many sign languages, some of which are Indigenous.[364] American Sign Language (ASL) is used across the country due to the prevalence of ASL in primary and secondary schools.[365] Quebec Sign Language (LSQ) is used primarily in Quebec.[366]  Canada is religiously diverse, encompassing a wide range of beliefs and customs.[368] The Constitution of Canada refers to God and the monarch carries the title of Defender of the Faith; however, Canada has no official church and the government is officially committed to religious pluralism.[369] Freedom of religion in Canada is a constitutionally protected right, allowing individuals to assemble and worship without limitation or interference.[370]  Rates of religious adherence have steadily decreased since the 1970s.[368] With Christianity in decline after having once been central and integral to Canadian culture and daily life,[371] Canada has become a post-Christian, secular state.[372][373][374] Although the majority of Canadians consider religion to be unimportant in their daily lives,[375] they still believe in God.[376] The practice of religion is generally considered a private matter throughout Canadian society and by the state.[377]  According to the 2021 census, Christianity is the largest religion in Canada, with Roman Catholics representing 29.9\u00a0percent of the population having the most adherents. Christians overall representing 53.3\u00a0percent of the population,[f] are followed by people reporting irreligion or having no religion at 34.6\u00a0percent.[380] Other faiths include Islam (4.9\u00a0percent), Hinduism (2.3\u00a0percent), Sikhism (2.1\u00a0percent), Buddhism (1.0\u00a0percent), Judaism (0.9\u00a0percent), and Indigenous spirituality (0.2\u00a0percent).[381] Canada has the second-largest national Sikh population, behind India.[382]  Healthcare in Canada is delivered through the provincial and territorial systems of publicly funded health care, informally called Medicare.[383][384] It is guided by the provisions of the Canada Health Act of 1984[385] and is universal.[386] Universal access to publicly funded health services \"is often considered by Canadians as a fundamental value that ensures national healthcare insurance for everyone wherever they live in the country.\"[387] Around 30\u00a0percent of Canadians' healthcare is paid for through the private sector.[388] This mostly pays for services not covered or partially covered by Medicare, such as prescription drugs, dentistry and optometry.[388] Approximately 65 to 75\u00a0percent of Canadians have some form of supplementary health insurance; many receive it through their employers or access secondary social service programs.[389][388]  In common with many other developed countries, Canada is experiencing an increase in healthcare expenditures due to a demographic shift toward an older population, with more retirees and fewer people of working age. In 2021, the average age in Canada was 41.9 years.[337] Life expectancy is 81.1 years.[390] A 2016 report by the chief public health officer found that 88\u00a0percent of Canadians, one of the highest proportions of the population among G7 countries, indicated that they \"had good or very good health\".[391] Eighty\u00a0percent of Canadian adults self-report having at least one major risk factor for chronic disease: smoking, physical inactivity, unhealthy eating or excessive alcohol use.[392] Canada has one of the highest rates of adult obesity among OECD countries, contributing to approximately 2.7\u00a0million cases of diabetes.[392] Four chronic diseases\u2014cancer (leading cause of death), cardiovascular diseases, respiratory diseases, and diabetes\u2014account for 65\u00a0percent of deaths in Canada.[393][394]  In 2021, the Canadian Institute for Health Information reported that healthcare spending reached $308\u00a0billion, or 12.7 percent of Canada's GDP for that year.[395] In 2022, Canada's per-capita spending on health expenditures ranked 12th among health-care systems in the OECD.[396] Canada has performed close to, or above the average on the majority of OECD health indicators since the early 2000s, ranking above the average on OECD indicators for wait-times and access to care, with average scores for quality of care and use of resources.[397][398] The Commonwealth Fund's 2021 report comparing the healthcare systems of the 11 most developed countries ranked Canada second-to-last.[399] Identified weaknesses were comparatively higher infant mortality rate, the prevalence of chronic conditions, long wait times, poor availability of after-hours care, and a lack of prescription drugs and dental coverage.[399] An increasing problem in Canada's health system is a lack of healthcare professionals,[400] and hospital capacity.[401]  Education in Canada is for the most part provided publicly, funded and overseen by federal, provincial, and local governments.[402] Education is within provincial jurisdiction and a province's curriculum is overseen by its government.[403][404] Education in Canada is generally divided into primary education, followed by secondary and post-secondary education. Education in both English and French is available in most places across Canada.[405] Canada has a large number of universities, almost all of which are publicly funded.[406] Established in 1663, Universit\u00e9 Laval is the oldest post-secondary institution in Canada.[407] The largest university is the University of Toronto, with over 85,000 students.[408] Four universities are regularly ranked among the top 100 worldwide, namely University of Toronto, University of British Columbia, McGill University, and McMaster University, with a total of 18 universities ranked in the top 500 worldwide.[409]  According to a 2022 report by the OECD, Canada is one of the most educated countries in the world;[411][412] the country ranks first worldwide in the percentage of adults having tertiary education, with over 56 percent of Canadian adults having attained at least an undergraduate college or university degree.[413] Canada spends an average of 5.3\u00a0percent of its GDP on education.[414] The country invests heavily in tertiary education (more than US$20,000 per student).[415] As of 2022[update], 89 percent of adults aged 25 to 64 have earned the equivalent of a high-school degree, compared to an OECD average of 75 percent.[416]  The mandatory education age ranges between 5\u20137 to 16\u201318 years,[417] contributing to an adult literacy rate of 99 percent.[418] Just over 60,000 children are homeschooled in the country as of 2016. The Programme for International Student Assessment indicates Canadian students perform well above the OECD average, particularly in mathematics, science, and reading,[419][420] ranking the overall knowledge and skills of Canadian 15-year-olds as the sixth-best in the world, although these scores have been declining in recent years. Canada is a well-performing OECD country in reading literacy, mathematics, and science, with the average student scoring 523.7, compared with the OECD average of 493 in 2015.[421][422]  Canada's culture draws influences from its broad range of constituent nationalities and policies that promote a \"just society\" are constitutionally protected.[424][425][426] Since the 1960s, Canada has emphasized equality and inclusiveness for all its people.[427][428][429] The official state policy of multiculturalism is often cited as one of Canada's significant accomplishments[430] and a key distinguishing element of Canadian identity.[431][432] In Quebec, cultural identity is strong and there is a French Canadian culture that is distinct from English Canadian culture.[433] As a whole, Canada is in theory a cultural mosaic of regional ethnic subcultures.[434][435][436]  Canada's approach to governance emphasizing multiculturalism, which is based on selective immigration, social integration, and suppression of far-right politics, has wide public support.[437] Government policies such as publicly funded health care, higher taxation to redistribute wealth, the outlawing of capital punishment, strong efforts to eliminate poverty, strict gun control, a social liberal attitude toward women's rights (like pregnancy termination) and LGBT rights, and legalized euthanasia and cannabis use are indicators of Canada's political and cultural values.[438][439][440] Canadians also identify with the country's foreign aid policies, peacekeeping roles, the national park system, and the Canadian Charter of Rights and Freedoms.[441][442]  Historically, Canada has been influenced by British, French, and Indigenous cultures and traditions. Through their language, art, and music, Indigenous peoples continue to influence the Canadian identity.[443] During the 20th century, Canadians with African, Caribbean, and Asian nationalities have added to the Canadian identity and its culture.[444]  Themes of nature, pioneers, trappers, and traders played an important part in the early development of Canadian symbolism.[446] Modern symbols emphasize the country's geography, cold climate, lifestyles, and the Canadianization of traditional European and Indigenous symbols.[447] The use of the maple leaf as a Canadian symbol dates to the early 18th century. The maple leaf is depicted on Canada's current and previous flags and on the Arms of Canada.[448] Canada's official tartan, known as the \"maple leaf tartan\", has four colours that reflect the colours of the maple leaf as it changes through the seasons\u2014green in the spring, gold in the early autumn, red at the first frost, and brown after falling.[449] The Arms of Canada are closely modelled after those of the United Kingdom, with French and distinctive Canadian elements replacing or added to those derived from the British version.[450]  Other prominent symbols include the national motto, \"A mari usque ad mare\" (\"From Sea to Sea\"),[451] the sports of ice hockey and lacrosse, the beaver, Canada goose, common loon, Canadian horse, the Royal Canadian Mounted Police, the Canadian Rockies,[448] and, more recently, the totem pole and Inuksuk.[452] Canadian beer, maple syrup, tuques, canoes, nanaimo bars, butter tarts, and poutine are defined as uniquely Canadian.[452][453] Canadian coins feature many of these symbols: the loon on the $1 coin, the Arms of Canada on the 50\u00a2 piece, and the beaver on the nickel.[454] An image of the previous monarch, Queen Elizabeth II, appears on $20 bank notes and the obverse of all current Canadian coins.[454]  Canadian literature is often divided into French- and English-language literatures, which are rooted in the literary traditions of France and Britain, respectively.[455] The earliest Canadian narratives were of travel and exploration.[456] This progressed into three major themes that can be found within historical Canadian literature: nature, frontier life, and Canada's position within the world, all three of which tie into the garrison mentality.[457] In recent decades, Canada's literature has been strongly influenced by immigrants from around the world.[458] By the 1990s, Canadian literature was viewed as some of the world's best.[459]  Numerous Canadian authors have accumulated international literary awards,[460] including novelist, poet, and literary critic Margaret Atwood, who received two Booker Prizes;[461] Nobel laureate Alice Munro, who has been called the best living writer of short stories in English;[462] and Booker Prize recipient Michael Ondaatje, who wrote the novel The English Patient, which was adapted as a film of the same name that won the Academy Award for Best Picture.[463] L. M. Montgomery produced a series of children's novels beginning in 1908 with Anne of Green Gables.[464]  Canada's media is highly autonomous, uncensored, diverse, and very regionalized.[465][466] The Broadcasting Act declares \"the system should serve to safeguard, enrich, and strengthen the cultural, political, social, and economic fabric of Canada\".[467] Canada has a well-developed media sector, but its cultural output\u2014particularly in English films, television shows, and magazines\u2014is often overshadowed by imports from the United States.[468] As a result, the preservation of a distinctly Canadian culture is supported by federal government programs, laws, and institutions such as the Canadian Broadcasting Corporation (CBC), the National Film Board of Canada (NFB), and the Canadian Radio-television and Telecommunications Commission (CRTC).[469]  Canadian mass media, both print and digital, and in both official languages, is largely dominated by a \"handful of corporations\".[470] The largest of these corporations is the country's national public broadcaster, the Canadian Broadcasting Corporation, which also plays a significant role in producing domestic cultural content, operating its own radio and TV networks in both English and French.[471] In addition to the CBC, some provincial governments offer their own public educational TV broadcast services as well, such as TVOntario and T\u00e9l\u00e9-Qu\u00e9bec.[472]  Non-news media content in Canada, including film and television, is influenced both by local creators as well as by imports from the United States, the United Kingdom, Australia, and France.[473] In an effort to reduce the amount of foreign-made media, government interventions in television broadcasting can include both regulation of content and public financing.[474] Canadian tax laws limit foreign competition in magazine advertising.[475]  Art in Canada is marked by thousands of years of habitation by its Indigenous peoples,[477] and, in later times, artists have combined British, French, Indigenous, and American artistic traditions, at times embracing European styles while working to promote nationalism.[478] The nature of Canadian art reflects these diverse origins, as artists have taken their traditions and adapted these influences to reflect the reality of their lives in Canada.[479]  The Canadian government has played a role in the development of Canadian culture through the department of Canadian Heritage, by giving grants to art galleries,[480] as well as establishing and funding art schools and colleges across the country, and through the Canada Council for the Arts, the national public arts funder, helping artists, art galleries and periodicals, and thus contributing to the development of Canada's cultural works.[481]  Canadian visual art has been dominated by figures, such as painter Tom Thomson and the Group of Seven.[482] The latter were painters with a nationalistic and idealistic focus, who first exhibited their distinctive works in May 1920. Though referred to as having seven members, five artists\u2014Lawren Harris, A. Y. Jackson, Arthur Lismer, J. E. H. MacDonald, and Frederick Varley\u2014were responsible for articulating the group's ideas. They were joined briefly by Frank Johnston and commercial artist Franklin Carmichael. A. J. Casson became part of the group in 1926.[483] Associated with the group was another prominent Canadian artist, Emily Carr, known for her landscapes and portrayals of the Indigenous peoples of the Pacific Northwest Coast.[484]  Canadian music reflects a variety of regional scenes.[486] Canada has developed a vast music infrastructure that includes church halls, chamber halls, conservatories, academies, performing arts centres, record companies, radio stations, and television music video channels.[487] Government support programs, such as the Canada Music Fund, assist a wide range of musicians and entrepreneurs who create, produce and market original and diverse Canadian music.[488] As a result of its cultural importance, as well as government initiatives and regulations, the Canadian music industry is one of the largest in the world,[489] producing internationally renowned composers, musicians, and ensembles.[490] Music broadcasting in the country is regulated by the CRTC.[491] The Canadian Academy of Recording Arts and Sciences presents Canada's music industry awards, the Juno Awards.[492] The Canadian Music Hall of Fame honours Canadian musicians for their lifetime achievements.[493]  Patriotic music in Canada dates back over 200 years. The earliest work of patriotic music in Canada, \"The Bold Canadian\", was written in 1812.[494] \"The Maple Leaf Forever\", written in 1866, was a popular patriotic song throughout English Canada and, for many years, served as an unofficial national anthem.[495] \"O Canada\" also served as an unofficial national anthem for much of the 20th century and was adopted as the country's official anthem in 1980.[496] Calixa Lavall\u00e9e wrote the music, which was a setting of a patriotic poem composed by the poet and judge Sir Adolphe-Basile Routhier. The text was originally only in French before it was adapted into English in 1906.[497]  The roots of organized sports in Canada date back to the 1770s,[499] culminating in the development and popularization of the major professional games of ice hockey, lacrosse, curling, basketball, baseball, soccer, and Canadian football.[500] Canada's official national sports are ice hockey and lacrosse.[501] Other sports such as golf, volleyball, skiing, cycling, swimming, badminton, tennis, bowling, and the study of martial arts are all widely enjoyed at the youth and amateur levels.[502] Great achievements in Canadian sports are recognized by Canada's Sports Hall of Fame.[503] There are numerous other sport \"halls of fame\" in Canada, such as the Hockey Hall of Fame.[503]  Canada shares several major professional sports leagues with the United States.[504] Canadian teams in these leagues include seven franchises in the National Hockey League, as well as three Major League Soccer teams and one team in each of Major League Baseball and the National Basketball Association. Other popular professional competitions include the Canadian Football League, National Lacrosse League, the Canadian Premier League, and the various curling tournaments sanctioned and organized by Curling Canada.[505]  Canada has enjoyed success both at the Winter Olympics and at the Summer Olympics[506]\u2014though, particularly, the Winter Games as a \"winter sports nation\"\u2014and has hosted several high-profile international sporting events such as the 1976 Summer Olympics,[507] the 1988 Winter Olympics,[508] the 2010 Winter Olympics,[509][510] and the 2015 FIFA Women's World Cup.[511] Most recently, Canada hosted the 2015 Pan American Games and 2015 Parapan American Games in Toronto.[512] The country is scheduled to co-host the 2026 FIFA World Cup alongside Mexico and the United States.[513]  Overview  Culture  Demography and statistics  Economy  Foreign relations and military  Geography and environment  Government and law  History  Social welfare  Overviews  Government  Travel    60\u00b0N 110\u00b0W\ufeff \/ \ufeff60\u00b0N 110\u00b0W\ufeff \/ 60; -110 "},{"title":"Entrenched clause","content":"An entrenched clause or entrenchment clause of a constitution is a provision that makes certain amendments either more difficult or impossible to pass. Overriding an entrenched clause may require a supermajority, a referendum, or the consent of the minority party. The term eternity clause is used in a similar manner in the constitutions of Brazil, the Czech Republic,[1] Germany, Greece,[2] India,[3] Iran, Italy,[4] Morocco,[5] Norway,[4] and Turkey, but specifically applies to an entrenched clause that can never be overridden. However, if a constitution provides for a mechanism of its own abolition or replacement, like the German Basic Law does in Article 146, this by necessity provides a \"back door\" for getting rid of the \"eternity clause\", too.[citation needed]  Any amendment to a constitution that would not satisfy the prerequisites enshrined in a valid entrenched clause would lead to so-called \"unconstitutional constitutional law\"\u2014that is, an amendment to constitutional law text that appears constitutional by its form, albeit unconstitutional due to the procedure used to enact it or due to the content of its provisions.  Entrenched clauses are, in some cases, justified as protecting the rights of a minority from the dangers of majoritarianism. In other cases, the objective may be to prevent amendments to the constitution that would pervert the fundamental principles it enshrines. However, entrenched clauses are often challenged by their opponents as being undemocratic.  The Algerian Constitution of 2016 contains clauses about the numbers[clarification needed] and the duration of the presidential term.  Article 226 of the Constitution of Egypt, defining the amendment procedure, ends with an entrenched clause stating that \"In all cases, texts pertaining to the re-election of the president of the republic or the principles of freedom and equality stipulated in this Constitution may not be amended, unless the amendment brings more guarantees.\"[6]  This clause failed to block the 2019 amendments that replaced \"a president cannot be re-elected except once\" with \"a president cannot serve more than two consecutive terms\". The article also failed to block a new article from being added that excludes president Abdel Fattah el-Sisi from the two consecutive terms constraint, enabling him to run for a third term. Also, the duration of the term was increased from four years to six years.[7]  In the Constitution of Morocco, eternity clauses exist that ensure certain provisions cannot be amended, including the role of Islam in the nation's law, and the role of the King of Morocco in law.[5]  There are several examples of entrenched clauses that ultimately failed in their objectives, since their protections were undermined in unintended ways. For instance, the South Africa Act, the initial constitution of the Union of South Africa, contained entrenchment clauses protecting voting rights in the Cape Province, including those of some Coloureds, that required two-thirds of a joint session of parliament to be repealed. The Coloureds, however, later lost their voting rights after the Government restructured the Senate and packed it with its sympathisers so that they were able to achieve said supermajority in what is known as the Coloured vote constitutional crisis.  The Tunisian Constitution of 2014 prohibits amending the constitution to change the duration of the presidential term or the maximum number of terms an individual can serve.[8]  Entrenched clauses of the Constitution of Brazil are listed in Article 60, Paragraph 4:[9]  No proposal of amendment shall be considered which is aimed at abolishing: There are other clauses that implicitly cannot be amended, mostly because they are dependent of the subjects above.  The amendment formula for the Constitution of Canada (sections 38-49 of the Constitution Act, 1982) contains multiple levels of entrenchment, but the issues most firmly entrenched (which can only be changed by the federal government with the unanimous consent of all provinces) under section 41 are the monarchy, each province's minimum allocation of representatives in Parliament, English-French bilingualism, the composition of the Supreme Court of Canada, and section 41 itself.  The Constitution of Honduras has an article stating that the article itself and certain other articles cannot be changed in any circumstances. Article 374 of the Honduras Constitution asserts this unmodifiability, stating, \"It is not possible to reform, in any case, the preceding article, the present article, the constitutional articles referring to the form of government, to the national territory, to the presidential period, the prohibition to serve again as President of the Republic, the citizen who has performed under any title in consequence of which she\/he cannot be President of the Republic in the subsequent period.\"[10] This unmodifiable article played an important role in the 2009 Honduran constitutional crisis.  Article V of the United States Constitution temporarily shielded certain clauses in Article I from being amended. The first clause in Section 9, which prevented Congress from passing any law that would restrict the importation of slaves prior to 1808, and the fourth clause in that same section, a declaration that direct taxes must be apportioned according to the state populations, were explicitly shielded from constitutional amendment prior to 1808.[11]  Article V also shields the first clause of Article I, Section 3, which provides for equal representation of the states in the United States Senate, from being amended.[12] This has been interpreted to require unanimous ratification of any amendment altering the composition of the Senate.[13] However, the text of the clause would indicate that the size of the Senate could be changed by an ordinary amendment if each state continued to have equal representation. Alternatively, Article V theoretically could be amended to remove such an entrenched clause designation, and then the clause could be amended itself.  The Crittenden Compromise and Corwin Amendment, both proposed in the months leading up to the Civil War but never passed, would have enshrined slavery in the Constitution and prevented Congress from interfering with it.  As Australian Parliaments have inherited the British principle of parliamentary sovereignty, they may not entrench themselves by a regular act. Therefore, the entrenchment of the national flag in the Flags Act of 1953 is without force as the entrenchment clause could be removed (through normal legislative amendment) by later parliaments.[14]  The Commonwealth Constitution is entrenched as it may only be amended by referendum; the amendment must gain the support of a majority of Australian voters nationwide, plus a majority of voters in a majority of states. These provisions are specified in section 128. The Imperial Parliament's power to amend it in Australian law was limited by the Statute of Westminster Adoption Act 1942 and terminated by the Australia Act 1986.  State laws respecting the constitution, powers or procedure of the parliament of a state need to follow any restrictions specified in state law on such acts, by virtue of section 6 of the Australia Act. This power does not extend to the whole constitution of the state, and the Parliament of Queensland has ignored entrenchments in amending its constitution.[15] Consequently, it is possible that the entrenchment clauses are unentrenchable, preventing state law from having effectively entrenching clauses.[15]  The Supreme Court has developed the basic structure doctrine which holds that certain features of the constitution are fundamental in nature and cannot be modified through parliamentary amendment. The Supreme Court has yet to clearly delimit which, if any, provisions constitute the components of the basic structure.  Article 37 on Chapter 16 of the Constitution of Indonesia governs the constitutional amendment procedure, yet it also specifies that the status of Indonesia as a unitary state is unmodifiable. The Ministry of Home Affairs, the Ministry of Defense as well as the Ministry of Foreign Affairs is also stated within the Constitution to not be dissolvable.  The final Article of the Constitution of the Islamic Republic of Iran, Art. 177, ensures that particular aspects of the Constitution are unalterable. These include the Islamic character of government and laws, the objectives of the republic, the democratic character of the government, \"the absolute wilayat al-'amr and the leadership of the Ummah\", the administration of the country by referendum, and the official religion of Islam.[16][unreliable source?]  Another example of entrenchment would be the entrenching of portions of the Malaysian Constitution related to the Malaysian social contract, which specifies that citizenship be granted to the substantial Chinese and Indian immigrant populations in return for the recognition of a special position for the indigenous Malay majority. The Constitution did not initially contain an entrenched clause; indeed, one of the articles later entrenched, Article 153, was initially intended to be subject to a sunset clause. However, after the May 13 incident of racial rioting in 1969, Parliament passed the Constitution (Amendment) Act 1971. The Act permitted criminalisation of the questioning of Articles 152, 153, 181, and Part III of the Constitution.  Article 152 designates the Malay language as the national language of Malaysia; Article 153 grants the Malays special privileges; Article 181 covers the position of the Malay rulers; and Part III deals with matters of citizenship. The restrictions, which even covered Members of Parliament, made the repeal of these sections of the Constitution unamendable or repealable by de facto; however, to entrench them further, the Act also amended Article 159(5), which covers Constitutional amendments, to prohibit the amending of the aforementioned Articles, as well as Article 159(5), without the consent of the Conference of Rulers \u2014 a non-elected body comprising the rulers of the Malay states and the governors of the other states.[17]  Section 268 of the Electoral Act (part of the Constitution of New Zealand) declares that the law governing the maximum term of Parliament, along with certain provisions of the Electoral Act relating to the redistribution of electoral boundaries, the voting age, and the secret ballot, may only be altered either by three-quarters of the entire membership of the House of Representatives, or by a majority of valid votes in a popular referendum.   However, Section 268 is not itself protected by this provision, so a government could legally repeal Section 268 and go on to alter the entrenched portions of law, both with a simple majority in Parliament.[18][19]  Article 4 of Part 1 of the Constitution of Turkey states that the \"provision of Article 1 of the Constitution establishing the form of the state as a Republic, the provisions in Article 2 on the characteristics of the Republic, and the provision of Article 3 shall not be amended, nor shall their amendment be proposed.\"  Article X of the Constitution of Bosnia and Herzegovina, defining the amendment procedure, provides in paragraph 2 that the rights and freedoms as established in Article II of the Constitution may not be eliminated or diminished, and that the paragraph 2 itself may not be altered.  Article 9 of the Czech Constitution, which concerns supplementing and amending the Constitution, states that \"the substantive requisites of the democratic, law-abiding State may not be amended\". This provision was invoked in 2009 when the Constitutional Court of the Czech Republic struck down a Constitutional Act adopted to invoke a one-off early legislative election. The disputed Act was judged to be an individual decision in violation of then-effective constitutional procedure regulating early elections.  The Constitution also contains an explicit eternity clause whereby the Constitutional Court is the ultimate arbiter of the effect of European law on the Constitution.[1]  Article 1 of Estonian Constitution states that \"The independence and sovereignty of Estonia are timeless and inalienable.\" As part of Chapter 1 of the Constitution, this provision may only be changed by a referendum (and such a referendum could only be organized after obtaining a 3\/5 supermajority in the parliament). This provision, however, does not prevent Estonia from being a member of the European Union and delegating some of its decision-making power to central EU institutions as long as \"fundamental constitutional principles\" are not breached (according to the special Constitution Amendment Act passed on a referendum in 2003).  The French Constitution states in Title XVI, Article 89, On Amendments to the Constitution, \"The republican form of government shall not be the object of any amendment\" thus forbidding the restoration of the monarchy or the empire.  The German eternity clause (German: Ewigkeitsklausel) is Article 79 paragraph (3) of the Basic Law for the Federal Republic of Germany (German: Grundgesetz). The eternity clause establishes that certain fundamental principles of Germany's democracy can never be removed, even by parliament.[20] The fundamental principles, (i.e., \"the basic principles\" of Articles 1 and 20), are as follows:  The original purpose of this eternity clause was to ensure that the establishment of any dictatorship in Germany would be clearly illegal; in legal practice the clause was used by plaintiffs at the Federal Constitutional Court challenging constitutional amendments that affected Articles 1, 10, 19, 101, and 103 regarding restrictions of legal recourse.[further explanation needed]  Although these basic principles are protected from being repealed, their particular expression may still be amended, such as to clarify, extend or refine an entrenched principle.  The Parlamentarischer Rat (Parliamentary Council) included the eternity clause in its Basic Law specifically to prevent a new \"legal\" pathway to a dictatorship as was the case in the Weimar Republic with the Enabling Act of 1933[21] and Article 48 of the Weimar Constitution.  It is not lawful for any political party, any legislation or any national commitment to violate \"the basic principles\" of \"this Basic Law\" laid down in Articles 1 and 20. Furthermore, the only way that Articles 1 and 20 can be removed is through Article 146, which requires \"a constitution that is adopted by a free decision of the German People\".[21]  So long as the principles of Articles 1 and 20 are retained, they may be amended (as Article 20 has indeed been amended to establish a 'right of resistance'), but the full protection of the eternity clause does not extend to such amendments.  Unlike the Weimar Constitution, which made human rights only an objective, the eternity clause and Articles 1 and 20 make specific demands of \"all state authority\" regarding \"human rights\" (that is, \"the basic rights\" guaranteed in \"this Basic Law\") and have established specific legislative, executive and judicial organs in \"the constitutional order\" of \"this Basic Law\", each with separate functions bound by the law. These are \"the basic principles\" of the democratic rule of law (German: Rechtsstaat) and the separation of powers, which are principles endorsed by three United Nations resolutions.[22][vague]  The Greek eternity clause is Article 110 of the Greek Constitution. This article states that every article of the Constitution can be revised by the Parliament, with the exception of the fundamental ones, which establish Greece as a parliamentary republic and those of articles 2 paragraph 1, article 4 paragraphs 1, 4 and 7, article 5 paragraphs 1 and 3, article 13 paragraph 1 and article 26.[23] These fundamental articles include:[24]  The Constitution of the Irish Free State was required in parts to be consistent with the 1922 Anglo-Irish Treaty, including the Oath of Allegiance and the Governor-General. The checks to protect this were removed by, for example, the Irish taking control of advice to the Governor-General, and when the Senate proved obstructive, its abolition.  In debate surround 2018 relaxation of abortion laws there were proposals to entrench certain aspects of the legislation, which was deemed unconstitutional.[25] An attempt to overturn the 34th Amendment to the constitution on the basis that amendments were impermissible if they contradicted other provisions of the constitution was rejected by the Court of Appeal.[26]  Article 139 of the Constitution of Italy, which came into effect in 1948, provides that the republican form of government shall not be a matter for constitutional amendment.  In the Constitution of Portugal, an eternity clause exists in the form of article 288. Titled Material limits on revision, it provides that the following can never be removed through amendment:  Most of the body of the Constitution of Spain can be modified by a three-fifths majority of both chambers of the Cortes Generales, or an absolute majority of the Senate and a two-thirds majority of the Congress of Deputies if the first method of approval fails.  However, modifications of the Preliminary Title (sovereignty and constitutional principles), the First Section of the First Title (fundamental rights and liberties of the Spaniards), or the Second Title (the Monarchy), as well as drafting a full new Constitution replacing the current, would require a two-thirds majority of both chambers, an immediate new general election, a two-thirds majority of the newly elected chambers, and a final referendum.  Constitutional amendments cannot be introduced during wartime or state of emergency.[27]  The doctrine of parliamentary supremacy holds that Parliament may pass any law it wishes, with the exception that it cannot bind its successors (or be limited by its predecessors). Moreover, the UK's constitution is uncodified, being contained instead in informal conventions, standing orders of the two Houses of Parliament, and ordinary legislation (in particular Acts of Parliament). Therefore, the constitution is unentrenched as previous legislation can be amended by the passing of statute, requiring a simple majority vote in the House of Commons.  Notions of entrenchment have emerged in consideration of a number of constitutional statutes, including the Parliament Acts 1911 and 1949. (See R (Jackson) v Attorney General [2005] UKHL 56.)[28]  Andrew Blick, Senior Lecturer in Politics at King's College London, argues that the use of a supermajority requirement for the House of Commons in the Fixed-term Parliaments Act 2011 represents a move towards entrenched clauses in the UK Constitution.[29] Nevertheless, after failing to secure the required supermajority for an election in 2019, the government passed the Early Parliamentary General Election Act 2019, which only required a simple majority, to override the act and call an early general election. The Fixed-term Parliaments Act 2011 was subsequently repealed and replaced by the Dissolution and Calling of Parliament Act 2022, which deleted the supermajority requirement altogether and reinstated the government's power to call an election at will.  Provisions may also be entrenched in the constitutions of corporate bodies. An example is in the memoranda and articles of a company limited by guarantee, in which the principles of common ownership may be entrenched. This practice can make it almost impossible for the company's members to dissolve the company and distribute its assets amongst them. This idea has more recently been extended in the UK through the invention of the community interest company (CIC), which incorporates an asset lock.[30] Other companies in the UK may make provision for entrenchment of certain articles so that, for example, the specified articles may only be amended or repealed by agreement of all the members of the company or by a court order.[31] In India there is similar provision in section 5 of the Companies Act 2013.[32] "},{"title":"Roller in-line hockey","content":"  Roller in-line hockey, American roller hockey or inline hockey, is a variant of hockey played on a hard, smooth surface, with players using inline skates to move and ice hockey sticks to shoot a hard, plastic puck into their opponent's goal to score points.[1] The sport is a very fast-paced and free-flowing game and is considered a contact sport, but body checking is prohibited. There are five players including the goalkeeper from each team on the rink at a time, while teams normally consist of 16 players.[2] There are professional leagues, one of which is the National Roller Hockey League (NRHL). While it is not a contact sport, there are exceptions, i.e. the  NRHL involves fighting.  Unlike ice hockey, there are no blue lines or defensive zones in roller hockey. This means that, according to most rule codes, there are no offsides or icings that can occur during gameplay. This along with fewer players on the rink allows for faster gameplay. There are traditionally two 20-minute periods or four 10-minute periods with a stopped clock.  In the United States, the highest governing body for the sport is USA Roller Sports (USARS). USARS is credited with the development of the present-day rules and regulations that is used throughout multiple tournament series. They organize tournaments across the United States but they are not the only tournament provider. Some of the other independent tournament providers include Amateur Athletic Union, North American Roller Championships, and the Torhs 2 Hot 4 Ice tournament series.[2] Internationally, inline hockey is represented by two different unions, the World Skate and the International Ice Hockey Federation (IIHF). Each organizes its own annual world championships.  Due to the 2022 Russian invasion of Ukraine, World Skate banned Russian and Belarusian athletes and officials from its competitions, and will not stage any events in Russia or Belarus in 2022.[3]  Some of the earliest video evidence of the sport is newsreel footage from the Giornale Luce taken in Vienna, Austria in 1938.[4] The video shows players using inline skates with five metal wheels and a front wheel brake. Each team has four skaters plus a netminder. They are using ice hockey sticks, with taped blades, and the goals closely resemble ice hockey goals of the wire-mesh type common in Europe around that time. The game is being played with a ball on a rectangular outdoor court, which appears to be asphalt.  The exact same footage was used in a newsreel produced by British Path\u00e9 in 1938.[5]  In the United States, the USA Roller Sports (USARS) predecessor organization was the Roller Skating Rink Operators Association (RSROA). In 1940, the RSROA published a set of roller hockey rules drawn from a booklet by the National Hockey League (NHL) which was designed to grow interest in playing hockey on roller skates. However, because of the intervention of World War II, the organization of roller hockey tournaments did not receive significant development until after this war in the late 1940s. At first skating club interest was confined to the northern tier of the United States, including the bordering Canadian cities. Puck roller hockey's spread in popularity during that period was helped along by the attention of local commercial television, which was getting its start and in desperate need for events to fill air time. The increased interest in the sport led in 1959 to the selection of a National Puck Hockey Committee to formulate special rules for the performance of puck hockey in the variety of rink sizes available to roller skates. The American Roller Hockey Association (ARHA) was formed with Joe Spillman, a roller rink operator from San Antonio, Texas as its first Commissioner. Under Spillman's direction, the sport of hockey on roller skates grew rapidly throughout the United States.  During the 1960 RSROA National Roller Skating Championships held in Little Rock, Arkansas, exhibition games for ball and puck roller hockey were held. Following these Nationals, the first full competitive season officially began in North America for roller hockey. This, of course, had puck roller hockey entirely performed on quad skates, for at that time there were no inline skates available. State and regional competitions determined the teams that would move on to the North American Championships.   In 1962, at Pershing Auditorium in Lincoln, Nebraska, both ball and puck hockey were part of the North American Championships. The Arcadia Wildcats from Detroit, Michigan, defeated the Van Wert Chiefs 3\u20131, becoming the first puck hockey national champions on quad skates.[6] Inline skates were not commercially available during that era.   On 1 September 1965, during their semi-annual board meeting, the RSROA installed puck hockey as an equal and separate division of roller hockey, which included ball hockey, a format most popular in Europe and South America. It was decided that both ball and puck hockey would compete under the same rules and award separate gold medal winners. Budd Van Roekel, RSROA president, was quoted in the January 1965 issue of Skate Magazine,  We believe this move will spark further growth of our roller hockey program. While we recognize the popularity of the international ball-and-cane version of hockey, we also realize that thousands of potential United States and Canadian players are more familiar with the Canadian stick-and-puck type sport. We see no reason why the two versions of the sport cannot grow side by side. The 1966 North American Championships marked the return of puck hockey after a four-year hiatus. The final game was a nail biter and the crowd appreciated the fast pace and excitement of puck hockey. The final game was between the Canadians of Windsor, Ontario and the Wildcats of Detroit, Michigan, the defending champions from 1962. The score seesawed between the two teams and was finally decided in favor of the Canadians with a final score of 5 to 3.  The win gave the Canadian team their only gold medal for the whole North American Championships. One Canadian team player was quoted in the 1966 Fall issue of Skate Magazine, \"We simply had to win the (puck) hockey championships, otherwise our fathers wouldn't allow us to return home.\" Another milestone occurred for puck roller hockey in 1977, when the North American Puck Hockey Championship was held in a venue away from ball hockey for the first time. The 1977 puck championships were staged in Houston, Texas to large crowds and a great amount of publicity, as fourteen newspapers and television stations covered the event. The year 1977 was also a milestone for women with this championship marking the debut of a women's hockey national championship.  The very first inline roller hockey team to earn a USA National Championship title did so at a USA Roller Sports (USARS) National Championship held in San Diego in July 1993. At the previous 1992 USARS National Championships, also staged in San Diego, the San Diego Hosers won the Senior Gold Division title wearing their customary quad roller skates. As of that time, the Hosers manager\/coach Paul Chapey felt that while inline skates were obviously faster, the advantage was to quad skates because of their assumed greater maneuverability. Some teams and individual players at the 1992 Nationals had been equipped with inline skates, but perhaps had not yet mastered their new vehicles. During the ensuing year, Paul Chapey became an inline convert and the San Diego Hosers came back to the USAC\/RS Nationals in 1993 entirely on inline skates and recaptured their national title. This significant event took place at least a year before all the other major roller inline hockey organizations were even in existence, including National Inline Hockey Association (NIHA), USA Hockey InLine, North American Roller Hockey Championships (NARCh) and American Inline Roller Hockey Series (AIRHS).  USA Roller Sports, under the auspices of F\u00e9d\u00e9ration Internationale de Roller Sports (FIRS), established and hosted the first World Inline Roller Hockey Championships for men at the Odeum Arena in Villa Park, Illinois (a suburb of Chicago) in 1995. USA Roller Sports established the first Inline Hockey World Championships for Juniors, again in Chicago in 1996, following the USA National Championships. The first World Inline Hockey Championships for Women occurred under sponsorship of USA Roller Sports in Rochester, New York in 2002. Since the introduction of these events, FIRS National Federations around the world have annually perpetuated inline world championships. USA (Ice) Hockey and International Ice Hockey Federation (IIHF) began their men's InLine Hockey World Championship in 1996, after the first such world championship by FIRS and has yet to organize a women's inline hockey world tournament or one for juniors.  In March 2002, the United States Olympic Committee (USOC) Membership and Credentials Committee officially reaffirmed that USA Roller Sports as the governing body for inline hockey in the United States, which continues to this day. This determination was based on a conclusion by the USOC that internationally the sport of inline hockey is recognized as a discipline of roller sports. Then, as now, USA Roller Sports is a member in good standing of Federation International de Roller Sports (\"FIRS\"), the international federation for roller sports as recognized by the International Olympic Committee, and FIRS is also recognized by the Pan American Sports Organization (PASO) as the controlling international federation for inline hockey, a sport of the Pan American Games.  For training purposes especially for hockey players, inline skates were produced in small quantities by several companies which were in fact modified ice skates, one of them was the \"Speedy\" by SKF which was available also with hockey-wheels. This changed when mass-produced inline skates from the USA were available in the early 1990s. In the mid-1990s first leagues started.  Inline roller hockey was introduced to the World Games for the first time in 2005, an International Olympic Committee (IOC) sanctioned event under the jurisdiction of the International World Games Association (IWGA), an affiliate of the General Association of International Sports Federations (GAISF). The United States won the gold medal, with Canada taking the Silver and Switzerland the bronze medal. Inline roller hockey replaced rink hockey (ball and cane) on the World Games program for Duisburg, Germany at the 2005 quadrennial World Games. Rink roller hockey had been part of the World Games since its first organization in 1979 at Santa Clara, California, as have the other disciplines of roller sports.  During the General Assembly of the IWGA, which took place in Madrid on 14 May 2003, the IWGA unanimously agreed that inline roller hockey was the responsibility of FIRS and that this variant form of roller hockey would be included on the program of the 2005 World Games in place of the previous format. This same scenario had previously played out before the Pan American Sports Organization in 1999, when inline hockey made its first appearance at the Pan American Games in Canada, and repeated again four years later in the Dominican Republic. PASO extends continued recognition of the inline hockey under the jurisdiction of FIRS. (sub to PAPA H)  Due to the 2022 Russian invasion of Ukraine, World Skate banned Russian and Belarusian athletes and officials from its competitions, and will not stage any events in Russia or Belarus in 2022.[3]  National Roller Hockey League is a professional league, founded in 2014.  The NRHL began its inaugural season 20 February 2015.  The NRHL games consist of 3 15-minute periods, with 10 minute intermissions.  It differs from professional ice hockey with rules including no offsides, and no icing. The NRHL permits fighting, with a 5-minute major penalty assessed to the combatants. The players in the NRHL pay nothing to play, with compensation opportunities available in the inaugural season. Players were paid a per game basis in the second season of the NRHL, based on a win or loss. The players were paid double for a win than a loss. The Detroit Bordercats won the inaugural Commissioner's Cup. The Bordercats repeated as Commissioner's Cup champions for the second season. The NRHL is expanding its role as a professional league in the summer of 2020. The NRHL will have franchises located throughout the United States and\/or Canada in arenas with a minimum stadium seating capacity of 3,000. The season will operate from May through August.[7]  MLRH (Major League Roller Hockey), is played in the United States and Europe. It consists of East and West Coast divisions, and the season is played from October to March with finals being held in either Europe or the USA. This is the only full check inline league in the world and it has a $10,000 championship purse. It has similar rules as the NHL, with some exceptions and only having two 17 min periods and in the \"Super\" League, 4 x 12 minute quarters. MLRH has offside and icing rules as well as allowing players to have a single fight per game.  The French Ligue Elite  is a professional league in Europe.  Although inline hockey appears to simply be ice hockey on inline skates, this singular difference reflects throughout the rest of the game, resulting in important differences between the two sports.  Inline hockey is typically played at room temperature on a surface that, rather than being made from (frozen) water, is kept dry to protect the bearings in the skate wheels. Several surface materials are used, including plastic tiles (sometimes known as sport-court flooring), wood, and sealed concrete; in general, surfaces try to balance the ability of wheels to grip against the ability of the puck to slide freely. None of these surfaces, however, is as smooth as ice; as a result, the puck is made of a much lighter plastic material, and rests on small nylon or poly-plastic nubs to reduce friction with the rink surface.  Besides these equipment differences, inline hockey uses less physical contact in comparison to ice hockey. Most leagues punish fighting harshly, and body checking is usually ruled a penalty. Inline hockey leagues generally require players to wear full face masks, but otherwise, players tend to wear lighter clothes and less protective padding.  Important differences in game rules also exist. Each inline hockey team fields only four skaters and one goaltender (5 players) rather than ice hockey's five skaters and one goaltender (six players). Many leagues do not stop play for icing. Offside rules are generally looser as well; originally, a few leagues would call offside only on the center line, presently, every rule book omits the rule entirely.  Inline hockey is a contact sport. Although body checks are usually not allowed, injuries can still be a common occurrence. Protective equipment is highly recommended and is enforced in all competitive situations. This usually includes a helmet (cage worn if certain age), elbow pads, protective gloves, athletic cup, shin pads, and skates at the very least. In addition, goaltenders use different gear, (optionally) a neck guard, chest\/arm protector, blocker, catch glove, and leg pads.  Good skates are stiffer and lighter and also have better bearings. Inline hockey-skates are similar to icehockey-skates, the main difference between ice and inline is the chassis and the wheels. Hockey equipment manufacturers such as Bauer and CCM offer parallel models of ice skates, but there are also inline hockey brands, including Mission, Tour and Labeda.  Most inline hockey skates had have a chassis with 4 identical wheels on each boot in 72, 76 or 80\u00a0mm diameter, or the \"Hi-Lo\" configuration of two low wheels in front and two higher rear, this was patented on 12 July 1996 by Jon G Wong in the US and marketed by Mission. There is also a chassis with a \"Tri-Di\" option, which allows three wheel sizes to be mounted on a chassis, in the configuration 80-76-76-72\u00a0mm. Inline Hockey wheels are much softer than road wheels, and therefore have more abrasion. The softest are used for soft surfaces like gym floors or interlocking plastic tiles, harder are used for surfaces such as asphalt.  The area where Inline hockey is played in known as a \"rink\". It consists of a playing surface that is surrounded by a boundary (commonly referred to as \"dasher boards\"), that is designed to separate the players from the spectators as well as to keep the puck in play. The playing surface is made of sport tile, wood, asphalt or cement and marked with special lines that help the referees officiate the game according to the official rules.  The recommended size of the rink can vary between 40m and 60m in length and 20m and 30m in width. In Germany the old standard was 40m x 20m which changed to 50m x 25m but also the ice hockey standard of 61m x 30.5m (200\u00d7100\u00a0ft) is used.  One of the most fundamental differences between the IIHF and World Skate-sanctioned versions of inline hockey lies within the dimensions of the net. The IIHF simply retains the use of ice hockey nets. However the World Skate rulebook substitutes the traditional ice hockey cage for a lower and narrower model patterned after the one used in rink hockey, the World Skates' flagship sport, however most World Skate leagues in the United States and Canada opt for the more popular and common ice hockey nets.  While the general characteristics of the game are the same wherever it is played, the exact rules depend on the particular code of play being used. The most important code is that of the Comit\u00e9 International Roller In-Line Hockey (CIRILH), an organization and discipline of the F\u00e9d\u00e9ration Internationale de Roller Sports[8]  Inline hockey is played on an inline hockey rink. During normal play, there are five players per side on the floor at any time, one of them being the goaltender, each of whom is on inline hockey skates. The objective of the game is to score goals by shooting a hard plastic disc, the puck, into the opponent's goal net, which is placed at the opposite end of the rink. The players may control the puck using a long stick with a blade that is commonly curved at one end.  Players may also redirect the puck with any part of their bodies, subject to certain restrictions. Players may not hold the puck in their hand and are prohibited from using their hands to pass the puck to their teammates, unless they are in the defensive zone. Players are also prohibited from kicking the puck into the opponent's goal, though unintentional redirections off the skate are permitted. Players may not intentionally bat the puck into the net with their hands.  The four players other than the goaltender are typically divided into two forwards and two defencemen. The forward positions consist of a center and a winger. The defencemen usually stay together as a pair generally divided between left and right. A substitution of an entire unit at once is called a line change. Teams typically employ alternate sets of forward lines and defensive pairings when shorthanded or on a power play. Substitutions are permitted at any time during the course of the game, although during a stoppage of play the home team is permitted the final change. When players are substituted during play, it is called changing on the fly.  The boards surrounding the floor help keep the puck in play and they can also be used as tools to play the puck. Players are not permitted to \"bodycheck\" opponents into the boards as a means of stopping progress. The referees and the outsides of the goal are \"in play\" and do not cause a stoppage of the game when the puck or players are influenced (by either bouncing or colliding) into them. Play can be stopped if the goal is knocked out of position. Play often proceeds for minutes without interruption. When play is stopped, it is restarted with a faceoff. Two players \"face\" each other and an official drops the puck to the floor, where the two players attempt to gain control of the puck. Markings on the floor indicate the locations for the \"faceoff\" and guide the positioning of players.  There is one major rule of play in inline hockey that limit the movement of the puck: the puck going out of play. The puck goes \"out of play\" whenever it goes past the perimeter of the rink (Onto the player benches, over the \"glass,\" or onto the protective netting above the glass) and a stoppage of play is called by the officials using whistles. It also does not matter if the puck comes back onto the playing surface from those areas as the puck is considered dead once it leaves the perimeter of the rink.  Under FIRS rules, each team may carry a maximum of 14 players and two goaltenders on their roster. The players are usually divided into three lines of two forwards, two pairs of defenceman, and two extra skaters.  For most penalties, the offending player is sent to the \"penalty box\" and his team has to play with one less skater for a short amount of time. Minor penalties last for two minutes, major penalties last for five minutes, and a double minor penalty is two consecutive penalties of two minutes duration. A single Minor penalty may be extended by a further two minutes for drawing blood from the victimized player. The team that has taken the penalty is said to be playing shorthanded while the other team is on a power play.  A two-minute minor penalty is often called for lesser infractions such as tripping, elbowing, roughing, high-sticking, delay of the game, too many players on the rink, boarding, illegal equipment, holding, interference, hooking, slashing, butt-ending (striking an opponent with the knob of the stick\u2014a very rare penalty) Or cross-checking. A minor is also assessed for diving, where a player embellishes a hook or trip. More egregious fouls may be penalized by a four-minute double-minor penalty, particularly those which cause injury to the victimized player. These penalties end either when the time runs out or the other team scores on the power play. In the case of a goal scored during the first two minutes of a double-minor, the penalty clock is set down to two minutes upon a score effectively expiring the first minor penalty. Five-minute major penalties are called for especially violent instances of most minor infractions that result in intentional injury to an opponent, or when a \"minor\" penalty results in visible injury (such as bleeding), as well as for fighting. Major penalties are always served in full; they do not terminate on a goal scored by the other team.  Some varieties of penalties do not always require the offending team to play a man short. Concurrent five-minute major penalties in the FIRS usually result from fighting. In the case of two players being assessed five-minute fighting majors, they both serve five minutes without their team incurring a loss of player (both teams still have a full complement of players on the floor). This differs with two players from opposing sides getting minor penalties, at the same time or at any intersecting moment, resulting from more common infractions. In that case, both teams will have only three skating players (not counting the goaltender) until one or both penalties expire (if one expires before the other, the opposing team gets a power play for the remainder); this applies regardless of current pending penalties, though in the FIRS, a team always has at least two skaters on the rink. Ten-minute misconduct penalties are served in full by the penalized player, but his team may immediately substitute another player on the floor unless a minor or major penalty is assessed in conjunction with the misconduct (a two-and-ten or five-and-ten). In that case, the team designates another player to serve the minor or major; both players go to the penalty box, but only the designee may not be replaced, and he is released upon the expiration of the two or five minutes, at which point the ten-minute misconduct begins. In addition, game misconducts are assessed for deliberate intent to inflict severe injury on an opponent (at the officials' discretion), or for a major penalty for a stick infraction or repeated major penalties. The offending player is ejected from the game and must immediately leave the playing surface (he does not sit in the penalty box); meanwhile, if a minor or major is assessed in addition, a designated player must serve out that segment of the penalty in the box (similar to the above-mentioned \"two-and-ten\"). In some rare cases, a player may receive up to nineteen minutes in penalties for one string of plays. This could involve receiving a four-minute double minor penalty, getting in a fight with an opposing player who retaliates, and then receiving a game misconduct after the fight. In this case, the player is ejected and two teammates must serve the double-minor and major penalties.  A player who is tripped, or illegally obstructed in some way, by an opponent on a breakaway\u00a0\u2013 when there are no defenders except the goaltender between him and the opponent's goal\u00a0\u2013 is awarded a penalty shot, an attempt to score without opposition from any defenders except the goaltender. A penalty shot is also awarded for a defender other than the goaltender covering the puck in the goal crease, a goaltender intentionally displacing his own goal posts during a breakaway to avoid a goal, a defender intentionally displacing his own goal posts when there is less than two minutes to play in regulation time or at any point during overtime, or a player or coach intentionally throwing a stick or other object at the puck or the puck carrier and the throwing action disrupts a shot or pass play.  Officials also stop play for puck movement violations, such as using one's hands to pass the puck in the offensive end, but no players are penalized for these offenses. The sole exceptions are deliberately falling on or gathering the puck to the body, carrying the puck in the hand, and shooting the puck out of play in one's defensive zone (all penalized two minutes for delay of game).  A typical game of inline hockey has two officials on the floor, charged with enforcing the rules of the game. There are typically two referees who call goals and penalties. Due to not having offside and icing violations, there usually are no linesmen used. On-ice officials are assisted by off-ice officials who act as time keepers, and official scorers.  Officials are selected by the league for which they work. Amateur hockey leagues use guidelines established by national organizing bodies as a basis for choosing their officiating staffs. In North America, the national organizing bodies USA Roller Sports and Canada Inline approve officials according to their experience level as well as their ability to pass rules knowledge and skating ability tests.  Offensive tactics include improving a team's position on the floor by advancing the puck towards the opponent's goal. FIRS rules have no offside or two-line passes. A player may pass the puck to a player on any spot on the floor. Offensive tactics, are designed ultimately to score a goal by taking a shot. When a player purposely directs the puck towards the opponent's goal, he or she is said to \"shoot\" the puck.  A deflection is a shot which redirects a shot or a pass towards the goal from another player, by allowing the puck to strike the stick and carom towards the goal. A one-timer is a shot which is struck directly off a pass, without receiving the pass and shooting in two separate actions. Headmanning the puck, also known as cherry-picking, the stretch pass or breaking out, is the tactic of rapidly passing to the player farthest down the floor.  A team that is losing by one or two goals in the last few minutes of play will often elect to pull the goalie; that is, remove the goaltender and replace him or her with an extra attacker on the floor in the hope of gaining enough advantage to score a goal. However, it is an act of desperation, as it sometimes leads to the opposing team extending their lead by scoring a goal in the empty net.  A delayed penalty call occurs when a penalty offense is committed by the team that does not have possession of the puck. In this circumstance the team with possession of the puck is allowed to complete the play; that is, play continues until a goal is scored, a player on the opposing team gains control of the puck, or the team in possession commits an infraction or penalty of their own. Because the team on which the penalty was called cannot control the puck without stopping play, it is impossible for them to score a goal, however, it is possible for the controlling team to mishandle the puck into their own net. In these cases the team in possession of the puck can pull the goalie for an extra attacker without fear of being scored on. If a delayed penalty is signaled and the team in possession scores, the penalty is still assessed to the offending player, but not served.  One of the most important strategies for a team is their forecheck. Forechecking is the act of attacking the opposition in their defensive zone. Forechecking is an important part of roller hockey, because certain leagues and rules allow teams that have possession of the puck to sit behind their net and wait until they are pressured before having to advance the puck. Each team will use their own unique forecheck system but the main ones are: 1\u20131\u20132, 1\u20132\u20131, and 1\u20133. The 1\u20131\u20132 is the most basic forecheck system where one forward will go in deep and pressure the opposition's defencemen, the second forward stays in the slot, and the two defencemen high. The 1\u20133 is the most defensive forecheck system where one forward will apply pressure to the puck carrier in the opponent's zone and the other three players stand basically in a line in their defensive zone in hopes the opposition will skate into one of them.  Roller hockey is unique in that its rules resemble more of a basketball\/soccer\/lacrosse strategy in many ways versus a traditional ice hockey approach.  There are many other little tactics used in the game of hockey. Pinching is the term used when a defenceman pressures the opposition's winger in the offensive zone when they are breaking out, attempting to stop their attack and keep the puck in the offensive zone. A saucer pass is a pass used when an opposition's stick or body is in the passing lane. It is the act of raising the puck over the obstruction and having it land on a teammates' stick.  A \"deke,\" short for \"decoy,\" is a feint with the body and\/or stick to fool a defender or the goalie. Due to the increased room and lack of body checking, many inline hockey players have picked up the skill of \"dangling,\" which is more fancy deking and requires more stick handling skills. Some of the more impressive \"dekes\" or \"dangles\" include the toe-drag, the Pavel Datsyuk, the back hand toe-drag, and the spin-o-rama.  Fighting is prohibited in the rules. It does happen rarely, however. Players used to an ice hockey mentality fight to demoralize the opposing players while exciting their own, as well as settling personal scores. A fight will also break if one of the team's skilled players gets hit hard or someone gets hit by what the team perceives as a dirty hit. Amateur recreation level players who play strictly inline hockey never consider fisticuffs a legitimate behavior. The amateur game penalizes fisticuffs more harshly, as a player who receives a fighting major is also assessed at least a 10-minute misconduct penalty or a game misconduct penalty and suspension. Most local recreation leagues also suspend or ban players who engage in fights.  A professional game consists of two halves of twenty minutes each, the clock running only when the puck is in play. The teams change ends for the second half, and again at the start of each overtime played (playoffs only; same ends as the second half otherwise). Some leagues such as the American Inline Hockey League (AIHL), recreational leagues and children's leagues often play shorter games, generally with two shorter periods or three running clock periods of play.  Various procedures are used if a game is tied. Some leagues and tournaments do not use an overtime, unless a \"winner\" must be determined, such as in tournament pool play and league regular season. Others will us either one, or a combination of; sudden death overtime periods, or penalty shootouts. Usually up to two 5-minute sudden death overtimes are played; if still tied, penalty shootouts.  Indoor inline hockey is played on any suitable non-slip surface. While converted roller rinks may use wooden floors, dedicated inline hockey facilities use Sport Court or similar surface, which allows maximum traction to inline hockey wheels whilst providing a smooth, unbroken gliding surface for the puck. The playing area should be surrounded by full boards similar to ice hockey with glass or fencing to a height of around 2m. Often, especially in European countries, the game is played in indoor sports halls, on wooden floors. Therefore, there will be no standardized boards but instead the perimeter of the playing surface will be brick walls. In such cases, the corners of the hall are rounded off with added curved boards.  Based on Ice Sledge Hockey, Inline Sledge Hockey is played to the same rules as Inline Puck Hockey (essentially ice hockey played off ice using inline skates) and has been made possible by the design and manufacture of inline sledges by RGK, Europe's premier sports wheelchair maker.  There is no classification points system dictating who can be involved in play within Inline Sledge Hockey unlike other team sports such as Wheelchair Basketball and Wheelchair Rugby. Inline Sledge Hockey is being developed to allow everyone, regardless of whether they have a disability or not, to complete up to World Championship level based solely on talent and ability. This makes Inline Sledge Hockey truly inclusive.  The first game of Inline Sledge Hockey was played at Bisley, England on 19 December 2009 between the Hull Stingrays and the Grimsby Redwings. Matt Lloyd (Paralympian) is credited with inventing Inline Sledge Hockey and Great Britain is seen as the international leader in the game's development.  Street hockey is a form of inline hockey played as pick-up hockey on streets[9] or parking lots. Street hockey tends to have very relaxed rules, as any pickup street game or sport would have.  Blind inline hockey is also played by athletes who are totally blind or visually impaired. Sighted players can also play, as all players must play while wearing opaque goggles, making all play sightless and \"evening the playing field.\" The blind game is best played on a regulation inline surface with two orienting, tactile zone lines, each 60 feet from the goal line. Either 5v5 or 4v4 skaters, each plus goalies, are both good games.  The puck and goals each have a sounding device that enable the players to hear the puck and orient themselves to direction on the playing surface. The players constantly communicate to their teammates regarding their actions and positions on the floor enabling teamwork and playmaking. A sighted referee directs stoppages and restarts. All usual hockey rules apply to blind play.  There are two lines of sanctioning bodies for inline hockey: those that are related to the roller sports community and those related to the ice hockey community. The International Ice Hockey Federation organizes IIHF Inline Hockey World Championships but the sport is recognized as being governed by the International Roller Sports Federation which organizes FIRS Inline Hockey World Championships.  USA Roller Sports is sanctioned by the International Olympic Committee to oversee roller sports. See the related links below for national bodies and further information.    There are several international competitions with national teams. "},{"title":"England","content":"  \u2013\u00a0in Europe\u00a0(green &\u00a0dark grey)\u2013\u00a0in the United Kingdom\u00a0(green) England is a country that is part of the United Kingdom.[6] The country is located on the island of Great Britain, of which it covers roughly 62%, and over 100 smaller adjacent islands. It has land borders with Scotland to the north and Wales to the west, and is otherwise surrounded by the North Sea to the east, the English Channel to the south, the Celtic Sea to the south-west, and the Irish sea to the west. Continental Europe lies to the south-east, and Ireland to the west. The population was 56,490,048 at the 2021 census. London is both the largest city and the capital.  The area now called England was first inhabited by modern humans during the Upper Paleolithic, but takes its name from the Angles, a Germanic tribe who settled during the 5th and 6th centuries. England became a unified state in the 10th century and has had a significant cultural and legal impact on the wider world since the Age of Discovery, which began during the 15th century.[7] The Kingdom of England, which included Wales after 1535, ceased being a separate sovereign state on 1 May 1707 when the Acts of Union put the terms agreed in the Treaty of Union the previous year into effect; this resulted in a political union with the Kingdom of Scotland that created the Kingdom of Great Britain.[8]  England is the origin of many well-known worldwide exports, including the English language, the English legal system (which served as the basis for the common law systems of many other countries), association football, and the Church of England; its parliamentary system of government has been widely adopted by other nations.[9] The Industrial Revolution began in 18th-century England, transforming its society into the world's first industrialised nation.[10] England is home to the two oldest universities in the English-speaking world: the University of Oxford, founded in 1096, and the University of Cambridge, founded in 1209. Both universities are ranked among the most prestigious in the world.[11][12]  England's terrain chiefly consists of low hills and plains, especially in the centre and south. Upland and mountainous terrain is mostly found in the north and west, including Dartmoor, the Lake District, the Pennines, and the Shropshire Hills. The country's capital is London, the greater metropolitan of which has a population of 14.2\u00a0million as of 2021, representing the United Kingdom's largest metropolitan area. England's population of 56.3\u00a0million comprises 84% of the population of the United Kingdom,[13] largely concentrated around London, the South East, and conurbations in the Midlands, the North West, the North East, and Yorkshire, which each developed as major industrial regions during the 19th century.[14]  The name \"England\" is derived from the Old English name Englaland, which means \"land of the Angles\".[15] The Angles were one of the Germanic tribes that settled in Great Britain during the Early Middle Ages. The Angles came from the Anglia peninsula in the Bay of Kiel area (present-day German state of Schleswig-Holstein) of the Baltic Sea.[16] The earliest recorded use of the term, as \"Engla londe\", is in the late-ninth-century translation into Old English of Bede's Ecclesiastical History of the English People. The term was then used to mean \"the land inhabited by the English\", and it included English people in what is now south-east Scotland but was then part of the English kingdom of Northumbria. The Anglo-Saxon Chronicle recorded that the Domesday Book of 1086 covered the whole of England, meaning the English kingdom, but a few years later the Chronicle stated that King Malcolm III went \"out of Scotlande into Lothian in Englaland\", thus using it in the more ancient sense.[17]  The earliest attested reference to the Angles occurs in the 1st-century work by Tacitus, Germania, in which the Latin word Anglii is used.[18] The etymology of the tribal name itself is disputed by scholars; it has been suggested that it derives from the shape of the Angeln peninsula, an angular shape.[19] How and why a term derived from the name of a tribe that was less significant than others, such as the Saxons, came to be used for the entire country is not known, but it seems this is related to the custom of calling the Germanic people in Britain Angli Saxones or English Saxons to distinguish them from continental Saxons (Eald-Seaxe) of Old Saxony in Germany.[20] In Scottish Gaelic, the Saxon tribe gave their name to the word for England (Sasunn);[21] similarly, the Welsh name for the English language is \"Saesneg\". A romantic name for England is Loegria, related to the Welsh word for England, Lloegr, and made popular by its use in Arthurian legend. Albion is also applied to England in a more poetic capacity,[22] though its original meaning is the island of Britain as a whole.  The earliest known evidence of human presence in the area now known as England was that of Homo antecessor, dating to approximately 780,000 years ago. The oldest proto-human bones discovered in England date from 500,000\u00a0years ago.[23] Modern humans are known to have inhabited the area during the Upper Paleolithic period, though permanent settlements were only established within the last 6,000 years.[24] After the last ice age only large mammals such as mammoths, bison and woolly rhinoceros remained. Roughly 11,000\u00a0years ago, when the ice sheets began to recede, humans repopulated the area; genetic research suggests they came from the northern part of the Iberian Peninsula.[25] The sea level was lower than the present day and Britain was connected by land bridge to Ireland and Eurasia.[26] As the seas rose, it was separated from Ireland 10,000\u00a0years ago and from Eurasia two millennia later.  The Beaker culture arrived around 2,500\u00a0BC, introducing drinking and food vessels constructed from clay, as well as vessels used as reduction pots to smelt copper ores.[27] It was during this time that major Neolithic monuments such as Stonehenge (phase III) and Avebury were constructed. By heating together tin and copper, which were in abundance in the area, the Beaker culture people made bronze, and later iron from iron ores. The development of iron smelting allowed the construction of better ploughs, advancing agriculture (for instance, with Celtic fields), as well as the production of more effective weapons.[28]  During the Iron Age, Celtic culture, deriving from the Hallstatt and La T\u00e8ne cultures, arrived from Central Europe. Brythonic was the spoken language during this time. Society was tribal; according to Ptolemy's Geographia there were around 20 tribes in the area. Like other regions on the edge of the Empire, Britain had long enjoyed trading links with the Romans. Julius Caesar of the Roman Republic attempted to invade twice in 55\u00a0BC; although largely unsuccessful, he managed to set up a client king from the Trinovantes.  The Romans invaded Britain in 43 AD during the reign of Emperor Claudius, subsequently conquering much of Britain, and the area was incorporated into the Roman Empire as Britannia province.[29] The best-known of the native tribes who attempted to resist were the Catuvellauni led by Caratacus. Later, an uprising led by Boudica, Queen of the Iceni, ended with Boudica's suicide following her defeat at the Battle of Watling Street.[30] The author of one study of Roman Britain suggested that from 43 AD to 84 AD, the Roman invaders killed somewhere between 100,000 and 250,000 people from a population of perhaps 2,000,000.[31] This era saw a Greco-Roman culture prevail with the introduction of Roman law, Roman architecture, aqueducts, sewers, many agricultural items and silk.[32] In the 3rd century, Emperor Septimius Severus died at Eboracum (now York), where Constantine was subsequently proclaimed emperor a century later.[33]  There is debate about when Christianity was first introduced; it was no later than the 4th century, probably much earlier. According to Bede, missionaries were sent from Rome by Eleutherius at the request of the chieftain Lucius of Britain in 180 AD, to settle differences as to Eastern and Western ceremonials, which were disturbing the church. There are traditions linked to Glastonbury claiming an introduction through Joseph of Arimathea, while others claim through Lucius of Britain.[34] By 410, during the decline of the Roman Empire, Britain was left exposed by the end of Roman rule in Britain and the withdrawal of Roman army units, to defend the frontiers in continental Europe and partake in civil wars.[35] Celtic Christian monastic and missionary movements flourished. This period of Christianity was influenced by ancient Celtic culture in its sensibilities, polity, practices and theology. Local \"congregations\" were centred in the monastic community and monastic leaders were more like chieftains, as peers, rather than in the more hierarchical system of the Roman-dominated church.[36]  Roman military withdrawals left Britain open to invasion by pagan, seafaring warriors from north-western continental Europe, chiefly the Saxons, Angles, Jutes and Frisians who had long raided the coasts of the Roman province. These groups then began to settle in increasing numbers over the course of the fifth and sixth centuries, initially in the eastern part of the country.[35] Their advance was contained for some decades after the Britons' victory at the Battle of Mount Badon, but subsequently resumed, overrunning the fertile lowlands of Britain and reducing the area under Brittonic control to a series of separate enclaves in the more rugged country to the west by the end of the 6th century. Contemporary texts describing this period are extremely scarce, giving rise to its description as a Dark Age. Details of the Anglo-Saxon settlement of Britain are consequently subject to considerable disagreement; the emerging consensus is that it occurred on a large scale in the south and east but was less substantial to the north and west, where Celtic languages continued to be spoken even in areas under Anglo-Saxon control.[37][38] Roman-dominated Christianity had, in general, been replaced in the conquered territories by Anglo-Saxon paganism, but was reintroduced by missionaries from Rome led by Augustine from 597.[39] Disputes between the Roman- and Celtic-dominated forms of Christianity ended in victory for the Roman tradition at the Council of Whitby (664), which was ostensibly about tonsures (clerical haircuts) and the date of Easter, but more significantly, about the differences in Roman and Celtic forms of authority, theology, and practice.[36]  During the settlement period the lands ruled by the incomers seem to have been fragmented into numerous tribal territories, but by the 7th century, when substantial evidence of the situation again becomes available, these had coalesced into roughly a dozen kingdoms including Northumbria, Mercia, Wessex, East Anglia, Essex, Kent and Sussex. Over the following centuries, this process of political consolidation continued.[40] The 7th century saw a struggle for hegemony between Northumbria and Mercia, which in the 8th century gave way to Mercian preeminence.[41] In the early 9th century Mercia was displaced as the foremost kingdom by Wessex. Later in that century escalating attacks by the Danes culminated in the conquest of the north and east of England, overthrowing the kingdoms of Northumbria, Mercia and East Anglia. Wessex under Alfred the Great was left as the only surviving English kingdom, and under his successors, it steadily expanded at the expense of the kingdoms of the Danelaw. This brought about the political unification of England, first accomplished under \u00c6thelstan in 927 and definitively established after further conflicts by Eadred in 953. A fresh wave of Scandinavian attacks from the late 10th century ended with the conquest of this united kingdom by Sweyn Forkbeard in 1013 and again by his son Cnut in 1016, turning it into the centre of a short-lived North Sea Empire that also included Denmark and Norway. However, the native royal dynasty was restored with the accession of Edward the Confessor in 1042.  A dispute over the succession to Edward led to an unsuccessful Norwegian Invasion in September 1066 close to York in the North, and the successful Norman Conquest in October 1066, accomplished by an army led by Duke William of Normandy invading at Hastings late September 1066.[42] The Normans themselves originated from Scandinavia and had settled in Normandy in the late 9th and early 10th centuries.[43] This conquest led to the almost total dispossession of the English elite and its replacement by a new French-speaking aristocracy, whose speech had a profound and permanent effect on the English language.[44]  Subsequently, the House of Plantagenet from Anjou inherited the English throne under Henry II, adding England to the budding Angevin Empire of fiefs the family had inherited in France including Aquitaine.[45] They reigned for three centuries, some noted monarchs being Richard I, Edward I, Edward III and Henry V.[45] The period saw changes in trade and legislation, including the signing of Magna Carta, an English legal charter used to limit the sovereign's powers by law and protect the privileges of freemen. Catholic monasticism flourished, providing philosophers, and the universities of Oxford and Cambridge were founded with royal patronage. The Principality of Wales became a Plantagenet fief during the 13th century[46] and the Lordship of Ireland was given to the English monarchy by the Pope. During the 14th century, the Plantagenets and the House of Valois claimed to be legitimate claimants to the House of Capet and of France; the two powers clashed in the Hundred Years' War.[47] The Black Death epidemic hit England; starting in 1348, it eventually killed up to half of England's inhabitants.[48]  Between 1453 and 1487, a civil war known as the War of the Roses waged between the two branches of the royal family, the Yorkists and Lancastrians.[49] Eventually it led to the Yorkists losing the throne entirely to a Welsh noble family the Tudors, a branch of the Lancastrians headed by Henry Tudor who invaded with Welsh and Breton mercenaries, gaining victory at the Battle of Bosworth Field where the Yorkist king Richard III was killed.[50]  During the Tudor period, England began to develop naval skills, and exploration intensified in the Age of Discovery.[51] Henry VIII broke from communion with the Catholic Church, over issues relating to his divorce, under the Acts of Supremacy in 1534 which proclaimed the monarch head of the Church of England. In contrast with much of European Protestantism, the roots of the split were more political than theological.[c] He also legally incorporated his ancestral land Wales into the Kingdom of England with the 1535\u20131542 acts. There were internal religious conflicts during the reigns of Henry's daughters, Mary I and Elizabeth I. The former took the country back to Catholicism while the latter broke from it again, forcefully asserting the supremacy of Anglicanism. The Elizabethan era is the epoch in the Tudor age of the reign of Queen Elizabeth I (\"the Virgin Queen\"). Historians often depict it as the golden age in English history that represented the apogee of the English Renaissance and saw the flowering of great art, drama, poetry, music and literature.[53] England during this period had a centralised, well-organised, and effective government.[54]  Competing with Spain, the first English colony in the Americas was founded in 1585 by explorer Walter Raleigh in Virginia and named Roanoke. The Roanoke colony failed and is known as the lost colony after it was found abandoned on the return of the late-arriving supply ship.[55] With the East India Company, England also competed with the Dutch and French in the East. During the Elizabethan period, England was at war with Spain. An armada sailed from Spain in 1588 as part of a wider plan to invade England and re-establish a Catholic monarchy. The plan was thwarted by bad coordination, stormy weather and successful harrying attacks by an English fleet under Lord Howard of Effingham. This failure did not end the threat: Spain launched two further armadas, in 1596 and 1597, but both were driven back by storms.  The political structure of the island changed in 1603, when the King of Scots, James VI, a kingdom which had been a long-time rival to English interests, inherited the throne of England as James I, thereby creating a personal union.[56] He styled himself King of Great Britain, although this had no basis in English law.[57] Under the auspices of James VI and I the Authorised King James Version of the Holy Bible was published in 1611. It was the standard version of the Bible read by most Protestant Christians for four hundred years until modern revisions were produced in the 20th century.  Based on conflicting political, religious and social positions, the English Civil War was fought between the supporters of Parliament and those of King Charles I, known colloquially as Roundheads and Cavaliers respectively. This was an interwoven part of the wider multifaceted Wars of the Three Kingdoms, involving Scotland and Ireland. The Parliamentarians were victorious, Charles I was executed and the kingdom replaced by the Commonwealth. Leader of the Parliament forces, Oliver Cromwell declared himself Lord Protector in 1653; a period of personal rule followed.[58] After Cromwell's death and the resignation of his son Richard as Lord Protector, Charles II was invited to return as monarch in 1660, in a move called the Restoration. With the reopening of theatres, fine arts, literature and performing arts flourished throughout the Restoration of the \"Merry Monarch\" Charles II.[59] After the Glorious Revolution of 1688, it was constitutionally established that King and Parliament should rule together, though Parliament would have the real power. This was established with the Bill of Rights in 1689. Among the statutes set down were that the law could only be made by Parliament and could not be suspended by the King, also that the King could not impose taxes or raise an army without the prior approval of Parliament.[60] Also since that time, no British monarch has entered the House of Commons when it is sitting, which is annually commemorated at the State Opening of Parliament by the British monarch when the doors of the House of Commons are slammed in the face of the monarch's messenger, symbolising the rights of Parliament and its independence from the monarch.[61] With the founding of the Royal Society in 1660, science was greatly encouraged.  In 1666 the Great Fire of London gutted the city of London, but it was rebuilt shortly afterward with many significant buildings designed by Sir Christopher Wren.[62] By the mid-to-late 17th century, two political factions had emerged \u2013 the Tories and Whigs. Though the Tories initially supported Catholic king James II, some of them, along with the Whigs, during the Revolution of 1688 invited the Dutch Prince William of Orange to defeat James and become the king. Some English people, especially in the north, were Jacobites and continued to support James and his sons. Under the Stuart dynasty England expanded in trade, finance and prosperity. The Royal Navy developed Europe's largest merchant fleet.[63] After the parliaments of England and Scotland agreed,[64] the two countries joined in political union, to create the Kingdom of Great Britain in 1707.[56] To accommodate the union, institutions such as the law and national churches of each remained separate.[65]  Under the newly formed Kingdom of Great Britain, output from the Royal Society and other English initiatives combined with the Scottish Enlightenment to create innovations in science and engineering, while the enormous growth in British overseas trade protected by the Royal Navy paved the way for the establishment of the British Empire. Domestically it drove the Industrial Revolution, a period of profound change in the socioeconomic and cultural conditions of England, resulting in industrialised agriculture, manufacture, engineering and mining, as well as new and pioneering road, rail and water networks to facilitate their expansion and development.[66] The opening of Northwest England's Bridgewater Canal in 1761 ushered in the canal age in Britain.[67] In 1825 the world's first permanent steam locomotive-hauled passenger railway \u2013 the Stockton and Darlington Railway \u2013 opened to the public.[67]  During the Industrial Revolution, many workers moved from England's countryside to new and expanding urban industrial areas to work in factories, for instance at Birmingham and Manchester,[69] with the latter the world's first industrial city.[70] England maintained relative stability throughout the French Revolution, under George III and William Pitt the Younger. The regency of George IV is noted for its elegance and achievements in the fine arts and architecture.[71] During the Napoleonic Wars, Napoleon planned to invade from the south-east; however, this failed to manifest and the Napoleonic forces were defeated by the British: at sea by Horatio Nelson, and on land by Arthur Wellesley. The major victory at the Battle of Trafalgar confirmed the naval supremacy Britain had established during the course of the eighteenth century.[72] The Napoleonic Wars fostered a concept of Britishness and a united national British people, shared with the English, Scots and Welsh.[73]  London became the largest and most populous metropolitan area in the world during the Victorian era, and trade within the British Empire \u2013 as well as the standing of the British military and navy \u2013 was prestigious.[74] Technologically, this era saw many innovations that proved key to the United Kingdom's power and prosperity.[75] Political agitation at home from radicals such as the Chartists and the suffragettes enabled legislative reform and universal suffrage.[76]  Power shifts in east-central Europe led to World War I; hundreds of thousands of English soldiers died fighting for the United Kingdom as part of the Allies.[d] Two decades later, in World War II, the United Kingdom was again one of the Allies. Developments in warfare technology saw many cities damaged by air-raids during the Blitz. Following the war, the British Empire experienced rapid decolonisation, and there was a speeding-up of technological innovations; automobiles became the primary means of transport and Frank Whittle's development of the jet engine led to wider air travel.[78] Residential patterns were altered in England by private motoring, and by the creation of the National Health Service in 1948, providing publicly funded health care to all permanent residents free at the point of need. Combined, these prompted the reform of local government in England in the mid-20th century.[79]  Since the 20th century, there has been significant population movement to England, mostly from other parts of the British Isles, but also from the Commonwealth, particularly the Indian subcontinent.[80] Since the 1970s there has been a large move away from manufacturing and an increasing emphasis on the service industry.[81] As part of the United Kingdom, the area joined a common market initiative called the European Economic Community which became the European Union. Since the late 20th century the administration of the United Kingdom has moved towards devolved governance in Scotland, Wales and Northern Ireland.[82] England and Wales continues to exist as a jurisdiction within the United Kingdom.[83] Devolution has stimulated a greater emphasis on a more English-specific identity and patriotism.[84] There is no devolved English government, but an attempt to create a similar system on a sub-regional basis was rejected by referendum.[85]  England is part of the United Kingdom, a constitutional monarchy with a parliamentary system.[86] There has not been a government of England since 1707, when the Acts of Union 1707,[87] putting into effect the terms of the Treaty of Union, joined England and Scotland to form the Kingdom of Great Britain.[64] Before the union England was ruled by its monarch and the Parliament of England. Today England is governed directly by the Parliament of the United Kingdom, although other countries of the United Kingdom have devolved governments.[88]  In the House of Commons which is the lower house of the British Parliament based at the Palace of Westminster, there are 532 members of parliament (MPs) for constituencies in England, out of the 650 total.[89] England is represented by 345 MPs from the Conservative Party, 179 from the Labour Party, seven from the Liberal Democrats, one from the Green Party, and the Speaker of the House.  Since devolution, in which other countries of the United Kingdom \u2013 Scotland, Wales and Northern Ireland \u2013 each have their own devolved parliament or assemblies for local issues, there has been debate about how to counterbalance this in England. Originally it was planned that various regions of England would be devolved, but following the proposal's rejection by the North East in a 2004 referendum, this has not been carried out.[85]  The English law legal system, developed over the centuries, is the basis of common law[90] legal systems used in most Commonwealth countries[91] and the United States (except Louisiana). Despite now being part of the United Kingdom, the legal system of the Courts of England and Wales continued, under the Treaty of Union, as a separate legal system from the one used in Scotland. The general essence of English law is that it is made by judges sitting in courts, applying their common sense and knowledge of legal precedent \u2013 stare decisis \u2013 to the facts before them.[92]  The court system is headed by the Senior Courts of England and Wales, consisting of the Court of Appeal, the High Court of Justice for civil cases, and the Crown Court for criminal cases.[93] The Supreme Court of the United Kingdom is the highest court for criminal and civil cases in England and Wales. It was created in 2009 after constitutional changes, taking over the judicial functions of the House of Lords.[94] A decision of the Supreme Court is binding on every other court in the hierarchy, which must follow its directions.[95]  The Secretary of State for Justice is the minister responsible to Parliament for the judiciary, the court system and prisons and probation in England.[96] Crime increased between 1981 and 1995 but fell by 42% in the period 1995\u20132006.[97] The prison population doubled over the same period, giving it one of the highest incarceration rates in Western Europe at 147 per 100,000.[98] His Majesty's Prison Service, reporting to the Ministry of Justice, manages most prisons, housing 81,309 prisoners in England and Wales as of September\u00a02022[update].[99]  The subdivisions of England consist of up to four levels of subnational division, controlled through a variety of types of administrative entities created for the purposes of local government.  Outside the London region, England's highest tier is the 48 ceremonial counties.[100] These are used primarily as a geographical frame of reference. Of these, 38 developed gradually since the Middle Ages; these were reformed to 51 in 1974 and to their current number in 1996.[101] Each has a Lord Lieutenant and High Sheriff; these posts are used to represent the British monarch locally.[100] Some counties, such as Herefordshire, are only divided further into civil parishes. The royal county of Berkshire and the metropolitan counties have different types of status to other ceremonial counties.[102]  The second tier is made up of combined authorities and the 27 county-tier shire counties. In 1974, all ceremonial counties were two-tier; and with the metropolitan county tier phased out, the 1996 reform separated the ceremonial county and the administrative county tier.  England is also divided into local government districts.[103] The district can align to a ceremonial county, or be a district tier within a shire county, be a royal or metropolitan borough, have borough or city status, or be a unitary authority.  At the community level, much of England is divided into civil parishes with their own councils; in Greater London only one such parish, Queen's Park, exists as of 2014[update] after they were abolished in 1965 until legislation allowed their recreation in 2007.  From 1994 until the early 2010s England was divided for a few purposes into regions; a 1998 referendum for the London Region created the London Assembly two years later.[104] A failed 2004 North East England devolution referendum cancelled further regional assembly devolution[85] with the regional structure outside London abolished.  Ceremonially and administratively, the region is divided between the City of London and Greater London; these are further divided into the 32 London Boroughs and the 25 Wards of the City of London.[105]  Geographically, England includes the central and southern two-thirds of the island of Great Britain, plus such offshore islands as the Isle of Wight and the Isles of Scilly. It is bordered by two other countries of the United Kingdom: to the north by Scotland and to the west by Wales.  England is closer than any other part of mainland Britain to the European continent. It is separated from France (Hauts-de-France) by a 21-mile (34\u00a0km)[106] sea gap, though the two countries are connected by the Channel Tunnel near Folkestone.[107] England also has shores on the Irish Sea, North Sea and Atlantic Ocean.  The ports of London, Liverpool, and Newcastle lie on the tidal rivers Thames, Mersey and Tyne respectively. At 220 miles (350\u00a0km), the Severn is the longest river flowing through England.[108] It empties into the Bristol Channel and is notable for its Severn Bore (a tidal bore), which can reach 2 metres (6.6\u00a0ft) in height.[109] However, the longest river entirely in England is the Thames, which is 215 miles (346\u00a0km) in length.[110]  There are many lakes in England; the largest is Windermere, within the aptly named Lake District.[111] Most of England's landscape consists of low hills and plains, with upland and mountainous terrain in the north and west of the country. The northern uplands include the Pennines, a chain of uplands dividing east and west, the Lake District mountains in Cumbria, and the Cheviot Hills, straddling the border between England and Scotland. The highest point in England, at 978 metres (3,209\u00a0ft), is Scafell Pike in the Lake District.[111] The Shropshire Hills are near Wales while Dartmoor and Exmoor are two upland areas in the south-west of the country. The approximate dividing line between terrain types is often indicated by the Tees\u2013Exe line.[112]  The Pennines, known as the \"backbone of England\", are the oldest range of mountains in the country, originating from the end of the Paleozoic Era around 300\u00a0million years ago.[113] Their geological composition includes, among others, sandstone and limestone, and also coal. There are karst landscapes in calcite areas such as parts of Yorkshire and Derbyshire. The Pennine landscape is high moorland in upland areas, indented by fertile valleys of the region's rivers. They contain two national parks, the Yorkshire Dales and the Peak District. In the West Country, Dartmoor and Exmoor of the Southwest Peninsula include upland moorland supported by granite.[114]  The English Lowlands are in the central and southern regions of the country, consisting of green rolling hills, including the Cotswold Hills, Chiltern Hills, North and South Downs; where they meet the sea they form white rock exposures such as the cliffs of Dover. This also includes relatively flat plains such as the Salisbury Plain, Somerset Levels, South Coast Plain and The Fens.  England has a temperate maritime climate: it is mild with temperatures not much lower than 0\u00a0\u00b0C (32\u00a0\u00b0F) in winter and not much higher than 32\u00a0\u00b0C (90\u00a0\u00b0F) in summer.[115] The weather is damp relatively frequently and is changeable. The coldest months are January and February, the latter particularly on the English coast, while July is normally the warmest month. Months with mild to warm weather are May, June, September and October.[115] Rainfall is spread fairly evenly throughout the year.  Important influences on the climate of England are its proximity to the Atlantic Ocean, its northern latitude and the warming of the sea by the Gulf Stream.[115] Rainfall is higher in the west, and parts of the Lake District receive more rain than anywhere else in the country.[115] Since weather records began, the highest temperature recorded was 40.3\u00a0\u00b0C (104.5\u00a0\u00b0F) on 19 July 2022 at Coningsby, Lincolnshire,[116] while the lowest was \u221226.1\u00a0\u00b0C (\u221215.0\u00a0\u00b0F) on 10 January 1982 in Edgmond, Shropshire.[117]  The fauna of England is similar to that of other areas in the British Isles with a wide range of vertebrate and invertebrate life in a diverse range of habitats.[119] National nature reserves in England are designated by Natural England as key places for wildlife and natural features in England. They were established to protect the most significant areas of habitat and of geological formations. NNRs are managed on behalf of the nation, many by Natural England themselves, but also by non-governmental organisations, including the members of The Wildlife Trusts partnership, the National Trust, and the Royal Society for the Protection of Birds. There are 229 NNRs in England covering 939 square kilometres (363 square miles). Often they contain rare species or nationally important populations of plants and animals.[120] .   The Environment Agency is a non-departmental public body, established in 1995 and sponsored by the Department for Environment, Food and Rural Affairs with responsibilities relating to the protection and enhancement of the environment in England.[121] The Secretary of State for Environment, Food and Rural Affairs is the minister responsible for environmental protection, agriculture, fisheries and rural communities in England.[122] England has a temperate oceanic climate in most areas, lacking extremes of cold or heat, but does have a few small areas of subarctic and warmer areas in the South West. Towards the North of England the climate becomes colder and most of England's mountains and high hills are located here and have a major impact on the climate and thus the local fauna of the areas. Deciduous woodlands are common across all of England and provide a great habitat for much of England's wildlife, but these give way in northern and upland areas of England to coniferous forests (mainly plantations) which also benefit certain forms of wildlife. Some species have adapted to the expanded urban environment, particularly the red fox, which is the most successful urban mammal after the brown rat, and other animals such as common wood pigeon, both of which thrive in urban and suburban areas.[124]  The Greater London Built-up Area is by far the largest urban area in England[125] and one of the busiest cities in the world. It is considered a global city and has a population larger than any other country in the United Kingdom besides England itself.[125] Other urban areas of considerable size and influence tend to be in northern England or the English Midlands.[125] There are 50 settlements which have designated city status in England, while the wider United Kingdom has 66.  While many cities in England are quite large, such as Birmingham, Sheffield, Manchester, Liverpool, Leeds, Newcastle, Bradford, Nottingham, population size is not a prerequisite for city status.[126] Traditionally the status was given to towns with diocesan cathedrals, so there are smaller cities like Wells, Ely, Ripon, Truro and Chichester.    England's economy is one of the largest and most dynamic in the world, with an average GDP per capita of \u00a334,690.[5] HM Treasury, led by the Chancellor of the Exchequer, is responsible for developing and executing the government's public finance policy and economic policy.[127] Usually regarded as a mixed market economy, it has adopted many free market principles, yet maintains an advanced social welfare infrastructure.[128]  The economy of England is the largest part of the UK's economy.[129] England is a leader in the chemical and pharmaceutical sectors and in key technical industries, particularly aerospace, the arms industry, and the software industry. London, home to the London Stock Exchange, the United Kingdom's main stock exchange and the largest in Europe, is England's financial centre, with 100 of Europe's 500\u00a0largest corporations being based there.[130] London is the largest financial centre in Europe and as of 2014 is the second largest in the world.[131]  London has also been named as the fastest growing technology hub in Europe, with England having over 100 unique tech companies with a value of $1\u00a0billion or more.[132][133] The Bank of England, founded in 1694 as private banker to the government of England and a state-owned institution since 1946, is the United Kingdom's central bank.[134] The bank has a monopoly on the issue of banknotes in England and Wales, although not in other parts of the UK. The government has devolved responsibility to the bank's Monetary Policy Committee for managing the monetary policy of the country and setting interest rates.[135]  England is highly industrialised, but since the 1970s there has been a decline in traditional heavy and manufacturing industries, and an increasing emphasis on a more service industry oriented economy.[81] Tourism has become a significant industry, attracting millions of visitors to England each year. The export part of the economy is dominated by pharmaceuticals, automotives, crude oil and petroleum from the English parts of North Sea oil along with Wytch Farm, aircraft engines and alcoholic beverages.[136] The creative industries accounted for 7 per cent GVA in 2005 and grew at an average of 6 per cent per annum between 1997 and 2005.[137]  Agriculture is intensive, highly mechanised and efficient by European standards, producing 60% of food needs with only 2% of the labour force.[138] Two-thirds of production is devoted to livestock, the remainder to arable crops.[139] The main crops that are grown are wheat, barley, oats, potatoes, and sugar beets. England retains a significant fishing industry. Its fleets bring home a variety of fish, ranging from sole to herring. England is also rich in natural resources including coal, petroleum, natural gas, tin, limestone, iron ore, salt, clay, chalk, gypsum, lead, and silica.[140]  Prominent English figures from the field of science and mathematics include Sir Isaac Newton, Charles Darwin, Robert Hooke, Alan Turing, Stephen Hawking, Edward Jenner, Francis Crick, Joseph Lister, Joseph Priestley, Thomas Young, Christopher Wren and Richard Dawkins.  England was a leading centre of the Scientific Revolution from the 17th century.[141] As the birthplace of the Industrial Revolution, England was home to many significant inventors during the late 18th and early 19th centuries. Famous English engineers include Isambard Kingdom Brunel, best known for the creation of the Great Western Railway, a series of famous steamships, and numerous important bridges, revolutionising public transport and modern-day engineering.[142] Thomas Newcomen's steam engine helped spawn the Industrial Revolution.[143]  The Father of Railways, George Stephenson, built the first public inter-city railway line in the world, the Liverpool and Manchester Railway, which opened in 1830. With his role in the marketing and manufacturing of the steam engine, and invention of modern coinage, Matthew Boulton (business partner of James Watt) is regarded as one of the most influential entrepreneurs in history.[144] The physician Edward Jenner's smallpox vaccine is said to have \"saved more lives\u00a0... than were lost in all the wars of mankind since the beginning of recorded history.\"[145]  Inventions and discoveries of the English include the jet engine; the first industrial spinning machine; the first computer and the first modern computer; the World Wide Web along with HTML; the first successful human blood transfusion; the motorised vacuum cleaner;[146] the lawn mower; the seat belt; the hovercraft; the electric motor; steam engines; and theories such as the Darwinian theory of evolution and atomic theory. Newton developed the ideas of universal gravitation, Newtonian mechanics, and calculus, and Robert Hooke his eponymously named law of elasticity. Other inventions include the iron plate railway, the thermosiphon, tarmac, the rubber band, the mousetrap, \"cat's eye\" road marker, joint development of the light bulb, steam locomotives, the modern seed drill and many modern techniques and technologies used in precision engineering.[147]  The Royal Society, formally The Royal Society of London for Improving Natural Knowledge,[148] is a learned society and the United Kingdom's national academy of sciences. Founded on 28 November 1660,[148] It is the oldest national scientific institution in the world.[149] The Royal Institution of Great Britain was founded in 1799 by leading English scientists, including Henry Cavendish.[150] Some experts claim that the earliest concept of a metric system was invented by John Wilkins in 1668.[151]  Scientific research and development remains important in the universities of England, with many establishing science parks to facilitate production and co-operation with industry.[152] Cambridge is the most intensive research cluster for science and technology in the world.[153] In 2022, the UK produced 6.3 per cent of the world's scientific research papers and had a 10.5 per cent share of scientific citations, the third highest in the world (after the United States and China).[154] Scientific journals produced in England include Nature, the British Medical Journal and The Lancet. The Department for Science, Innovation and Technology, Secretary of State for Science, Innovation and Technology, and Minister of State for Science, Research and Innovation has responsibility for science in England.[155]  The Department for Transport is the government body responsible for overseeing transport in England. The department is run by the Secretary of State for Transport.   England has a dense and modern transportation infrastructure. There are many motorways in England, and many other trunk roads, such as the A1 Great North Road, which runs through eastern England from London to Newcastle[156] (much of this section is motorway) and onward to the Scottish border. The longest motorway in England is the M6, from Rugby through the North West up to the Anglo-Scottish border, a distance of 232 miles (373\u00a0km).[156] Other major routes include: the M1 from London to Leeds, the M25 which encircles London, the M60 which encircles Manchester, the M4 from London to South Wales, the M62 from Liverpool via Manchester to East Yorkshire, and the M5 from Birmingham to Bristol and the South West.[156]  Bus transport across the country is widespread; major companies include Arriva, FirstGroup, Go-Ahead Group, Mobico Group, Rotala and Stagecoach Group. Bus Rapid Transit originated in England with the Runcorn Busway opening in 1971.[157][158] The red double-decker buses in London have become a symbol of England. National Cycle Route offers cycling routes nationally.  Rail transport in England is the oldest in the world: passenger railways originated in England in 1825.[159] Much of Britain's 10,000 miles (16,000\u00a0km) of rail network lies in England, covering the country fairly extensively. There is rail transport access to France and Belgium through an undersea rail link, the Channel Tunnel, which was completed in 1994.  Great British Railways is a planned state-owned public body that will oversee rail transport in Great Britain from 2024. The Office of Rail and Road is responsible for the economic and safety regulation of England's railways.[160] Crossrail was Europe's largest construction project with a \u00a315\u00a0billion projected cost, opened in 2022.[161] High Speed 2, a new high-speed north\u2013south railway line, is under construction.[162]  There is a rapid transit network in two English cities: the London Underground, and the Tyne and Wear Metro in Newcastle upon Tyne, Gateshead and Sunderland.[163] There are several extensive tram networks, such as the Manchester Metrolink, Sheffield Supertram, West Midlands Metro, Nottingham Express Transit, and Tramlink in South London.[163] England also has extensive domestic and international aviation links. The largest airport is Heathrow, which is the world's second busiest airport measured by number of international passengers.[164]  By sea there is ferry transport, both local and international, including from Liverpool to Ireland and the Isle of Man, and Hull to the Netherlands and Belgium.[165] There are around 4,400 miles (7,100\u00a0km) of navigable waterways in England, half of which is owned by the Canal & River Trust,[165] however, water transport is very limited. The River Thames is the major waterway in England, with imports and exports focused at the Port of Tilbury in the Thames Estuary, one of the United Kingdom's three major ports.[165]  Successive governments have outlined numerous commitments to reduce carbon dioxide emissions. Notably, the UK is one of the best sites in Europe for wind energy, and wind power production is its fastest growing supply.[167] Wind power contributed 26.8% of UK electricity generation in 2022.[168] England is home to Hornsea 2, the largest offshore wind farm in the world, situated in waters roughly 89 kilometres off the coast of Yorkshire.[169]  The Climate Change Act 2008 was passed in Parliament with an overwhelming majority across political parties. It sets out emission reduction targets that the UK must comply with legally. It represents the first global legally binding climate change mitigation target set by a country.[170] UK government energy policy aims to play a key role in limiting greenhouse gas emissions, while meeting energy demand. Shifting availabilities of resources and development of technologies also change the country's energy mix through changes in costs.[171]  The current energy policy is the responsibility of the Department for Energy Security and Net Zero and Secretary of State for Energy Security and Net Zero.[172] The Minister of State for Business, Energy and Clean Growth is responsible for green finance, climate science and innovation, and low carbon generation.[173] In 2022, the United Kingdom was ranked 2 out of 180 countries in the Environmental Performance Index.[174] A law has been passed that UK greenhouse gas emissions will be net zero by 2050.[175]  The National Health Service (NHS), is the publicly funded healthcare system responsible for providing the majority of healthcare in the country. The NHS began on 5 July 1948, putting into effect the provisions of the National Health Service Act 1946. It was based on the findings of the Beveridge Report, prepared by the economist and social reformer, William Beveridge.[176] The NHS is largely funded by general taxation and National Insurance payments;[177] it provides most of its services free at the point of use, although there are charges for some people for eye tests, dental care, prescriptions and aspects of personal care.[178]  The government department responsible for the NHS is the Department of Health, under the Secretary of State for Health. Most of the department's expenses are on the NHS\u2014\u00a398.6\u00a0billion was spent in 2008\u20132009.[179] Regulatory bodies such as the General Medical Council and the Nursing and Midwifery Council are organised on a UK-wide basis, as are non-governmental bodies such as the Royal Colleges.  The average life expectancy is 77.5 years for males and 81.7 years for females, the highest of the four countries of the United Kingdom.[180] The south of England has a higher life expectancy than the north, but regional differences seem to be slowly narrowing: between 1991\u20131993 and 2012\u20132014, life expectancy in the North East increased by 6.0 years and in the North West by 5.8 years.[180]  With over 56\u00a0million inhabitants, England is by far the most populous country of the United Kingdom, accounting for 84% of the combined total.[3] England taken as a unit and measured against international states would be the 26th largest country by population in the world.[181]  The English people are British people.[182] There is an English diaspora in former parts of the British Empire; especially the United States, Canada, Australia, South Africa and New Zealand.[e] Since the late 1990s, many English people have migrated to Spain.[187] Due in particular to the economic prosperity of South East England, it has received many economic migrants from the other parts of the United Kingdom.[182] There has been significant Irish migration.[188] The proportion of ethnically European residents totals at 87.50%, including Germans[189] and Poles.[182] Other people from much further afield in the former British colonies have arrived since the 1950s: in particular, 6% of people living in England have family origins in the Indian subcontinent, mostly India, Pakistan and Bangladesh.[182][189] About 0.7% are Chinese.[182][189] 2.90% of the population are black, from Africa and the Caribbean, especially former British colonies.[182][189] In 2007, 22% of primary school children in England were from ethnic minority families,[190] and in 2011 that figure was 26.5%.[191] About half of the population increase between 1991 and 2001 was due to immigration.[192]  England contains one indigenous national minority, the Cornish people, recognised by the UK government under the Framework Convention for the Protection of National Minorities in 2014.[193]  (thousands)[194]  English, today spoken by hundreds of millions of people around the world, originated in what is now England, where it remains the principal tongue. According to a 2011 census, it is spoken well or very well by 98% of the population[195] and is widely spoken around the world.[196]  English language learning and teaching is an important economic activity. There is no legislation mandating an official language for England,[197] but English is the only language used for official business. Despite the country's relatively small size, there are many distinct regional accents.  Cornish died out as a community language in the 18th century but is being revived,[198] and is now protected under the European Charter for Regional or Minority Languages.[199] It is spoken by 0.1% of people in Cornwall,[200] and is taught to some degree in several primary and secondary schools.[201]  State schools teach students a second language or third language from the ages of seven, most commonly French, Spanish or German.[202] It was reported in 2007 that around 800,000 school students spoke a foreign language at home,[190] the most common being Punjabi and Urdu. However, following the 2011 census data released by the Office for National Statistics, figures now show that Polish is the main language spoken in England after English.[203] In 2022, British Sign Language became an official language of England when the British Sign Language Act 2022 came into effect.[204]  In the 2011 census, 59.4% of the population of England specified their religion as Christian, 24.7% answered that they had no religion, 5% specified that they were Muslim, while 3.7% of the population belongs to other religions and 7.2% did not give an answer.[205] Christianity is the most widely practised religion in England. The established church of England is the Church of England,[206] which left communion with Rome in the 1530s when Henry\u00a0VIII was unable to annul his marriage to Catherine of Aragon. The church regards itself as both Catholic and Protestant.[207]  There are High Church and Low Church traditions and some Anglicans regard themselves as Anglo-Catholics, following the Tractarian movement. The monarch of the United Kingdom is the supreme governor of the Church of England, which has around 26\u00a0million baptised members (of whom the vast majority are not regular churchgoers). It forms part of the Anglican Communion with the Archbishop of Canterbury acting as its symbolic worldwide head.[208] Many cathedrals and parish churches are historic buildings of significant architectural importance, such as Westminster Abbey, York Minster, Durham Cathedral, and Salisbury Cathedral.  The second-largest Christian denomination is the Catholic Church. Since its reintroduction after the Catholic Emancipation, the Church has organised ecclesiastically on an England and Wales basis where there are 4.5\u00a0million members (most of whom are English).[209] There has been one Pope from England to date, Adrian IV, while saints Bede and Anselm are regarded as Doctors of the Church.  A form of Protestantism known as Methodism is the third largest Christian practice and grew out of Anglicanism through John Wesley.[210] It gained popularity in the mill towns of Lancashire and Yorkshire, and among tin miners in Cornwall.[211] There are other non-conformist minorities, such as Baptists, Quakers, Congregationalists, Unitarians and The Salvation Army.[212]  The patron saint of England is Saint George; his symbolic cross is included in the flag of England.[213] There are many other English and associated saints, including Cuthbert, Edmund, Alban, Wilfrid, Aidan, Edward the Confessor, John Fisher, Thomas More, Petroc, Piran, Margaret Clitherow and Thomas Becket. There are non-Christian religions practised. Jews have a history of a small minority on the island since 1070.[214] They were expelled from England in 1290 following the Edict of Expulsion, and were allowed back in 1656.[214]  Especially since the 1950s, religions from the former British colonies have grown in numbers, due to immigration. Islam is the most common of these, now accounting for around 5% of the population in England.[215] Hinduism, Sikhism and Buddhism are next in number, adding up to 2.8% combined,[215] introduced from India and Southeast Asia.[215]  A small minority of the population practise ancient Pagan religions. Neopaganism in the United Kingdom is primarily represented by Wicca and Neopagan witchcraft, Druidry, and Heathenry. According to the 2011 census, there are roughly 53,172 people who identify as Pagan in England,[f] including 11,026 Wiccans.[g] 24.7% of people in England declared no religion, compared with 14.6% in 2001.[216] Norwich had the highest such proportion at 42.5%, followed by Brighton and Hove at 42.4%.  The Department for Education is the government department responsible for issues affecting people in England up to the age of 19, including education.[217] State-funded schools are attended by approximately 93% of English schoolchildren.[218] Education is the responsibility of the Secretary of State for Education.[219]   Children between the ages of 3 and 5 attend nursery or an Early Years Foundation Stage reception unit within a primary school. Children between the ages of 5 and 11 attend primary school, and secondary school is attended by those aged between 11 and 16. State-funded schools are obliged by law to teach the National Curriculum; basic areas of learning include English literature, English language, mathematics, science, art & design, citizenship, history, geography, religious education, design & technology, computing, ancient & modern languages, music, and physical education.[220] The Programme for International Student Assessment coordinated by the OECD currently ranks the overall knowledge and skills of British 15-year-olds as 13th in the world in literacy, mathematics, and science with the average British student scoring 503.7, well above the OECD average of 493.[221]  Although most English secondary schools are comprehensive, there are selective intake grammar schools to which entrance is subject to passing the eleven-plus exam. Around 7.2 per cent of English schoolchildren attend private schools, which are funded by private sources.[222] Standards in state schools are monitored by the Office for Standards in Education, and in private schools by the Independent Schools Inspectorate.[223]  After finishing compulsory education, students take GCSE examinations. Students may then opt to continue into further education for two years. Further education colleges (particularly sixth form colleges) often form part of a secondary school site. A-level examinations are sat by a large number of further education students, and often form the basis of an application to university. Further education covers a wide curriculum of study and apprenticeships, including T-levels, BTEC, NVQ and others. Tertiary colleges provide both academic and vocational courses.[224]  Higher education students normally attend university from age 18 onwards, where they study for an academic degree. There are over 90\u00a0universities in England, all but one of which are public institutions. The Department for Business, Innovation and Skills is the government department responsible for higher education in England.[225] Students are generally entitled to student loans to cover tuition fees and living costs.[h] The first degree offered to undergraduates is the bachelor's degree, which usually takes three years to complete. Students are then able to work towards a postgraduate degree, which usually takes one year, or a doctorate, which takes three or more years.[227]  England's universities include some of the highest-ranked universities in the world. As of 2024, four England-based universities, the University of Cambridge, University of Oxford, Imperial College London, and University College London, are ranked among the top ten in the 2024 QS World University Rankings. The University of Cambridge, founded in 1209, and the University of Oxford, founded in 1096, are the two oldest universities in the English-speaking world.[228]  The London School of Economics has been described as the world's leading social science institution for both teaching and research.[229] The London Business School is considered one of the world's leading business schools and in 2010 its MBA programme was ranked best in the world by the Financial Times.[230] Academic degrees in England are usually split into classes: first class, upper second class, lower second class, third, and unclassified.[227] The King's School, Canterbury and King's School, Rochester are the oldest schools in the English-speaking world.[231] Many of England's most well-known schools, such as Winchester College, Eton, St Paul's School, Harrow School and Rugby School are fee-paying institutions.[232]  Many ancient standing stone monuments were erected during the prehistoric period; among the best known are Stonehenge, Devil's Arrows, Rudston Monolith and Castlerigg.[233] With the introduction of Ancient Roman architecture there was a development of basilicas, baths, amphitheaters, triumphal arches, villas, Roman temples, Roman roads, Roman forts, stockades and aqueducts.[234] It was the Romans who founded the first cities and towns such as London, Bath, York, Chester and St Albans. Perhaps the best-known example is Hadrian's Wall stretching right across northern England.[234] Another well-preserved example is the Roman Baths at Bath, Somerset.[234]  Early medieval architecture's secular buildings were simple constructions mainly using timber with thatch for roofing. Ecclesiastical architecture ranged from a synthesis of Hiberno\u2013Saxon monasticism,[235][236] to Early Christian basilica and architecture characterised by pilaster-strips, blank arcading, baluster shafts and triangular headed openings. After the Norman conquest in 1066 various castles were created; the best known include the Tower of London, Warwick Castle, Durham Castle and Windsor Castle.[237]  Throughout the Plantagenet era, an English Gothic architecture flourished, with prime examples including the medieval cathedrals such as Canterbury Cathedral, Westminster Abbey and York Minster.[237] Expanding on the Norman base there was also castles, palaces, great houses, universities and parish churches. Medieval architecture was completed with the 16th-century Tudor style; the four-centred arch, now known as the Tudor arch, was a defining feature as were wattle and daub houses domestically. In the aftermath of the Renaissance a form of architecture echoing classical antiquity synthesised with Christianity appeared, the English Baroque style of architect Christopher Wren being particularly championed.[238]  Georgian architecture followed in a more refined style, evoking a simple Palladian form; the Royal Crescent at Bath is one of the best examples of this. With the emergence of romanticism during Victorian period, a Gothic Revival was launched. In addition to this, around the same time the Industrial Revolution paved the way for buildings such as The Crystal Palace. Since the 1930s various modernist forms have appeared whose reception is often controversial, though traditionalist resistance movements continue with support in influential places.[i]  Landscape gardening, as developed by Capability Brown, set an international trend for the English landscape garden. Gardening, and visiting gardens, are regarded as typically English pursuits. The English garden presented an idealized view of nature. At large country houses, the English garden usually included lakes, sweeps of gently rolling lawns set against groves of trees, and recreations of classical temples, Gothic ruins, bridges, and other picturesque architecture, designed to recreate an idyllic pastoral landscape.[241]  By the end of the 18th century, the English garden was being imitated by the French landscape garden, and as far away as Pavlovsk, Saint Petersburg, the gardens of the future Emperor Paul. It also had a major influence on the public parks and gardens which appeared around the world in the 19th century.[242] The English landscape garden was centred on the English country house and manor houses.[241]  English Heritage and the National Trust preserve great gardens and landscape parks throughout the country.[243] The RHS Chelsea Flower Show is held every year by the Royal Horticultural Society and is said to be the largest gardening show in the world.[244]  English folklore developed over many centuries. Some of the characters and stories are present across England, but most belong to specific regions. Common folkloric beings include pixies, giants, elves, bogeymen, trolls, goblins and dwarves. While many legends and folk-customs are thought to be ancient, such as the tales featuring Offa of Angel and Wayland the Smith,[245] others date from after the Norman invasion. The legends featuring Robin Hood and his Merry Men of Sherwood, and their battles with the Sheriff of Nottingham, are among the best-known of these.[246]  During the High Middle Ages tales originating from Brythonic traditions entered English folklore and developed into the Arthurian myth.[247][248][249] These were derived from Anglo-Norman, Welsh and French sources,[248] featuring King Arthur, Camelot, Excalibur, Merlin and the Knights of the Round Table such as Lancelot. These stories are most centrally brought together within Geoffrey of Monmouth's Historia Regum Britanniae (History of the Kings of Britain).[j]  Some folk figures are based on semi or actual historical people whose story has been passed down centuries.[251] On 5 November people celebrate Bonfire Night to commemorate the foiling of the Gunpowder Plot centred on Guy Fawkes. There are various national and regional folk activities, participated in to this day, such as Morris dancing, Maypole dancing, Rapper sword in the North East, Long Sword dance in Yorkshire, Mummers Plays, bottle-kicking in Leicestershire, and cheese-rolling at Cooper's Hill.[252] There is no official national costume, but a few are well established such as the Pearly Kings and Queens associated with cockneys, the Royal Guard, the Morris costume and Beefeaters.[253]  Since the early modern period the food of England has historically been characterised by its simplicity of approach and a reliance on the high quality of natural produce.[254] During the Middle Ages and the Renaissance, English cuisine enjoyed an excellent reputation, though a decline began during the Industrial Revolution with increasing urbanisation. The cuisine of England has, however, recently undergone a revival, which has been recognised by food critics with some good ratings in Restaurant's best restaurant in the world charts.[255] Traditional examples of English food include the Sunday roast, featuring a roasted joint (usually beef, lamb, chicken or pork) served with assorted vegetables, Yorkshire pudding and gravy.[256] Other prominent meals include fish and chips and the full English breakfast (generally consisting of bacon, sausages, grilled tomatoes, fried bread, black pudding, baked beans, mushrooms and eggs).[257] Various meat pies are consumed, such as steak and kidney pie, steak and ale pie, cottage pie, pork pie (usually eaten cold)[256] and the Cornish pasty.  Sausages are commonly eaten, either as bangers and mash or toad in the hole. Lancashire hotpot is a well-known stew originating in the northwest. Some of the more popular cheeses are Cheddar, Red Leicester, Wensleydale, Double Gloucester and Blue Stilton. Many Anglo-Indian hybrid dishes, curries, have been created, such as chicken tikka masala and balti. Traditional English dessert dishes include apple pie or other fruit pies; spotted dick \u2013 all generally served with custard; and, more recently, sticky toffee pudding. Sweet pastries include scones served with jam or cream, dried fruit loaves, Eccles cakes and mince pies as well as sweet or spiced biscuits.  Common non-alcoholic drinks include tea[258] and coffee; frequently consumed alcoholic drinks include wine, ciders and English beers, such as bitter, mild, stout and brown ale.[259]  The earliest known examples are the prehistoric rock and cave art pieces, most prominent in North Yorkshire, Northumberland and Cumbria, but also feature further south, for example at Creswell Crags.[260] With the arrival of Roman culture in the 1st century, various forms of art such as statues, busts, glasswork and mosaics were the norm. There are numerous surviving artefacts, such as those at Lullingstone and Aldborough.[261] During the Early Middle Ages the style favoured sculpted crosses and ivories, manuscript painting, gold and enamel jewellery, demonstrating a love of intricate, interwoven designs such as in the Staffordshire Hoard discovered in 2009. Some of these blended Gaelic and Anglian styles, such as the Lindisfarne Gospels and Vespasian Psalter.[262] Later Gothic art was popular at Winchester and Canterbury, examples survive such as Benedictional of St. \u00c6thelwold and Luttrell Psalter.[263]  The Tudor era saw prominent artists as part of their court; portrait painting, which would remain an enduring part of English art, was boosted by German Hans Holbein, and natives such as Nicholas Hilliard built on this.[263] Under the Stuarts, Continental artists were influential especially the Flemish, examples from the period include Anthony van Dyck, Peter Lely, Godfrey Kneller and William Dobson.[263] The 18th century saw the founding of the Royal Academy; a classicism based on the High Renaissance prevailed, with Thomas Gainsborough and Joshua Reynolds becoming two of England's most treasured artists.[263]  In the 19th century, John Constable and J. M. W. Turner were major landscape artists. The Norwich School continued the landscape tradition, while the Pre-Raphaelite Brotherhood, led by artists such as Holman Hunt, Dante Gabriel Rossetti and John Everett Millais, revived the Early Renaissance style with their vivid and detailed style.[263] Prominent among 20th-century artists was Henry Moore, regarded as the voice of British sculpture, and of British modernism in general.[264] The Royal Society of Arts is an organisation committed to the arts.[265]  Early authors such as Bede and Alcuin wrote in Latin.[266] The period of Old English literature provided the epic poem Beowulf and the secular prose of the Anglo-Saxon Chronicle,[267] along with Christian writings such as Judith, C\u00e6dmon's Hymn and hagiographies.[266] Following the Norman conquest Latin continued among the educated classes, as well as an Anglo-Norman literature.  Middle English literature emerged with Geoffrey Chaucer, author of The Canterbury Tales, along with Gower, the Pearl Poet and Langland. William of Ockham and Roger Bacon, who were Franciscans, were major philosophers of the Middle Ages. Julian of Norwich, who wrote Revelations of Divine Love, was a prominent Christian mystic. With the English Renaissance literature in the Early Modern English style appeared. William Shakespeare, whose works include Hamlet, Romeo and Juliet, Macbeth, and A Midsummer Night's Dream, remains one of the most championed authors in English literature.[268]  Christopher Marlowe, Edmund Spenser, Philip Sydney, Thomas Kyd, John Donne, and Ben Jonson are other established authors of the Elizabethan age.[269] Francis Bacon and Thomas Hobbes wrote on empiricism and materialism, including scientific method and social contract.[269] Filmer wrote on the Divine Right of Kings. Marvell was the best-known poet of the Commonwealth,[270] while John Milton authored Paradise Lost during the Restoration.  This royal throne of kings, this sceptred isle, this earth of majesty, this seat of Mars, this other Eden, demi-paradise; this fortress, built by nature for herself. This blessed plot, this earth, this realm, this England.  William Shakespeare.[271] Some of the most prominent philosophers of the Enlightenment were John Locke, Thomas Paine, Samuel Johnson and Jeremy Bentham. More radical elements were later countered by Edmund Burke who is regarded as the founder of conservatism.[272] The poet Alexander Pope with his satirical verse became well regarded. The English played a significant role in romanticism: Samuel Taylor Coleridge, Lord Byron, John Keats, Mary Shelley, Percy Bysshe Shelley, William Blake and William Wordsworth were major figures.[273]  In response to the Industrial Revolution, agrarian writers sought a way between liberty and tradition; William Cobbett, G. K. Chesterton and Hilaire Belloc were main exponents, while the founder of guild socialism, Arthur Penty, and cooperative movement advocate G. D. H. Cole are somewhat related.[274] Empiricism continued through John Stuart Mill and Bertrand Russell, while Bernard Williams was involved in analytics. Authors from around the Victorian era include Charles Dickens, the Bront\u00eb sisters, Jane Austen, George Eliot, Rudyard Kipling, Thomas Hardy, H. G. Wells and Lewis Carroll.[275] Since then England has continued to produce novelists such as George Orwell, D. H. Lawrence, Virginia Woolf, C. S. Lewis, Enid Blyton, Aldous Huxley, Agatha Christie, Terry Pratchett, J. R. R. Tolkien, and J. K. Rowling.[276]  The traditional folk music of England is centuries old and has contributed to several genres prominently; mostly sea shanties, jigs, hornpipes and dance music. It has its own distinct variations and regional peculiarities. Ballads featuring Robin Hood, printed by Wynkyn de Worde in the 16th century, are an important artefact, as are John Playford's The Dancing Master and Robert Harley's Roxburghe Ballads collections.[277] Some of the best-known songs are Greensleeves, Pastime with Good Company, Maggie May and Spanish Ladies among others. Many nursery rhymes are of English origin such as Mary, Mary, Quite Contrary, Roses Are Red, Jack and Jill, London Bridge Is Falling Down, The Grand Old Duke of York, Hey Diddle Diddle and Humpty Dumpty.[278] Traditional English Christmas carols include \"We Wish You a Merry Christmas\", \"The First Noel\", \"I Saw Three Ships\" and \"God Rest You Merry, Gentlemen\".   Early English composers in classical music include Renaissance artists Thomas Tallis and William Byrd, followed by Henry Purcell from the Baroque period and Thomas Arne who was well known for his patriotic song Rule, Britannia!. German-born George Frideric Handel spent most of his composing life in London and became a national icon in Britain, creating some of the most well-known works of classical music, especially his English oratorios, The Messiah, Solomon, Water Music, and Music for the Royal Fireworks.[279] Classical music attracted much attention in the 18th century with the formation of the Birmingham Triennial Music Festival, which was the longest running classical music festival of its kind until the final concerts in 1912. The English Musical Renaissance was a hypothetical development in the late 19th and early 20th century, when English composers, often those lecturing or trained at the Royal College of Music, were said to have freed themselves from foreign musical influences. There was a revival in the profile of composers from England in the 20th century led by Edward Elgar, Benjamin Britten, Frederick Delius, Gustav Holst, Ralph Vaughan Williams and others.[281] Present-day composers from England include Michael Nyman, best known for The Piano, and Andrew Lloyd Webber, whose musicals have achieved enormous success in the West End and worldwide.  In popular music, many English bands and solo artists have been cited as the most influential and best-selling musicians of all time. Acts such as the Beatles, Led Zeppelin, Pink Floyd, Elton John, Queen, Rod Stewart, David Bowie, the Rolling Stones and Def Leppard are among the highest-selling recording artists in the world.[282] Many musical genres have origins in (or strong associations with) England, such as British invasion, progressive rock, hard rock, Mod, glam rock, heavy metal, Britpop, indie rock, gothic rock, shoegazing, acid house, garage, trip hop, drum and bass and dubstep.[283]  Large outdoor music festivals in the summer and autumn are popular, such as Glastonbury, V Festival, and the Reading and Leeds Festivals. England was at the forefront of the illegal, free rave movement from the late 1980s, which inspired the pan-European culture of teknivals.[284] The Boishakhi Mela is a Bengali New Year festival celebrated by the British Bangladeshi community. It is the largest open-air Asian festival in Europe. After the Notting Hill Carnival, it is the second-largest street festival in the UK, attracting over 80,000 visitors.  The most prominent opera house in England is the Royal Opera House at Covent Garden.[285] The Proms is a major annual cultural event in the English calendar.[285] The Royal Ballet is one of the world's foremost classical ballet companies. The Royal Academy of Music is the oldest conservatoire in the UK, founded in 1822, receiving its royal charter in 1830.[286] England is home to numerous major orchestras such as the BBC Symphony Orchestra, the Royal Philharmonic Orchestra, the Philharmonia Orchestra, and the London Symphony Orchestra.[287] Other forms of entertainment that originated in England include the circus[288][289][290] and the pantomime.[291]  England has had a considerable influence on the history of the cinema, producing some of the greatest actors, directors and motion pictures of all time, including Alfred Hitchcock, Charlie Chaplin, David Lean, Laurence Olivier, Vivien Leigh, John Gielgud, Peter Sellers, Julie Andrews, Michael Caine, Gary Oldman, Helen Mirren, Kate Winslet and Daniel Day-Lewis. Hitchcock and Lean are among the most critically acclaimed filmmakers.[292] Hitchcock's The Lodger: A Story of the London Fog (1926) helped shape the thriller genre in film, while his 1929 Blackmail is often regarded as the first British sound feature film.[293]  Major film studios in England include Pinewood, Elstree and Shepperton. Some of the most commercially successful films of all time have been produced in England, including two of the highest-grossing film franchises (Harry Potter and James Bond).[294] Ealing Studios in London has a claim to being the oldest continuously working film studio in the world.[295] Famous for recording many motion picture film scores, the London Symphony Orchestra first performed film music in 1935.[296] The Hammer Horror films starring Christopher Lee saw the production of the first gory horror films showing blood and guts in colour.[297]  The BFI Top 100 British films includes Monty Python's Life of Brian (1979), a film regularly voted the funniest of all time by the UK public.[298] English producers are also active in international co-productions and English actors, directors and crew feature regularly in American films. The UK film council ranked David Yates, Christopher Nolan, Mike Newell, Ridley Scott and Paul Greengrass the five most commercially successful English directors since 2001.[299] Other contemporary English directors include Sam Mendes, Guy Ritchie and Richard Curtis. Current actors include Tom Hardy, Daniel Craig, Benedict Cumberbatch, Lena Headey, Felicity Jones, Emilia Clarke, Lashana Lynch, and Emma Watson. Acclaimed for his motion capture work, Andy Serkis opened The Imaginarium Studios in London in 2011.[300] The visual effects company Framestore in London has produced some of the most critically acclaimed special effects in modern film.[301] Many successful Hollywood films have been based on English people, stories or events. The 'English Cycle' of Disney animated films include Alice in Wonderland, The Jungle Book and Winnie the Pooh.[302]  English Heritage is a governmental body with a broad remit of managing the historic sites, artefacts and environments of England. It is currently sponsored by the Department for Culture, Media and Sport. A non-governmental charity, the National Trust holds a complementary role, focussed on landscapes and country houses. 17 of the 25 United Kingdom UNESCO World Heritage Sites fall within England.[303] Some of the best-known of these are: Hadrian's Wall, Stonehenge, Avebury and Associated Sites, the Tower of London, the Jurassic Coast, Saltaire, Ironbridge Gorge, Blenheim Palace and the Lake District.[304]  London's British Museum holds more than seven million objects,[305] one of the largest and most comprehensive collections in the world,[306] illustrating and documenting global human culture from its beginnings to the present. The British Library in London is the national library and is one of the world's largest research libraries, holding over 150\u00a0million items in almost all known languages and formats, including around 25\u00a0million books.[307][308] The National Gallery in Trafalgar Square houses a collection of over 2,300 paintings dating from the mid-13th century to 1900.[309] The Tate galleries house the national collections of British and international modern art; they also host the Turner Prize.[310]  The Secretary of State for Culture, Media and Sport has overall responsibility for cultural property and heritage.[311][312] A blue plaque, the oldest historical marker scheme in the world, is a permanent sign installed in a public place in England to commemorate a link between that location and a famous person or event. In 2011 there were around 1,600 museums in England.[313] Entry to most museums and galleries is free.[314] London is one of the world's most visited cities, regularly taking the top five most visited cities in Europe. It is considered a global centre of finance, art and culture.[315]  The BBC, founded in 1922, is the UK's publicly funded radio, television and Internet broadcasting corporation, and is the oldest and largest broadcaster in the world.[317][318] It operates numerous television and radio stations in the UK and abroad and its domestic services are funded by the television licence.[319][320] The BBC World Service is an international broadcaster owned and operated by the BBC. It is the world's largest of any kind.[321] It broadcasts radio news, speech and discussions in more than 40 languages.[322][323]  London dominates the media sector in England: national newspapers and television and radio are largely based there, although Manchester is also a significant national media centre. The UK publishing sector, including books, directories and databases, journals, magazines and business media, newspapers and news agencies, has a combined turnover of around \u00a320\u00a0billion and employs around 167,000 people.[324] National newspapers produced in England include The Times, The Guardian, The Daily Telegraph, and the Financial Times.[325]  Magazines and journals published in England that have achieved worldwide circulation include Nature, New Scientist, The Spectator, Prospect, NME and The Economist. The Secretary of State for Culture, Media and Sport has overall responsibility over media and broadcasting in England.[326]  England has a strong sporting heritage, and during the 19th century codified many sports that are now played around the world. Sports originating in England include association football,[327] cricket, rugby union, rugby league, tennis, boxing, badminton, squash,[328] rounders,[329] hockey, snooker, billiards, darts, table tennis, bowls, netball, thoroughbred horseracing, greyhound racing and fox hunting. It has helped the development of golf, sailing and Formula One.  Football is the most popular of these sports. The England national football team, whose home venue is Wembley Stadium, played Scotland in the first ever international football match in 1872.[330] Referred to as the \"home of football\" by FIFA, England hosted and won the 1966 FIFA World Cup.[331] With a British television audience peak of 32.30\u00a0million viewers, the final is the most watched television event ever in the UK.[332] England is recognised by FIFA as the birthplace of club football: Sheffield F.C., founded in 1857, is the world's oldest club.[327] The England women's national football team won the UEFA Euro 2022, hosted by England.[333]  Cricket is generally thought to have been developed in the early medieval period among the farming and metalworking communities of the Weald.[334] The England cricket team is a composite England and Wales team. One of the game's top rivalries is The Ashes series between England and Australia, contested since 1882. Lord's Cricket Ground situated in London is sometimes referred to as the \"Mecca of Cricket\".[335] After winning the 2019 Cricket World Cup, England became the first country to win the World Cups in football, rugby union, and cricket.[336]  William Penny Brookes was prominent in organising the format for the modern Olympic Games.[337] London has hosted the Summer Olympic Games three times, in 1908, 1948, and 2012. England competes in the Commonwealth Games, held every four years. Sport England is the governing body responsible for distributing funds and providing strategic guidance for sporting activity in England.  Rugby union originated in Rugby School, Warwickshire in the early 19th century.[338] The top level of club participation is the English Premiership. Rugby league was born in Huddersfield in 1895. Since 2008, the England national rugby league team has been a full test nation in lieu of the Great Britain national rugby league team, which won three World Cups. Club sides play in Super League, the present-day embodiment of the Rugby Football League Championship. Rugby League is most popular among towns in the northern English counties of Lancashire, Yorkshire and Cumbria.[339]  Golf has been prominent in England, due in part to its cultural and geographical ties to Scotland.[340] There are professional tours for men and women, in two main tours: the PGA and the European Tour. The world's oldest golf tournament, and golf's first major is The Open Championship, played both in England and Scotland. The biennial golf competition, the Ryder Cup, is named after English businessman Samuel Ryder.[341]  Tennis was created in Birmingham in the late 19th century, and the Wimbledon Championships is the oldest tennis tournament in the world, and widely considered the most prestigious.[342] Wimbledon has a major place in the English cultural calendar.[343]  In boxing, under the Marquess of Queensberry Rules, England has produced many world champions across the weight divisions internationally recognised by the governing bodies.[344]  Originating in 17th and 18th-century England, the thoroughbred is a horse breed best known for its use in horse racing. The National Hunt horse race the Grand National, is held annually at Aintree Racecourse in early April. It is the most watched horse race in the UK, and three-time winner Red Rum is the most successful racehorse in the event's history.[345]  The 1950 British Grand Prix at Silverstone was the first race in the newly created Formula One World Championship.[346][347] It has manufactured some of the most technically advanced racing cars, and many of today's racing companies choose England as their base of operations. England also has a rich heritage in Grand Prix motorcycle racing, the premier championship of motorcycle road racing, and produced several world champions.  Darts is a widely popular sport in England; a professional competitive sport, it is a traditional pub game.[348][349] Another popular sport commonly associated with pub games is snooker, and England has produced several world champions. The English are keen sailors and enjoy competitive sailing; founding and winning some of the world's most famous international competitive tournaments across the various race formats, including the match race, a regatta, and the America's Cup.  The St George's Cross has been the national flag of England since the 13th century. Originally the flag was used by the maritime Republic of Genoa. The English monarch paid a tribute to the Doge of Genoa from 1190 onwards so that English ships could fly the flag as a means of protection when entering the Mediterranean. A red cross was a symbol for many Crusaders in the 12th and 13th centuries, and became associated with Saint George.[350] Since 1606 the St George's Cross has formed part of the design of the Union Flag, a Pan-British flag designed by King James I.[213] During the English Civil War and Interregnum, the New Model Army's standards and the Commonwealth's Great Seal both incorporated the flag of Saint George.[351][352]  There are numerous other symbols and symbolic artefacts, both official and unofficial, including the Tudor rose, the nation's floral emblem, and the Three Lions featured on the Royal Arms of England. The Tudor rose was adopted as a national emblem of England around the time of the Wars of the Roses as a symbol of peace.[353] It is a syncretic symbol in that it merged the white rose of the Yorkists and the red rose of the Lancastrians. It is also known as the Rose of England.[354] The oak tree is a symbol of England: the Royal Oak symbol and Oak Apple Day commemorate the escape of King Charles II after his father's execution, when he hid in an oak to avoid detection by the parliamentarians before safely reaching exile.  The Royal Arms of England, a national coat of arms featuring three lions, originated with Richard the Lionheart in 1198. It is blazoned as gules, three lions passant guardant or and it provides one of the most prominent symbols of England. England does not have an official national anthem, as the United Kingdom as a whole has God Save the King. However, Jerusalem, Land of Hope and Glory (used for England during the 2002 Commonwealth Games),[355] and I Vow to Thee, My Country are often considered unofficial English national anthems. England's National Day is 23 April which is Saint George's Day: Saint George is the patron saint of England.[356]  53\u00b008\u2032N 1\u00b023\u2032W\ufeff \/ \ufeff53.13\u00b0N 1.38\u00b0W\ufeff \/ 53.13; -1.38 "},{"title":"Hockey","content":"    Hockey is a term used to denote a family of various types of both summer and winter team sports which originated on either an outdoor field, sheet of ice, or dry floor such as in a gymnasium. While these sports vary in specific rules, numbers of players, apparel, and playing surface, they share broad characteristics of two opposing teams using a stick to propel a ball or disk into a goal.  There are many types of hockey. Some games make the use of skates, either wheeled or bladed, while others do not. In order to help make the distinction between these various games, the word hockey is often preceded by another word i.e. field hockey, ice hockey, roller hockey, rink hockey, or floor hockey.  In each of these sports, two teams play against each other by trying to manoeuvre the object of play, either a type of ball or a disk (such as a puck), into the opponent's goal using a hockey stick. Two notable exceptions use a straight stick and an open disk (still referred to as a puck) with a hole in the center instead. The first case is a style of floor hockey whose rules were codified in 1936 during the Great Depression by Canada's Sam Jacks. The second case involves a variant which was later modified in roughly the 1970s to make a related game that would be considered suitable for inclusion as a team sport in the newly emerging Special Olympics. The floor game of gym ringette, though related to floor hockey, is not a true variant due to the fact that it was designed in the 1990s and modelled off of the Canadian ice skating team sport of ringette, which was invented in Canada in 1963. Ringette was also invented by Sam Jacks, the same Canadian who codified the rules for the open disk style of floor hockey 1936.  Certain sports which share general characteristics with the forms of hockey, but are not generally referred to as hockey include lacrosse, hurling, camogie, and shinty.  The first recorded use of the word hockey is in the 1773 book Juvenile Sports and Pastimes, to Which Are Prefixed, Memoirs of the Author: Including a New Mode of Infant Education by Richard Johnson (Pseud. Master Michel Angelo), whose chapter XI was titled \"New Improvements on the Game of Hockey\".[1] The belief that hockey was mentioned in a 1363 proclamation by King Edward III of England[2] is based on modern translations of the proclamation, which was originally in Latin and explicitly forbade the games \"Pilam Manualem, Pedivam, & Bacularem: & ad Canibucam & Gallorum Pugnam\".[3][4] The English historian and biographer John Strype did not use the word \"hockey\" when he translated the proclamation in 1720, instead translating \"Canibucam\" as \"Cambuck\";[5] this may have referred to either an early form of hockey or a game more similar to golf or croquet.[6]  The word hockey itself is of unknown origin. One supposition is that it is a derivative of hoquet, a Middle French word for a shepherd's stave.[7] The curved, or \"hooked\" ends of the sticks used for hockey would indeed have resembled these staves, and similar folk etymologies exist for the bat-and-ball sports of Croquet and Cricket. Another supposition derives from the known use of cork bungs (stoppers), in place of wooden balls to play the game. The stoppers came from barrels containing \"hock\" ale, also called \"hocky\".[8]  In most of the world, the term hockey when used without clarification refers to field hockey, while in Canada, the United States, Russia and most of Eastern and Northern Europe, the term usually refers to ice hockey.[9]  In more recent history, the word \"hockey\" is used in reference to either the summer Olympic sport of field hockey, which is a stick and ball game, and the winter ice team skating sports of bandy and ice hockey. This is due to the fact that field hockey and other stick and ball sports and their related variants preceded games which would eventually be played on ice with ice skates, namely bandy and ice hockey, as well as sports involving dry floors such as roller hockey and floor hockey. However, the \"hockey\" referred to in common parlance often depends on locale, geography, and the size and popularity of the sport involved. For example, in Europe, \"hockey\" more typically refers to field hockey, whereas in Canada, it typically refers to ice hockey. In the case of bandy, the game was initially called \"hockey on the ice\" and preceded the organization and development of ice hockey, but was officially changed to \"bandy\" in the early 20th century in order to avoid confusion with ice hockey, a separate sport. Bandy, while related to other hockey games, derives some of its inspiration from Association football.  Sledge hockey, a variant of ice hockey designed for players with physical disabilities, was created in the 1960s and has since been renamed, \"Para-ice hockey\".[10]  Games played with curved sticks and a ball can be found in the histories of many cultures. In Egypt, 4000-year-old carvings feature teams with sticks and a projectile, hurling dates to before 1272 BC in Ireland, and there is a depiction from approximately 600 BC in Ancient Greece, where the game may have been called ker\u0113t\u00edzein (\u03ba\u03b5\u03c1\u03b7\u03c4\u03af\u03b6\u03b5\u03b9\u03bd) because it was played with a horn or horn-like stick (k\u00e9ras, \u03ba\u03ad\u03c1\u03b1\u03c2).[11] In Inner Mongolia, the Daur people have been playing beikou, a game similar to modern field hockey, for about 1,000 years.[12]  Most evidence of hockey-like games during the Middle Ages is found in legislation concerning sports and games. The Galway Statute enacted in Ireland in 1527 banned certain types of ball games, including games using \"hooked\" (written \"hockie\", similar to \"hooky\") sticks.[13]  ...at no tyme to use ne occupye the horlinge of the litill balle with hockie stickes or staves, nor use no hande ball to play withoute walles, but only greate foote balle[14]  Bandy,\u00a0\u00bb. a game, like that of Golf, in which the ad- verse parties endeavour to beat a ball (generally a knob or gnarl from the trunk of a tree,) opposite ways...the stick with which the game is played is crook'd at the end;. [15] By the 19th century, the various forms and divisions of historic games began to differentiate and coalesce into the individual sports defined today. Organizations dedicated to the codification of rules and regulations began to form, and national and international bodies sprang up to manage domestic and international competition.  Bandy is played with a ball on a football pitch-sized ice arena (bandy rink), typically outdoors, and with many rules similar to association football. It is played professionally in Russia and Sweden. The sport is recognized by the IOC; its international governing body is the Federation of International Bandy.  Bandy has its roots in England in the 19th century, was originally called \"hockey on the ice\",[16] and spread from England to other European countries around 1900; a similar Russian sport can also be seen as a predecessor and in Russia, bandy is sometimes called \"Russian hockey\". Bandy World Championships have been played since 1957 and Women's Bandy World Championships since 2004. There are national club championships in many countries and the top clubs in the world play in the Bandy World Cup every year.  Field hockey is played on gravel, natural grass, or sand-based or water-based artificial turf, with a small, hard ball approximately 73\u00a0mm (2.9\u00a0in) in diameter. The game is popular among both men and women in many parts of the world, particularly in Europe, Asia, Australia, New Zealand, South Africa, and Argentina. In most countries, the game is played between single-sex sides, although they can be mixed-sex.  The governing body is the 126-member International Hockey Federation (FIH). Men's field hockey has been played at each Summer Olympic Games since 1908 except for 1912 and 1924, while women's field hockey has been played at the Summer Olympic Games since 1980.  Modern field hockey sticks are constructed of a composite of wood, glass fibre or carbon fibre (sometimes both) and are J-shaped, with a curved hook at the playing end, a flat surface on the playing side and a curved surface on the rear side. All sticks are right-handed \u2013 left-handed sticks are not permitted.  While field hockey in its current form appeared in mid-18th century England, primarily in schools, it was not until the first half of the 19th century that it became firmly established. The first club was created in 1849 at Blackheath in south-east London. Field hockey is the national sport of Pakistan.[17] It was the national sport of India until the Ministry of Youth Affairs and Sports declared in August 2012 that India has no national sport.[18]  Ice hockey is played between two teams of skaters on a large flat area of ice, using a three-inch-diameter (76.2\u00a0mm) vulcanized rubber disc called a puck. This puck is often frozen before high-level games to decrease the amount of bouncing and friction on the ice. The game is played all over North America, Europe and to varying extents in many other countries around the world. It is the most popular sport in Canada, Finland, Latvia, the Czech Republic, and Slovakia. Ice hockey is the national sport of Latvia[19] and the national winter sport of Canada.[20] Ice hockey is played at a number of levels, by all ages.  The governing body of international play is the 77-member International Ice Hockey Federation (IIHF). Men's ice hockey has been played at the Winter Olympics since 1924, and was in the 1920 Summer Olympics. Women's ice hockey was added to the Winter Olympics in 1998. North America's National Hockey League (NHL) is the strongest professional ice hockey league, drawing top ice hockey players from around the globe. The NHL rules are slightly different from those used in Olympic ice hockey over many categories. International ice hockey rules were adopted from Canadian rules in the early 1900s.[21]  The contemporary sport developed in Canada from European and native influences. These included various stick and ball games similar to field hockey, bandy and other games where two teams push a ball or object back and forth with sticks. These were played outdoors on ice under the name \"hockey\" in England throughout the 19th century, and even earlier under various other names.[22] In Canada, there are 24 reports[23] of hockey-like games in the 19th century before 1875 (five of them using the name \"hockey\"). The first organized and recorded game of ice hockey was played indoors in Montreal, Quebec, Canada, on March 3, 1875, and featured several McGill University students.  Ice hockey sticks are long L-shaped sticks made of wood, graphite, or composites with a blade at the bottom that can lie flat on the playing surface when the stick is held upright and can legally curve either way, for left- or right-handed players.[24]  Ice sledge hockey, or \"para ice hockey\", is a form of ice hockey designed for players with physical disabilities affecting their lower bodies. Players sit on double-bladed sledges and use two sticks; each stick has a blade at one end and small picks at the other. Players use the sticks to pass, stickhandle and shoot the puck, and to propel their sledges. The rules are very similar to IIHF ice hockey rules.[25]  Canada is a recognized international leader in the development of sledge hockey, and much of the equipment for the sport was first developed there, such as sledge hockey sticks laminated with fiberglass, as well as aluminum shafts with hand-carved insert blades and special aluminum sledges with regulation skate blades.  Based on ice sledge hockey, inline sledge hockey is played to the same rules as inline puck hockey (essentially ice hockey played off-ice using inline skates). There is no classification point system dictating who can play inline sledge hockey, unlike the situation with other team sports such as wheelchair basketball and wheelchair rugby. Inline sledge hockey is being developed to allow everyone, regardless of whether they have a disability or not, to complete up to world championship level based solely on talent and ability.[citation needed]  The first game of organized inline sledge hockey was played at Bisley, Surrey, England, on December 19, 2009, between the Hull Stingrays and the Grimsby Redwings. Matt Lloyd is credited with inventing inline sledge hockey, and Great Britain is seen as the international leader in the game's development.  Though inline hockey is considered a variant of roller hockey a.k.a. \"rink hockey\", it was derived from ice hockey instead and uses a type of hockey puck or a ball. Both roller games use a type of wheeled skate but inline hockey uses inline skates rather than roller skates or \"quads\".  The puck-based inline variant is more commonly played in North America than Europe while the ball-based variant is more popular in Europe.  Inline hockey puck variant is played by two teams, consisting of four skaters and one goalie, on a dry rink divided into two halves by a center line, with one net at each end of the rink. The game is played in three 15-minute periods with a variation of the ice hockey off-side rule. Icings are also called, but are usually referred to as illegal clearing.[26] The governing body is the International Ice Hockey Federation (IIHF), just as it is for ice hockey, but some leagues and competitions do not follow the IIHF regulations, in particular USA Inline and Canada Inline.  Roller hockey, also known as \"quad hockey\", \"international-style ball hockey\", \"rink hockey\" and \"Hoquei em Patins\", is an overarching name for a roller sport that uses quad skates. It has existed long before the invention of inline skates. The sport is played in over sixty countries and has a worldwide following. Roller hockey was a demonstration sport at the 1992 Barcelona Summer Olympics.  Also known as road hockey, this is a dry-land variant of ice and roller hockey played year-round on a hard surface (usually asphalt). A ball is usually used instead of a puck, and protective equipment is not usually worn.  Other games derived from hockey or its predecessors include the following: "},{"title":"Ebenezer Cobb Morley","content":"  Ebenezer Cobb Morley (16 August 1831 \u2013 20 November 1924) was an English sportsman. He is regarded as one of the fathers of the Football Association (FA) and modern football.  The 1863 laws written by Morley, the first secretary of the FA, includes the rule: \"No player shall carry the ball.\" In 2013, marking the 150th anniversary of the FA, the rule book was displayed at the British Library alongside Magna Carta and works of Shakespeare.[2]  Morley was born at 10 Garden Square, Princess Street in Hull to the Reverend Ebenezer Morley, a nonconformist minister, and his wife Hannah (n\u00e9e Cobb).[3][4][5] He lived in the city until he was 22.[3]  Morley qualified as a lawyer in 1854.[6] In 1858 he moved to the London suburb of Barnes to practise as a solicitor in the capital.[5]  Morley founded Barnes Football Club in 1862,[5] and served as its captain until 1867.[7][8][9]  The Barnes club played its first recorded game, a 2\u20130 victory, against Richmond F.C., on 29 November 1862.[10] A match the following month against Blackheath FC went less happily: the Blackheath club played a rugby-style game, necessitating the adoption of compromise rules. \"Very weak\" play by Barnes resulted in a loss by two goals to nothing, with Morley narrowly escaping being \"garrotted\".[11]  In 1863, Morley wrote to Bell's Life newspaper proposing a governing body for the sport, with the power to set common rules.[5] This led to the first meeting of the FA at Freemasons' Tavern, on 26 October 1863. At this meeting, Morley was elected the first secretary of the association.[12]  At this time, some football clubs followed the example of Rugby School by allowing the ball to be carried in the hands, with players allowed to \"hack\" (kick in the shins) opponents who were carrying the ball. Other clubs forbade both practices. During the meetings to draw up the FA laws, there was an acrimonious division between the \"hacking\" and \"non-hacking\" clubs.[13] An FA meeting of 17 November 1863 discussed this question, with the \"hacking\" clubs predominating.[14] A further meeting was scheduled in order to finalise (\"settle\") the laws, based on the draft created by Morley in his role as secretary.[15]  At this crucial 24 November meeting, the \"hackers\" were again in a narrow majority. During the meeting, however, Morley brought the delegates' attention to a recently published set of football laws from Cambridge University which banned carrying and hacking.[15] Discussion of the Cambridge rules, and suggestions for possible communication with Cambridge on the subject, served to delay the final \"settlement\" of the laws to a further meeting, on 1 December.[13][16] A number of representatives who supported rugby-style football did not attend this additional meeting,[17] resulting in hacking and carrying being banned in the laws that were published later that month.[13]  Morley played in the first ever match under FA rules, for Barnes against Richmond in December 1863. On 2 January 1864, Morley led his \"Secretary's Side\" to defeat against the \"President's Side\" in a friendly match at Battersea Park to test out the new laws.[18]  He continued to serve as FA secretary until 1866. At that year's annual meeting, Morley resigned as FA secretary, citing the demands of business. He also objected to FA member clubs playing under any other rules,[19] and made an unsuccessful proposal to abolish the offside law.[19]  Even though he was no longer FA secretary, Morley continued to be involved in football. He remained captain of Barnes FC, continued to serve on the FA's committee, and played for the \"London\" (FA) team in the London v Sheffield match held on 31 March 1866, scoring a goal.  By the time of the next FA annual meeting, in February 1867, the Association's future looked bleak. Membership had fallen to ten clubs,[20] and founding president Arthur Pember needed to be replaced. Morley volunteered for the role, and was duly elected by the few club representatives in attendance.[21]  During the next year, the secretary Robert Graham attempted to increase membership by writing to every known club in the country.[22] This increased membership to thirty by 1868, but did not prevent the association from running out of money, with the officers having to cover expenses out of their own pockets.[23]  Morley continued to serve as president until 1874, presiding over the birth of the FA Cup and a general increase in the popularity and influence of the Association. He was the first man to present the FA Cup, in 1872.[5]  When the FA celebrated its  50th anniversary in 1913, Morley, the most prominent founder of the association who was still living, was a notable guest at the festivities. He was presented with a silver cigar-case at a dinner held at the King's Hall, Holborn in central London.[24][25]  Morley was also active in the sport of rowing. Immediately upon moving to Barnes in 1858, he participated in the Barnes and Mortlake Regatta of that year,[26] served as the treasurer of the Regatta in 1860, and as secretary from 1862 to 1870.[27][5] Morley was associated with the London Rowing Club from 1860.[28] In 1864, he competed as a member of that club's eight in the Grand Challenge Cup at Henley.[5]  Morley continued to row long after he had ceased his work with the Football Association. In 1913, it was reported that the octogenarian was still \"sculling daily in his well-known boat\".[24]  Morley was also a keen fox hunter, keeping his own pack of beagles.[5][29]  Morley worked as a solicitor, handling such matters as mortgages and wills.[30][31]  Morley was the agent of the Radical Member of Parliament Donald Nicoll, who represented the constituency of Frome from 1857 to 1859. Following Nicoll's defeat in the 1859 United Kingdom general election, Morley was caught up in a controversy over a petition, later withdrawn, to have the election result overturned because of \"bribery, treating, and undue influence\".[32][33]  Morley served on Surrey County Council for Barnes (1903\u20131919).  In 1906, he was appointed a Justice of the Peace.[34]  Morley's wife, Frances, died of pneumonia in 1911. Morley himself succumbed to the same condition in 1924. He was buried[35] in Barnes Cemetery, a now abandoned graveyard on Barnes Common, Barnes. He had no children.[35]  \"The importance of the 1863 FA Minute Book cannot be underestimated. Without it, quite simply, the world would be without its most popular sport.\" The house at which Morley created the first draft of the FA's laws (No 26 The Terrace) carried a blue plaque to Morley. It subsequently collapsed in November 2015 during building work.[36][37]  Morley was the subject of a Google Doodle on 16 August 2018, the 187th anniversary of his birth.[38] "},{"title":"Ball bearing","content":"A ball bearing is a type of rolling-element bearing that uses balls to maintain the separation between the bearing races.  The purpose of a ball bearing is to reduce rotational friction and support radial and axial loads. It achieves this by using at least two races to contain the balls and transmit the loads through the balls. In most applications, one race is stationary and the other is attached to the rotating assembly (e.g., a hub or shaft). As one of the bearing races rotates it causes the balls to rotate as well. Because the balls are rolling they have a much lower coefficient of friction than if two flat surfaces were sliding against each other.  Ball bearings tend to have lower load capacity for their size than other kinds of rolling-element bearings due to the smaller contact area between the balls and races. However, they can tolerate some misalignment of the inner and outer races.  Although bearings had been developed since ancient times, the first modern recorded patent on ball bearings was awarded to Philip Vaughan, a Welsh inventor and ironmaster who created the first design for a ball bearing in Carmarthen in 1794. His was the first modern ball-bearing design, with the ball running along a groove in the axle assembly.[1]  Jules Suriray, a Parisian bicycle mechanic, designed the first radial style ball bearing in 1869,[2] which was then fitted to the winning bicycle ridden by James Moore in the world's first bicycle road race, Paris-Rouen, in November 1869.[3]  There are several common designs of ball bearing, each offering various performance trade-offs. They can be made from many different materials, including stainless steel, chrome steel, and ceramic (silicon nitride, Si3N4). A hybrid ball bearing is a bearing with ceramic balls and metal races.  The calculated life for a bearing is based on the load it carries and its operating speed. The industry standard usable bearing lifespan is inversely proportional to the bearing load cubed.[citation needed] Nominal maximum load of a bearing, is for a lifespan of 1 million rotations, which at 50\u00a0Hz (i.e., 3000 RPM) is a lifespan of 5.5 working hours. 90% of bearings of that type have at least that lifespan, and 50% of bearings have a lifespan at least 5 times as long.[7]  The industry standard life calculation is based upon the work of Lundberg and Palmgren performed in 1947. The formula assumes the life to be limited by metal fatigue and that the life distribution can be described by a Weibull distribution. Many variations of the formula exist that include factors for material properties, lubrication, and loading. Factoring for loading may be viewed as a tacit admission that modern materials demonstrate a different relationship between load and life than Lundberg and Palmgren determined .[7]  If a bearing is not rotating, maximum load is determined by force that causes plastic deformation of elements or raceways. The indentations caused by the elements can concentrate stresses and generate cracks at the components. Maximum load for not or very slowly rotating bearings is called \"static\" maximum load.[7]  Also if a bearing is not rotating, oscillating forces on the bearing can cause impact damage to the bearing race or the rolling elements, known as brinelling. A second lesser form called false brinelling occurs if the bearing only rotates across a short arc and pushes lubricant out away from the rolling elements.  For a rotating bearing, the dynamic load capacity indicates the load to which the bearing endures 1,000,000 cycles.  If a bearing is rotating, but experiences heavy load that lasts shorter than one revolution, static max load must be used in computations, since the bearing does not rotate during the maximum load.[7]  If a sideways torque is applied to a deep groove radial bearing, an uneven force in the shape of an ellipse is applied on the outer ring by the rolling elements, concentrating in two regions on opposite sides of the outer ring. If the outer ring is not strong enough, or if it is not sufficiently braced by the supporting structure, the outer ring will deform into an oval shape from the sideways torque stress, until the gap is large enough for the rolling elements to escape. The inner ring then pops out and the bearing structurally collapses.  A sideways torque on a radial bearing also applies pressure to the cage that holds the rolling elements at equal distances, due to the rolling elements trying to all slide together at the location of highest sideways torque. If the cage collapses or breaks apart, the rolling elements group together, the inner ring loses support, and may pop out of the center.  In general, maximum load on a ball bearing is proportional to outer diameter of the bearing times the width of the bearing (where width is measured in direction of axle).[7]  Bearings have static load ratings. These are based on not exceeding a certain amount of plastic deformation in the raceway. These ratings may be exceeded by a large amount for certain applications.  For a bearing to operate properly, it needs to be lubricated. In most cases the lubricant is based on elastohydrodynamic effect (by oil or grease) but working at extreme temperatures dry lubricated bearings are also available.  For a bearing to have its nominal lifespan at its nominal maximum load, it must be lubricated with a lubricant (oil or grease) that has at least the minimum dynamic viscosity (usually denoted with the Greek letter     \u03bd   {\\displaystyle \\nu }  ) recommended for that bearing.[7]  The recommended dynamic viscosity is inversely proportional to diameter of bearing.[7]  The recommended dynamic viscosity decreases with rotating frequency. As a rough indication: for less than 3000 RPM, recommended viscosity increases with factor 6 for a factor 10 decrease in speed, and for more than 3000 RPM, recommended viscosity decreases with factor 3 for a factor 10 increase in speed.[7]  For a bearing where average of outer diameter of bearing and diameter of axle hole is 50 mm, and that is rotating at 3000 RPM, recommended dynamic viscosity is 12\u00a0mm2\/s.[7]  Note that dynamic viscosity of oil varies strongly with temperature: a temperature increase of 50\u201370\u00a0\u00b0C causes the viscosity to decrease by factor 10.[7]  If the viscosity of lubricant is higher than recommended, lifespan of bearing increases, roughly proportional to square root of viscosity. If the viscosity of the lubricant is lower than recommended, the lifespan of the bearing decreases, and by how much depends on which type of oil being used. For oils with EP ('extreme pressure') additives, the lifespan is proportional to the square root of dynamic viscosity, just as it was for too high viscosity, while for ordinary oils lifespan is proportional to the square of the viscosity if a lower-than-recommended viscosity is used.[7]  Lubrication can be done with a grease, which has advantages that grease is normally held within the bearing releasing the lubricant oil as it is compressed by the balls. It provides a protective barrier for the bearing metal from the environment, but has disadvantages that this grease must be replaced periodically, and maximum load of bearing decreases (because if bearing gets too warm, grease melts and runs out of bearing). Time between grease replacements decreases very strongly with diameter of bearing: for a 40 mm bearing, grease should be replaced every 5000 working hours, while for a 100 mm bearing it should be replaced every 500 working hours.[7]  Lubrication can also be done with an oil, which has advantage of higher maximum load, but needs some way to keep oil in bearing, as it normally tends to run out of it. For oil lubrication it is recommended that for applications where oil does not become warmer than 50\u00a0\u00b0C, oil should be replaced once a year, while for applications where oil does not become warmer than 100\u00a0\u00b0C, oil should be replaced 4 times per year. For car engines, oil becomes 100\u00a0\u00b0C but the engine has an oil filter to maintain oil quality; therefore, the oil is usually changed less frequently than the oil in bearings.[7]  If the bearing is used under oscillation, oil lubrication should be preferred.[8] If grease lubrication is necessary, the composition should be adapted to the parameters that occur. Greases with a high bleeding rate and low base oil viscosity should be preferred if possible.[9]  Most bearings are meant for supporting loads perpendicular to axle (\"radial loads\"). Whether they can also bear axial loads, and if so, how much, depends on the type of bearing. Thrust bearings (commonly found on lazy susans) are specifically designed for axial loads.[7]  For single-row deep-groove ball bearings, SKF's documentation says that maximum axial load is circa 50% of maximum radial load, but it also says that \"light\" and\/or \"small\" bearings can take axial loads that are 25% of maximum radial load.[7]  For single-row edge-contact ball bearings, axial load can be about 2 times max radial load, and for cone-bearings maximum axial load is between 1 and 2 times maximum radial load.[7]  Often Conrad-style ball bearings will exhibit contact ellipse truncation under axial load. That means that either the ID of the outer ring is large enough, or the OD of the inner ring is small enough, so as to reduce the area of contact between the balls and raceway. When this is the case, it can significantly increase the stresses in the bearing, often invalidating rules of thumb regarding relationships between radial and axial load capacity. With construction types other than Conrad, one can further decrease the outer ring ID and increase the inner ring OD to guard against this.  If both axial and radial loads are present, they can be added vectorially, to result in the total load on bearing, which in combination with nominal maximum load can be used to predict lifespan.[7] However, in order to correctly predict the rating life of ball bearings the ISO\/TS 16281 should be used with the help of a calculation software.  The part of a bearing that rotates (either axle hole or outer circumference) must be fixed, while for a part that does not rotate this is not necessary (so it can be allowed to slide). If a bearing is loaded axially, both sides must be fixed.[7]  If an axle has two bearings, and temperature varies, axle shrinks or expands, therefore it is not admissible for both bearings to be fixed on both their sides, since expansion of axle would exert axial forces that would destroy these bearings. Therefore, at least one of the bearings must be able to slide.[7]  A 'freely sliding fit' is one where there is at least a 4\u00a0\u03bcm clearance, presumably because surface-roughness of a surface made on a lathe is normally between 1.6 and 3.2\u00a0\u03bcm.[7]  Bearings can withstand their maximum load only if the mating parts are properly sized. Bearing manufacturers supply tolerances for the fit of the shaft and the housing so that this can be achieved. The material and hardness may also be specified.[7]  Fittings that are not allowed to slip are made to diameters that prevent slipping and consequently the mating surfaces cannot be brought into position without force. For small bearings this is best done with a press because tapping with a hammer damages both bearing and shaft, while for large bearings the necessary forces are so great that there is no alternative to heating one part before fitting, so that thermal expansion allows a temporary sliding fit.[7]  If a shaft is supported by two bearings, and the center-lines of rotation of these bearings are not the same, then large forces are exerted on the bearing, which may destroy it. Some very small amount of misalignment is acceptable, and how much depends on type of bearing. For bearings that are specifically made to be 'self-aligning', acceptable misalignment is between 1.5 and 3 degrees of arc. Bearings that are not designed to be self-aligning can accept misalignment of only 2\u201310 minutes of arc (0.033-0.166 degrees) .[7]  In general, ball bearings are used in most applications that involve moving parts. Some of these applications have specific features and requirements:  The ball size increases as the series increases, for any given inner diameter or outer diameter (not both). The larger the ball the greater the load carrying capacity. Series 200 and 300 are the most common.[4]   "},{"title":"Deliberative assembly","content":"A deliberative assembly is a meeting of members who use parliamentary procedure.   In a speech to the electorate at Bristol in 1774, Edmund Burke described the British Parliament as a \"deliberative assembly\", and the expression became the basic term for a body of persons meeting to discuss and determine common action.[1][2] Merriam-Webster's definition excludes legislatures.[3]  Robert's Rules of Order Newly Revised by Henry Martyn Robert describes the following characteristics of a deliberative assembly:[4]  Robert's Rules of Order Newly Revised identifies several types of deliberative assemblies.  A mass meeting, which is an unorganized group meeting open to all individuals in a sector of the population who are interested in deliberating about a subject proposed by the meeting's sponsors. Examples include meetings to discuss common political concerns or community interests, or meetings to form a new society.[5]  A local assembly of an organized society, which is a membership meeting of a local chapter or branch of a membership organization.[6] Examples include local chapter meetings of organizations like the Sierra Club.  A convention, which is a meeting of delegates who represent constituent units of a population. Conventions are not permanently established bodies, and delegates are normally elected for only one term. A convention may be held by an organized society, where each local assembly is represented by a delegate.[7]  A legislative body, which is a legally established public lawmaking body. It consists of representatives chosen by the electorate. Examples include national legislatures such as parliaments, and local government councils such as state legislatures, regional assemblies and city councils.[8]  A board, which is an administrative, managerial, or quasi-judicial body. A board derives its power from an outside authority that defines the scope of its operations. Examples include an organized society's or company's board of directors and government agency boards like a board of education.[9]  A member of a deliberative assembly has the right to attend meetings and make and second motions, speak in the debate, and vote.[10] Organizations may have different classes of members (such as regular members, active members, associate members, and honorary members), but the rights of each class of membership must be defined (such as whether a \"member\" in a class has the right to vote).[10][11] There may also be ex officio members or persons who are members under some other office or position they hold.[12] Ex officio members have the same rights as other members.[12] "},{"title":"Ball (association football)","content":"  A football (also known as a football ball, soccer ball, or association football ball specifically in the United Kingdom) is the ball used in the sport of association football. The name of the ball varies according to whether the sport is called \"football\", \"soccer\", or \"association football\". The ball's spherical shape, as well as its size, weight, mass, and material composition, are specified by Law 2 of the Laws of the Game maintained by the International Football Association Board.[1] Additional, more stringent standards are specified by FIFA and other big governing bodies for the balls used in the competitions they sanction.  Early footballs began as animal bladders or stomachs that would easily fall apart if kicked too much. Improvements became possible in the 19th century with the introduction of rubber and discoveries of vulcanization by Charles Goodyear. The modern 32-panel ball design was developed in 1962 by Eigil Nielsen, and technological research continues to develop footballs with improved performance. The 32-panel ball design was soon joined by 24-panel balls as well as 42-panel balls, both of which improved on performance prior to 2007.[citation needed]  A black-and-white patterned spherical truncated icosahedron design, brought to prominence by the Adidas Telstar, has become a symbol of association football.[2] Many different designs of balls exist, varying both in appearance and physical characteristics.[3]  In the year 1863, the first specifications for footballs were set by the Football Association. Previous to this, footballs were made out of inflated animal bladder, with later leather coverings to help footballs maintain their shapes.[4] In 1872 the specifications were revised, and have been kept essentially unchanged by the International Football Association Board. Differences in footballs made since this rule came into effect have been with the material used to create them.  Footballs have dramatically changed over time. During medieval times balls were normally made from an outer shell of leather filled with cork shavings.[5] Another method of creating a ball was using animal bladders to make it inflatable inside. However, these two styles of footballs were easy to puncture and were inadequate for kicking.  It was not until the 19th century that footballs developed a more modern appearance.  In 1838, Charles Goodyear introduced vulcanized rubber, which dramatically improved football.[6] Vulcanization is the treatment of rubber to give it certain qualities such as strength, elasticity, and resistance to solvents. Vulcanization of rubber also helps the football resist moderate heat and cold.  Vulcanization helped create inflatable bladders that pressurize the outer panel arrangement of the football. Charles Goodyear's innovation increased the bounce ability of the ball and made it easier to kick. Most balls of this time had tanned leather with eighteen sections stitched together. These were arranged in six panels of three strips each.[7][8]  During the 1900s, footballs were made out of leather with a lace of the same material (known as tiento in Spanish) used to stitch the panels. Although leather was perfect for bouncing and kicking the ball, when heading the football (hitting it with the player's head) it was usually painful. This problem was most probably due to water absorption of the leather from rain, which caused a considerable increase in weight, causing head or neck injury. By around 2017, this had also been associated with dementia in former players.[9] Another problem of early footballs was that they deteriorated quickly, as the plastic used in manufacturing the basketballs varied in thickness and in quality.[7]  The ball without the leather lace was developed and patented by Romano Polo, Antonio Tossolini and Juan Valbonesi in 1931 in Bell Ville, C\u00f3rdoba Province, Argentina.[10][11] This innovative ball (named Superball) was adopted by the Argentine Football Association as the official ball for its competitions since 1932.[12]  The deformation of the football when it is kicked or when the ball hits a surface is tested. Two styles of footballs have been tested by the Sports Technology Research Group of Wolfson School of Mechanical and Manufacturing Engineering in Loughborough University; these two models are called the Basic FE model and the Developed FE model of the football. The basic model considered the ball as a spherical shell with isotropic material properties. The developed model also used isotropic material properties but included an additional stiffer stitching seam region.  Manufacturers are experimenting with microchips and even cameras embedded inside the ball. The microchip technology was considered for the goal-line technology. The ball used in the 2018 FIFA World Cup in Russia had an embedded chip which did not provide any measurements, but provided 'user experience' via smartphone after connecting with the ball via NFC.[13][14][15]  Companies such as Umbro, Mitre, Adidas, Nike, Select and Puma are releasing footballs made out of new materials which are intended to provide more accurate flight and more power to be transferred to the football.[16][17]  Modern footballs are much more complex than past footballs. Most footballs consist of twelve regular pentagonal and twenty regular hexagonal panels positioned in a truncated icosahedron spherical geometry.[5] Some premium-grade 32-panel balls use non-regular polygons to give a closer approximation to sphericality.[18] The inside of the football is made up of a latex or butyl rubber bladder which enables the football to be pressurised. The ball's outside is made of leather, synthetic leather, polyurethane or PVC panels. The surface can be textured, weaved or embossed for greater control and touch. The panel pairs are either machine-stitched, hand-stitched or thermo-bonded (glued and bonded by heat) along the edge.[6] To prevent water absorption balls may be specially coated, or the stitches bonded with glue. The size of a football is roughly 22\u00a0cm (8.66 inches) in diameter for a regulation size 5 ball. Rules state that a size 5 ball must be 68 to 70\u00a0cm (27 to 28\u00a0in) in circumference.[19] Averaging that to 69\u00a0cm (27\u00a0in) and then dividing by \u03c0 gives a diameter of about 22\u00a0cm (8.7\u00a0in).  Regulation size and weight for a football is a circumference of 68\u201370\u00a0cm (27\u201328\u00a0in) and a weight of between 410\u2013450\u00a0g (14\u201316\u00a0oz).  The ball is inflated to a pressure of 0.6\u20131.1 bars (8.7\u201316.0\u00a0psi) at sea level.[20] This is known as \"Size 5\". Smaller balls, sizes 1, 3 and 4 are also produced for younger players or as training tools.[20]  There are different types of football balls depending on the match and turf including training footballs, match footballs, professional match footballs, beach footballs, street footballs, indoor footballs, turf balls, futsal footballs and mini\/skills footballs.[21]  Many companies throughout the world produce footballs. The earliest balls were made by local suppliers where the game was played. It is estimated that 40% of all footballs are made in Sialkot, Pakistan with other major producers being China and India.[22]  As a response to the problems with the balls in the 1962 FIFA World Cup,[clarification needed] Adidas created the Adidas Santiago[23] \u2013 this led to Adidas winning the contract to supply the match balls for all official FIFA and UEFA matches, which they have held since the 1970s, and also for the Olympic Games.[24] They also supply the ball for the UEFA Champions League which is called the Adidas Finale.  In early FIFA World Cups, match balls were mostly provided by the hosts from local suppliers. Records indicate a variety of models being used within individual tournaments and even, on some occasions, individual games. Over time, FIFA took more control over the choice of ball used. Since 1970 Adidas have supplied official match balls (all of which were made in Sialkot, Pakistan) for every tournament.[25]  The most up-to-date balls used in various club football competitions as of 2023\u201324 season are:  Adidas Finale London (UCL)  Adidas Finale Bilbao (UWCL)  Nike Flight[28]  Malaysia Cup  Malaysia FA Cup  MFL Cup  Piala Sumbangsih  The association football symbol (U+26BD \u26bd SOCCER BALL) was introduced by computing standard Unicode.[29] The symbol was representable in HTML as &#9917; or &#x26BD;.[citation needed] The addition of this symbol follows a 2008 proposal by Karl Pentzlin.[30] "},{"title":"Scoring in association football","content":"  In games of association football, teams compete to score the most goals during the match. A goal is scored when the ball passes completely over a goal line at either end of the field of play between two centrally positioned upright goal posts 24\u00a0feet (7.32\u00a0m) apart and underneath a horizontal crossbar at a height of 8\u00a0feet (2.44\u00a0m) \u2014 this frame is itself referred to as a goal. Each team aims to score at one end of the pitch, while preventing their opponents from scoring at the other end. Nets are usually attached to the goal frame to catch goalscoring balls, but the ball is not required to touch the net.  Rules concerning goal scoring are described in Law 10 of the Laws of the Game:  A goal is scored when the whole of the ball passes over the goal line, between the goalposts and under the crossbar, provided that no offence has been committed by the team scoring the goal. As with other cases of the ball travelling out of the field of play, all of the ball must cross all of the line, otherwise play continues.[2] A goal is credited to the team attacking the goal scored upon, regardless of which team actually caused the ball to enter the goal. A ball entering a goal from the action of a player defending that goal is called an own goal.  If the ball hits the frame of the goal and remains in play, play continues. Goals can be scored going in off the goal frame.  Even if serious foul play unambiguously prevents a goal from being scored, the referee cannot award a goal unless the ball enters the goal as described above; i.e., there is no provision for awarding a goal akin to the awarded goal in ice hockey, the penalty try in rugby football, or the goaltending offence in basketball (although such a provision did once exist, as described below).  A goal cannot be scored directly from a dropped ball, indirect free kick or a throw-in. Should the ball go into the opponents' goal from these without first being touched by another player, play is restarted with a goal kick. A player cannot score an own goal directly from any restart of play (other than, theoretically, a penalty kick); in that case a corner kick would be awarded. Both of these situations, especially the latter, are exceedingly rare.  As a result of rule-changes introduced in 2019, it is not possible to score an attacking goal with the hands or arm.  If a goalkeeper throws the ball directly into the opponent's goal from his\/her own penalty area, no goal is awarded: instead a goal-kick is awarded to the defending side.[3]  In practice such a situation is improbable given the distances involved, but this can occur in variations of the sport where the Laws are adapted to play on a smaller area.[4] If the ball goes directly into the opponent's goal from the hands or arm of a player in any other circumstances, the handling is penalised as a handball offence (even if it was unintentional, or would otherwise have been legal).[5] It remains possible to score an own goal with the hands or arm.  The 2019 rule changes also provided that a goal cannot be scored if the ball enters either goal directly after touching a match official; a dropped ball is awarded if this occurs.[1]  If a player or team official is illegally on the field of play when that person's team scores a goal, the goal is disallowed, with a direct free kick being awarded to the opposing side.[6]  After a goal is scored, play is restarted with a kick-off by the side which conceded the goal.  Most goals are relatively unambiguous, as the ball will usually strike the net attached to the goal structure indicating that it has passed over the goal line as described above. Occasionally, however, situations occur where it is difficult for officials to tell if the ball completely crossed the goal line before a rebound, save, or clearance from the goal area. Additionally, even if the ball crosses the goal line as required, a goal may be disallowed if the attacking team commits an infringement of the Laws of the Game, such as the offside offence or a foul.  As with all other decisions on the Laws of the Game, the referee is the final authority as to whether a goal is scored. The match referee is advised by assistant referees, whose view across the pitch from the sidelines may in some cases be more useful in determining whether the ball crossed the goal line or whether the attacking team committed an infringement.  Goals incorrectly awarded or disallowed due to mistakes in determining if the ball crossed the line are referred to as ghost goals. The goal net was one of the earliest tools employed to aid match officials in determining whether a goal was scored. Introduced in the 1890s, the goal net provides a simple way to help determine whether the ball passed on the correct side of the goal posts and crossbar. Although not mandated by the Laws of the Game, goal nets are now ubiquitous across most levels of organised football. Since 2012, goal-line technology has been used at the highest levels of professional football; it employs a system of cameras and\/or sensors to provide the referee with a discreet signal when the ball has crossed the goal line.[7] The video assistant referee was added in 2018 after years of trials; this is an additional assistant referee who constantly monitors video footage of the match and is empowered to advise the referee if he\/she makes \"clear and obvious errors\" in matters, including in the awarding of goals.  The Laws make no mention of attributing goals to individual players. Nevertheless, goals are almost always attributed to individuals, that player being the one who provided the final action causing the goal to be scored. Generally, this is the last player to touch the ball, notwithstanding inconsequential deflections such as failed attempts at a save. Should a player cause a goal to be scored against their own team, the goal is recorded as an own goal.  The authority on attributing goals varies between competitions. The Premier League in England has a dedicated Dubious Goals Committee for resolving attribution disputes.[8]  For an individual player, scoring multiple goals in a game is considered a notable achievement. In association football, a hat-trick refers to the uncommon feat of scoring three goals in a single game. Awards exist for individual players who score the most goals in some competitions, such awards are often called the \"Golden Boot\".  Players will typically celebrate scoring a goal with team mates, occasionally putting on elaborate displays for the crowd. The Laws allow this, but mandate that celebration must not be \"excessive\".[9]  On average, only a few scores occur per game in association football.  An analysis of several years' results from several English leagues found that 1\u20130 was the most common result, occurring in approximately 20% of games.[15]  In English traditional football, the object of the game was typically to convey a ball into a specified area, or to touch a specific object (the area or object often being called the \"goal\")[16][17][18] defended by the opposing team.  This feat might itself be called a \"goal\";[19] alternative names such as \"inn\"[16] were also in use.  The game might be decided by a fixed number of goals (e.g. first goal scored wins or best of three)[20][21][22] or be played for a fixed period of time.  In the more formalised football games of English public schools and universities, the object was typically to kick the ball between goal-posts guarded by the opposition.  This might be required to be above a crossbar (as in the game of football played at Rugby School),[23] below a bar or other object (as in the Sheffield Rules of 1862)[24] or at any height (as at Shrewsbury School).[25]  The size and type of goals were among the first questions decided by the Football Association (FA).  At its second meeting, on 10 November 1863, the FA agreed on the following three resolutions:[41]  The next meeting, on 17 November, added the further condition that a goal could not be scored when the ball was \"thrown, knocked or carried\" between the posts.[41]   These points were reflected in the first draft of the Laws of the Game created by FA secretary E. C. Morley.[42]  Morley's proposal met with objections expressed in correspondence from J. C. Thring of Uppingham School, and also from William Chesterman of Sheffield F. C.,[43] principally on the grounds that it would be difficult to judge whether a ball that went above the height of the posts should count as a goal; Thring correctly predicted that a crossbar \"w[ould] be adopted in the end\".[44]  Nevertheless, this feature of the game was preserved in the Association's first published set of laws, which read:[45]  A goal shall be won when the ball passes between the goal posts or over the space between the goal posts (at whatever height), not being thrown, knocked on, or carried  At the first revision of the FA rules, in 1866, a tape was introduced between the posts at a height of 8 feet, with a goal counting only if the ball went below this tape.[46]  According to a contemporary newspaper report of the meeting:[47]  The chairman urged some strong reasons why a goal should not be won so long as the ball was between the posts at no matter what height, and quoted an instance which occurred at Reigate, where one of the opposite side raised the ball quite 90 feet in the air between the goal posts.  A dispute arose as to whether the goal was won or not, and the bystanders decided that the ball was kicked between the posts, but he thought it was a most unsatisfactory goal, and was therefore decidedly in favour of goals being kicked under the tape In 1875, after a proposal by Queen's Park FC, the laws allowed the option of using either a crossbar or tape.[48] At the International Football Conference of December 1882, it was decided to require a crossbar;[49]  this change was introduced into the Football Association's laws in 1883.[50]  The dimensions of the goal (8 yards wide and 8 feet high) have remained unchanged since 1866.  The original FA laws of 1863 disallowed a goal when the ball was \"thrown, knocked on, or carried\",[45]  even if the handling was otherwise legal.[51] In 1882, a change in the laws, introduced by Nicholas Lane Jackson of Finchley FC and Morton Betts of Old Harrovians FC, made it possible to score an own goal by use of the hands.[52]  In 1962, a change introduced by the Scottish Football Association permitted a goal-keeper to score a goal by throwing the ball into the opposing goal from his own penalty area.[53] This innovation was heavily criticised in some quarters.[54] In 1974, a further change to the laws allowed a goal to be scored when the ball was handled unintentionally by an attacker.[55] In 2019 both of these changes were reversed:   The original laws of the game, in 1863, specified no punishments for infringements of the rules.[56]  In 1872, the indirect free kick was introduced as a punishment for handball.[57]  This indirect free-kick was thought to be an inadequate remedy for a handball which prevented an otherwise-certain goal.  From a meeting of the Sheffield Football Association in February 1879, we have the following report:[58][59]  It was proposed by Mr. T. Banks, on behalf of the Norfolk Club, to add to law 8 \u2014 \"If any player of the defending side, except the goalkeeper, stop the ball with his hands within three yards of the goal, when it is going in goal, it shall count a goal to the opponents.\"[60] After a \"long and noisy discussion\", the change was rejected. At the 1881 meeting of the Football Association, a similar proposal was introduced by J. Arnall and J. B. Clayton of the Birmingham Football Association, but it was likewise rejected.[61]  Such a law was finally approved the next year, to become part of the FA's laws for the 1882-83 season:  When any player, other than the goal-keeper, wilfully stops a ball in the vicinity of his own goal by using his hands when, in the opinion of the umpires or referee, the ball would have passed through the goal, a goal shall be scored to his opponents.[62] This goal, which was similar to today's penalty try in rugby, survived as part of the game for only one season.  At the International Football Conference of December 1882, it was decided to remove this law from the 1883-84 season.[63][64]  One commentator wrote that the rule \"was the means of causing the referee a very awkward point to decide at times, and we all know the duties of the referee are heavy enough without this; and, further, the penalty, in my opinion, is too great [...]  A free kick [...] is quite sufficient\".[65]  The laws have at various times restricted the ability to score from a set piece situation (such as a free kick or corner-kick). If the ball goes into the goal directly from such a restart but the laws do not permit the awarding of a goal, depending on which team performed the set piece a goal kick or corner kick is awarded. "},{"title":"Major League Soccer","content":"  Major League Soccer (MLS) is a men's professional soccer league sanctioned by the United States Soccer Federation, which represents the sport's highest level in the United States.[2][3] The league comprises 29 teams\u201426 in the United States and 3 in Canada\u2014since the 2023 season.[4][5] MLS is headquartered in Midtown Manhattan.  Major League Soccer is the most recent in a series of men's premier professional national soccer leagues established in the United States and Canada. The predecessor of MLS was the North American Soccer League (NASL), which existed from 1968 until 1984.[6] MLS was founded in 1993 as part of the United States' successful bid to host the 1994 FIFA World Cup.[7] The inaugural season took place in 1996 with ten teams.[8] MLS experienced financial and operational struggles in its first few years, losing millions of dollars and folding two teams in 2002.[9] Since then, developments such as the proliferation of soccer-specific stadiums around the league, implementation of the Designated Player Rule allowing teams to sign star players such as David Beckham, and national TV contracts have made MLS profitable.[10] In 2022, with an average attendance of over 21,000 per game, MLS has the fourth-highest average attendance of the major professional sports leagues in the United States and Canada, behind the National Football League (NFL) with over 69,000 fans per game and Major League Baseball (MLB) with over 26,000 fans per game, and the Canadian Football League (CFL) with over 21,700 fans per game.[11][12] MLS was the eighth-highest attended professional soccer league worldwide by 2018.[13]  The MLS regular season typically starts in late February or early March and runs through mid-October, with each team playing 34\u00a0games;[14][15] the team with the best record is awarded the Supporters' Shield. Eighteen teams compete in the postseason MLS Cup Playoffs in late October and November, culminating in the league's championship game, the MLS Cup.[16]  Instead of operating as an association of independently owned clubs, MLS is a single entity in which each team is owned by the league and individually operated by the league's investors.[17] The league has a fixed membership like most sports leagues in the United States and Canada, which makes it one of the few soccer leagues that does not use a promotion and relegation process.[18]  The LA Galaxy have the most MLS Cups, with five. They are also tied with D.C. United for most Supporters' Shields, with four each. The Columbus Crew are the defending champions, as they defeated Los Angeles FC 2\u20131 on December 9, 2023, to mark the end of the 2023 season.  Major League Soccer's regular season runs from late February or early March to October. Teams are geographically divided into the Eastern and Western Conferences, playing 34 games in an unbalanced schedule. With 29 teams in 2023, each team plays two games, home and away, against every team in its conference and one game against all but four or five of the teams in the opposite conference. The 2020 season was the first season in league history in which teams did not play against every other team in the league.[19] At the end of the regular season, the team with the highest point total is awarded the Supporters' Shield and home-field advantage throughout the playoffs.[20]  Teams break for the annual All-Star Game midway through the season, an exhibition game containing the league's best players. The format of the All-Star Game has changed several times since the league's inception; 2020 was the first year in which the MLS All-Stars were planned to play against an all-star team from Mexico's Liga MX, before the event's cancellation due to the COVID-19 pandemic.[21][22][23]  Unlike most major soccer leagues around the world, but similar to other leagues in the Americas,[24] the MLS regular season is followed by a postseason knockout tournament to determine the league champion.[25] As of 2023[update], eighteen teams participate in the MLS Cup Playoffs in October and November, which concludes with the MLS Cup championship game in early December.[26] The 2023 playoff format includes a pair of single-elimination play-in matches for the two lowest-ranked teams in each conference ahead of a best-of-three round; the round is followed by more single-elimination rounds that lead up to the MLS Cup final.[27]  Major League Soccer's spring-to-fall schedule results in scheduling conflicts with the FIFA calendar and with summertime international tournaments such as the World Cup and the Gold Cup,[28] causing some players to miss league matches.[29] While MLS has looked into changing to a fall-to-spring format, there are no current plans to do so. Were the league to change its schedule, a winter break would be necessary to accommodate teams located in harsh winter climates.[30][31][32] It would also have to compete with the popularity and media presence of the National Football League (NFL), National Basketball Association (NBA), and National Hockey League (NHL), which all run on fall-to-spring schedules.[32]  MLS teams also play in other international and domestic competitions. Each season, up to five MLS teams\u2014four from the U.S. and one from Canada\u2014play in the CONCACAF Champions Cup (CCC) against other clubs from the CONCACAF region. Two U.S.-based MLS teams qualify based on regular-season results from the previous year: the teams with the highest point total from each of the two conferences, one of whom is the Supporter's Shield champion. The third U.S. team to qualify is the reigning MLS Cup champion. A fourth U.S.-based team can qualify by winning the U.S. Open Cup.[33] In 2024, the league will send eight teams to participate in the U.S. Open Cup instead of every U.S.-based club, with MLS Next Pro teams as representatives for some teams. MLS had announced their intention to remove itself from the tournament entirely,[34] but reached a compromise with U.S. Soccer to send representatives from clubs that were not participating in the Champions Cup, with the exception of the defending Open Cup champions.[35][36] If a team qualifies through multiple berths, or if any of the three MLS berths are taken by a Canadian team, the berth is reallocated to the highest-placed U.S.-based team in the previous season's overall table that has otherwise not qualified. Montreal, Toronto, and Vancouver compete against other Canadian sides in the Canadian Championship for the one CONCACAF Champions Cup berth allocated to Canada.[37] Seattle Sounders FC became the first MLS team to win the CONCACAF Champions Cup under the competition's updated format in 2022.[38][39]  Since 2018, the reigning MLS Cup champion plays in the Campeones Cup, a Super Cup-style single game against the Campe\u00f3n de Campeones from Liga MX, hosted by the MLS team in September.[40] The inaugural edition saw Tigres UANL defeat Toronto FC at BMO Field in Toronto in 2018.[41]  Another inter-league competition with Liga MX, the Leagues Cup, was established in 2019.[42] The 2020 edition of the tournament was originally planned to pair eight MLS clubs against eight Liga MX clubs in a single-elimination tournament hosted in the United States, reviving an inter-league rivalry that previously took place in the now-defunct North American Superliga, before its cancelation.[23] Beginning with the 2023 edition all MLS and Liga MX teams participate in the competition, which functions as the regional cup for the North American zone of CONCACAF.[43]  The 29 teams of Major League Soccer are divided between the Eastern and Western conferences. MLS has regularly expanded since the 2005 season, most recently with the addition of St. Louis City SC for the 2023 season.[44] San Diego FC is planned to enter the league in 2025.[45]  The league features numerous rivalry cups that are contested by two or more teams, usually geographic rivals.[46] Each trophy is awarded to the team with the best record in matches during the regular season involving the participating teams. The concept is comparable to rivalry trophies played for by American college football teams.[47]  MLS features some of the longest travel distances for a domestic soccer league, with Vancouver Whitecaps FC and Inter Miami CF the furthest apart teams at 2,801 miles (4,508\u00a0km).[48] During the 2018 season, the team with the shortest distance traveled over the entire regular schedule was Toronto FC at 25,891 miles (41,668\u00a0km), while the longest was Vancouver at 51,178 miles (82,363\u00a0km).[49]  Notes  Major League Soccer is the most recent of a series of men's premier professional national soccer leagues established in the United States and Canada. The predecessor of MLS was the North American Soccer League (NASL), which existed from 1968 until 1984.[50] The United States did not have a truly national top-flight league with FIFA-sanctioning until the creation of the NASL. The first league to have U.S. and Canadian professional clubs, the NASL struggled until the mid-1970s when the New York Cosmos, the league's most prominent team, signed a number of the world's best players including Pel\u00e9 and Franz Beckenbauer.[51] Pel\u00e9's arrival attracted other well-known international stars to the league including Johan Cruyff, Gerd M\u00fcller, Eus\u00e9bio, Bobby Moore, and George Best. Despite dramatic increases in attendance (with some matches drawing over 70,000 fans such as Soccer Bowl '78, the highest attendance to date for any club soccer championship in the United States) over-expansion, the economic recession of the early 1980s, and disputes with the players union ultimately led to the collapse of the NASL following the 1984 season, leaving the United States without a top-level soccer league until MLS.[52][53]  In 1988, in exchange for FIFA awarding the right to host the 1994 World Cup, U.S. Soccer promised to establish a Division 1 professional soccer league.[54] In 1993, U.S. Soccer selected Major League Professional Soccer (the precursor to MLS) as the exclusive Division 1 professional soccer league.[54] Major League Soccer was officially formed in February 1995 as a limited liability company.[54]  Tab Ramos was the first player signed by MLS, on January 3, 1995, and was assigned to the New York\/New Jersey MetroStars.[55] MLS began play in 1996 with ten teams. The first game was held on April 6, 1996, as the San Jose Clash defeated D.C. United before 31,000 fans at Spartan Stadium in San Jose in a game broadcast on ESPN.[56] The league had generated some buzz by managing to lure some marquee players from the 1994 World Cup to play in MLS\u2014including U.S. stars such as Alexi Lalas, Tony Meola and Eric Wynalda, and foreign players such as Mexico's Jorge Campos and Colombia's Carlos Valderrama.[57] D.C. United won the MLS Cup in three of the league's first four seasons.[58] The league added its first two expansion teams in 1998\u2014the Miami Fusion and the Chicago Fire; the Chicago Fire won its first title in its inaugural season.[59]  After its first season, MLS suffered from a decline in attendance.[60] The league's low attendance was all the more apparent in light of the fact that eight of the original ten teams played in large American football stadiums.[59] One aspect that had alienated fans was that MLS experimented with rules deviations in its early years in an attempt to \"Americanize\" the sport. The league implemented the use of shootouts to resolve tie games. MLS also used a countdown clock and halves ended when the clock reached 0:00. The league realized that the rule changes had alienated some traditional soccer fans while failing to draw new American sports fans, and the shootout and countdown clock were eliminated after the 1999 season.[61] The league's quality was cast into doubt when the U.S. men's national team, which was made up largely of MLS players, finished in last place at the 1998 World Cup.[59]  Major League Soccer lost an estimated $250\u00a0million during its first five years, and more than $350\u00a0million between its founding and 2004.[62][63][64][65] The league's financial problems led to Commissioner Doug Logan being replaced by Don Garber, a former NFL executive, in August 1999.[66] Following decreased attendance and increased losses by late 2001, league officials planned to fold but were able to secure new financing from owners Lamar Hunt, Philip Anschutz, and the Kraft family to take on more teams.[67] MLS announced in January 2002 that it had decided to contract the Tampa Bay Mutiny and Miami Fusion, leaving the league with ten teams.[68]  Despite the financial problems, though, MLS did have some accomplishments that would set the stage for the league's resurgence. Columbus Crew Stadium, now known as Historic Crew Stadium, was built in 1999, becoming MLS's first soccer-specific stadium.[69] This began a trend among MLS teams to construct their own venues instead of leasing American football stadiums, where they would not be able to generate revenue from other events.[70][71] In 2000, the league won an antitrust lawsuit, Fraser v. Major League Soccer, that the players had filed in 1996. The court ruled that MLS's policy of centrally contracting players and limiting player salaries through a salary cap and other restrictions were a legal method for the league to maintain solvency and competitive parity since MLS was a single entity and therefore incapable of conspiring with itself.[72]  The 2002 FIFA World Cup, in which the United States unexpectedly made the quarterfinals, coincided with a resurgence in American soccer and MLS.[46] MLS Cup 2002 drew 61,316 spectators to Gillette Stadium, the largest attendance in an MLS Cup final until 2018.[73] MLS limited teams to three substitutions per game in 2003, and adopted International Football Association Board (IFAB) rules in 2005.[74]  MLS underwent a transition in the years leading up to the 2006 World Cup. After marketing itself on the talents of American players, the league lost some of its homegrown stars to prominent European leagues. For example, Tim Howard was transferred to Manchester United for $4 million in one of the most lucrative contract deals in league history.[75][76] Many more American players did make an impact in MLS. In 2005, Jason Kreis became the first player to score 100 career MLS goals.[77]  The league's financial stabilization plan included teams moving out of large American football stadiums and into soccer-specific stadiums.[68] From 2003 to 2008, the league oversaw the construction of six additional soccer-specific stadiums, largely funded by owners such as Lamar Hunt and Phil Anschutz, so that by the end of 2008, a majority of teams were now in soccer-specific stadiums.[59]  It was also in this era that MLS expanded for the first time since 1998. Real Salt Lake and Chivas USA began play in 2005, with Chivas USA becoming the second club in Los Angeles.[78] By 2006 the San Jose Earthquakes owners, players and a few coaches moved to Texas to become the expansion Houston Dynamo, after failing to build a stadium in San Jose. The Dynamo became an expansion team, leaving their history behind for a new San Jose ownership group that formed in 2007.[79]  In 2007, the league expanded beyond the United States' borders into Canada with the Toronto FC expansion team.[80] Major League Soccer took steps to further raise the level of play by adopting the Designated Player Rule, which helped bring international stars into the league.[81] The 2007 season witnessed the MLS debut of David Beckham. Beckham's signing had been seen as a coup for American soccer, and was made possible by the Designated Player Rule. Players such as Cuauht\u00e9moc Blanco (Chicago Fire) and Juan Pablo \u00c1ngel (New York Red Bulls), are some of the first Designated Players who made major contributions to their clubs.[82] The departures of Clint Dempsey and Jozy Altidore, coupled with the return of former U.S. national team stars Claudio Reyna and Brian McBride, highlighted the exchange of top prospects to Europe for experienced veterans to MLS.[83]  By 2008, San Jose had returned to the league under new ownership, and in 2009, the expansion side Seattle Sounders FC began play in MLS.[80] The Sounders set a new average attendance record for the league, with 30,943 spectators per match, and were the first expansion team to qualify for the playoffs since 1998.[84] The 2010 season ushered in an expansion franchise in the Philadelphia Union and their new PPL Park stadium (now known as Subaru Park).[80] The 2010 season also brought the opening of the New York Red Bulls' soccer-specific stadium, Red Bull Arena, and the debut of French striker Thierry Henry.[85]  The 2011 season brought further expansion with the addition of the Vancouver Whitecaps FC, the second Canadian MLS franchise, and the Portland Timbers.[86] Real Salt Lake reached the finals of the 2010\u201311 CONCACAF Champions League.[87] During the 2011 season, the Galaxy signed another international star in Republic of Ireland all-time leading goalscorer Robbie Keane.[88] MLS drew an average attendance of 17,872 in 2011, higher than the average attendances of the NBA and NHL.[89] In 2012, the Montreal Impact became the league's 19th franchise and the third in Canada, and made their home debut in front of a crowd of 58,912,[90] while the New York Red Bulls added Australian all-time leading goalscorer Tim Cahill.  In 2012, with an average attendance of over 18,000 per game, MLS had the third highest average attendance of any sports league in the U.S. after the National Football League (NFL) and Major League Baseball (MLB),[91] and was the seventh highest attended professional soccer league worldwide as of 2013[update].[92]  In 2013, MLS introduced New York City FC[93] as its 20th team, and Orlando City Soccer Club[94] as its 21st team, both of which would begin playing in 2015.  In 2013, the league implemented its \"Core Players\" initiative, allowing teams to retain key players using retention funds instead of losing the players to foreign leagues.[95] Among the first high-profile players re-signed in 2013 using retention funds were U.S. national team regulars Graham Zusi and Matt Besler. Beginning in summer of 2013 and continuing in the run up to the 2014 World Cup, MLS began signing U.S. stars based abroad, including Clint Dempsey, Jermaine Jones, and Michael Bradley from Europe; and DaMarcus Beasley from Mexico's Liga MX.[96] By the 2014 season, fifteen of the nineteen MLS head coaches had previously played in MLS.[97] By 2013, the league's popularity had increased to the point where MLS was as popular as Major League Baseball among 12- to 17-year-olds, as reported by the 2013 Luker on Trends ESPN poll, having jumped in popularity since the 2010 World Cup.[98][99]  In 2014, the league announced Atlanta United FC as the 22nd team to start playing in 2017.[100] Even though New York City FC and Orlando City were not set to begin play until 2015, each team made headlines during the summer 2014 transfer window by announcing their first Designated Players\u2014Spain's leading scorer David Villa and Chelsea's leading scorer Frank Lampard to New York, and Ballon d'Or winner Kak\u00e1 to Orlando.[101] The 2014 World Cup featured 21 MLS players on World Cup rosters and a record 11 MLS players playing for foreign teams\u2014including players from traditional powerhouses Brazil (J\u00falio C\u00e9sar) and Spain (David Villa); in the U.S. v. Germany match the U.S. fielded a team with seven MLS starters.[102]  On September 18, 2014, MLS unveiled their new logo as part of a branding initiative. In addition to the new crest logo, MLS teams display versions in their own colors on their jerseys.[103] Chivas USA folded following the 2014 season, while New York City FC and Orlando City SC joined the league in 2015 as the 19th and 20th teams.[104] Sporting Kansas City and the Houston Dynamo moved from the Eastern Conference to the Western Conference in 2015 to make two 10-team conferences.[104][105]  In early 2015, the league announced that two teams\u2014Los Angeles FC and Minnesota United FC\u2014would join MLS in either 2017 or 2018.[106] The 20th season of MLS saw the arrivals of several players who have starred at the highest levels of European club soccer and in international soccer: Giovanni dos Santos, Kak\u00e1, Andrea Pirlo, Frank Lampard, Steven Gerrard, Didier Drogba, David Villa, and Sebastian Giovinco.[107] MLS confirmed in August 2016 that Minnesota United would begin play in 2017 along with Atlanta United FC.[108]  In April 2016, the league's commissioner Don Garber reiterated the intention of the league to expand to 28 teams, with the next round of expansion \"likely happening in 2020\".[109][110] In December 2016, he updated the expansion plans stating that the league will look to approve the 25th and 26th teams in 2017 and to start play in 2020.[111] In January 2017, the league received bids from 12 ownership groups.[112]  In July 2017, it was reported that Major League Soccer had rejected an offer by MP & Silva to acquire all television rights to the league following the conclusion of its current contracts with Fox, ESPN, and Univision, where MP & Silva insisted that the deal would be conditional on Major League Soccer adopting a promotion and relegation system. The league stated that it rejected the offer due to the exclusive periods that the current rightsholders have to negotiate extensions to their contracts. Additionally, media noted that Major League Soccer has long-opposed the adoption of promotion and relegation, continuing to utilize the fixed, franchise-based model used in other U.S. sports leagues.[18][113] Furthermore, MP & Silva founder Riccardo Silva also owned Miami FC of the NASL, which stood to benefit from such a promotion and relegation system.[113]  In October 2017, Columbus Crew owner Anthony Precourt announced plans to move the franchise to Austin, Texas by 2019.[114] The announcement spawned a league-wide backlash and legal action against the league by the Ohio state government.[115] On August 15, 2018, the Austin City Council voted to approve an agreement with Precourt to move Crew SC to Austin, and on August 22, 2018, the club's new name, Austin FC, was announced.[116] After negotiations between Precourt and Jimmy Haslam, owner of the Cleveland Browns, were announced, MLS made it clear that Austin would receive an expansion team only after a deal to sell Columbus to a local buyer had completed.[117] The purchase of Crew SC by Haslam's group was finalized in late December 2018,[118] and on January 15, 2019, Austin FC was officially announced as a 2021 MLS entry.[119]  MLS announced on December 20, 2017, that it would be awarding an expansion franchise to Nashville, Tennessee, to play in a yet-to-be-built 27,000-seat soccer-specific stadium, Nashville Fairgrounds Stadium, and would join MLS in 2020.[120] The management of the Nashville franchise announced in February 2019 that the MLS side would assume the Nashville SC name then in use by the city's USL Championship team.[121]  On January 29, 2018, MLS awarded Miami an expansion team, led by David Beckham. Inter Miami CF started MLS play on March 1, 2020, and plan on opening the proposed 25,000-seat stadium sometime in the near future.[122] An expansion team was awarded to Cincinnati, Ohio on May 29, 2018, to the ownership group of USL's FC Cincinnati. The team, which assumed the existing FC Cincinnati name, started MLS play in 2019 and moved to the new 26,000-seat TQL Stadium in 2021.[123]  The league planned to expand to 30 teams with the addition of Austin FC in 2021,[119] Charlotte in 2022,[124] and Sacramento and St. Louis in 2023; however, this was reduced to 29 after Sacramento Republic FC's bid was placed on indefinite hold.[44][125][5][126] Commissioner Don Garber has suggested that another round of expansion could lead to 32 teams in MLS.[127]  The league suspended its 2020 season on March 12, 2020, after two weeks, due to the COVID-19 pandemic in the United States, and other U.S.-based sports leagues did the same.[128][129][130] The 2020 season resumed in July with the MLS is Back Tournament, a competition in which 24 out of the 26 teams competed at the ESPN Wide World of Sports Complex in Orlando for a spot in the CONCACAF Champions League. In September 2020, the league announced the formation of MLS Next, an academy league for MLS academy teams from the under-13 to under-19 level.[131]  In 2022, the league signed a $2.5 billion deal with Apple Inc. that will make Apple TV the primary broadcaster for all MLS games. The agreement will see both MLS and Leagues Cup games shared across the streaming service.[132]  In May 2023, the league announced it would expand to 30 teams with the addition of San Diego FC for the 2025 season.[133]  In 2005, Toronto FC's ownership paid $10 million (about $15.6\u00a0million in today's dollars)[134] to join the league in 2007; San Jose paid $20 million the next year, and the fee had risen to $30 million when Sounders FC paid the fee in 2007 to join the league in 2009.[135] In 2013, New York City FC agreed to pay a record $100 million expansion fee for the right to join MLS in 2015.[136] This record was surpassed by the ownership groups of FC Cincinnati and Nashville SC, which each paid $150 million to join MLS 2019 and 2020, respectively.[137] Despite being announced in January 2018, Inter Miami CF only paid a $25 million expansion fee due to a clause in part-owner David Beckham's original playing contract signed in 2007.[138] $150 million was paid as an effective entrance fee by a group that bought Columbus Crew in 2018, which led to that team's previous operator receiving rights to Austin FC, which joined MLS in 2021.[139][140] MLS has also announced the ownership groups of the 28th and 29th teams would each pay a $200 million entrance fee.[136]  As of the 2023 season, 32 different clubs have competed in the league, with 15 having won at least one MLS Cup, and 16 winning at least one Supporters' Shield.[141] The two trophies have been won by the same club in the same year on eight occasions (two clubs have accomplished the feat twice).[142]  Major League Soccer operates under a single-entity structure in which teams and player contracts are centrally owned by the league.[3][143][144] Each team has an investor-operator that is a shareholder in the league.[145] In order to control costs, MLS shares revenues and holds players contracts instead of players contracting with individual teams. In Fraser v. Major League Soccer, a lawsuit filed in 1996 and decided in 2002, the league won a legal battle with its players in which the court ruled that MLS was a single entity that can lawfully centrally contract for player services.[3] The court also ruled that even absent their collective bargaining agreement, players could opt to play in other leagues if they were unsatisfied.[3]  Having multiple clubs operated by a single investor was a necessity in the league's first ten years.[146] At one time, Phil Anschutz's AEG operated six MLS franchises and Lamar Hunt's Hunt Sports operated three franchises. In order to attract additional investors, in 2002 the league announced changes to the operating agreement between the league and its teams to improve team revenues and increase the incentives to be an individual club operator.[147] These changes included granting operators the rights to a certain number of players they develop through their club's academy system each year, sharing the profits of Soccer United Marketing, and being able to sell individual club jersey sponsorships.[147]  As MLS appeared to be on the brink of overall profitability in 2006 and developed significant expansion plans, MLS announced that it wanted each club to have a distinct operator.[148] The league has attracted new investors that have injected more money into the league.[149] Examples include Red Bull's purchase of the MetroStars from AEG in 2006 for over $100\u00a0million.[146][150] For the 2014 season, the league assumed control of the former Chivas USA club, which had suffered from mismanagement and poor financial results under its individual operator relationship.[151][152] The league eventually dissolved the team,[153] in favor of awarding rights to a second soccer club in the Los Angeles area to a new investor group on October 30, 2014.[154]  The league now has 29 investor-operators for its 29 current clubs, with no member of any club's investor group having a stake in that of any other club. Since December 2015, when AEG sold its remaining 50% interest in the Houston Dynamo, the former multiple-team operators AEG and Hunt Sports, with the LA Galaxy and FC Dallas respectively, now only control one franchise.[155][156]  Don Garber has been the commissioner of Major League Soccer since 1999, serving as the league's chief executive. The league's first commissioner was Doug Logan, who served in the role from 1995 to 1999.[157][158]  Mark Abbott, a former MLS business partner, has served as the league's president and Deputy Commissioner since 2006.[159]  In 2016, the average salary for MLS players was $373,094,[160] lower than the average salaries in England's second-tier EFL Championship ($420,000 in 2015),[161] the Netherlands' Eredivisie ($445,000),[162] or Mexico's Liga MX ($418,000 in 2015).[163] The league's minimum player salary increased in 2017 to $65,000 for most players, and roster players #25\u201330 saw their minimum salary increased to $53,000.[164][165]  MLS salaries are limited by a salary cap, which MLS has had in place since the league's inception in 1996. The purpose of the salary cap is to prevent the team's owners from unsustainable spending on player salaries and to prevent a competitive imbalance among teams.[54] The salary cap survived a legal challenge by the players in the Fraser v. Major League Soccer lawsuit. The 2017 salary cap increased to $3.845 million per team.[164][165] Each team is allowed up to 30 players on its first team roster.[166] All 30 players are eligible for selection to each 18-player game-day squad during the regular season and playoffs.  Teams may augment their squads by signing players from other leagues. MLS has two transfer windows\u2014the primary pre-season transfer window lasts three months from mid February until mid May, and the secondary mid season transfer window runs one month from early July to early August.[167] When an MLS club sells one of its players overseas, the club and the league split the transfer revenues, with the club retaining from 33% to 75% depending on the player's status and tenure.[168] MLS teams have a limited number of international roster slots that they can use to sign non-domestic players. However, MLS teams often obtain green cards for their non-domestic players in order to qualify them for domestic status and thus free up international roster slots.[169] In 2015, 49% of MLS players were born outside of the U.S. and Canada, with players from 58 countries represented.[170][171]  MLS has a set of pool goalkeepers who are signed to a contract with the league and are loaned to teams during emergencies in which they are missing a goalkeeper due to injuries or suspensions.[172] The pool goalkeeper trains with an MLS club or an affiliated team when not assigned to a team; some pool goalkeepers, including Tim Melia, have gone on to be signed to permanent contract with their assigned teams.[173] In the past, when rosters were smaller, there were multiple goalkeepers signed to the pool, however, in recent years only one or two keepers are signed as team rosters are much larger.[174]  MLS has also introduced various initiatives and rules intended to improve quality of players while still maintaining the salary cap. Rules concerning Designated Players and allocation money allow for additional wage spending that is exempt from the salary cap. These initiatives have brought about an increase in on-field competition.[175][unreliable source?]  The designated player (DP) rule allows teams to sign a limited number of players whose salary exceeds the maximum cap; in 2017, each DP player only counted as $480,625 (the maximum non-DP salary) against the cap. Instituted in 2007, England's David Beckham was the first signing under the DP rule.[81] The DP rule has led to large income inequality in MLS with top DPs earning as much as 180 times more than a player earning the league minimum.[176] In the 2013 season, 21% of the league's wage spending went to just five players; this stretched to 29% on the top 6 players in the 2014 season.[177][178][unreliable source?]  The league's \"Core Players\" initiative allows teams to re-sign players using retention funds that do not count against the salary cap.[95] Retention funds were implemented in 2013 as a mechanism for MLS to retain key players; among the first high-profile players re-signed using retention funds were U.S. national team regulars Graham Zusi and Matt Besler.[95] MLS teams can also obtain allocation money, which is money that the team can use on player salaries that does not count against the cap, and teams can earn allocation money in several ways, such as from the transfer fees earned by selling players to teams in other leagues.[179] MLS teams can also use Targeted Allocation Money (often referred to as TAM), an initiative announced in 2015. Teams can use TAM funds to attract high-profile players by \"buying down\" contracts of players to below the Designated Player level.[180] High-profile players for which TAM funds were used include Hector Villalba, Zlatan Ibrahimovi\u0107 and Giorgio Chiellini.  MLS has introduced various initiatives and rules intended to develop young players. Rules concerning Generation Adidas players and home grown players provide incentives for clubs to develop and retain young players.[175]  MLS has required all of its teams to operate youth development programs since 2008.[181] MLS roster rules allow teams to sign an unlimited number of players straight from their academies and bypassing the draft process.[182] There is also supplementary salary budget made by MLS only for homegrown players that are registered using senior roster slots called homegrown player funds.[183] One of the most prominent and lucrative examples of success in \"home-grown\" development was Jozy Altidore, who rose to prominence as a teenager in MLS before his record transfer fee $10\u00a0million move to Villarreal in Spain in 2008.[184] The various MLS teams' development academies play matches in a U.S. Soccer developmental league against youth academies from other leagues such as the North American Soccer League (NASL), which had been a Division II league prior to 2018, and USL Pro, originally a Division III league but now the Division II USL Championship.[185]  The league operates a Generation Adidas program, which is a joint venture between MLS and U.S. Soccer that encourages young American players to enter MLS.[186] The Generation Adidas program has been in place since 1997, and has introduced players such as Landon Donovan, Clint Dempsey, Tim Howard and Michael Bradley into MLS. Players under the Home Grown Player rule are signed to Generation Adidas contracts,[167] all players on Generation Adidas contracts are \"off budget players\" and their salaries do not count against the cap.  MLS has operated reserve leagues, which give playing time to players who were not starters for their MLS teams, during two different periods. The MLS Reserve League was formed in 2005, and operated through 2014 (with the exception of the 2009 & 2010 seasons).[187] MLS began integrating its Reserve League with the league then known as USL Pro in 2013,[188] and after the 2014 season folded the Reserve League, with MLS then requiring all teams to either affiliate with a USL team or field their own reserve side in that league. However, this requirement was never strictly enforced, and MLS eventually relaunched its reserve league in 2022 under the banner of MLS Next Pro. In the inaugural 2022 season, 19 of the league's then-current clubs, plus future club St. Louis City SC, fielded reserve sides in Next Pro. In the 2023 season, the only MLS teams that will not field Next Pro sides are CF Montr\u00e9al and D.C. United.[189][190]  Following the folding of the Development Academy,[191] MLS announced its own development league in 2020.[192] It includes all of the MLS team academies as well as 95 clubs across the country; many of which were a part of the Development Academy.[citation needed]  Since 1999, the league has overseen the construction of twelve stadiums specifically designed for soccer. The development of soccer-specific stadiums owned by the teams has generated a better gameday experience for the fans.[193] The soccer-specific stadiums have yielded positive financial results as teams were no longer required to pay to rent out facilities and gained control over revenue streams such as concessions, parking, naming rights, and the ability to host non-MLS events.[152][193] Several teams have doubled their season tickets following the team's move into a soccer-specific stadium.[194] The establishment of soccer-specific stadiums is considered the key to the league and the ability of teams to turn a profit.[195] In 2006, Tim Leiweke, then CEO of Anschutz Entertainment Group, described the proliferation of soccer-specific stadiums as the turning point for MLS.[195]  Columbus Crew owner Lamar Hunt started this trend in 1999 by constructing Columbus Crew Stadium, now known as Historic Crew Stadium, as MLS's first soccer-specific stadium.[69] The Los Angeles Galaxy followed four years later with the opening of the Home Depot Center, now Dignity Health Sports Park, in 2003.[196] FC Dallas opened Pizza Hut Park, now Toyota Stadium, in 2005, and the Chicago Fire began playing their home games in Toyota Park, now SeatGeek Stadium, in 2006. The 2007 season brought the opening of Dick's Sporting Goods Park for the Colorado Rapids and BMO Field for Toronto FC.[197]  Near the end of the 2008 season, Rio Tinto Stadium (now known as America First Field) became the home of Real Salt Lake, which meant that for the first time in MLS history a majority of MLS's teams (8 out of 14) played in soccer-specific stadiums.[198] Red Bull Arena, the new home of the New York Red Bulls opened for the start of the 2010 season,[199] and the Philadelphia Union opened PPL Park, now Subaru Park, in June 2010, midway through their inaugural season.[200]  The following season, in 2011, the Portland Timbers made their MLS debut in a newly renovated Jeld-Wen Field, now renamed Providence Park, which was originally a multi-purpose venue but turned into a soccer-specific facility.[201] Also in 2011, Sporting Kansas City moved to new Livestrong Sporting Park, now Children's Mercy Park.[202] The Houston Dynamo relocated to their new home at BBVA Compass Stadium, now Shell Energy Stadium, in 2012.[199] In the same year, the Montreal Impact joined the league in an expanded Stade Saputo, which reopened in June 2012, when renovations pushed the seating capacity to over 20,000. The Impact has used Olympic Stadium for early season matches and for games that require a larger capacity.[203] The San Jose Earthquakes, who had played at Buck Shaw Stadium from 2008 until 2014, opened their new Avaya Stadium (now PayPal Park) before the 2015 season.[204] Orlando City SC intended to begin constructing its soccer-specific stadium, now known as Exploria Stadium, in 2014 to be completed in 2015.[205] Delays caused by changes to the stadium plans pushed back the new venue's opening, first to late 2016 and finally to the start of the 2017 season.[206] Orlando City played at the Florida Citrus Bowl Stadium, now Camping World Stadium, while awaiting the construction of their new venue through the 2016 season. Exploria Stadium hosted its first MLS match on March 5, 2017, against New York City FC as Orlando City Stadium.  The development of additional MLS stadiums has continued to progress.  D.C. United had played their home games at former NFL and Major League Baseball venue RFK Stadium. In 2013, D.C. United announced the signing of a public-private partnership term sheet to build a new soccer stadium in Washington, D.C., and a final deal was reached in late 2014. In late February 2017,  D.C. United finally broke ground on their new stadium, Audi Field.[207] After 21 years of playing at RFK Stadium, DC United played their first game at Audi field in July 2018.  Two teams have announced their desire to build a soccer-specific stadium, although these teams have not finalized the stadium site and received all necessary government approvals. New York City FC play home games at Yankee Stadium, a Major League Baseball venue, although they intend to move into a soccer-specific stadium in the future. The New England Revolution play home games at Gillette Stadium which is an NFL Stadium also owned by the Revolution's owner, Robert Kraft. The team are currently in discussion with the City of Boston regarding a potential soccer-specific stadium in South Boston.[208]  Several remaining clubs play in stadiums not originally built for MLS and have not announced plans to move. The Seattle Sounders FC play at Lumen Field, a dual-purpose facility used for both American football and soccer. The Vancouver Whitecaps FC joined the league with Portland in 2011 and temporarily held matches at Empire Field before moving into the refurbished BC Place in October 2011,[209] a retractable-roof stadium that hosts Canadian football as well as soccer.[210]  Of the three teams that made their MLS debuts in 2017 and 2018, one opened a soccer-specific stadium in 2019, a second is playing in a shared football stadium, and the last opened a soccer-specific stadium for its inaugural 2018 season. Minnesota United FC, which debuted in 2017, built Allianz Field in St. Paul which hosted its inaugural game against New York City FC on April 13, 2019.[211][212] Until that time, the team played in Minneapolis at TCF Bank Stadium (now Huntington Bank Stadium), home to University of Minnesota football.[213] Atlanta United FC began play in 2017 at a college football facility, Georgia Tech's Bobby Dodd Stadium, before moving into its permanent home at the retractable-roof Mercedes-Benz Stadium, which it shares with the NFL's Atlanta Falcons; the two teams share a common owner and the stadium is equipped with screens to cordon off the upper tiers for most matches.[214] Los Angeles FC, which began play in 2018, opened Banc of California Stadium (now BMO Stadium) on the former site of the Los Angeles Sports Arena in April of its inaugural season.[215]  FC Cincinnati made its MLS debut in 2019 at Nippert Stadium, the football home of the University of Cincinnati. The stadium had been home to FCC's USL Championship predecessor for all of its three seasons of play. The club moved within Cincinnati to the new TQL Stadium in 2021.[216] Inter Miami began play in 2020 at Inter Miami CF Stadium, now known as DRV PNK Stadium, at the former site of Lockhart Stadium in Fort Lauderdale before opening Miami Freedom Park in the future.[217] Nashville SC played the 2020 and 2021 seasons at an NFL facility, the Tennessee Titans' Nissan Stadium, before opening Geodis Park in 2022.[218] Austin FC opened Q2 Stadium for its first season in 2021.[119] St. Louis City SC opened CityPark in November 2022, a few months before the club's first season in 2023.[219]  Major League Soccer began to demonstrate positive signs of long-term profitability as early as 2004 with the single-entity ownership structure, salary cap, and the media and marketing umbrella Soccer United Marketing (SUM) all contributing towards MLS's financial security.[63] As soccer-specific stadiums are built, ownership expands, and television coverage increases, MLS has seen its revenues increase while controlling costs.[9]  Television coverage and revenue have increased since the league's early years. In 2006, MLS reached an 8-year TV deal with ESPN spanning the 2007\u20132014 seasons, and marked the first time that MLS earned rights fees, reported to be worth $7\u20138\u00a0million annually.[221] In September 2012 the league extended its distribution agreement with London-based Media rights agency MP & Silva until 2014 in a deal worth $10\u00a0million annually. Total league TV revenues are over $40\u00a0million annually.[222][223] In 2011, MLS earned $150\u00a0million when it sold a 25% stake in SUM.[9]  In early 2005, MLS signed a 10-year, $150\u00a0million sponsorship deal with Adidas for its jerseys and other equipment.[63] In 2007, MLS teams started selling ad space on the front of jerseys to go along with the league-wide sponsorship partners who had already been advertising on the back of club jerseys, following the practice of international sport, specifically soccer. MLS established a floor of $500,000 per shirt sponsorship, with the league receiving a flat fee of $200,000 per deal.[252] As of July 2014, sixteen teams had signed sponsorship deals to have company logos placed on the front of their jerseys (and another team is directly owned by its shirt sponsor), and the league average from jersey sponsors was about $2.4\u00a0million.[253] Sleeve sponsorship was introduced to MLS in the 2020 season, with the teams able to sell a 2-by-2-inch (51 by 51\u00a0mm) section on the right arm where the league logo patch is normally positioned.[254]  The Los Angeles Galaxy made a profit in 2003 in their first season at The Home Depot Center,[62] and FC Dallas turned a profit after moving into Pizza Hut Park in 2005.[255] For each season between 2006 and 2009, two to three MLS clubs (generally clubs with a soccer-specific stadium) were reported as profitable by the league.[255][256][257]  By 2012 the league had shown a marked improvement in its financial health. In November 2013, Forbes published a report that revealed that ten of the league's nineteen teams earned an operating profit in 2012, while two broke even and seven had a loss. Forbes estimated that the league's collective annual revenues were $494\u00a0million, and that the league's collective annual profit was $34 million. Forbes valued the league's franchises to be worth $103\u00a0million on average, almost three times as much as the $37\u00a0million average valuation in 2008. The Seattle Sounders FC franchise was named the most valuable at $175\u00a0million, a 483% gain over the $30 million league entrance fee it paid in 2009.[152]  The trend in increased team values has continued with MLS teams seeing a strong 52% increase in franchise values from 2012 to 2014. In August 2015 Forbes updated its MLS franchise values with the most profitable team measuring $245 million and the least $105 million. The average value jumped from $103 to $157 million.[10]  As of 2018 Forbes estimates Atlanta United FC is the most valuable MLS team, worth $330 million, while the Colorado Rapids are the lowest value, at $155 million.[258] These valuations do not include the value of stadiums or training facilities owned by the respective clubs.  Prior to the COVID-19 pandemic, MLS teams typically used commercial flights to transport players and staff between matches, with only four charter flights allowed under league rules.[259] These commercial flights were often non-direct, requiring transfers and layovers, and contributed to long travel days.[260] The number of charters allowed for league matches was increased to eight legs prior to the 2020 season and lifted entirely due to the COVID-19 pandemic.[261][262] Sun Country Airlines has provided charter service to MLS teams since 2020 and became the league's official carrier in 2022.[263]  When the league began play, it tried to gain popularity by \"Americanizing\" the game: the game clock counted down in each half and stopped for certain dead ball situations and games level at the end of regulation were resolved with a running penalty shootout.[264]  Now MLS follows the rules and standards of the International Football Association Board (IFAB). Since 2005, the playoff extra time structure follows IFAB standards: two full 15-minute periods, followed by a penalty shootout if necessary.  U.S. Soccer hired the first full-time professional referees in league history in 2007 as part of the league's \"Game First\" initiatives.[265] Major League Soccer has been implementing fines and suspensions since the 2011 season for simulation (diving) through its Disciplinary Committee, which reviews plays after the match. The first player fined under the new rule was Charlie Davies, fined $1,000 for intentionally deceiving match officials.[266]  MLS uses the list of banned substances published by the World Anti-Doping Agency.[267]  The current MLS logo debuted in 2014, ahead of the league's 20th season, replacing an earlier logo that featured a stylized boot and ball. The current logo is a simple crest with a diagonal stripe, the MLS wordmark, and three stars that represent \"community, club, and country\". The logo was designed to be remixed in different color schemes that match teams when used on merchandise and jerseys.[268]  The first MLS anthem was unveiled in 2007 and was composed by Audiobrain. The current league anthem debuted in 2020 and was composed by film score composer Hans Zimmer. It will be used during league broadcasts and as a prelude to kickoff at stadiums.[269]  In the early years of MLS, teams were typically given official nicknames in the style of other U.S. sports leagues (e.g., Columbus Crew, Los Angeles Galaxy, New England Revolution). Several club names in MLS originated with previous professional soccer clubs, such as the 1970s-era NASL team names San Jose Earthquakes, Seattle Sounders, Portland Timbers, and Vancouver Whitecaps.[270]  D.C. United was the only MLS team to adopt European naming conventions during the 1990s.[271] In more recent years, European-style names have become increasingly common in MLS, with expansion teams such as Real Salt Lake, Toronto FC, New York City FC, Atlanta United FC, Minnesota United FC, and FC Cincinnati, along with rebrandings such as FC Dallas (formerly the Dallas Burn),[272] Sporting Kansas City (formerly the Kansas City Wizards),[273] and CF Montr\u00e9al (formerly the Montreal Impact).  Austrian beverage company Red Bull GmbH owns and sponsors the New York Red Bulls as well as other sports teams outside the U.S.[150]  Starting in 2023, all MLS and Leagues Cup matches, as well as certain matches from MLS Next Pro and MLS Next, are streamed worldwide on MLS Season Pass via Apple TV. This agreement ended the previous regional sports network-based system.[274] The contract allows for some broadcasts on linear television. ESPN and Univision exited negotiations, apparently because MLS would not allow them to stream via their own platforms or use their own commentators.[275][276] Following their departures, Fox Sports joined Apple as MLS's linear broadcast partners in the U.S., with Bell Media's TSN and RDS doing so in Canada.[277]  From 2012 to 2014, MLS matches were broadcast by NBC Sports, with 40 matches per year\u2014primarily on NBCSN, and select matches broadcast on the NBC network.[278] The move from Fox Soccer to the more widely distributed NBCSN caused viewership numbers to double for the 2012 season.[279]  Soccer United Marketing partnered with Google and Bedrocket Media Ventures in 2012 to launch \"KickTV\", a premium YouTube channel with original soccer programming.[280] KickTV was sold to Copa90 in 2015 to form its American branch.[281] In 2020, Soccer United Marketing signed a multi-year agreement with Bleacher Report to produce content and highlights for MLS and the U.S. national teams through the 2022 season.[282]  From 2015 to 2022, MLS matches were broadcast nationally by ESPN networks and Fox Sports in English, and Univision networks in Spanish under an eight-year contract. Each broadcaster had a window for national regular season matches, with UniM\u00e1s airing a game on Friday nights in Spanish and additional matches on Univision Deportes Network, and ESPN and Fox Sports 1 airing games on Sunday evenings in English. ESPN, FS1, and Univision shared coverage of the playoffs, while ABC and Fox alternated broadcasting the MLS Cup final in English. In total, at least 125 matches were aired per-season across all three networks. The three contracts have an average estimated value of $90 million per season\u2014five times larger than the average $18 million value of the previous contracts with ESPN, Univision, and NBC Sports.[283][284][285]  Matches not televised nationally were broadcast regionally, often by regional sports networks like Bally Sports, NBC Sports Regional Networks, Spectrum Sports and Root Sports, and sometimes by terrestrial stations like KTXA, WGN and KMYU.[89] Regionally televised matches were available outside their local markets on ESPN+, which replaced MLS Live from 2018 until 2022.[286]  Coverage of MLS expanded into Canada in 2007 with the addition of Toronto FC. Currently, English-language national MLS broadcast rights in Canada are held by the TSN networks through a five-year deal first renewed in 2017. The networks primarily broadcast matches involving the league's Canadian franchises, in combination with separate \"regional\" rights deals giving TSN exclusive rights to all Toronto FC and Vancouver Whitecaps FC matches.[287][288][289] A limited number of matches are also carried by CTV.[289]  TVA Sports holds exclusive French-language rights to MLS in Canada as of the 2017 season. As part of a separate \"regional\" rights deal, it also holds exclusive rights to all CF Montr\u00e9al games.[289][290]  In 2018, online streaming service DAZN obtained Major League Soccer's digital out-of-market service MLS Live with live and on-demand streaming of matches featuring U.S. teams (matches with Canadian teams are only available after a 48-hour delay to protect the league's main rightsholders TSN and TVA Sports).[291]  MLS also entered into a four-year contract with Sky Sports to broadcast two MLS matches per week in the United Kingdom and Ireland from 2015 to 2019.[292] As part of the agreement, Sky Sports broadcast at least two MLS regular-season matches each week, as well as the MLS All-Star Game, every MLS Cup Playoff game, and the MLS Cup final. The matches appeared across Sky's family of networks. It also carried weekly MLS highlights across various platforms, including Sky Sports News and SkySports.com. Sky Sports also broadcast at least one match from MLS's \"Decision Day\" \u2013 the final day of the MLS regular season. Many of the matches on Decision Day every year are expected to determine the final spots for the MLS Cup Playoffs.[293]  DSport, owned by Discovery Communications, will televise league matches in India beginning in 2017.[294]  Major League Soccer is a playable league in the EA Sports FC series, the eFootball series, and the Football Manager series. The league made its video game debut in 1999 with FIFA 2000. Kids video game company Humongous Entertainment had the rights to teams and players for their game, Backyard Soccer MLS Edition and for Backyard Soccer 2004. In 2000, Konami released ESPN MLS GameNight, and two years later, they released its sequel, ESPN MLS ExtraTime 2002. The league made its first appearance in the management series Football Manager 2005 in 2004.[295]  Statistics below are for all-time leaders. Statistics are for regular season only. Bold indicates active MLS players.      Statistics below are for all-time leaders who are still playing. Statistics are for regular season only.    At the conclusion of each season, the league presents several awards for outstanding achievements, mostly to players, but also to coaches, referees, and teams. The finalists in each category are determined by voting from MLS players, team employees, and the media.[297]   "},{"title":"Europe","content":"  Europe is a continent[t] located entirely in the Northern Hemisphere and mostly in the Eastern Hemisphere. It is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, the Mediterranean Sea to the south, and Asia to the east. Europe shares the landmass of Eurasia with Asia, and of Afro-Eurasia with both Asia and Africa.[10][11] Europe is commonly considered to be separated from Asia by the watershed of the Ural Mountains, the Ural River, the Caspian Sea, the Greater Caucasus, the Black Sea, and the waterway of the Bosporus Strait.[12]  Europe covers about 10.18\u00a0million\u00a0km2 (3.93\u00a0million\u00a0sq\u00a0mi), or 2% of Earth's surface (6.8% of land area), making it the second-smallest continent (using the seven-continent model). Politically, Europe is divided into about fifty sovereign states, of which Russia is the largest and most populous, spanning 39% of the continent and comprising 15% of its population. Europe had a total population of about 745 million (about 10% of the world population) in 2021; the third-largest after Asia and Africa.[2][3] The European climate is affected by warm Atlantic currents, such as the Gulf Stream, which produce a temperate climate, tempering winters and summers, on much of the continent. Further from the sea, seasonal differences are more noticeable producing more continental climates.  European culture consists of a range of national and regional cultures, which form the central roots of the wider Western civilisation, and together commonly reference ancient Greece and ancient Rome, particularly through their Christian successors, as crucial and shared roots.[13][14] Beginning with the fall of the Western Roman Empire in 476 CE, Christian consolidation of Europe in the wake of the Migration Period marked the European post-classical Middle Ages. The Italian Renaissance, radiating from Florence, spread to the rest of the continent a new humanist interest in art and science which led to the modern era. Since the Age of Discovery, led by Spain and Portugal, Europe played a predominant role in global affairs with multiple explorations and conquests around the world. Between the 16th and 20th centuries, European powers colonised at various times the Americas, almost all of Africa and Oceania, and the majority of Asia.  The Age of Enlightenment, the French Revolution, and the Napoleonic Wars shaped the continent culturally, politically and economically from the end of the 17th century until the first half of the 19th century. The Industrial Revolution, which began in Great Britain at the end of the 18th century, gave rise to radical economic, cultural and social change in Western Europe and eventually the wider world. Both world wars began and were fought to a great extent in Europe, contributing to a decline in Western European dominance in world affairs by the mid-20th century as the Soviet Union and the United States took prominence and competed over dominance in Europe and globally.[15] The resulting Cold War divided Europe along the Iron Curtain, with NATO in the West and the Warsaw Pact in the East. This divide ended with the Revolutions of 1989, the fall of the Berlin Wall, and the dissolution of the Soviet Union, which allowed European integration to advance significantly.  European integration is being advanced institutionally since 1948 with the founding of the Council of Europe, and significantly through the realisation of the European Union (EU), which represents today the majority of Europe.[16] The European Union is a supranational political entity that lies between a confederation and a federation and is based on a system of European treaties.[17] The EU originated in Western Europe but has been expanding eastward since the dissolution of the Soviet Union in 1991. A majority of its members have adopted a common currency, the euro, and participate in the European single market and a customs union. A large bloc of countries, the Schengen Area, have also abolished internal border and immigration controls. Regular popular elections take place every five years within the EU; they are considered to be the second-largest democratic elections in the world after India's. The EU is the third-largest economy in the world.    The place name Evros was first used by the ancient Greeks to refer to their northernmost province, which bears the same name today. The principal river there \u2013 Evros (today's Maritsa) \u2013 flows through the fertile valleys of Thrace,[18] which it self was also called Europe, before the term meant the continent.[19]  In classical Greek mythology, Europa (Ancient Greek: \u0395\u1f50\u03c1\u03ce\u03c0\u03b7, Eur\u1e53p\u0113) was a Phoenician princess. One view is that her name derives from the Ancient Greek elements \u03b5\u1f50\u03c1\u03cd\u03c2 (eur\u00fas) 'wide, broad', and \u1f64\u03c8 (\u014dps, gen. \u1f60\u03c0\u03cc\u03c2, \u014dp\u00f3s) 'eye, face, countenance', hence their composite Eur\u1e53p\u0113 would mean 'wide-gazing' or 'broad of aspect'.[20][21][22][23] Broad has been an epithet of Earth herself in the reconstructed Proto-Indo-European religion and the poetry devoted to it.[20] An alternative view is that of Robert Beekes, who has argued in favour of a pre-Indo-European origin for the name, explaining that a derivation from eurus would yield a different toponym than Europa. Beekes has located toponyms related to that of Europa in the territory of ancient Greece, and localities such as that of Europos in ancient Macedonia.[24]  There have been attempts to connect Eur\u1e53p\u0113 to a Semitic term for west, this being either Akkadian erebu meaning 'to go down, set' (said of the sun) or Phoenician 'ereb 'evening, west',[25] which is at the origin of Arabic maghreb and Hebrew ma'arav. Martin Litchfield West stated that \"phonologically, the match between Europa's name and any form of the Semitic word is very poor\",[26] while Beekes considers a connection to Semitic languages improbable.[24]  Most major world languages use words derived from Eur\u1e53p\u0113 or Europa to refer to the continent. Chinese, for example, uses the word \u014cuzh\u014du (\u6b50\u6d32\/\u6b27\u6d32), which is an abbreviation of the transliterated name \u014culu\u00f3b\u0101 zh\u014du (\u6b50\u7f85\u5df4\u6d32) (zh\u014du means \"continent\"); a similar Chinese-derived term \u014csh\u016b (\u6b27\u5dde) is also sometimes used in Japanese such as in the Japanese name of the European Union, \u014csh\u016b Reng\u014d (\u6b27\u5dde\u9023\u5408), despite the katakana Y\u014droppa (\u30e8\u30fc\u30ed\u30c3\u30d1) being more commonly used. In some Turkic languages, the originally Persian name Frangistan (\"land of the Franks\") is used casually in referring to much of Europe, besides official names such as Avrupa or Evropa.[27]  Clickable map of Europe, showing one of the most commonly used continental boundaries[u] Key: blue: states which straddle the border between Europe and Asia; green: countries not geographically in Europe, but closely associated with the continent   The prevalent definition of Europe as a geographical term has been in use since the mid-19th century. Europe is taken to be bounded by large bodies of water to the north, west and south; Europe's limits to the east and north-east are usually taken to be the Ural Mountains, the Ural River, and the Caspian Sea; to the south-east, the Caucasus Mountains, the Black Sea, and the waterways connecting the Black Sea to the Mediterranean Sea.[28]  Islands are generally grouped with the nearest continental landmass, hence Iceland is considered to be part of Europe, while the nearby island of Greenland is usually assigned to North America, although politically belonging to Denmark. Nevertheless, there are some exceptions based on sociopolitical and cultural differences. Cyprus is closest to Anatolia (or Asia Minor), but is considered part of Europe politically and it is a member state of the EU. Malta was considered an island of North-western Africa for centuries, but now it is considered to be part of Europe as well.[29] \"Europe\", as used specifically in British English, may also refer to Continental Europe exclusively.[30]  The term \"continent\" usually implies the physical geography of a large land mass completely or almost completely surrounded by water at its borders. Prior to the adoption of the current convention that includes mountain divides, the border between Europe and Asia had been redefined several times since its first conception in classical antiquity, but always as a series of rivers, seas and straits that were believed to extend an unknown distance east and north from the Mediterranean Sea without the inclusion of any mountain ranges. Cartographer Herman Moll suggested in 1715 Europe was bounded by a series of partly-joined waterways directed towards the Turkish straits, and the Irtysh River draining into the upper part of the Ob River and the Arctic Ocean. In contrast, the present eastern boundary of Europe partially adheres to the Ural and Caucasus Mountains, which is somewhat arbitrary and inconsistent compared to any clear-cut definition of the term \"continent\".  The current division of Eurasia into two continents now reflects East-West cultural, linguistic and ethnic differences which vary on a spectrum rather than with a sharp dividing line. The geographic border between Europe and Asia does not follow any state boundaries and now only follows a few bodies of water. Turkey is generally considered a transcontinental country divided entirely by water, while Russia and Kazakhstan are only partly divided by waterways. France, the Netherlands, Portugal and Spain are also transcontinental (or more properly, intercontinental, when oceans or large seas are involved) in that their main land areas are in Europe while pockets of their territories are located on other continents separated from Europe by large bodies of water. Spain, for example, has territories south of the Mediterranean Sea\u2014namely, Ceuta and Melilla\u2014which are parts of Africa and share a border with Morocco. According to the current convention, Georgia and Azerbaijan are transcontinental countries where waterways have been completely replaced by mountains as the divide between continents.  The first recorded usage of Eur\u1e53p\u0113 as a geographic term is in the Homeric Hymn to Delian Apollo, in reference to the western shore of the Aegean Sea. As a name for a part of the known world, it is first used in the 6th century BCE by Anaximander and Hecataeus. Anaximander placed the boundary between Asia and Europe along the Phasis River (the modern Rioni River on the territory of Georgia) in the Caucasus, a convention still followed by Herodotus in the 5th century BCE.[31] Herodotus mentioned that the world had been divided by unknown persons into three parts\u2014Europe, Asia, and Libya (Africa)\u2014with the Nile and the Phasis forming their boundaries\u2014though he also states that some considered the River Don, rather than the Phasis, as the boundary between Europe and Asia.[32] Europe's eastern frontier was defined in the 1st century by geographer Strabo at the River Don.[33] The Book of Jubilees described the continents as the lands given by Noah to his three sons; Europe was defined as stretching from the Pillars of Hercules at the Strait of Gibraltar, separating it from Northwest Africa, to the Don, separating it from Asia.[34]  The convention received by the Middle Ages and surviving into modern usage is that of the Roman era used by Roman-era authors such as Posidonius,[35] Strabo[36] and Ptolemy,[37] who took the Tanais (the modern Don River) as the boundary.  The Roman Empire did not attach a strong identity to the concept of continental divisions. However, following the fall of the Western Roman Empire, the culture that developed in its place, linked to Latin and the Catholic church, began to associate itself with the concept of \"Europe\".[38] The term \"Europe\" is first used for a cultural sphere in the Carolingian Renaissance of the 9th century. From that time, the term designated the sphere of influence of the Western Church, as opposed to both the Eastern Orthodox churches and to the Islamic world.  A cultural definition of Europe as the lands of Latin Christendom coalesced in the 8th century, signifying the new cultural condominium created through the confluence of Germanic traditions and Christian-Latin culture, defined partly in contrast with Byzantium and Islam, and limited to northern Iberia, the British Isles, France, Christianised western Germany, the Alpine regions and northern and central Italy.[39][40] The concept is one of the lasting legacies of the Carolingian Renaissance: Europa often[dubious  \u2013 discuss] figures in the letters of Charlemagne's court scholar, Alcuin.[41] The transition of Europe to being a cultural term as well as a geographic one led to the borders of Europe being affected by cultural considerations in the East, especially relating to areas under Byzantine, Ottoman, and Russian influence. Such questions were affected by the positive connotations associated with the term Europe by its users. Such cultural considerations were not applied to the Americas, despite their conquest and settlement by European states. Instead, the concept of \"Western civilization\" emerged as a way of grouping together Europe and these colonies.[42]  The question of defining a precise eastern boundary of Europe arises in the Early Modern period, as the eastern extension of Muscovy began to include North Asia. Throughout the Middle Ages and into the 18th century, the traditional division of the landmass of Eurasia into two continents, Europe and Asia, followed Ptolemy, with the boundary following the Turkish Straits, the Black Sea, the Kerch Strait, the Sea of Azov and the Don (ancient Tanais). But maps produced during the 16th to 18th centuries tended to differ in how to continue the boundary beyond the Don bend at Kalach-na-Donu (where it is closest to the Volga, now joined with it by the Volga\u2013Don Canal), into territory not described in any detail by the ancient geographers.  Around 1715, Herman Moll produced a map showing the northern part of the Ob River and the Irtysh River, a major tributary of the Ob, as components of a series of partly-joined waterways taking the boundary between Europe and Asia from the Turkish Straits, and the Don River all the way to the Arctic Ocean. In 1721, he produced a more up to date map that was easier to read. However, his proposal to adhere to major rivers as the line of demarcation was never taken up by other geographers who were beginning to move away from the idea of water boundaries as the only legitimate divides between Europe and Asia.  Four years later, in 1725, Philip Johan von Strahlenberg was the first to depart from the classical Don boundary. He drew a new line along the Volga, following the Volga north until the Samara Bend, along Obshchy Syrt (the drainage divide between the Volga and Ural Rivers), then north and east along the latter waterway to its source in the Ural Mountains. At this point he proposed that mountain ranges could be included as boundaries between continents as alternatives to nearby waterways. Accordingly, he drew the new boundary north along Ural Mountains rather than the nearby and parallel running Ob and Irtysh rivers.[43] This was endorsed by the Russian Empire and introduced the convention that would eventually become commonly accepted. However, this did not come without criticism. Voltaire, writing in 1760 about Peter the Great's efforts to make Russia more European, ignored the whole boundary question with his claim that neither Russia, Scandinavia, northern Germany, nor Poland were fully part of Europe.[38] Since then, many modern analytical geographers like Halford Mackinder have declared that they see little validity in the Ural Mountains as a boundary between continents.[44]  The mapmakers continued to differ on the boundary between the lower Don and Samara well into the 19th century. The 1745 atlas published by the Russian Academy of Sciences has the boundary follow the Don beyond Kalach as far as Serafimovich before cutting north towards Arkhangelsk, while other 18th- to 19th-century mapmakers such as John Cary followed Strahlenberg's prescription. To the south, the Kuma\u2013Manych Depression was identified c.\u20091773 by a German naturalist, Peter Simon Pallas, as a valley that once connected the Black Sea and the Caspian Sea,[45][46] and subsequently was proposed as a natural boundary between continents.  By the mid-19th century, there were three main conventions, one following the Don, the Volga\u2013Don Canal and the Volga, the other following the Kuma\u2013Manych Depression to the Caspian and then the Ural River, and the third abandoning the Don altogether, following the Greater Caucasus watershed to the Caspian. The question was still treated as a \"controversy\" in geographical literature of the 1860s, with Douglas Freshfield advocating the Caucasus crest boundary as the \"best possible\", citing support from various \"modern geographers\".[47]  In Russia and the Soviet Union, the boundary along the Kuma\u2013Manych Depression was the most commonly used as early as 1906.[48] In 1958, the Soviet Geographical Society formally recommended that the boundary between the Europe and Asia be drawn in textbooks from Baydaratskaya Bay, on the Kara Sea, along the eastern foot of Ural Mountains, then following the Ural River until the Mugodzhar Hills, and then the Emba River; and Kuma\u2013Manych Depression,[49] thus placing the Caucasus entirely in Asia and the Urals entirely in Europe.[50] The Flora Europaea adopted a boundary along the Terek and Kuban rivers, so southwards from the Kuma and the Manych, but still with the Caucasus entirely in Asia.[51][52] However, most geographers in the Soviet Union favoured the boundary along the Caucasus crest,[53] and this became the common convention in the later 20th century, although the Kuma\u2013Manych boundary remained in use in some 20th-century maps.  Some view the separation of Eurasia into Asia and Europe as a residue of Eurocentrism: \"In physical, cultural and historical diversity, China and India are comparable to the entire European landmass, not to a single European country. [...].\"[54]  During the 2.5 million years of the Pleistocene, numerous cold phases called glacials (Quaternary ice age), or significant advances of continental ice sheets, in Europe and North America, occurred at intervals of approximately 40,000 to 100,000 years. The long glacial periods were separated by more temperate and shorter interglacials which lasted about 10,000\u201315,000 years. The last cold episode of the last glacial period ended about 10,000 years ago.[56] Earth is currently in an interglacial period of the Quaternary, called the Holocene.[57]  Homo erectus georgicus, which lived roughly 1.8 million years ago in Georgia, is the earliest hominin to have been discovered in Europe.[58] Other hominin remains, dating back roughly 1 million years, have been discovered in Atapuerca, Spain.[59] Neanderthal man (named after the Neandertal valley in Germany) appeared in Europe 150,000 years ago (115,000 years ago it is found already in the territory of present-day Poland[60]) and disappeared from the fossil record about 40,000 years ago,[61] with their final refuge being the Iberian Peninsula. The Neanderthals were supplanted by modern humans (Cro-Magnons), who appeared in Europe around 43,000 to 40,000 years ago.[62] Homo sapiens arrived in Europe around 54,000 years ago, some 10,000 years earlier than previously thought.[63] The earliest sites in Europe dated 48,000 years ago are Riparo Mochi (Italy), Geissenkl\u00f6sterle (Germany) and Isturitz (France).[64][65]  The European Neolithic period\u2014marked by the cultivation of crops and the raising of livestock, increased numbers of settlements and the widespread use of pottery\u2014began around 7000 BCE in Greece and the Balkans, probably influenced by earlier farming practices in Anatolia and the Near East.[66] It spread from the Balkans along the valleys of the Danube and the Rhine (Linear Pottery culture), and along the Mediterranean coast (Cardial culture). Between 4500 and 3000 BCE, these central European neolithic cultures developed further to the west and the north, transmitting newly acquired skills in producing copper artifacts. In Western Europe the Neolithic period was characterised not by large agricultural settlements but by field monuments, such as causewayed enclosures, burial mounds and megalithic tombs.[67] The Corded Ware cultural horizon flourished at the transition from the Neolithic to the Chalcolithic. During this period giant megalithic monuments, such as the Megalithic Temples of Malta and Stonehenge, were constructed throughout Western and Southern Europe.[68][69]  The modern native populations of Europe largely descend from three distinct lineages:[70] Mesolithic hunter-gatherers, descended from populations associated with the Paleolithic Epigravettian culture;[55] Neolithic Early European Farmers who migrated from Anatolia during the Neolithic Revolution 9,000 years ago;[71] and Yamnaya Steppe herders who expanded into Europe from the Pontic\u2013Caspian steppe of Ukraine and southern Russia in the context of Indo-European migrations 5,000 years ago.[70][72] The European Bronze Age began c. 3200 BCE in Greece with the Minoan civilisation on Crete, the first advanced civilisation in Europe.[73] The Minoans were followed by the Myceneans, who collapsed suddenly around 1200 BCE, ushering the European Iron Age.[74] Iron Age colonisation by the Greeks and Phoenicians gave rise to early Mediterranean cities. Early Iron Age Italy and Greece from around the 8th century BCE gradually gave rise to historical Classical antiquity, whose beginning is sometimes dated to 776 BCE, the year of the first Olympic Games.[75]  Ancient Greece was the founding culture of Western civilisation. Western democratic and rationalist culture are often attributed to Ancient Greece.[76] The Greek city-state, the polis, was the fundamental political unit of classical Greece.[76] In 508 BCE, Cleisthenes instituted the world's first democratic system of government in Athens.[77] The Greek political ideals were rediscovered in the late 18th century by European philosophers and idealists. Greece also generated many cultural contributions: in philosophy, humanism and rationalism under Aristotle, Socrates and Plato; in history with Herodotus and Thucydides; in dramatic and narrative verse, starting with the epic poems of Homer;[78] in drama with Sophocles and Euripides; in medicine with Hippocrates and Galen; and in science with Pythagoras, Euclid and Archimedes.[79][80][81] In the course of the 5th century BCE, several of the Greek city states would ultimately check the Achaemenid Persian advance in Europe through the Greco-Persian Wars, considered a pivotal moment in world history,[82] as the 50 years of peace that followed are known as Golden Age of Athens, the seminal period of ancient Greece that laid many of the foundations of Western civilisation.  Greece was followed by Rome, which left its mark on law, politics, language, engineering, architecture, government and many more key aspects in western civilisation.[76] By 200 BCE, Rome had conquered Italy and over the following two centuries it conquered Greece and Hispania (Spain and Portugal), the North African coast, much of the Middle East, Gaul (France and Belgium) and Britannia (England and Wales).  Expanding from their base in central Italy beginning in the third century BCE, the Romans gradually expanded to eventually rule the entire Mediterranean Basin and Western Europe by the turn of the millennium. The Roman Republic ended in 27 BCE, when Augustus proclaimed the Roman Empire. The two centuries that followed are known as the pax romana, a period of unprecedented peace, prosperity and political stability in most of Europe.[83] The empire continued to expand under emperors such as Antoninus Pius and Marcus Aurelius, who spent time on the Empire's northern border fighting Germanic, Pictish and Scottish tribes.[84][85] Christianity was legalised by Constantine I in 313 CE after three centuries of imperial persecution. Constantine also permanently moved the capital of the empire from Rome to the city of Byzantium (modern-day Istanbul) which was renamed Constantinople in his honour in 330 CE. Christianity became the sole official religion of the empire in 380 CE and in 391\u2013392 CE, the emperor Theodosius outlawed pagan religions.[86] This is sometimes considered to mark the end of antiquity; alternatively antiquity is considered to end with the fall of the Western Roman Empire in 476 CE; the closure of the pagan Platonic Academy of Athens in 529 CE;[87] or the rise of Islam in the early 7th century CE. During most of its existence, the Byzantine Empire was one of the most powerful economic, cultural, and military forces in Europe.[88]  During the decline of the Roman Empire, Europe entered a long period of change arising from what historians call the \"Age of Migrations\". There were numerous invasions and migrations amongst the Ostrogoths, Visigoths, Goths, Vandals, Huns, Franks, Angles, Saxons, Slavs, Avars, Bulgars and, later on, the Vikings, Pechenegs, Cumans and Magyars.[83] Renaissance thinkers such as Petrarch would later refer to this as the \"Dark Ages\".[89]  Isolated monastic communities were the only places to safeguard and compile written knowledge accumulated previously; apart from this very few written records survive and much literature, philosophy, mathematics and other thinking from the classical period disappeared from Western Europe, though they were preserved in the east, in the Byzantine Empire.[90]  While the Roman empire in the west continued to decline, Roman traditions and the Roman state remained strong in the predominantly Greek-speaking Eastern Roman Empire, also known as the Byzantine Empire. During most of its existence, the Byzantine Empire was the most powerful economic, cultural and military force in Europe. Emperor Justinian I presided over Constantinople's first golden age: he established a legal code that forms the basis of many modern legal systems, funded the construction of the Hagia Sophia and brought the Christian church under state control.[91]  From the 7th century onwards, as the Byzantines and neighbouring Sasanid Persians were severely weakened due to the protracted, centuries-lasting and frequent Byzantine\u2013Sasanian wars, the Muslim Arabs began to make inroads into historically Roman territory, taking the Levant and North Africa and making inroads into Asia Minor. In the mid-7th century, following the Muslim conquest of Persia, Islam penetrated into the Caucasus region.[92] Over the next centuries Muslim forces took Cyprus, Malta, Crete, Sicily and parts of southern Italy.[93] Between 711 and 720, most of the lands of the Visigothic Kingdom of Iberia was brought under Muslim rule\u2014save for small areas in the north-west (Asturias) and largely Basque regions in the Pyrenees. This territory, under the Arabic name Al-Andalus, became part of the expanding Umayyad Caliphate. The unsuccessful second siege of Constantinople (717) weakened the Umayyad dynasty and reduced their prestige. The Umayyads were then defeated by the Frankish leader Charles Martel at the Battle of Poitiers in 732, which ended their northward advance. In the remote regions of north-western Iberia and the middle Pyrenees the power of the Muslims in the south was scarcely felt. It was here that the foundations of the Christian kingdoms of Asturias, Leon and Galicia were laid and from where the reconquest of the Iberian Peninsula would start. However, no coordinated attempt would be made to drive the Moors out. The Christian kingdoms were mainly focused on their own internal power struggles. As a result, the Reconquista took the greater part of eight hundred years, in which period a long list of Alfonsos, Sanchos, Ordo\u00f1os, Ramiros, Fernandos and Bermudos would be fighting their Christian rivals as much as the Muslim invaders.  During the Dark Ages, the Western Roman Empire fell under the control of various tribes. The Germanic and Slav tribes established their domains over Western and Eastern Europe, respectively.[94] Eventually the Frankish tribes were united under Clovis\u00a0I.[95] Charlemagne, a Frankish king of the Carolingian dynasty who had conquered most of Western Europe, was anointed \"Holy Roman Emperor\" by the Pope in 800. This led in 962 to the founding of the Holy Roman Empire, which eventually became centred in the German principalities of central Europe.[96]  East Central Europe saw the creation of the first Slavic states and the adoption of Christianity (c. 1000\u00a0CE). The powerful West Slavic state of Great Moravia spread its territory all the way south to the Balkans, reaching its largest territorial extent under Svatopluk I and causing a series of armed conflicts with East Francia. Further south, the first South Slavic states emerged in the late 7th and 8th century and adopted Christianity: the First Bulgarian Empire, the Serbian Principality (later Kingdom and Empire) and the Duchy of Croatia (later Kingdom of Croatia). To the East, Kievan Rus' expanded from its capital in Kiev to become the largest state in Europe by the 10th century. In 988, Vladimir the Great adopted Orthodox Christianity as the religion of state.[97][98] Further East, Volga Bulgaria became an Islamic state in the 10th century, but was eventually absorbed into Russia several centuries later.[99]  The period between the year 1000 and 1250 is known as the High Middle Ages, followed by the Late Middle Ages until c. 1500.  During the High Middle Ages the population of Europe experienced significant growth, culminating in the Renaissance of the 12th century. Economic growth, together with the lack of safety on the mainland trading routes, made possible the development of major commercial routes along the coast of the Mediterranean and Baltic Seas. The growing wealth and independence acquired by some coastal cities gave the Maritime Republics a leading role in the European scene.  The Middle Ages on the mainland were dominated by the two upper echelons of the social structure: the nobility and the clergy. Feudalism developed in France in the Early Middle Ages, and soon spread throughout Europe.[102] A struggle for influence between the nobility and the monarchy in England led to the writing of Magna Carta and the establishment of a parliament.[103] The primary source of culture in this period came from the Roman Catholic Church. Through monasteries and cathedral schools, the Church was responsible for education in much of Europe.[102]  The Papacy reached the height of its power during the High Middle Ages. An East-West Schism in 1054 split the former Roman Empire religiously, with the Eastern Orthodox Church in the Byzantine Empire and the Roman Catholic Church in the former Western Roman Empire. In 1095 Pope Urban II called for a crusade against Muslims occupying Jerusalem and the Holy Land.[104] In Europe itself, the Church organised the Inquisition against heretics. In the Iberian Peninsula, the Reconquista concluded with the fall of Granada in 1492, ending over seven centuries of Islamic rule in the south-western peninsula.[105]  In the east, a resurgent Byzantine Empire recaptured Crete and Cyprus from the Muslims, and reconquered the Balkans. Constantinople was the largest and wealthiest city in Europe from the 9th to the 12th centuries, with a population of approximately 400,000.[106] The Empire was weakened following the defeat at Manzikert, and was weakened considerably by the sack of Constantinople in 1204, during the Fourth Crusade.[107][108][109][110][111][112][113][114][115] Although it would recover Constantinople in 1261, Byzantium fell in 1453 when Constantinople was taken by the Ottoman Empire.[116][117][118]  In the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Pechenegs and the Cuman-Kipchaks, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north, and temporarily halted the expansion of the Rus' state to the south and east.[119] Like many other parts of Eurasia, these territories were overrun by the Mongols.[120] The invaders, who became known as Tatars, were mostly Turkic-speaking peoples under Mongol suzerainty. They established the state of the Golden Horde with headquarters in Crimea, which later adopted Islam as a religion, and ruled over modern-day southern and central Russia for more than three centuries.[121][122] After the collapse of Mongol dominions, the first Romanian states (principalities) emerged in the 14th century: Moldavia and Walachia. Previously, these territories were under the successive control of Pechenegs and Cumans.[123] From the 12th to the 15th centuries, the Grand Duchy of Moscow grew from a small principality under Mongol rule to the largest state in Europe, overthrowing the Mongols in 1480, and eventually becoming the Tsardom of Russia. The state was consolidated under Ivan III the Great and Ivan the Terrible, steadily expanding to the east and south over the next centuries.  The Great Famine of 1315\u20131317 was the first crisis that would strike Europe in the late Middle Ages.[124] The period between 1348 and 1420 witnessed the heaviest loss. The population of France was reduced by half.[125][126] Medieval Britain was afflicted by 95 famines,[127] and France suffered the effects of 75 or more in the same period.[128] Europe was devastated in the mid-14th century by the Black Death, one of the most deadly pandemics in human history which killed an estimated 25\u00a0million people in Europe alone\u2014a third of the European population at the time.[129]  The plague had a devastating effect on Europe's social structure; it induced people to live for the moment as illustrated by Giovanni Boccaccio in The Decameron (1353). It was a serious blow to the Roman Catholic Church and led to increased persecution of Jews, beggars and lepers.[130] The plague is thought to have returned every generation with varying virulence and mortalities until the 18th century.[131] During this period, more than 100 plague epidemics swept across Europe.[132]  The Renaissance was a period of cultural change originating in Florence, and later spreading to the rest of Europe. The rise of a new humanism was accompanied by the recovery of forgotten classical Greek and Arabic knowledge from monastic libraries, often translated from Arabic into Latin.[133][134][135] The Renaissance spread across Europe between the 14th and 16th centuries: it saw the flowering of art, philosophy, music, and the sciences, under the joint patronage of royalty, the nobility, the Roman Catholic Church and an emerging merchant class.[136][137][138] Patrons in Italy, including the Medici family of Florentine bankers and the Popes in Rome, funded prolific quattrocento and cinquecento artists such as Raphael, Michelangelo and Leonardo da Vinci.[139][140]  Political intrigue within the Church in the mid-14th century caused the Western Schism. During this forty-year period, two popes\u2014one in Avignon and one in Rome\u2014claimed rulership over the Church. Although the schism was eventually healed in 1417, the papacy's spiritual authority had suffered greatly.[141] In the 15th century, Europe started to extend itself beyond its geographic frontiers. Spain and Portugal, the greatest naval powers of the time, took the lead in exploring the world.[142][143] Exploration reached the Southern Hemisphere in the Atlantic and the southern tip of Africa. Christopher Columbus reached the New World in 1492, and Vasco da Gama opened the ocean route to the East linking the Atlantic and Indian Oceans in 1498. The Portuguese-born explorer Ferdinand Magellan reached Asia westward across the Atlantic and the Pacific Oceans in a Spanish expedition, resulting in the first circumnavigation of the globe, completed by the Spaniard Juan Sebasti\u00e1n Elcano (1519\u20131522). Soon after, the Spanish and Portuguese began establishing large global empires in the Americas, Asia, Africa and Oceania.[144] France, the Netherlands and England soon followed in building large colonial empires with vast holdings in Africa, the Americas and Asia. In 1588, a Spanish armada failed to invade England. A year later England tried unsuccessfully to invade Spain, allowing Philip II of Spain to maintain his dominant war capacity in Europe. This English disaster also allowed the Spanish fleet to retain its capability to wage war for the next decades. However, two more Spanish armadas failed to invade England (2nd Spanish Armada and 3rd Spanish Armada).[145][146][147][148]  The Church's power was further weakened by the Protestant Reformation in 1517 when German theologian Martin Luther nailed his Ninety-five Theses criticising the selling of indulgences to the church door. He was subsequently excommunicated in the papal bull Exsurge Domine in 1520 and his followers were condemned in the 1521 Diet of Worms, which divided German princes between Protestant and Roman Catholic faiths.[150] Religious fighting and warfare spread with Protestantism.[151] The plunder of the empires of the Americas allowed Spain to finance religious persecution in Europe for over a century.[152] The Thirty Years War (1618\u20131648) crippled the Holy Roman Empire and devastated much of Germany, killing between 25 and 40 percent of its population.[153] In the aftermath of the Peace of Westphalia, France rose to predominance within Europe.[154] The defeat of the Ottoman Turks at the Battle of Vienna in 1683 marked the historic end of Ottoman expansion into Europe.[155]  The 17th century in Central and parts of Eastern Europe was a period of general decline;[156] the region experienced more than 150 famines in a 200-year period between 1501 and 1700.[157] From the Union of Krewo (1385) east-central Europe was dominated by the Kingdom of Poland and the Grand Duchy of Lithuania. The hegemony of the vast Polish\u2013Lithuanian Commonwealth had ended with the devastation brought by the Second Northern War (Deluge) and subsequent conflicts;[158] the state itself was partitioned and ceased to exist at the end of the 18th century.[159]  From the 15th to 18th centuries, when the disintegrating khanates of the Golden Horde were conquered by Russia, Tatars from the Crimean Khanate frequently raided Eastern Slavic lands to capture slaves.[160] Further east, the Nogai Horde and Kazakh Khanate frequently raided the Slavic-speaking areas of contemporary Russia and Ukraine for hundreds of years, until the Russian expansion and conquest of most of northern Eurasia (i.e. Eastern Europe, Central Asia and Siberia).  The Renaissance and the New Monarchs marked the start of an Age of Discovery, a period of exploration, invention and scientific development.[161] Among the great figures of the Western scientific revolution of the 16th and 17th centuries were Copernicus, Kepler, Galileo and Isaac Newton.[162] According to Peter Barrett, \"It is widely accepted that 'modern science' arose in the Europe of the 17th century (towards the end of the Renaissance), introducing a new understanding of the natural world.\"[133]  The Seven Years' War brought to an end the \"Old System\" of alliances in Europe. Consequently, when the American Revolutionary War turned into a global war between 1778 and 1783, Britain found itself opposed by a strong coalition of European powers, and lacking any substantial ally.[163]  The Age of Enlightenment was a powerful intellectual movement during the 18th century promoting scientific and reason-based thoughts.[164][165][166] Discontent with the aristocracy and clergy's monopoly on political power in France resulted in the French Revolution, and the establishment of the First Republic as a result of which the monarchy and many of the nobility perished during the initial reign of terror.[167] Napoleon Bonaparte rose to power in the aftermath of the French Revolution, and established the First French Empire that, during the Napoleonic Wars, grew to encompass large parts of Europe before collapsing in 1815 with the Battle of Waterloo.[168][169] Napoleonic rule resulted in the further dissemination of the ideals of the French Revolution, including that of the nation state, as well as the widespread adoption of the French models of administration, law and education.[170][171][172] The Congress of Vienna, convened after Napoleon's downfall, established a new balance of power in Europe centred on the five \"Great Powers\": the UK, France, Prussia, Austria and Russia.[173] This balance would remain in place until the Revolutions of 1848, during which liberal uprisings affected all of Europe except for Russia and the UK. These revolutions were eventually put down by conservative elements and few reforms resulted.[174] The year 1859 saw the unification of Romania, as a nation state, from smaller principalities. In 1867, the Austro-Hungarian empire was formed; 1871 saw the unifications of both Italy and Germany as nation-states from smaller principalities.[175]  In parallel, the Eastern Question grew more complex ever since the Ottoman defeat in the Russo-Turkish War (1768\u20131774). As the dissolution of the Ottoman Empire seemed imminent, the Great Powers struggled to safeguard their strategic and commercial interests in the Ottoman domains. The Russian Empire stood to benefit from the decline, whereas the Habsburg Empire and Britain perceived the preservation of the Ottoman Empire to be in their best interests. Meanwhile, the Serbian Revolution (1804) and Greek War of Independence (1821) marked the beginning of the end of Ottoman rule in the Balkans, which ended with the Balkan Wars in 1912\u20131913.[176] Formal recognition of the de facto independent principalities of Montenegro, Serbia and Romania ensued at the Congress of Berlin in 1878.  The Industrial Revolution started in Great Britain in the last part of the 18th century and spread throughout Europe. The invention and implementation of new technologies resulted in rapid urban growth, mass employment and the rise of a new working class.[177] Reforms in social and economic spheres followed, including the first laws on child labour, the legalisation of trade unions,[178] and the abolition of slavery.[179] In Britain, the Public Health Act of 1875 was passed, which significantly improved living conditions in many British cities.[180] Europe's population increased from about 100 million in 1700 to 400 million by 1900.[181] The last major famine recorded in Western Europe, the Great Famine of Ireland, caused death and mass emigration of millions of Irish people.[182] In the 19th century, 70\u00a0million people left Europe in migrations to various European colonies abroad and to the United States.[183] The industrial revolution also led to large population growth, and the share of the world population living in Europe reached a peak of slightly above 25% around the year 1913.[184][185]  Two world wars and an economic depression dominated the first half of the 20th century. The First World War was fought between 1914 and 1918. It started when Archduke Franz Ferdinand of Austria was assassinated by the Yugoslav nationalist[186] Gavrilo Princip.[187] Most European nations were drawn into the war, which was fought between the Entente Powers (France, Belgium, Serbia, Portugal, Russia, the United Kingdom, and later Italy, Greece, Romania, and the United States) and the Central Powers (Austria-Hungary, Germany, Bulgaria, and the Ottoman Empire). The war left more than 16\u00a0million civilians and military dead.[188] Over 60\u00a0million European soldiers were mobilised from 1914 to 1918.[189]  Russia was plunged into the Russian Revolution, which threw down the Tsarist monarchy and replaced it with the communist Soviet Union,[190] leading also to the independence of many former Russian governorates, such as Finland, Estonia, Latvia and Lithuania, as new European countries.[191] Austria-Hungary and the Ottoman Empire collapsed and broke up into separate nations, and many other nations had their borders redrawn. The Treaty of Versailles, which officially ended the First World War in 1919, was harsh towards Germany, upon whom it placed full responsibility for the war and imposed heavy sanctions.[192] Excess deaths in Russia over the course of the First World War and the Russian Civil War (including the postwar famine) amounted to a combined total of 18 million.[193] In 1932\u20131933, under Stalin's leadership, confiscations of grain by the Soviet authorities contributed to the second Soviet famine which caused millions of deaths;[194] surviving kulaks were persecuted and many sent to Gulags to do forced labour. Stalin was also responsible for the Great Purge of 1937\u201338 in which the NKVD executed 681,692 people;[195] millions of people were deported and exiled to remote areas of the Soviet Union.[196]  The social revolutions sweeping through Russia also affected other European nations following The Great War: in 1919, with the Weimar Republic in Germany and the First Austrian Republic; in 1922, with Mussolini's one-party fascist government in the Kingdom of Italy and in Atat\u00fcrk's Turkish Republic, adopting the Western alphabet and state secularism. Economic instability, caused in part by debts incurred in the First World War and 'loans' to Germany played havoc in Europe in the late 1920s and 1930s. This, and the Wall Street Crash of 1929, brought about the worldwide Great Depression. Helped by the economic crisis, social instability and the threat of communism, fascist movements developed throughout Europe placing Adolf Hitler in power of what became Nazi Germany.[202][203]  In 1933, Hitler became the leader of Germany and began to work towards his goal of building Greater Germany. Germany re-expanded and took back the Saarland and Rhineland in 1935 and 1936. In 1938, Austria became a part of Germany following the Anschluss. Later that year, following the Munich Agreement signed by Germany, France, the United Kingdom, and Italy, Germany annexed the Sudetenland, which was a part of Czechoslovakia inhabited by ethnic Germans, and in early 1939, the remainder of Czechoslovakia was split into the Protectorate of Bohemia and Moravia, controlled by Germany and the Slovak Republic. At the time, the United Kingdom and France preferred a policy of appeasement.  With tensions mounting between Germany and Poland over the future of Danzig, the Germans turned to the Soviets and signed the Molotov\u2013Ribbentrop Pact, which allowed the Soviets to invade the Baltic states and parts of Poland and Romania. Germany invaded Poland on 1 September 1939, prompting France and the United Kingdom to declare war on Germany on 3 September, opening the European Theatre of the Second World War.[204][205][206] The Soviet invasion of Poland started on 17 September and Poland fell soon thereafter. On 24 September, the Soviet Union attacked the Baltic countries and, on 30 November, Finland, the latter of which was followed by the devastating Winter War for the Red Army.[207] The British hoped to land at Narvik and send troops to aid Finland, but their primary objective in the landing was to encircle Germany and cut the Germans off from Scandinavian resources. Around the same time, Germany moved troops into Denmark. The Phoney War continued.  In May 1940, Germany attacked France through the Low Countries. France capitulated in June 1940. By August, Germany had begun a bombing offensive against the United Kingdom but failed to convince the Britons to give up.[208] In 1941, Germany invaded the Soviet Union in Operation Barbarossa.[209] On 7 December 1941 Japan's attack on Pearl Harbor drew the United States into the conflict as allies of the British Empire, and other allied forces.[210][211]  After the staggering Battle of Stalingrad in 1943, the German offensive in the Soviet Union turned into a continual fallback. The Battle of Kursk, which involved the largest tank battle in history, was the last major German offensive on the Eastern Front. In June 1944, British and American forces invaded France in the D-Day landings, opening a new front against Germany. Berlin finally fell in 1945, ending the Second World War in Europe. The war was the largest and most destructive in human history, with 60\u00a0million dead across the world.[212] More than 40\u00a0million people in Europe had died as a result of the Second World War,[213] including between 11 and 17\u00a0million people who perished during the Holocaust.[214] The Soviet Union lost around 27\u00a0million people (mostly civilians) during the war, about half of all Second World War casualties.[215] By the end of the Second World War, Europe had more than 40\u00a0million refugees.[216][217][218] Several post-war expulsions in Central and Eastern Europe displaced a total of about 20\u00a0million people.[219]  The First World War, and especially the Second World War, diminished the eminence of Western Europe in world affairs. After the Second World War the map of Europe was redrawn at the Yalta Conference and divided into two blocs, the Western countries and the communist Eastern bloc, separated by what was later called by Winston Churchill an \"Iron Curtain\". The United States and Western Europe established the NATO alliance and, later, the Soviet Union and Central Europe established the Warsaw Pact.[220] Particular hot spots after the Second World War were Berlin and Trieste, whereby the Free Territory of Trieste, founded in 1947 with the UN, was dissolved in 1954 and 1975, respectively. The Berlin blockade in 1948 and 1949 and the construction of the Berlin Wall in 1961 were one of the great international crises of the Cold War.[221][222][223]  The two new superpowers, the United States and the Soviet Union, became locked in a fifty-year-long Cold War, centred on nuclear proliferation. At the same time decolonisation, which had already started after the First World War, gradually resulted in the independence of most of the European colonies in Asia and Africa.[15]  In the 1980s the reforms of Mikhail Gorbachev and the Solidarity movement in Poland weakened the previously rigid communist system. The opening of the Iron Curtain at the Pan-European Picnic then set in motion a peaceful chain reaction, at the end of which the Eastern bloc, the Warsaw Pact and other communist states collapsed, and the Cold War ended.[225][226][227] Germany was reunited, after the symbolic fall of the Berlin Wall in 1989 and the maps of Central and Eastern Europe were redrawn once more.[228] This made old previously interrupted cultural and economic relationships possible, and previously isolated cities such as Berlin, Prague, Vienna, Budapest and Trieste were now again in the centre of Europe.[202][229][230][231]  European integration also grew after the Second World War. In 1949 the Council of Europe was founded, following a speech by Sir Winston Churchill, with the idea of unifying Europe[16] to achieve common goals. It includes all European states except for Belarus, Russia,[232] and Vatican City. The Treaty of Rome in 1957 established the European Economic Community between six Western European states with the goal of a unified economic policy and common market.[233] In 1967 the EEC, European Coal and Steel Community, and Euratom formed the European Community, which in 1993 became the European Union. The EU established a parliament, court and central bank, and introduced the euro as a unified currency.[234] Between 2004 and 2013, more Central European countries began joining, expanding the EU to 28 European countries and once more making Europe a major economical and political centre of power.[235] However, the United Kingdom withdrew from the EU on 31 January 2020, as a result of a June 2016 referendum on EU membership.[236] The Russo-Ukrainian conflict, which has been ongoing since 2014, steeply escalated when Russia launched a full-scale invasion of Ukraine on 24 February 2022, marking the largest humanitarian and refugee crisis in Europe since the Second World War[237] and the Yugoslav Wars.[238]  Europe makes up the western fifth of the Eurasian landmass.[28] It has a higher ratio of coast to landmass than any other continent or subcontinent.[239] Its maritime borders consist of the Arctic Ocean to the north, the Atlantic Ocean to the west and the Mediterranean, Black and Caspian Seas to the south.[240] Land relief in Europe shows great variation within relatively small areas. The southern regions are more mountainous, while moving north the terrain descends from the high Alps, Pyrenees and Carpathians, through hilly uplands, into broad, low northern plains, which are vast in the east. This extended lowland is known as the Great European Plain and at its heart lies the North German Plain. An arc of uplands also exists along the north-western seaboard, which begins in the western parts of the islands of Britain and Ireland, and then continues along the mountainous, fjord-cut spine of Norway.  This description is simplified. Subregions such as the Iberian Peninsula and the Italian Peninsula contain their own complex features, as does mainland Central Europe itself, where the relief contains many plateaus, river valleys and basins that complicate the general trend. Sub-regions like Iceland, Britain and Ireland are special cases. The former is a land unto itself in the northern ocean that is counted as part of Europe, while the latter are upland areas that were once joined to the mainland until rising sea levels cut them off.  Europe lies mainly in the temperate climate zone of the northern hemisphere, where the prevailing wind direction is from the west. The climate is milder in comparison to other areas of the same latitude around the globe due to the influence of the Gulf Stream, an ocean current which carries warm water from the Gulf of Mexico across the Atlantic ocean to Europe.[241] The Gulf Stream is nicknamed \"Europe's central heating\", because it makes Europe's climate warmer and wetter than it would otherwise be. The Gulf Stream not only carries warm water to Europe's coast but also warms up the prevailing westerly winds that blow across the continent from the Atlantic Ocean.  Therefore, the average temperature throughout the year of Aveiro is 16\u00a0\u00b0C (61\u00a0\u00b0F), while it is only 13\u00a0\u00b0C (55\u00a0\u00b0F) in New York City which is almost on the same latitude, bordering the same ocean. Berlin, Germany; Calgary, Canada; and Irkutsk, in far south-eastern Russia, lie on around the same latitude; January temperatures in Berlin average around 8\u00a0\u00b0C (14\u00a0\u00b0F) higher than those in Calgary and they are almost 22\u00a0\u00b0C (40\u00a0\u00b0F) higher than average temperatures in Irkutsk.[241]  The large water masses of the Mediterranean Sea, which equalise the temperatures on an annual and daily average, are also of particular importance. The water of the Mediterranean extends from the Sahara desert to the Alpine arc in its northernmost part of the Adriatic Sea near Trieste.[242]  In general, Europe is not just colder towards the north compared to the south, but it also gets colder from the west towards the east. The climate is more oceanic in the west and less so in the east. This can be illustrated by the following table of average temperatures at locations roughly following the 64th, 60th, 55th, 50th, 45th and 40th latitudes. None of them is located at high altitude; most of them are close to the sea.  [244] It is notable how the average temperatures for the coldest month, as well as the annual average temperatures, drop from the west to the east. For instance, Edinburgh is warmer than Belgrade during the coldest month of the year, although Belgrade is around 10\u00b0 of latitude farther south.  The geological history of Europe traces back to the formation of the Baltic Shield (Fennoscandia) and the Sarmatian craton, both around 2.25\u00a0billion years ago, followed by the Volgo\u2013Uralia shield, the three together leading to the East European craton (\u2248 Baltica) which became a part of the supercontinent Columbia. Around 1.1\u00a0billion years ago, Baltica and Arctica (as part of the Laurentia block) became joined to Rodinia, later resplitting around 550\u00a0million years ago to reform as Baltica. Around 440\u00a0million years ago Euramerica was formed from Baltica and Laurentia; a further joining with Gondwana then leading to the formation of Pangea. Around 190\u00a0million years ago, Gondwana and Laurasia split apart due to the widening of the Atlantic Ocean. Finally and very soon afterwards, Laurasia itself split up again, into Laurentia (North America) and the Eurasian continent. The land connection between the two persisted for a considerable time, via Greenland, leading to interchange of animal species. From around 50\u00a0million years ago, rising and falling sea levels have determined the actual shape of Europe and its connections with continents such as Asia. Europe's present shape dates to the late Tertiary period about five million years ago.[250]  The geology of Europe is hugely varied and complex and gives rise to the wide variety of landscapes found across the continent, from the Scottish Highlands to the rolling plains of Hungary.[251] Europe's most significant feature is the dichotomy between highland and mountainous Southern Europe and a vast, partially underwater, northern plain ranging from Ireland in the west to the Ural Mountains in the east. These two halves are separated by the mountain chains of the Pyrenees and Alps\/Carpathians. The northern plains are delimited in the west by the Scandinavian Mountains and the mountainous parts of the British Isles. Major shallow water bodies submerging parts of the northern plains are the Celtic Sea, the North Sea, the Baltic Sea complex and Barents Sea.  The northern plain contains the old geological continent of Baltica and so may be regarded geologically as the \"main continent\", while peripheral highlands and mountainous regions in the south and west constitute fragments from various other geological continents. Most of the older geology of western Europe existed as part of the ancient microcontinent Avalonia.  Having lived side by side with agricultural peoples for millennia, Europe's animals and plants have been profoundly affected by the presence and activities of humans. With the exception of Fennoscandia and northern Russia, few areas of untouched wilderness are currently found in Europe, except for various national parks.  The main natural vegetation cover in Europe is mixed forest. The conditions for growth are very favourable. In the north, the Gulf Stream and North Atlantic Drift warm the continent. Southern Europe has a warm but mild climate. There are frequent summer droughts in this region. Mountain ridges also affect the conditions. Some of these, such as the Alps and the Pyrenees, are oriented east\u2013west and allow the wind to carry large masses of water from the ocean in the interior. Others are oriented south\u2013north (Scandinavian Mountains, Dinarides, Carpathians, Apennines) and because the rain falls primarily on the side of mountains that is oriented towards the sea, forests grow well on this side, while on the other side, the conditions are much less favourable. Few corners of mainland Europe have not been grazed by livestock at some point in time, and the cutting down of the preagricultural forest habitat caused disruption to the original plant and animal ecosystems.  Possibly 80 to 90 percent of Europe was once covered by forest.[252] It stretched from the Mediterranean Sea to the Arctic Ocean. Although over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the broadleaf and mixed forests, taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European forest dwelling species which require a mixture of tree species and diverse forest structure. The amount of natural forest in Western Europe is just 2\u20133% or less, while in its Western Russia its 5\u201310%. The European country with the smallest percentage of forested area is Iceland (1%), while the most forested country is Finland (77%).[253]  In temperate Europe, mixed forest with both broadleaf and coniferous trees dominate. The most important species in central and western Europe are beech and oak. In the north, the taiga is a mixed spruce\u2013pine\u2013birch forest; further north within Russia and extreme northern Scandinavia, the taiga gives way to tundra as the Arctic is approached. In the Mediterranean, many olive trees have been planted, which are very well adapted to its arid climate; Mediterranean Cypress is also widely planted in southern Europe. The semi-arid Mediterranean region hosts much scrub forest. A narrow east\u2013west tongue of Eurasian grassland (the steppe) extends westwards from Ukraine and southern Russia and ends in Hungary and traverses into taiga to the north.  Glaciation during the most recent ice age and the presence of humans affected the distribution of European fauna. As for the animals, in many parts of Europe most large animals and top predator species have been hunted to extinction. The woolly mammoth was extinct before the end of the Neolithic period. Today wolves (carnivores) and bears (omnivores) are endangered. Once they were found in most parts of Europe. However, deforestation and hunting caused these animals to withdraw further and further. By the Middle Ages the bears' habitats were limited to more or less inaccessible mountains with sufficient forest cover. Today, the brown bear lives primarily in the Balkan peninsula, Scandinavia and Russia; a small number also persist in other countries across Europe (Austria, Pyrenees etc.), but in these areas brown bear populations are fragmented and marginalised because of the destruction of their habitat. In addition, polar bears may be found on Svalbard, a Norwegian archipelago far north of Scandinavia. The wolf, the second-largest predator in Europe after the brown bear, can be found primarily in Central and Eastern Europe and in the Balkans, with a handful of packs in pockets of Western Europe (Scandinavia, Spain, etc.).  Other carnivores include the European wildcat, red fox and arctic fox, the golden jackal, different species of martens, the European hedgehog, different species of reptiles (like snakes such as vipers and grass snakes) and amphibians, as well as different birds (owls, hawks and other birds of prey).  Important European herbivores are snails, larvae, fish, different birds and mammals, like rodents, deer and roe deer, boars and living in the mountains, marmots, steinbocks, chamois among others. A number of insects, such as the small tortoiseshell butterfly, add to the biodiversity.[256]  Sea creatures are also an important part of European flora and fauna. The sea flora is mainly phytoplankton. Important animals that live in European seas are zooplankton, molluscs, echinoderms, different crustaceans, squids and octopuses, fish, dolphins and whales.  Biodiversity is protected in Europe through the Council of Europe's Bern Convention, which has also been signed by the European Community as well as non-European states.    The political map of Europe is substantially derived from the re-organisation of Europe following the Napoleonic Wars in 1815. The prevalent form of government in Europe is parliamentary democracy, in most cases in the form of Republic; in 1815, the prevalent form of government was still the Monarchy. Europe's remaining eleven monarchies[257] are constitutional.  European integration is the process of political, legal, economic (and in some cases social and cultural) integration of European states as it has been pursued by the powers sponsoring the Council of Europe since the end of the Second World War. The European Union has been the focus of economic integration on the continent since its foundation in 1993. More recently, the Eurasian Economic Union has been established as a counterpart comprising former Soviet states.  27 European states are members of the politico-economic European Union, 26 of the border-free Schengen Area and 20 of the monetary union Eurozone. Among the smaller European organisations are the Nordic Council, the Benelux, the Baltic Assembly and the Visegr\u00e1d Group.  The least democratic countries in Europe are Belarus, Russia and Turkey in 2024 according to the V-Dem Democracy indices.[258]  This list includes all internationally recognised sovereign countries falling even partially under any common geographical or political definitions of Europe.  Within the above-mentioned states are several de facto independent countries with limited to no international recognition. None of them are members of the UN:  Several dependencies and similar territories with broad autonomy are also found within or close to Europe. This includes \u00c5land (an autonomous county of Finland), two autonomous territories of the Kingdom of Denmark (other than Denmark proper), three Crown Dependencies and two British Overseas Territories. Svalbard is also included due to its unique status within Norway, although it is not autonomous. Not included are the three countries of the United Kingdom with devolved powers and the two Autonomous Regions of Portugal, which despite having a unique degree of autonomy, are not largely self-governing in matters other than international affairs. Areas with little more than a unique tax status, such as the Canary Islands and Heligoland, are also not included for this reason.  As a continent, the economy of Europe is currently the largest on Earth and it is the richest region as measured by assets under management with over $32.7\u00a0trillion compared to North America's $27.1\u00a0trillion in 2008.[259] In 2009 Europe remained the wealthiest region. Its $37.1 trillion in assets under management represented one-third of the world's wealth. It was one of several regions where wealth surpassed its precrisis year-end peak.[260] As with other continents, Europe has a large wealth gap among its countries. The richer states tend to be in the Northwest and West in general, followed by Central Europe, while most economies of Eastern and Southeastern Europe are still reemerging from the collapse of the Soviet Union and the breakup of Yugoslavia.  The model of the Blue Banana was designed as an economic geographic representation of the respective economic power of the regions, which was further developed into the Golden Banana or Blue Star. The trade between East and West, as well as towards Asia, which had been disrupted for a long time by the two world wars, new borders and the Cold War, increased sharply after 1989. In addition, there is new impetus from the Chinese Belt and Road Initiative across the Suez Canal towards Africa and Asia.[261]  The European Union, a political entity composed of 27 European states, comprises the largest single economic area in the world. Nineteen EU countries share the euro as a common currency. Five European countries rank in the top ten of the world's largest national economies in GDP (PPP). This includes (ranks according to the CIA): Germany (6), Russia (7), the United Kingdom (10), France (11) and Italy (13).[262]  Some European countries are much richer than others. The richest in terms of nominal GDP is Monaco with its US$185,829 per capita (2018) and the poorest is Ukraine with its US$3,659 per capita (2019).[263]  As a whole, Europe's GDP per capita is US$21,767 according to a 2016 International Monetary Fund assessment.[264]  Capitalism has been dominant in the Western world since the end of feudalism.[270] From Britain, it gradually spread throughout Europe.[271] The Industrial Revolution started in Europe, specifically the United Kingdom in the late 18th century,[272] and the 19th century saw Western Europe industrialise. Economies were disrupted by the First World War, but by the beginning of the Second World War, they had recovered and were having to compete with the growing economic strength of the United States. The Second World War, again, damaged much of Europe's industries.  After the Second World War the economy of the UK was in a state of ruin,[273] and continued to suffer relative economic decline in the following decades.[274] Italy was also in a poor economic condition but regained a high level of growth by the 1950s. West Germany recovered quickly and had doubled production from pre-war levels by the 1950s.[275] France also staged a remarkable comeback enjoying rapid growth and modernisation; later on Spain, under the leadership of Franco, also recovered and the nation recorded huge unprecedented economic growth beginning in the 1960s in what is called the Spanish miracle.[276] The majority of Central and Eastern European states came under the control of the Soviet Union and thus were members of the Council for Mutual Economic Assistance (COMECON).[277]  The states which retained a free-market system were given a large amount of aid by the United States under the Marshall Plan.[278] The western states moved to link their economies together, providing the basis for the EU and increasing cross border trade. This helped them to enjoy rapidly improving economies, while those states in COMECON were struggling in a large part due to the cost of the Cold War. Until 1990, the European Community was expanded from 6 founding members to 12. The emphasis placed on resurrecting the West German economy led to it overtaking the UK as Europe's largest economy.  With the fall of communism in Central and Eastern Europe in 1991, the post-socialist states underwent shock therapy measures to liberalise their economies and implement free market reforms.  After East and West Germany were reunited in 1990, the economy of West Germany struggled as it had to support and largely rebuild the infrastructure of East Germany, while the latter experienced sudden mass unemployment and plummeting of industrial production.  By the millennium change, the EU dominated the economy of Europe, comprising the five largest European economies of the time: Germany, the United Kingdom, France, Italy, and Spain. In 1999, 12 of the 15 members of the EU joined the Eurozone, replacing their national currencies by the euro.  Figures released by Eurostat in 2009 confirmed that the Eurozone had gone into recession in 2008.[280] It impacted much of the region.[281] In 2010, fears of a sovereign debt crisis[282] developed concerning some countries in Europe, especially Greece, Ireland, Spain and Portugal.[283] As a result, measures were taken, especially for Greece, by the leading countries of the Eurozone.[284] The EU-27 unemployment rate was 10.3% in 2012. For those aged 15\u201324 it was 22.4%.[285]  The population of Europe was about 742 million in 2023 according to UN estimates.[2][3] This is slightly more than one ninth of the world's population.[v] The population density of Europe (the number of people per area) is the second highest of any continent, behind Asia. The population of Europe is currently slowly decreasing, by about 0.2% per year,[287] because there are fewer births than deaths. This natural decrease in population is reduced by the fact that more people migrate to Europe from other continents than vice versa.  Southern Europe and Western Europe are the regions with the highest average number of elderly people in the world. In 2021, the percentage of people over 65 years old was 21% in Western Europe and Southern Europe, compared to 19% in all of Europe and 10% in the world.[288] Projections suggest that by 2050 Europe will reach 30%.[289] This is caused by the fact that the population has been having children below replacement level since the 1970s. The United Nations predicts that Europe will decline its population between 2022 and 2050 by \u22127 per cent, without changing immigration movements.[290]  According to a population projection of the UN Population Division, Europe's population may fall to between 680 and 720 million people by 2050, which would be 7% of the world population at that time.[291] Within this context, significant disparities exist between regions in relation to fertility rates. The average number of children per female of child-bearing age is 1.52, far below the replacement rate.[292] The UN predicts a steady population decline in Central and Eastern Europe as a result of emigration and low birth rates.[293]  Pan and Pfeil (2004) count 87 distinct \"peoples of Europe\", of which 33 form the majority population in at least one sovereign state, while the remaining 54 constitute ethnic minorities.[294]  Europe is home to the highest number of migrants of all global regions at nearly 87 million people in 2020, according to the International Organisation for Migration.[295] In 2005, the EU had an overall net gain from immigration of 1.8\u00a0million people. This accounted for almost 85% of Europe's total population growth.[296] In 2021, 827,000 persons were given citizenship of an EU member state, an increase of about 14% compared with 2020.[297] 2.3 million immigrants from non-EU countries entered the EU in 2021.[297]  Early modern emigration from Europe began with Spanish and Portuguese settlers in the 16th century,[298][299] and French and English settlers in the 17th century.[300] But numbers remained relatively small until waves of mass emigration in the 19th century, when millions of poor families left Europe.[301]  Today, large populations of European descent are found on every continent. European ancestry predominates in North America and to a lesser degree in South America (particularly in Uruguay, Argentina, Chile and Brazil, while most of the other Latin American countries also have a considerable population of European origins). Australia and New Zealand have large European-derived populations. Africa has no countries with European-derived majorities (or with the exception of Cape Verde and probably S\u00e3o Tom\u00e9 and Pr\u00edncipe, depending on context), but there are significant minorities, such as the White South Africans in South Africa. In Asia, European-derived populations, specifically Russians, predominate in North Asia and some parts of Northern Kazakhstan.[302]  Europe has about 225 indigenous languages,[303] mostly falling within three Indo-European language groups: the Romance languages, derived from the Latin of the Roman Empire; the Germanic languages, whose ancestor language came from southern Scandinavia; and the Slavic languages.[250] Slavic languages are mostly spoken in Southern, Central and Eastern Europe. Romance languages are spoken primarily in Western and Southern Europe, as well as in Switzerland in Central Europe and Romania and Moldova in Eastern Europe. Germanic languages are spoken in Western, Northern and Central Europe as well as in Gibraltar and Malta in Southern Europe.[250] Languages in adjacent areas show significant overlaps (such as in English, for example). Other Indo-European languages outside the three main groups include the Baltic group (Latvian and Lithuanian), the Celtic group (Irish, Scottish Gaelic, Manx, Welsh, Cornish and Breton[250]), Greek, Armenian and Albanian.  A distinct non-Indo-European family of Uralic languages (Estonian, Finnish, Hungarian, Erzya, Komi, Mari, Moksha and Udmurt) is spoken mainly in Estonia, Finland, Hungary and parts of Russia. Turkic languages include Azerbaijani, Kazakh and Turkish, in addition to smaller languages in Eastern and Southeast Europe (Balkan Gagauz Turkish, Bashkir, Chuvash, Crimean Tatar, Karachay-Balkar, Kumyk, Nogai and Tatar). Kartvelian languages (Georgian, Mingrelian and Svan) are spoken primarily in Georgia. Two other language families reside in the North Caucasus (termed Northeast Caucasian, most notably including Chechen, Avar and Lezgin; and Northwest Caucasian, most notably including Adyghe). Maltese is the only Semitic language that is official within the EU, while Basque is the only European language isolate.  Multilingualism and the protection of regional and minority languages are recognised political goals in Europe today. The Council of Europe Framework Convention for the Protection of National Minorities and the Council of Europe's European Charter for Regional or Minority Languages set up a legal framework for language rights in Europe.  Religion in Europe according to the Global Religious Landscape survey by the Pew Forum, 2016[8]  The largest religion in Europe is Christianity, with 76.2% of Europeans considering themselves Christians,[304][305] including Catholic, Eastern Orthodox and various Protestant denominations. Among Protestants, the most popular are Lutheranism, Anglicanism and the Reformed faith. Smaller Protestant denominations include Anabaptists as well as denominations centered in the United States such as Pentecostalism, Methodism, and Evangelicalism. Although Christianity originated in the Middle East, its centre of mass shifted to Europe when it became the official religion of the Roman Empire in the late 4th century. Christianity played a prominent role in the development of the European culture and identity.[306][307][308] Today, a bit over 25% of the world's Christians live in Europe.[309]  Islam is the second most popular religion in Europe. Over 25 million, or roughly 5% of the population, adhere to it.[310] In Albania and Bosnia and Herzegovina, two countries in the Balkan peninsula in Southeastern Europe, Islam instead of Christianity is the majority religion. This is also the case in Turkey and in certain parts of Russia, as well as in Azerbaijan and Kazakhstan, all of which are at the border to Asia.[310] Many countries in Europe are home to a sizeable Muslim minority, and immigration to Europe has increased the number of Muslim people in Europe in recent years.  The Jewish population in Europe was about 1.4 million people in 2020 (about 0.2% of the population).[311] There is a long history of Jewish life in Europe, beginning in antiquity. During the late 19th and early 20th centuries, the Russian Empire had the majority of the world's Jews living within its borders.[312] In 1897, according to Russian census of 1897, the total Jewish population of Russia was 5.1 million people, which was 4.13% of total population. Of this total, the vast majority lived within the Pale of Settlement.[313] In 1933, there were about 9.5 million Jewish people in Europe, representing 1.7% of the population,[314] but most were killed, and most of the rest displaced, during The Holocaust.[315][311] In the 21st century, France has the largest Jewish population in Europe, followed by the United Kingdom, Germany and Russia.[8]  Other religions practiced in Europe include Hinduism and Buddhism, which are minority religions, except in Russia's Republic of Kalmykia, where Tibetan Buddhism is the majority religion.  A large and increasing number of people in Europe are irreligious, atheist and agnostic. They are estimated to make up about 18.3% of Europe's population currently.[8]  The three largest urban areas of Europe are Moscow, London and Paris. All have over 10 million residents,[316] and as such have been described as megacities.[317] While Istanbul has the highest total city population, it lies partly in Asia. 64.9% of the residents live on the European side and 35.1% on the Asian side. The next largest cities in order of population are Madrid, Saint Petersburg, Milan, Barcelona, Berlin, and Rome each having over three million residents.[316]  When considering the commuter belts or metropolitan areas within Europe (for which comparable data is available), Moscow covers the largest population, followed in order by Istanbul, London, Paris, Madrid, Milan, Ruhr Area, Saint Petersburg, Rhein-S\u00fcd, Barcelona and Berlin.[318]  \"Europe\" as a cultural concept is substantially derived from the shared heritage of ancient Greece and the Roman Empire and its cultures. The boundaries of Europe were historically understood as those of Christendom (or more specifically Latin Christendom), as established or defended throughout the medieval and early modern history of Europe, especially against Islam, as in the Reconquista and the Ottoman wars in Europe.[319]  This shared cultural heritage is combined by overlapping indigenous national cultures and folklores, roughly divided into Slavic, Latin (Romance) and Germanic, but with several components not part of either of these groups (notably Greek, Basque and Celtic). Historically, special examples with overlapping cultures are Strasbourg with Latin (Romance) and Germanic, or Trieste with Latin, Slavic and Germanic roots. Cultural contacts and mixtures shape a large part of the regional cultures of Europe. Europe is often described as \"maximum cultural diversity with minimal geographical distances\".  Different cultural events are organised in Europe, with the aim of bringing different cultures closer together and raising awareness of their importance, such as the European Capital of Culture, the European Region of Gastronomy, the European Youth Capital and the European Capital of Sport.  Sport in Europe tends to be highly organized with many sports having professional leagues.  In Europe many people are unable to access basic social conditions, which makes it harder for them to thrive and flourish. Access to basic necessities can be compromised, for example 10% of Europeans spend at least 40% of household income on housing. 75 million Europeans feel socially isolated. From the 1980s income inequality has been rising and wage shares have been falling. In 2016, the richest 20% of households earned over five times more than the poorest 20%. Many workers experience stagnant real wages and precarious work is common even for essential workers.[321]  Historical Maps  Africa  Antarctica  Asia  Australia  Europe  North America  South America  Afro-Eurasia  Americas  Eurasia  Oceania "},{"title":"Bailiwick of Guernsey","content":"  in the English Channel\u00a0(red) The Bailiwick of Guernsey (French: Bailliage de Guernesey; Guern\u00e9siais: Bailliage d\u00e9 Guern\u00e9si) is a self-governing British Crown Dependency off the coast of Normandy, France, comprising several of the Channel Islands. It has a total land area of 78 square kilometres (30\u00a0sq\u00a0mi) and an estimated total population of 67,334.  The Channel Islands were part of the Duchy of Normandy, whose dukes became kings of England from 1066. In 1204, as a consequence of the Treaty of Le Goulet, insular Normandy alone remained loyal to the English Crown, leading to a political split from the mainland. Around 1290, the Channel Islands' Governor, Otto de Grandson, split the archipelago into two bailiwicks, establishing those parts other than Jersey as a single Bailiwick of Guernsey.[8]:\u200a21\u200a  The Bailiwick is a parliamentary constitutional monarchy, comprising three separate jurisdictions: Guernsey (incorporating Herm), Alderney and Sark. The Lieutenant Governor is the representative of the British monarch, who remains the head of state. The States of Guernsey is the parliament and government of the whole Bailiwick, though several matters are decided locally by the States of Alderney and by Sark's Chief Pleas. The Bailiff of Guernsey is the civil head of the Bailiwick, and is also president of the States of Guernsey and head of the Bailiwick's judiciary.  The Bailiwick is self-governing and not part of the United Kingdom.[9][10] Its defence and international representation \u2013 as well as certain policy areas, such as nationality law \u2013 are the responsibility of the UK Government, but the Bailiwick still has a separate international identity.[11]  The history of the Bailiwick of Guernsey goes back to 933, when the islands came under the control of William Longsword, having been annexed from the Duchy of Brittany by the Duchy of Normandy. The island of Guernsey and the other Channel Islands formed part of the lands of William the Conqueror. In 1204, France conquered mainland Normandy \u2013 but not the offshore islands of the bailiwick. The islands represent the last remnants of the medieval Duchy of Normandy.[12]  Initially, there was one governor, or co-governors working together, of the islands making up the Channel Islands. The title \"governor\" has changed over the centuries. \"Warden\", \"keeper\", and \"captain\" have previously been used.[13] The bailiff stands in for the Governor, or more recently the Lieutenant Governor, if the latter is absent, for a short term or for longer: for instance during the five years of the German occupation of the Channel Islands. The Lieutenant Governor of Guernsey is the Lieutenant Governor of the Bailiwick of Guernsey and, being the personal representative of the British monarch,[14] has usually had a distinguished military service.[15]  Originally, the local courts in Guernsey were \"fiefs\" with the lord of the manor presiding. Before 1066, a superior court was introduced above the fiefs and below the Eschequier Court in Rouen and comprised the bailiff and four knights; the court heard appeals and tried criminal cases.[16]  Otton de Grandson, then the governor of the Islands, delegated the civil powers to two separate bailiffs for Guernsey and Jersey before he went on crusade to the Holy Land in 1290.[8]:\u200a21\u200a This can be assessed as the date of first creation of the two bailiwicks.  Situated around 49\u00b024\u2032N 2\u00b036\u2032W\ufeff \/ \ufeff49.4\u00b0N 2.6\u00b0W\ufeff \/ 49.4; -2.6, Alderney, Guernsey, Herm, Sark, and some other smaller islands together have a total area of 78\u00a0km2 (30\u00a0sq\u00a0mi) and coastlines of about 50\u00a0km (31\u00a0mi). Elevation varies from sea level to 114\u00a0m (374\u00a0ft) at Le Moulin on Sark.  There are many smaller islands, islets, rocks and reefs in the Bailiwick. Combined with a tidal range of 10 m and fast currents of up to 12 knots, sailing in local waters is dangerous.  The Bailiwick of Guernsey is a separate jurisdiction in itself and is, in turn, also three separate sub-jurisdictions. It does not form part of, and is separate from (but is not independent of, or from) the United Kingdom.[17] The two Bailiwicks of Jersey and Guernsey together make up the Channel Islands.  The islanders have never had formal representation in the House of Commons of the British Parliament,[14] nor the European Parliament.[17] Those islanders who were not somehow qualified and eligible in their own right to register to vote and to vote in the United Kingdom under the Representation of the People Acts as \"overseas voters\", were excluded from the 2016 United Kingdom European Union membership referendum.  Guernsey has an unwritten constitution arising from the Treaty of Paris (1259). When Henry III and the King of France came to terms over the Duchy of Normandy, the Norman mainland fell under the suzerainty of the king of France. The Channel Islands, however, remained loyal to the British crown due to the loyalties of its Seigneurs. However, they were never absorbed into the Kingdom of England by any Act of Union, but exist as \"peculiars of the Crown\".  A unique constitutional position has arisen as successive British monarchs have confirmed the liberties and privileges of the Bailiwick, often referring to the so-called Constitutions of King John, a legendary document supposed to have been granted by King John in the aftermath of 1204. Governments of the Bailiwick have generally tried to avoid testing the limits of the unwritten constitution by avoiding conflict with British governments.  This peculiar political position has often been to the benefit of islanders. Until the 19th century, the Bailiwick was generally exempt from the harsher parts of Westminster legislation while being included in favourable policies, such as protectionist economic policies. England, and later the United Kingdom, passively exploited the strategic benefits of the Channel Islands. For example, the islands were a convenient stop-off point for trade to Gascony.[18]  The bailiwick comprises twelve parishes: Alderney, Sark, and ten on mainland Guernsey (one of which includes Herm). Each parish has a parish church dating from the 11th century, with strong religious control exercised initially by the French Catholic church and for the last 500 years by the English church. Over the years, the religious aspect of the administration of each parish has been reduced in favour of democratically elected douzeniers.  Each jurisdiction has inhabited and uninhabited islands and its own elected government. All three legal jurisdictions need royal assent from the Monarch on its primary legislation, but as of February 29, 2024, certain domestic primary legislation need only the Lieutenant-Governor's assent. Each jurisdiction raises its own taxation,[14] although in 1949 Alderney transferred its rights to Guernsey.  With a population of around 2,200 in 7.8\u00a0km2 (3\u00a0sq\u00a0mi), Alderney has its own parliament, the States of Alderney, which has ten elected members and an elected president.[19]  From 1612, Alderney had a judge appointed, with similar judicial powers to a bailiff, but on 1 January 1949, the island adopted a new constitution, giving up some independence, moving closer to Guernsey, and confirming that it is part of the Bailiwick of Guernsey.[citation needed]  The island of Guernsey has a population of around 63,000 in 62\u00a0km2 (24\u00a0sq\u00a0mi) and forms the legal and administrative centre of the Bailiwick of Guernsey. The parliament of Guernsey and the nearby inhabited islands of Herm, Jethou and Lihou[14] is the States of Guernsey.[19]  Sark has a population of around 600 who live in 2 square miles (5.2\u00a0km2). Its parliament (together with the inhabited island of Brecqhou)[14] is the Chief Pleas of Sark, with 18 elected members.[19]  In 1565, Helier de Carteret, Seigneur of St. Ouen in Jersey, was granted the fief of Sark by Queen Elizabeth I. He received letters patent granting him Sark in perpetuity on condition that he kept the island free of pirates and that at least forty men occupied it to defend it. Despite most families coming from Jersey, Sark remained within the Bailiwick of Guernsey.[20]  There is no flag or coat of arms for the Bailiwick of Guernsey. In historic times, the governor would have used his personal symbols before a generic flag was created for use by the governor.  In 1279, Edward I granted a Seal for use in the Channel Islands. In 1304, separate seals were provided to Jersey and Guernsey. The provision of different seals is one of the earliest indications of the individual identity and personality of the two Bailiwicks. The seal comprised three leopards (or lions), a symbol taken from the original arms of the Duchy of Normandy.[21]  The United Kingdom and His Majesty's Government in the United Kingdom are responsible for the defence and also for formal international, intergovernmental, and consular representation of, and the foreign affairs generally, of the Bailiwick.[14]  While never a member of the European Union or its predecessors, before Brexit the Bailiwick had a special relationship with the EU under Protocol 3 of the UK's Treaty of Accession 1972 to the European Community.[14] Pooling resources with Jersey, the Bailiwick established in 2010 an office in Brussels to develop the Channel Islands' influence with the EU,[22] to advise the Channel Islands' governments on European matters, and to promote economic links with the EU.[23]  The Bailiwick of Guernsey is in the Commonwealth (Commonwealth of Nations), although not as a member, in its own right. The Bailiwick is also a member of the Commonwealth Games Federation and competes in the Commonwealth Games.[24]  In 1969, Royal Mail relinquished control of postal services in the Bailiwick,[25] with Guernsey then being recognised by the Universal Postal Union.[citation needed]  Since 1999, the Bailiwick of Guernsey has been a member of the British\u2013Irish Council, currently represented by the Chief Minister of Guernsey. "},{"title":"Mark (Australian rules football)","content":"  A mark in Australian rules football is the catch of a kicked ball which earns the catching player a free kick. The catch must be cleanly taken, or deemed by the umpire to have involved control of the ball for sufficient time. A tipped ball, or one that has touched the ground cannot be marked. Since 2002, in most Australian competitions, the minimum distance for a mark is 15 metres (16 yards or 49 feet).  Marking is one of the most important skills in Australian football. Aiming for a teammate who can mark their kick is the primary focus of any kicking player not kicking for goal. Marking can also be one of the most spectacular and distinctive aspects of the game, and the best mark of the AFL season is awarded with the Mark of the Year, with similar competitions running across smaller leagues.  The most prolific markers in the history of the Australian Football League, Nick Riewoldt, Matthew Richardson, Stewart Loewe and Gary Dempsey took an average of around eight marks per game.[1] An AFL match between St Kilda and Port Adelaide in 2006 set a record of 303 marks in a single game.  Upon taking a mark, the umpire will blow the whistle to signify the mark and a player is entitled to an unimpeded kick of the ball. The nearest opposition player stands on the spot where the player marked the ball, which is also known as 'the mark' and he becomes 'the man on the mark.' When awarded the free kick, the player can choose to forego their kick to play-on and run into space, with the defending players then allowed to tackle as normal. The player has 10 seconds to move the ball on after a mark unless they are taking a shot on goal in which case they have 30 seconds to take their kick. If the player takes too long to complete their free kick, the umpire will call play-on, rescinding the award of the free kick, which also allows the defenders to tackle as normal.  A mark must be caught cleanly, with the player having complete control of the ball, even if only for a short time. As such, if the ball is punched out from between the player's hands after it is caught, or the ball is dislodged upon hitting the ground, a mark is still paid, even if the ball was held for only an instant.  Although the rules make no provision for two players marking the ball simultaneously,[2] by convention the umpire will award the mark to the man in front, i.e. the player who has the front position in the marking contest. If he cannot determine which player is in front, then a ball-up will result.  The mark has been included in the compromise rules used in the International Rules Football series between teams from Australia and Ireland since 1984.  The current minimum distance the ball must travel for a mark to be awarded is 15 metres in any direction; a cleanly caught ball which travels a shorter distance is called 'play on'. This has been the case since 2002; for more than a century before that, the minimum distance was ten metres or ten yards.[3] There are very few ground markings on an Australian rules football field which could be used to measure this distance precisely, leaving the decision on distance up to the best judgement of the umpire; a kick which is too short will typically be met with shouts of 'play on' or 'not fifteen' by the umpire.  In the early decades of Australian rules football, the minimum distance was substantially shorter, resulting in a type of play called a \"little mark\", in which a team could earn a mark by kicking the ball a short distance into the hands of a team-mate standing almost immediately adjacent. Little marks were polarising: they were considered by supporters as one of the game's best features and an effective way for teams to clear scrimmages; and considered by detractors as too difficult to accurately adjudicate and sometimes exploited by crafty players who would disguise a hand-off as a little mark.[4][5] The minimum distance for a mark changed many times over the early years: until 1877, no minimum; in 1877, six yards;[6] in 1886, five yards;[5] in 1887, two yards[7] \u2013 but in practice by the start of the 1890s it was reported that most umpires would pay little marks over only a few inches.[8][9] Little marking was effectively abolished with the introduction of the ten yard minimum distance in 1897.  Only one player may stand the mark; this restriction was introduced in 1924. Since 2021, a player standing the mark must remain stationary upon taking up the mark until the kicker has disposed of the ball or played on; prior to this, the man on the mark was free to leave the mark or move laterally, provided he did not move over the mark towards the kicker. Breaking this rule is punishable by a 50-metre penalty. If the team chooses not to put a man on the mark, then players may defend the kick from five metres behind the mark; these players are allowed to move.[10]  There is a protected area around the kicker, which is a corridor which extends ten metres either side of the line between the man on the mark and the kicker, five metres behind the kicker, and five metres behind the mark. Opposing players may not enter the protected area unless following their direct opponent within two metres; and player who find themselves within the area need to make best endeavours to leave it. Breaking the rule is also punishable by 50-metre penalty.[10]  The combination of kick and mark as the primary means for advancing the ball has been a distinctive feature of Australian football ever since the first rules were created in 1859. The original rules of the game, which were published in The Footballer newspaper in 1859, included the phrase \"A mark shall be considered to be a clean catch of the ball, on the full, without it touching the ground\". This rule was included in the Victorian Football Association's rules in 1866, and was included in the Australian National Football Council's rules in 1897.  Other forms of football descended from English public school football games of the 19th century have featured a fair catch, with similar rules to the mark. It was abolished early in the development of soccer and is only used occasionally in rugby union and American football.  The origin of the term has a few possible sources. In rugby and the early days of soccer, a player would shout 'mark' and mark the ground with their foot. It was formerly a requirement in the Australian game to make such a mark but this is no longer the case. Sometimes a cap which formed part of the uniform was used to show where the fair catch was taken.  Another source of the term may have been from the traditional Aboriginal game of Marn Grook, which is said to have influenced founder Tom Wills' development of the early forms of Australian football.[11] It is claimed that in Marn Grook, jumping to catch the ball, called \"mumarki\", an Aboriginal word meaning \"to catch\", results in a free kick.[11]  These early influences may be limited in their relevance, as the term \"catching the ball\" was more commonly used throughout the early 20th century. The term \"mark\" only became widely used in the 1940s, and used by players and commentators alike by the 1950s.  Early forms of Australian football were characterised by low, short kicks and scrimmages. Marks were taken on the chest as all other marks were seen as dangerous or risky. One of the first players to attempt an overhead mark and high mark was Jack Kerley in 1883. Jack Worrall popularised the high mark between 1885 and 1887 and others followed, ushering in a new era of overhead marking in the sport.[12] However players who leapt for the ball could be pushed in mid air, risking immediate dispossession, if not injury.   At a meeting of the Australasian Football Council (AFC) in 1890 a motion was passed banning pushing in the back in a marking contest which was agreed to by its member leagues including Victoria.[13] It was adopted by the newly formed VFL in 1897.  While the rule encouraged high marking, players marking from behind were still often penalised.  In 1907 the AFC introduced the concept of unintentional interference in a marking contest.[14] Spectacular marks subsequently became more common.  In Australian football, marks are often described in combination of the following ways.  While the Mark of the Year competition has identified many famous marks, other marks include:  In the 1970 Grand Final before a record crowd of 121,696, Carlton full forward, and giant of the game, Alex Jesaulenko, took one of the most inspirational marks in the history of 'the Australian game.' Leaping high for a specky over Collingwood's Graeme Jenkin just before half time, the mark inspired a Carlton side that was behind by 44 points at the half. It was retroactively classified as the Mark of the Year.  Sydney's Leo Barry leapt into history with his match-saving mark in the final seconds of the 2005 grand final against the West Coast Eagles to seal the game. His contested overhead mark was taken in a congested pack of three teammates and three opposition players.  Shaun Smith's and Gary Ablett's marks share the title of Mark of the Century.  St Kilda\/South Melbourne player Roy Cazaly was renowned for his high marks, giving rise to the catchphrase and song \"Up There Cazaly\".  Spoiling is the technique typically employed by opposition defenders to legally stop a player from catching the ball. It is performed as a punching action by hand or fist just before the opposing player has caught the ball in their hands.  The rules are quite strict on defensive spoiling methods. Players are not allowed to push other players out of marking contests or make forceful front on contact with an opponent in a marking contest, if they are not simultaneously attempting to mark or spoil the ball. Also, no high contact is allowed unless such contact is incidental to attempting to mark or spoil the ball.  Deliberately taking, hacking or chopping the arms is an infringement committed by players which will result in a free kick.  The arm interference free kick was introduced as a specific free kick in the AFL and its affiliates in 2005, although it was paid as a blocking, striking or holding free kick previously. The free kick was designed predominately to make it easier for forwards to take contested marks by not allowing defending player to punch or pull a marking player's outstretched arms in a marking contest.[19]  The rule was introduced by the AFL amidst on-going calls from fans and commentators to take action against the defensive tactic of flooding. The rule does directly limit the effectiveness of defenders, but the AFL has never stated whether or not flooding was the reason for the change.[19]  Marking can cause injuries to hands and fingers, including hyperextension, joint and tendon damage, dislocation and fractures.  Over a long period of time and with re-injury there can be long-term effects such as chronic injury and debilitating arthritis.  To overcome these injuries, some players will strap problem fingers together, whole hands, wear splints or gloves.  Some of these injuries require surgery and extended recovery, threatening professional careers.  AFL players whose careers were threatened by such injuries include Robert Campbell, Fraser Gehrig, Brett Backwell and Daniel Chick.  Some players, such as Backwell and Chick, have opted for amputation of digits in a bid to extend their playing careers and continue to mark the ball. "},{"title":"List of islands of England","content":" This is a list of islands of England (excluding the mainland which is itself a part of the island of Great Britain), as well as a table of the largest English islands by area and by population.  To group islands by geographical region, sort the table by \"Island Group\/Location\" (click the icon by the column heading).  There are numerous islands within freshwater lakes and rivers in England. They are most numerous in the Lake District but other concentrations occur within the Norfolk Broads, some major reservoirs and principal rivers.  To group islands by lake, sort the table by \"Lake\" (click the icon by the column heading).  To group islands by location, sort the table by \"Location\" (click the icon by the column heading).  Some places in the British Isles are called islands or isles, but are not. Some of these were formerly islands surrounded by marshland. Others are peninsulas or just coastal settlements. They include: "},{"title":"United States","content":"  The United States of America (USA or U.S.A.), commonly known as the United States (US or U.S.) or America, is a country primarily located in North America. It is a federation of 50 states, a federal capital district (Washington, D.C.), and 326 Indian reservations. Outside the union of states, it asserts sovereignty over five major unincorporated island territories and various uninhabited islands.[j] The country has the world's third-largest land area,[d] second-largest exclusive economic zone, and third-largest population, exceeding 334 million.[k]  Paleo-Indians migrated across the Bering land bridge more than 12,000 years ago. British colonization led to the first settlement of the Thirteen Colonies in Virginia in 1607. Clashes with the British Crown over taxation and political representation sparked the American Revolution, with the Second Continental Congress formally declaring independence on July 4, 1776. Following its victory in the Revolutionary War (1775\u20131783), the country continued to expand across North America. As more states were admitted, sectional division over slavery led to the secession of the Confederate States of America, which fought the remaining states of the Union during the 1861\u20131865 American Civil War. With the Union's victory and preservation, slavery was abolished nationally. By 1890, the United States had established itself as a great power. After Japan's attack on Pearl Harbor in December 1941, the U.S. entered World War II. The aftermath of the war left the U.S. and the Soviet Union as the world's two superpowers and led to the Cold War, during which both countries engaged in a struggle for ideological dominance and international influence. Following the Soviet Union's collapse and the end of the Cold War in 1991, the U.S. emerged as the world's sole superpower.  The U.S. national government is a presidential constitutional republic and liberal democracy with three separate branches: legislative, executive, and judicial. It has a bicameral national legislature composed of the House of Representatives, a lower house based on population; and the Senate, an upper house based on equal representation for each state. Substantial autonomy is given to states and several territories, with a political culture that emphasizes liberty, equality under the law, individualism, and limited government.  One of the world's most developed countries, the United States has had the largest nominal GDP since 1890 and accounted for 15% of the global economy in 2023.[l] It possesses by far the largest amount of wealth of any country and the highest disposable household income per capita among OECD countries.[20] The U.S. ranks among the world's highest in economic competitiveness, productivity, innovation, human rights, and higher education. Its hard power and cultural influence have a global reach. The U.S. is a founding member of the World Bank, IMF, Organization of American States, NATO, World Health Organization, and a permanent member of the UN Security Council.  The first documentary evidence of the phrase \"United States of America\" dates to a letter from January 2, 1776, written by Stephen Moylan, a Continental Army aide to General George Washington, to Joseph Reed, Washington's aide-de-camp. Moylan expressed his desire to go \"with full and ample powers from the United States of America to Spain\" to seek assistance in the Revolutionary War effort.[21][22] The first known publication of the phrase \"United States of America\" was in an anonymous essay in The Virginia Gazette newspaper in Williamsburg, on April\u00a06, 1776.[23]  By June 1776, the name \"United States of America\" appeared in drafts of the Articles of Confederation and Perpetual Union, authored by John Dickinson, a Founding Father from the Province of Pennsylvania,[24][25] and in the Declaration of Independence, written primarily by Thomas Jefferson and adopted by the Second Continental Congress in Philadelphia, on July 4, 1776.[24][26]  The first inhabitants of North America migrated from Siberia across the Bering land bridge at least 12,000 years ago;[28][29] the Clovis culture, which appeared around 11,000 BC, is believed to be the first widespread culture in the Americas.[30][31] Over time, indigenous North American cultures grew increasingly sophisticated, and some, such as the Mississippian culture, developed agriculture, architecture, and complex societies.[32] Indigenous peoples and cultures such as the Algonquian peoples,[33] Ancestral Puebloans,[34] and the Iroquois developed across the present-day United States.[35] Native population estimates of what is now the United States before the arrival of European immigrants range from around 500,000[36][37] to nearly 10 million.[37][38]  Christopher Columbus began exploring the Caribbean in 1492, leading to Spanish settlements in present-day Puerto Rico, Florida, and New Mexico.[39][40][41] France established its own settlements along the Mississippi River and Gulf of Mexico.[42] British colonization of the East Coast began with the Virginia Colony (1607) and Plymouth Colony (1620).[43][44] The Mayflower Compact and the Fundamental Orders of Connecticut established precedents for representative self-governance and constitutionalism that would develop throughout the American colonies.[45][46] While European settlers in what is now the United States experienced conflicts with Native Americans, they also engaged in trade, exchanging European tools for food and animal pelts.[47][m] Relations ranged from close cooperation to warfare and massacres. The colonial authorities often pursued policies that forced Native Americans to adopt European lifestyles, including conversion to Christianity.[51][52] Along the eastern seaboard, settlers trafficked African slaves through the Atlantic slave trade.[53]  The original Thirteen Colonies[n] that would later found the United States were administered by Great Britain,[54] and had local governments with elections open to most white male property owners.[55][56] The colonial population grew rapidly, eclipsing Native American populations;[57] by the 1770s, the natural increase of the population was such that only a small minority of Americans had been born overseas.[58] The colonies' distance from Britain allowed for the development of self-governance,[59] and the First Great Awakening, a series of Christian revivals, fueled colonial interest in religious liberty.[60]  After winning the French and Indian War, Britain began to assert greater control over local colonial affairs, creating colonial political resistance; one of the primary colonial grievances was a denial of their rights as Englishmen, particularly the right to representation in the British government that taxed them. In 1774, the First Continental Congress met in Philadelphia, and passed a colonial boycott of British goods that proved effective. The British attempt to then disarm the colonists resulted in the 1775 Battles of Lexington and Concord, igniting the American Revolutionary War. At the Second Continental Congress, the colonies appointed George Washington commander-in-chief of the Continental Army and created a committee led by Thomas Jefferson to write the Declaration of Independence, adopted on July 4, 1776.[61] The political values of the American Revolution included liberty, inalienable individual rights; and the sovereignty of the people;[62] supporting republicanism and rejecting monarchy, aristocracy, and hereditary political power; virtue and faithfulness in the performance of civic duties; and vilification of corruption.[63] The Founding Fathers of the United States, which included George Washington, Benjamin Franklin, Alexander Hamilton, Thomas Jefferson, John Jay, James Madison, Thomas Paine, and John Adams, were inspired by Greco-Roman, Renaissance, and Age of Enlightenment philosophies and ideas.[64][65]  After the British surrender at the siege of Yorktown in 1781, American sovereignty was internationally recognized by the Treaty of Paris (1783), through which the U.S. gained territory stretching west to the Mississippi River, north to present-day Canada, and south to Spanish Florida.[66] Ratified in 1781, the Articles of Confederation established a decentralized government that operated until 1789.[61] The Northwest Ordinance (1787) established the precedent by which the country's territory would expand with the admission of new states, rather than the expansion of existing states.[67] The U.S. Constitution was drafted at the 1787 Constitutional Convention to overcome the limitations of the Articles; it went into effect in 1789, creating a federation administered by three branches on the principle of checks and balances.[68] Washington was elected the country's first president under the Constitution, and the Bill of Rights was adopted in 1791 to allay concerns by skeptics of the more centralized government;[69][70] his resignations first as commander-in-chief after the Revolution and later as president set a precedent followed by John Adams, establishing the peaceful transfer of power between rival parties.[71][72]  In the late 18th century, American settlers began to expand westward, some with a sense of manifest destiny.[73] The Louisiana Purchase (1803) from France nearly doubled the territory of the United States.[74] Lingering issues with Britain remained, leading to the War of 1812, which was fought to a draw.[75] Spain ceded Florida and its Gulf Coast territory in 1819.[76] The Missouri Compromise attempted to balance desires of northern states to prevent expansion of slavery in the country with those of southern states to expand it, admitting Missouri as a slave state and Maine as a free state and declared a policy of prohibiting slavery in the remaining Louisiana Purchase lands north of the 36\u00b030\u2032 parallel.[77] As Americans expanded further into land inhabited by Native Americans, the federal government often applied policies of Indian removal or assimilation.[78][79] The infamous Trail of Tears (1830\u20131850) was a U.S. government policy that forcibly removed and displaced most Native Americans living east of the Mississippi River to lands far to the west. These and earlier organized displacements prompted a long series of American Indian Wars west of the Mississippi.[80][81] The Republic of Texas was annexed in 1845,[82] and the 1846 Oregon Treaty led to U.S. control of the present-day American Northwest.[83] Victory in the Mexican\u2013American War resulted in the 1848 Mexican Cession of California and much of the present-day American Southwest.[73][84] The California Gold Rush of 1848\u20131849 spurred a huge migration of white settlers to the Pacific coast, leading to even more confrontations with Native populations. One of the most violent, the California genocide of thousands of Native inhabitants, lasted into the early 1870s,[85][86] just as additional western territories and states were created.[87]  During the colonial period, slavery was legal in the American colonies, though the practice began to be significantly questioned during the American Revolution.[88] States in The North enacted abolition laws,[89] though support for slavery strengthened in Southern states, as inventions such as the cotton gin made the institution increasingly profitable for Southern elites.[90][91][92] This sectional conflict regarding slavery culminated in the American Civil War (1861\u20131865).[93][94]  Eleven slave states seceded and formed the Confederate States of America, while the other states remained in the Union.[95] War broke out in April 1861 after the Confederacy bombarded Fort Sumter.[96] After the January 1863 Emancipation Proclamation, many freed slaves joined the Union Army.[97] The war began to turn in the Union's favor following the 1863 Siege of Vicksburg and Battle of Gettysburg, and the Confederacy surrendered in 1865 after the Union's victory in the Battle of Appomattox Court House.[98]  The Reconstruction era followed the war. After the assassination of President Abraham Lincoln, Reconstruction Amendments were passed to protect the rights of African Americans. National infrastructure, including transcontinental telegraph and railroads, spurred growth in the American frontier.[99]  From 1865 through 1917 an unprecedented stream of immigrants arrived in the United States, including 24.4 million from Europe.[102] Most came through the port of New York City, and New York City and other large cities on the East Coast became home to large Jewish, Irish, and Italian populations, while many Germans and Central Europeans moved to the Midwest. At the same time, about one million French Canadians migrated from Quebec to New England.[103] During the Great Migration, millions of African Americans left the rural South for urban areas in the North.[104] Alaska was purchased from Russia in 1867.[105]  The Compromise of 1877 effectively ended Reconstruction and white supremacists took local control of Southern politics.[106][107] African Americans endured a period of heightened, overt racism following Reconstruction, a time often called the nadir of American race relations.[108][109] A series of Supreme Court decisions, including Plessy v. Ferguson, emptied the Fourteenth and Fifteenth Amendments of their force, allowing Jim Crow laws in the South to remain unchecked, sundown towns in the Midwest, and segregation in cities across the country, which would be reinforced by the policy of redlining later adopted by the federal Home Owners' Loan Corporation.[110]  An explosion of technological advancement accompanied by the exploitation of cheap immigrant labor[111] led to rapid economic development during the late 19th and early 20th centuries, allowing the United States to outpace England, France, and Germany combined.[112][113] This fostered the amassing of power by a few prominent industrialists, largely by their formation of trusts and monopolies to prevent competition.[114] Tycoons led the nation's expansion in the railroad, petroleum, and steel industries. The United States emerged as a pioneer of the automotive industry.[115] These changes were accompanied by significant increases in economic inequality, slum conditions, and social unrest, creating the environment for labor unions to begin to flourish.[116][117][118] This period eventually ended with the advent of the Progressive Era, which was characterized by significant reforms.[119][120]  Pro-American elements in Hawaii overthrew the Hawaiian monarchy; the islands were annexed in 1898. Puerto Rico, Guam, and the Philippines were ceded by Spain following the Spanish\u2013American War.[121] American Samoa was acquired by the United States in 1900 after the Second Samoan Civil War.[122] The U.S. Virgin Islands were purchased from Denmark in 1917.[123] The United States entered World War I alongside the Allies of World War I, helping to turn the tide against the Central Powers.[124] In 1920, a constitutional amendment granted nationwide women's suffrage.[125] During the 1920s and 30s, radio for mass communication and the invention of early television transformed communications nationwide.[126] The Wall Street Crash of 1929 triggered the Great Depression, which President Franklin D. Roosevelt responded to with New Deal social and economic policies.[127][128]  At first neutral during World War II, the U.S. began supplying war materiel to the Allies of World War II in March 1941 and entered the war in December after the Empire of Japan's attack on Pearl Harbor.[129][130] The U.S. developed the first nuclear weapons and used them against the Japanese cities of Hiroshima and Nagasaki in August 1945, ending the war.[131][132] The United States was one of the \"Four Policemen\" who met to plan the postwar world, alongside the United Kingdom, Soviet Union, and China.[133][134] The U.S. emerged relatively unscathed from the war, with even greater economic and international political influence.[135]  After World War II, the United States entered the Cold War, where geopolitical tensions between the U.S. and the Soviet Union led the two countries to dominate world affairs.[136] The U.S. engaged in regime change against governments perceived to be aligned with the Soviet Union, and competed in the Space Race, culminating in the first crewed Moon landing in 1969.[137][138][139][140]  Domestically, the U.S. experienced economic growth, urbanization, and population growth following World War II.[141] The civil rights movement emerged, with Martin Luther King Jr. becoming a prominent leader in the early 1960s.[142] The Great Society plan of President Lyndon Johnson's administration resulted in groundbreaking and broad-reaching laws, policies and a constitutional amendment to counteract some of the worst effects of lingering institutional racism.[143] The counterculture movement in the U.S. brought significant social changes, including the liberalization of attitudes toward recreational drug use and sexuality. It also encouraged open defiance of the military draft (leading to the end of conscription in 1973) and wide opposition to U.S. intervention in Vietnam (with the U.S. totally withdrawing in 1975).[144][145][146] The societal shift in the roles of women partly resulted in large increases in female labor participation in the 1970s, and by 1985 the majority of women aged 16 and older were employed.[147] The late 1980s and early 1990s saw the collapse of the Warsaw Pact and the dissolution of the Soviet Union, which marked the end of the Cold War and solidified the U.S. as the world's sole superpower.[148][149][150][151]  The 1990s saw the longest recorded economic expansion in American history, a dramatic decline in crime, and advances in technology, with the World Wide Web, the evolution of the Pentium microprocessor in accordance with Moore's law, rechargeable lithium-ion batteries, the first gene therapy trial, and cloning all emerging and being improved upon throughout the decade. The Human Genome Project was formally launched in 1990, while Nasdaq became the first stock market in the United States to trade online in 1998.[152] In 1991, an American-led international coalition of states expelled an Iraqi invasion force from Kuwait in the Gulf War.[153]  The September 11 attacks in 2001 by the pan-Islamist militant organization al-Qaeda led to the war on terror and subsequent military interventions in Afghanistan and Iraq.[154][155] The cultural impact of the attacks was profound and long-lasting.  The U.S. housing bubble culminated in 2007 with the Great Recession, the largest economic contraction since the Great Depression.[156] Coming to a head in the 2010s, political polarization increased as sociopolitical debates on cultural issues dominated politics.[157] This polarization was capitalized upon in the January 2021 Capitol attack,[158] when a mob of protesters entered the U.S. Capitol and attempted to prevent the peaceful transfer of power.[159]  The United States is the world's third-largest country by total area behind Russia and Canada.[d][160][161] The 48 contiguous states and the District of Columbia occupy a combined area of 3,119,885 square miles (8,080,470\u00a0km2).[162][163] The coastal plain of the Atlantic seaboard gives way to inland forests and rolling hills in the Piedmont plateau region.[164]  The Appalachian Mountains and the Adirondack massif separate the East Coast from the Great Lakes and the grasslands of the Midwest.[165] The Mississippi River System, the world's fourth-longest river system, runs predominantly north\u2013south through the heart of the country. The flat and fertile prairie of the Great Plains stretches to the west, interrupted by a highland region in the southeast.[165]  The Rocky Mountains, west of the Great Plains, extend north to south across the country, peaking at over 14,000 feet (4,300\u00a0m) in Colorado.[166] Farther west are the rocky Great Basin and Chihuahua, Sonoran, and Mojave deserts.[167] In the northwest corner of Arizona, carved by the Colorado River over millions of years, is the Grand Canyon, a steep-sided canyon and popular tourist destination known for its overwhelming visual size and intricate, colorful landscape.  The Sierra Nevada and Cascade mountain ranges run close to the Pacific coast. The lowest and highest points in the contiguous United States are in the state of California,[168] about 84 miles (135\u00a0km) apart.[169] At an elevation of 20,310 feet (6,190.5\u00a0m), Alaska's Denali is the highest peak in the country and continent.[170] Active volcanoes are common throughout Alaska's Alexander and Aleutian Islands, and Hawaii consists of volcanic islands. The supervolcano underlying Yellowstone National Park in the Rockies is the continent's largest volcanic feature.[171] In 2021, the United States had 8% of global permanent meadows and pastures and 10% of cropland.[172]  With its large size and geographic variety, the United States includes most climate types. East of the 100th meridian, the climate ranges from humid continental in the north to humid subtropical in the south.[173] The western Great Plains are semi-arid. Many mountainous areas of the American West have an alpine climate. The climate is arid in the Southwest, Mediterranean in coastal California, and oceanic in coastal Oregon, Washington, and southern Alaska. Most of Alaska is subarctic or polar. Hawaii, the southern tip of Florida and U.S. territories in the Caribbean and Pacific are tropical.[174]  States bordering the Gulf of Mexico are prone to hurricanes, and most of the world's tornadoes occur in the country, mainly in Tornado Alley.[175] Overall, the United States receives more high-impact extreme weather incidents than any other country.[176] Extreme weather became more frequent in the U.S. in the 21st century, with three times the number of reported heat waves as in the 1960s. In the American Southwest, droughts became more persistent and more severe.[177]    The U.S. is one of 17 megadiverse countries containing large numbers of endemic species: about 17,000 species of vascular plants occur in the contiguous United States and Alaska, and over 1,800 species of flowering plants are found in Hawaii, few of which occur on the mainland.[179] The United States is home to 428 mammal species, 784 birds, 311 reptiles, 295 amphibians,[180] and 91,000 insect species.[181]  There are 63 national parks, and hundreds of other federally managed parks, forests, and wilderness areas, managed by the National Park Service and other agencies.[182] About 28% of the country's land is publicly owned and federally managed,[183] primarily in the western states.[184] Most of this land is protected, though some is leased for commercial use, and less than one percent is used for military purposes.[185][186]  Environmental issues in the United States include debates on non-renewable resources and nuclear energy, air and water pollution, biodiversity, logging and deforestation,[187][188] and climate change.[189][190] The U.S. Environmental Protection Agency (EPA) is the federal agency charged with addressing most environmental-related issues.[191] The idea of wilderness has shaped the management of public lands since 1964, with the Wilderness Act.[192] The Endangered Species Act of 1973 provides a way to protect threatened and endangered species and their habitats. The United States Fish and Wildlife Service implements and enforces the Act.[193] As of 2022[update], the U.S. ranked 43rd among 180 countries in the Environmental Performance Index.[194] The country joined the Paris Agreement on climate change in 2016 and has many other environmental commitments.[195]  The United States is a federal republic of 50 states, with its capital in a federal district, asserting sovereignty over five unincorporated territories and several uninhabited island possessions (some of which are disputed).[196][197] It is the world's oldest surviving federation, and, according to the World Economic Forum, the oldest democracy as well.[198] It is a liberal representative democracy \"in which majority rule is tempered by minority rights protected by law.\"[199] The Constitution of the United States serves as the country's supreme legal document, also establishing the structure and responsibilities of the national federal government and its relationship with the individual states.[200]  Composed of three branches, all headquartered in Washington, D.C., the federal government is the national government of the United States. It is regulated by a strong system of checks and balances.[201]  The three-branch system is known as the presidential system, in contrast to the parliamentary system, where the executive is part of the legislative body. Many countries around the world copied this aspect of the 1789 Constitution of the United States, especially in the Americas.[209]  The Constitution is silent on political parties. However, they developed independently in the 18th century with the Federalist and Anti-Federalist parties.[210] Since then, the United States has operated as a de facto two-party system, though the parties in that system have been different at different times.  The two main national parties are presently the Democratic and the Republican. The former is perceived as relatively liberal in its political platform while the latter is perceived as relatively conservative.[211] Each has a primary system to nominate a presidential ticket, and each runs candidates for other offices in every state in the Union. Other smaller and less influential parties exist but do not have the national scope and breadth of the two main parties.  In the American federal system, sovereign powers are shared between two levels of elected government: national and state. People in the states are also represented by local elected governments, which are administrative divisions of the states.[212] States are subdivided into counties or county equivalents, and further divided into municipalities. The District of Columbia is a federal district that contains the capital of the United States, the city of Washington.[213] The territories and the District of Columbia are administrative divisions of the federal government.[214] Federally recognized tribes govern 326[215] Indian reservations.  The United States has an established structure of foreign relations, and it has the world's second-largest diplomatic corps as of 2024[update]. It is a permanent member of the United Nations Security Council,[216] and home to the United Nations headquarters.[217] The United States is a member of the G7,[218] G20,[219] and OECD intergovernmental organizations.[220] Almost all countries have embassies and many have consulates (official representatives) in the country. Likewise, nearly all countries host formal diplomatic missions with the United States, except Iran,[221] North Korea,[222] and Bhutan.[223] Though Taiwan does not have formal diplomatic relations with the U.S., it maintains close unofficial relations.[224] The United States regularly supplies Taiwan with military equipment to deter potential Chinese aggression.[225] Its geopolitical attention also turned to the Indo-Pacific when the United States joined the Quadrilateral Security Dialogue with Australia, India, and Japan.[226]  The United States has a \"Special Relationship\" with the United Kingdom[227] and strong ties with Canada,[228] Australia,[229] New Zealand,[230] the Philippines,[231] Japan,[232] South Korea,[233] Israel,[234] and several European Union countries (France, Italy, Germany, Spain, and Poland).[235] The U.S. works closely with its NATO allies on military and national security issues, and with countries in the Americas through the Organization of American States and the United States\u2013Mexico\u2013Canada Free Trade Agreement. In South America, Colombia is traditionally considered to be the closest ally of the United States.[236] The U.S. exercises full international defense authority and responsibility for Micronesia, the Marshall Islands, and Palau through the Compact of Free Association.[237] It has increasingly conducted strategic cooperation with India,[238] but its ties with China have steadily deteriorated.[239][240] Since 2014, the U.S. has become a key ally of Ukraine;[241] it has also provided the country with significant military equipment and other support in response to Russia's 2022 invasion.[242]  The President is the commander-in-chief of the United States Armed Forces and appoints its leaders, the secretary of defense and the Joint Chiefs of Staff. The Department of Defense, which is headquartered at the Pentagon near Washington, D.C., administers five of the six service branches, which are made up of the Army, Marine Corps, Navy, Air Force, and Space Force. The Coast Guard is administered by the Department of Homeland Security in peacetime and can be transferred to the Department of the Navy in wartime.[243]  The United States spent $916 billion on its military in 2023, which is by far the largest amount of any country, making up 37% of global military spending and accounting for 3.4% of the country's GDP.[244][245] The U.S. has 45% of the world's nuclear weapons, the second-largest amount after Russia.[246]  The United States has the third-largest combined armed forces in the world, behind the Chinese People's Liberation Army and Indian Armed Forces.[247] The military operates about 800 bases and facilities abroad,[248] and maintains deployments greater than 100 active duty personnel in 25 foreign countries.[249]  There are about 18,000 U.S. police agencies from local to national level in the United States.[250] Law in the United States is mainly enforced by local police departments and sheriff departments in their municipal or county jurisdictions. The state police departments have authority in their respective state, and federal agencies such as the Federal Bureau of Investigation (FBI) and the U.S. Marshals Service have national jurisdiction and specialized duties, such as protecting civil rights, national security and enforcing U.S. federal courts' rulings and federal laws.[251] State courts conduct most civil and criminal trials,[252] and federal courts handle designated crimes and appeals of state court decisions.[253]  As of January 2023, the United States has the sixth highest per-capita incarceration rate in the world, at 531 people per 100,000; and the largest prison and jail population in the world with almost 2\u00a0million people incarcerated.[254][255][256] An analysis of the World Health Organization Mortality Database from 2010 showed U.S. homicide rates \"were 7 times higher than in other high-income countries, driven by a gun homicide rate that was 25 times higher.\"[257]  The U.S. has been the world's largest economy nominally since about 1890.[260] The 2023 nominal U.S. gross domestic product (GDP) of $27\u00a0trillion was the largest in the world, constituting over 25% of the global economy or 15% at purchasing power parity (PPP).[261][13] From 1983 to 2008, U.S. real compounded annual GDP growth was 3.3%, compared to a 2.3% weighted average for the rest of the Group of Seven.[262] The country ranks first in the world by nominal GDP,[263] second when adjusted for purchasing power parities (PPP),[13] and ninth by GDP (PPP) per capita.[13] It possesses the highest disposable household income per capita among OECD countries.[264]  Of the world's 500 largest companies, 136 are headquartered in the U.S.[265] The U.S. dollar is the currency most used in international transactions and is the world's foremost reserve currency, backed by the country's dominant economy, its military, the petrodollar system, and its linked eurodollar and large U.S. treasuries market.[258] Several countries use it as their official currency and in others it is the de facto currency.[266][267] It has free trade agreements with several countries, including the USMCA.[268] The U.S. ranked second in the Global Competitiveness Report in 2019, after Singapore.[269] While its economy has reached a post-industrial level of development, the United States remains an industrial power.[270] As of 2021[update], the U.S. is the second-largest manufacturing country after China.[271]  New York City is the world's principal financial center[273][274] and the epicenter of the world's largest metropolitan economy.[275] The New York Stock Exchange and Nasdaq, both located in New York City, are the world's two largest stock exchanges by market capitalization and trade volume.[276][277] The United States is at or near the forefront of technological advancement and innovation[278] in many economic fields, especially in artificial intelligence; computers; pharmaceuticals; and medical, aerospace and military equipment.[279] The country's economy is fueled by abundant natural resources, a well-developed infrastructure, and high productivity.[280] The largest U.S. trading partners are the European Union, Mexico, Canada, China, Japan, South Korea, the United Kingdom, Vietnam, India, and Taiwan.[281] The United States is the world's largest importer and the second-largest exporter after China.[282] It is by far the world's largest exporter of services.[283]  Americans have the highest average household and employee income among OECD member states,[284] and the fourth-highest median household income,[285] up from sixth-highest in 2013.[286] Wealth in the United States is highly concentrated; the richest 10% of the adult population own 72% of the country's household wealth, while the bottom 50% own just 2%.[287] Income inequality in the U.S. remains at record highs,[288] with the top fifth of earners taking home more than half of all income[289] and giving the U.S. one of the widest income distributions among OECD members.[290][291] The U.S. ranks first in the number of dollar billionaires and millionaires, with 735 billionaires and nearly 22 million millionaires (as of 2023).[292] There were about 582,500 sheltered and unsheltered homeless persons in the U.S. in 2022, with 60% staying in an emergency shelter or transitional housing program.[293] In 2018, six million children experienced food insecurity.[294] Feeding America estimates that around one in seven, or approximately 11 million, children experience hunger and do not know where they will get their next meal or when.[295] As of 2021,[update] 38\u00a0million people, about 12% of the U.S. population, were living in poverty.[296]  The United States has a smaller welfare state and redistributes less income through government action than most other high-income countries.[297][298] It is the only advanced economy that does not guarantee its workers paid vacation nationally[299] and is one of a few countries in the world without federal paid family leave as a legal right.[300] The United States has a higher percentage of low-income workers than almost any other developed country, largely because of a weak collective bargaining system and lack of government support for at-risk workers.[301]  The United States has been a leader in technological innovation since the late 19th century and scientific research since the mid-20th century. Methods for producing interchangeable parts and the establishment of a machine tool industry enabled the large-scale manufacturing of U.S. consumer products in the late 19th century. By the early 20th century, factory electrification, the introduction of the assembly line, and other labor-saving techniques created the system of mass production.[302] The United States is a leader in the development of artificial intelligence technology and has maintained a space program since the late 1950s, with plans for long-term habitation of the Moon.[303][304]  In 2022, the United States was the country with the second-highest number of published scientific papers.[305] As of 2021, the U.S. ranked second by the number of patent applications, and third by trademark and industrial design applications.[306] In 2023, the United States ranked 3rd in the Global Innovation Index.[307]  As of 2022[update], the United States receives approximately 81% of its energy from fossil fuel and the largest source of the country's energy came from petroleum (35.8%), followed by natural gas (33.4%), renewable sources (13.3%), coal (9.8%), and nuclear power (8%).[308][309] The United States constitutes less than 5% of the world's population, but consumes 17% of the world's energy.[310][311] The U.S. ranks as the second-highest emitter of greenhouse gases.[312]  Personal transportation in the United States is dominated by automobiles,[314][315] which operate on a network of 4\u00a0million miles (6.4\u00a0million kilometers) of public roads, making it the longest network in the world.[316][317] The Oldsmobile Curved Dash and the Ford Model T, both American cars, are considered the first mass-produced[318] and mass-affordable[319] cars, respectively. As of 2022, the United States is the second-largest manufacturer of motor vehicles[320] and is home to Tesla, the world's most valuable car company.[321] American automotive company General Motors held the title of the world's best-selling automaker from 1931 to 2008.[322] The American automotive industry is the world's second-largest automobile market by sales, having been overtaken by China in 2010,[323] and the U.S. has the highest vehicle ownership per capita in the world,[324] with 910 vehicles per 1000 people.[325] The United States's rail transport network, the longest network in the world,[326] handles mostly freight.[327][328]  The American civil airline industry is entirely privately owned and has been largely deregulated since 1978, while most major airports are publicly owned.[329] The three largest airlines in the world by passengers carried are U.S.-based; American Airlines is number one after its 2013 acquisition by US Airways.[330] Of the world's 50 busiest passenger airports, 16 are in the United States, including the top five and the busiest, Hartsfield\u2013Jackson Atlanta International Airport.[331][332] As of 2022[update], there are 19,969 airports in the U.S., of which 5,193 are designated as \"public use\", including for general aviation and other activities.[333]  Of the fifty busiest container ports, four are located in the United States, of which the busiest is the Port of Los Angeles.[334] The country's inland waterways are the world's fifth-longest, and total 41,009\u00a0km (25,482\u00a0mi).[335]  The U.S. Census Bureau reported 331,449,281 residents as of April 1, 2020,[o][336] making the United States the third-most-populous country in the world, after China and India.[337] According to the Bureau's U.S. Population Clock, on January\u00a028, 2021, the U.S. population had a net gain of one person every 100 seconds, or about 864 people per day.[338] In 2018, 52% of Americans age 15 and over were married, 6% were widowed, 10% were divorced, and 32% had never been married.[339] In 2021, the total fertility rate for the U.S. stood at 1.7 children per woman,[340] and it had the world's highest rate of children (23%) living in single-parent households in 2019.[341] As of 2023, the five most populous states in the nation are California (38.9 million), Texas (30.5 million), Florida (22.6 million), New York (19.5 million), and Pennsylvania (12.9 million).  The United States has a diverse population; 37 ancestry groups have more than one million members.[342] White Americans with ancestry from Europe, the Middle East or North Africa, form the largest racial and ethnic group at 57.8% of the United States population.[343][344] Hispanic and Latino Americans form the second-largest group and are 18.7% of the United States population. African Americans constitute the country's third-largest ancestry group and are 12.1% of the total U.S. population.[342] Asian Americans are the country's fourth-largest group, composing 5.9% of the United States population. The country's 3.7 million Native Americans account for about 1%,[342] and some 574 native tribes are  recognized by the federal government.[345] In 2020, the median age of the United States population was 38.5 years.[337]  While many languages are spoken in the United States, English is by far the most commonly spoken and written.[346] Although there is no official language at the federal level, some laws, such as U.S. naturalization requirements, standardize English, and most states have declared it the official language.[347] Three states and four U.S. territories have recognized local or indigenous languages in addition to English, including Hawaii (Hawaiian),[348] Alaska (twenty Native languages),[p][349] South Dakota (Sioux),[350] American Samoa (Samoan), Puerto Rico (Spanish), Guam (Chamorro), and the Northern Mariana Islands (Carolinian and Chamorro). In total, 169 Native American languages are spoken in the United States.[351] In Puerto Rico, Spanish is more widely spoken than English.[352]  According to the American Community Survey in 2010, some 229 million people out of the total U.S. population of 308 million spoke only English at home. About 37 million spoke Spanish at home, making it the second most commonly used language. Other languages spoken at home by one million people or more include Chinese (2.8 million), Tagalog (1.6 million), Vietnamese (1.4 million), French (1.3 million), Korean (1.1 million), and German (1 million).[353]  America's immigrant population, 51 million, is by far the world's largest in absolute terms.[354][355] In 2022, there were 87.7 million immigrants and U.S.-born children of immigrants in the United States, accounting for nearly 27% of the overall U.S. population.[356] In 2017, out of the U.S. foreign-born population, some 45% (20.7\u00a0million) were naturalized citizens, 27% (12.3\u00a0million) were lawful permanent residents, 6% (2.2\u00a0million) were temporary lawful residents, and 23% (10.5\u00a0million) were unauthorized immigrants.[357] In 2019, the top countries of origin for immigrants were Mexico (24% of immigrants), India (6%), China (5%), the Philippines (4.5%), and El Salvador (3%).[358] The United States has led the world in refugee resettlement for decades, admitting more refugees than the rest of the world combined.[359]  Religious affiliation in the U.S., according to a 2022 Gallup poll:[7]  The First Amendment guarantees the free exercise of religion and forbids Congress from passing laws respecting its establishment.[360][361] Religious practice is widespread, among the most diverse in the world,[362] and profoundly vibrant.[363] The country has the world's largest Christian population.[364] A majority of the global Jewish population lives in the United States, as measured by the Law of Return.[365] Other notable faiths include Buddhism, Hinduism, Islam, many New Age movements, and Native American religions.[366] Religious practice varies significantly by region.[367] \"Ceremonial deism\" is common in American culture.[368]  The overwhelming majority of Americans believe in a higher power or spiritual force, engage in spiritual practices such as prayer, and consider themselves religious or spiritual.[369][370] In the \"Bible Belt\", located within the Southern United States, evangelical Protestantism plays a significant role culturally, whereas New England and the Western United States tend to be more secular.[367] Mormonism\u2014a Restorationist movement, whose members migrated westward from Missouri and Illinois under the leadership of Brigham Young in 1847 after the assassination of Joseph Smith[371]\u2014remains the predominant religion in Utah to this day.[372]  About 82% of Americans live in urban areas, including suburbs;[160] about half of those reside in cities with populations over 50,000.[373] In 2022, 333 incorporated municipalities had populations over 100,000, nine cities had more than one million residents, and four cities (New York City, Los Angeles, Chicago, and Houston) had populations exceeding two million.[374] Many U.S. metropolitan populations are growing rapidly, particularly in the South and West.[375]     According to the Centers for Disease Control (CDC), average American life expectancy at birth was 77.5 years in 2022 (74.8 years for men and 80.2 years for women). This was a gain of 1.1 years from 76.4 years in 2021, but the CDC noted that the new average \"didn't fully offset the loss of 2.4 years between 2019 and 2021\". The COVID pandemic and higher overall mortality due to opioid overdoses and suicides were held mostly responsible for the previous drop in life expectancy.[380] The same report stated that the 2022 gains in average U.S. life expectancy were especially significant for men, Hispanics, and American Indian\u2013Alaskan Native people (AIAN). Starting in 1998, the life expectancy in the U.S. fell behind that of other wealthy industrialized countries, and Americans' \"health disadvantage\" gap has been increasing ever since.[381] The U.S. has one of the highest suicide rates among high-income countries.[382] Approximately one-third of the U.S. adult population is obese and another third is overweight.[383] The U.S. healthcare system far outspends that of any other country, measured both in per capita spending and as a percentage of GDP, but attains worse healthcare outcomes when compared to peer countries for reasons that are debated.[384] The United States is the only developed country without a system of universal healthcare, and a significant proportion of the population that does not carry health insurance.[385] Government-funded healthcare coverage for the poor (Medicaid) and for those age 65 and older (Medicare) is available to Americans who meet the programs' income or age qualifications. In 2010, former President Obama passed the Patient Protection and Affordable Care Act.[q][386]  American primary and secondary education (known in the U.S. as K-12, \"kindergarten through 12th grade\") is decentralized. It is operated by state, territorial, and sometimes municipal governments and regulated by the U.S. Department of Education. In general, children are required to attend school or an approved homeschool from the age of five or six (kindergarten or first grade) until they are 18 years old. This often brings students through the 12th grade, the final year of a U.S. high school, but some states and territories allow them to leave school earlier, at age 16 or 17.[387] The U.S. spends more on education per student than any country in the world,[388] an average of $12,794 per year per public elementary and secondary school student in 2016\u20132017.[389] Among Americans age 25 and older, 84.6% graduated from high school, 52.6% attended some college, 27.2% earned a bachelor's degree, and 9.6% earned a graduate degree.[390] The U.S. literacy rate is near-universal.[160][391] The country has the most Nobel Prize winners in history, with 411 (having won 413 awards).[392][393]  U.S. tertiary or higher education has earned a global reputation. Many of the world's top universities, as listed by various ranking organizations, are in the United States, including 19 of the top 25.[394][395] American higher education is dominated by state university systems, although the country's many private universities and colleges enroll about 20% of all American students. Large amounts of federal financial aid are provided to students in the form of grants and loans.  Colleges and universities directly funded by the federal government are limited to military personnel and government employees and include the U.S. service academies, the Naval Postgraduate School, and military staff colleges. Local community colleges generally offer coursework and degree programs covering the first two years of college study. They often have more open admission policies, shorter academic programs, and lower tuition.[396]  As for public expenditures on higher education, the U.S. spends more per student than the OECD average, and more than all nations in combined public and private spending.[397] Despite some student loan forgiveness programs in place,[398] student loan debt has increased by 102% in the last decade,[399] and exceeded 1.7\u00a0trillion dollars as of 2022.[400]  Americans have traditionally been characterized by a unifying political belief in an \"American creed\" emphasizing liberty, equality under the law, democracy, social equality, property rights, and a preference for limited government.[402][403] Culturally, the country has been described as having the values of individualism and personal autonomy,[404][405] having a strong work ethic,[406] competitiveness,[407] and voluntary altruism towards others.[408][409][410] According to a 2016 study by the Charities Aid Foundation, Americans donated 1.44% of total GDP to charity, the highest rate in the world by a large margin.[411] The United States is home to a wide variety of ethnic groups, traditions, and values. It has acquired significant cultural and economic soft power.[412][413]  Nearly all present Americans or their ancestors came from Europe, Africa, and Asia (\"the Old World\") within the past five centuries.[414] Mainstream American culture is a Western culture largely derived from the traditions of European immigrants with influences from many other sources, such as traditions brought by slaves from Africa.[415] More recent immigration from Asia and especially Latin America has added to a cultural mix that has been described as a homogenizing melting pot, and a heterogeneous salad bowl, with immigrants contributing to, and often assimilating into, mainstream American culture. The American Dream, or the perception that Americans enjoy high social mobility, plays a key role in attracting immigrants.[416] Whether this perception is accurate has been a topic of debate.[417][418][419] While mainstream culture holds that the United States is a classless society,[420] scholars identify significant differences between the country's social classes, affecting socialization, language, and values.[421] Americans tend to greatly value socioeconomic achievement, but being ordinary or average is promoted by some as a noble condition as well.[422]  The United States is considered to have the strongest protections of free speech of any country under the First Amendment,[423] which protects flag desecration, hate speech, blasphemy, and lese-majesty as forms of protected expression.[424][425][426] A 2016 Pew Research Center poll found that Americans were the most supportive of free expression of any polity measured.[427] They are the \"most supportive of freedom of the press and the right to use the Internet without government censorship.\"[428] It is a socially progressive country[429] with permissive attitudes surrounding human sexuality.[430] LGBT rights in the United States are advanced by global standards.[430][431][432]  Colonial American authors were influenced by John Locke and various other Enlightenment philosophers.[434][435] Before and shortly after the Revolutionary War, the newspaper rose to prominence, filling a demand for anti-British national literature.[436][437] Led by Ralph Waldo Emerson and Margaret Fuller in New England,[438] transcendentalism branched from Unitarianism as the first major American philosophical movement.[439][440] During the nineteenth-century American Renaissance, writers like Walt Whitman and Harriet Beecher Stowe established a distinctive American literary tradition.[441][442] As literacy rates rose, periodicals published more stories centered around industrial workers, women, and the rural poor.[443][444] Naturalism, regionalism, and realism\u2014the latter associated with Mark Twain\u2014were the major literary movements of the period.[445][446]  While modernism generally took on an international character, modernist authors working within the United States more often rooted their work in specific regions, peoples, and cultures.[447] Following the Great Migration to northern cities, African-American and black West Indian authors of the Harlem Renaissance developed an independent tradition of literature that rebuked a history of inequality and celebrated black culture. An important cultural export during the Jazz Age, these writings were a key influence on the n\u00e9gritude philosophy.[448][449] In the 1950s, an ideal of homogeneity led many authors to attempt to write the Great American Novel,[450] while the Beat Generation rejected this conformity, using styles that elevated the impact of the spoken word over mechanics to describe drug use, sexuality, and the failings of society.[451][452] Contemporary literature is more pluralistic than in previous eras, with the closest thing to a unifying feature being a trend toward self-conscious experiments with language.[453]  Media is broadly uncensored, with the First Amendment providing significant protections, as reiterated in New York Times Co. v. United States.[423] The four major broadcasters in the U.S. are the National Broadcasting Company (NBC), Columbia Broadcasting System (CBS), American Broadcasting Company (ABC), and Fox Broadcasting Company (FOX). The four major broadcast television networks are all commercial entities. Cable television offers hundreds of channels catering to a variety of niches.[454] As of 2021[update], about 83% of Americans over age 12 listen to broadcast radio, while about 40% listen to podcasts.[455] As of 2020[update], there were 15,460 licensed full-power radio stations in the U.S. according to the Federal Communications Commission (FCC).[456] Much of the public radio broadcasting is supplied by NPR, incorporated in February 1970 under the Public Broadcasting Act of 1967.[457]  U.S. newspapers with a global reach and reputation include The Wall Street Journal, The New York Times, The Washington Post, and USA Today.[458] About 800 publications are produced in Spanish.[459][460] With few exceptions, newspapers are privately owned, either by large chains such as Gannett or McClatchy, which own dozens or even hundreds of newspapers; by small chains that own a handful of papers; or, in a situation that is increasingly rare, by individuals or families. Major cities often have alternative newspapers to complement the mainstream daily papers, such as The Village Voice in New York City and LA Weekly in Los Angeles. The five most popular websites used in the U.S. are Google, YouTube, Amazon, Yahoo, and Facebook, with all of them being American companies.[461]  As of 2022[update], the video game market of the United States is the world's largest by revenue.[462] There are 444 publishers, developers, and hardware companies in California alone.[463]  The United States is well known for its cinema and theater. Mainstream theater in the United States derives from the old European theatrical tradition and has been heavily influenced by the British theater.[464] By the middle of the 19th century America had created new distinct dramatic forms in the Tom Shows, the showboat theater and the minstrel show.[465] The central hub of the American theater scene is Manhattan, with its divisions of Broadway, off-Broadway, and off-off-Broadway.[466]  Many movie and television stars have gotten their big break working in New York productions. Outside New York City, many cities have professional regional or resident theater companies that produce their own seasons. The biggest-budget theatrical productions are musicals. U.S. theater has an active community theater culture.[467]  The Tony Awards recognizes excellence in live Broadway theatre and are presented at an annual ceremony in Manhattan. The awards are given for Broadway productions and performances. One is also given for regional theatre. Several discretionary non-competitive awards are given as well, including a Special Tony Award, the Tony Honors for Excellence in Theatre, and the Isabelle Stevenson Award.[468]  In the visual arts, the Hudson River School was a mid-19th-century movement in the tradition of European naturalism. The 1913 Armory Show in New York City, an exhibition of European modernist art, shocked the public and transformed the U.S. art scene.[470]  Georgia O'Keeffe, Marsden Hartley, and others experimented with new and individualistic styles, which would become known as American modernism. Major artistic movements such as the abstract expressionism of Jackson Pollock and Willem de Kooning and the pop art of Andy Warhol and Roy Lichtenstein developed largely in the United States. Major photographers include Alfred Stieglitz, Edward Steichen, Dorothea Lange, Edward Weston, James Van Der Zee, Ansel Adams, and Gordon Parks.[471]  The tide of modernism and then postmodernism has brought global fame to American architects, including Frank Lloyd Wright, Philip Johnson, and Frank Gehry.[472] The Metropolitan Museum of Art in Manhattan is the largest art museum in the United States.[473]  American folk music encompasses numerous music genres, variously known as traditional music, traditional folk music, contemporary folk music, or roots music. Many traditional songs have been sung within the same family or folk group for generations, and sometimes trace back to such origins as the British Isles, Mainland Europe, or Africa.[474] The rhythmic and lyrical styles of African-American music in particular have influenced American music.[475] Banjos were brought to America through the slave trade. Minstrel shows incorporating the instrument into their acts led to its increased popularity and widespread production in the 19th century.[476][477] The electric guitar, first invented in the 1930s, and mass-produced by the 1940s, had an enormous influence on popular music, in particular due to the development of rock and roll.[478]  Elements from folk idioms such as the blues and old-time music were adopted and transformed into popular genres with global audiences. Jazz grew from blues and ragtime in the early 20th century, developing from the innovations and recordings of composers such as W.C. Handy and Jelly Roll Morton. Louis Armstrong and Duke Ellington increased its popularity early in the 20th century.[479] Country music developed in the 1920s,[480] rock and roll in the 1930s,[478] and bluegrass[481] and rhythm and blues in the 1940s.[482] In the 1960s, Bob Dylan emerged from the folk revival to become one of the country's most celebrated songwriters.[483] The musical forms of punk and hip hop both originated in the United States in the 1970s.[484]  The United States has the world's largest music market with a total retail value of $15.9 billion in 2022.[485] Most of the world's major record companies are based in the U.S.; they are represented by the Recording Industry Association of America (RIAA).[486] Mid-20th-century American pop stars, such as Frank Sinatra[487] and Elvis Presley,[488] became global celebrities and best-selling music artists,[479] as have artists of the late 20th century, such as Michael Jackson,[489] Madonna,[490] Whitney Houston,[491] and Prince,[492] and of early 21st century such as Taylor Swift and Beyonc\u00e9.[493]  The United States and China collectively account for the majority of global apparel demand. Apart from professional business attire, American fashion is eclectic and predominantly informal. While Americans' diverse cultural roots are reflected in their clothing, sneakers, jeans, T-shirts, and baseball caps are emblematic of American styles.[494] New York is considered to be one of the \"big four\" global fashion capitals, along with Paris, Milan, and London. A study demonstrated that general proximity to Manhattan's Garment District has been synonymous with American fashion since its inception in the early 20th century.[495]  The headquarters of many designer labels reside in Manhattan. Labels cater to niche markets, such as pre teens. There has been a trend in the United States fashion towards sustainable clothing.[496] New York Fashion Week is one of the most influential fashion weeks in the world, and occurs twice a year.[497]  The U.S. film industry has a worldwide influence and following. Hollywood, a district in northern Los Angeles, the nation's second-most populous city, is also metonymous for the American filmmaking industry, the third-largest in the world, following India and Nigeria.[498][499][500] The major film studios of the United States are the primary source of the most commercially successful and most ticket-selling movies in the world.[501][502] Since the early 20th century, the U.S. film industry has largely been based in and around Hollywood, although in the 21st century an increasing number of films are not made there, and film companies have been subject to the forces of globalization.[503] The Academy Awards, popularly known as the Oscars, have been held annually by the Academy of Motion Picture Arts and Sciences since 1929,[504] and the Golden Globe Awards have been held annually since January 1944.[505]  The industry enjoyed its golden years, in what is commonly referred to as the \"Golden Age of Hollywood\", from the early sound period until the early 1960s,[506] with screen actors such as John Wayne and Marilyn Monroe becoming iconic figures.[507][508] In the 1970s, \"New Hollywood\" or the \"Hollywood Renaissance\"[509] was defined by grittier films influenced by French and Italian realist pictures of the post-war period.[510] The 21st century was marked by the rise of American streaming platforms, which came to rival traditional cinema.[511][512]  Early settlers were introduced by Native Americans to foods such as turkey, sweet potatoes, corn, squash, and maple syrup. Of the most enduring and pervasive examples are variations of the native dish called succotash. Early settlers and later immigrants combined these with foods they were familiar with, such as wheat flour,[513] beef, and milk to create a distinctive American cuisine.[514][515] New World crops, especially pumpkin, corn, potatoes, and turkey as the main course are part of a shared national menu on Thanksgiving, when many Americans prepare or purchase traditional dishes to celebrate the occasion.[516]  Characteristic American dishes such as apple pie, fried chicken, doughnuts, french fries, macaroni and cheese, ice cream, pizza, hamburgers, and hot dogs derive from the recipes of various immigrant groups.[517][518][519][520] Mexican dishes such as burritos and tacos preexisted the United States in areas later annexed from Mexico, and adaptations of Chinese cuisine as well as pasta dishes freely adapted from Italian sources are all widely consumed.[521] American chefs have had a significant impact on society both domestically and internationally. In 1946, the Culinary Institute of America was founded by Katharine Angell and Frances Roth. This would become the United States' most prestigious culinary school, where many of the most talented American chefs would study prior to successful careers.[522][523]  The United States restaurant industry was projected at $899 billion in sales for 2020,[524][525] and employed more than 15 million people, representing 10% of the nation's workforce directly.[524] It is the country's second-largest private employer and the third-largest employer overall.[526][527] The United States is home to over 220 Michelin Star rated restaurants, 70 of which are in New York City alone.[528] Wine has been produced in what is now the United States since the 1500s, with the first widespread production beginning in what is now New Mexico in 1628.[529][530][531] Today, wine production is undertaken in all fifty states, with California producing 84 percent of all US wine. With more than 1,100,000 acres (4,500\u00a0km2) under vine, the United States is the fourth-largest wine producing country in the world, after Italy, Spain, and France.[532][533]  The American fast-food industry, the world's first and largest, pioneered the drive-through format in the 1940s[534] and is often viewed as being a symbol of U.S. marketing dominance. American companies such as McDonald's,[535] Burger King, Pizza Hut, Kentucky Fried Chicken, and Domino's Pizza, among many others, have numerous outlets around the world.[536]  The most popular spectator sports in the U.S. are American football, basketball, baseball, soccer, and ice hockey.[537] While most major U.S. sports such as baseball and American football have evolved out of European practices, basketball, volleyball, skateboarding, and snowboarding are American inventions, many of which have become popular worldwide.[538] Lacrosse and surfing arose from Native American and Native Hawaiian activities that predate European contact.[539] The market for professional sports in the United States was approximately $69\u00a0billion in July 2013, roughly 50% larger than that of all of Europe, the Middle East, and Africa combined.[540]  American football is by several measures the most popular spectator sport in the United States;[541] the National Football League has the highest average attendance of any sports league in the world, and the Super Bowl is watched by tens of millions globally.[542] However, baseball has been regarded as the U.S. \"national sport\" since the late 19th century. After American football, the next four most popular professional team sports are basketball, baseball, soccer, and ice hockey. Their premier leagues are, respectively, the National Basketball Association, Major League Baseball, Major League Soccer, and the National Hockey League. The most-watched individual sports in the U.S. are golf and auto racing, particularly NASCAR and IndyCar.[543][544]  On the collegiate level, earnings for the member institutions exceed $1 billion annually,[545] and college football and basketball attract large audiences, as the NCAA March Madness tournament and the College Football Playoff are some of the most watched national sporting events.[546] In the U.S., the intercollegiate sports level serves as a feeder system for professional sports. This differs greatly from practices in nearly all other countries, where publicly and privately funded sports organizations serve this function.[547]  Eight Olympic Games have taken place in the United States. The 1904 Summer Olympics in St. Louis, Missouri, were the first-ever Olympic Games held outside of Europe.[548] The Olympic Games will be held in the U.S. for a ninth time when Los Angeles hosts the 2028 Summer Olympics. U.S. athletes have won a total of 2,959 medals (1,173 gold) at the Olympic Games, the most of any country.[549][550][551]  In international competition, the U.S. men's national soccer team has qualified for eleven World Cups, while the women's national team has won the FIFA Women's World Cup and Olympic soccer tournament four times each.[552] The United States hosted the 1994 FIFA World Cup and will co-host, along with Canada and Mexico, the 2026 FIFA World Cup.[553] The 1999 FIFA Women's World Cup was also hosted by the United States. Its final match was watched by 90,185, setting the world record for most-attended women's sporting event.[554]    40\u00b0N 100\u00b0W\ufeff \/ \ufeff40\u00b0N 100\u00b0W\ufeff \/ 40; -100\ufeff (United States of America) "},{"title":"Football pitch","content":"  A football pitch (also known as a soccer field in the United States)[1] is the playing surface for the game of association football. Its dimensions and markings are defined by Law 1 of the Laws of the Game, \"The Field of Play\".[2] The pitch is typically made of natural turf or artificial turf, although amateur and recreational teams often play on dirt fields. Artificial surfaces are allowed only to be green in colour.[2]  All line markings on the pitch form part of the area which they define. For example, a ball on or above the touchline is still on the field of play, and a foul committed over the line bounding the penalty area results in a penalty. Therefore, a ball has to completely cross the touchline to be out of play, and a ball has to fully cross the goal line (between the goal posts) in order for a goal to be scored; if any part of the ball is still on or above the line, a goal is not scored and the ball is still in play.[3]  The field descriptions that apply to adult matches are described below. Because of the role of the British football associations in the history of the game, the dimensions of the field of play were originally formulated and expressed in imperial units.  Since 1999, the Laws of the Game have preferred metric units, with imperial equivalents given only in brackets.  Because the actual values have, in general, not changed since the early twentieth century, they tend to be round numbers in imperial units (for example the width of the goal, unchanged since 1863, is 8 yards (7.32 metres)). Use of the imperial values remains common, especially in the United Kingdom.[citation needed]  The pitch is rectangular in shape. The shorter sides are called goal lines and the longer sides are called the touchlines. The two goal lines are between 50 and 100 yards (46 and 91 metres) wide and have to be of the same length.[4] The two touchlines are between 100 and 130 yards (91 and 119 metres) long and have to be of the same length.[4] All lines on the ground are equally wide, not to exceed 12 centimetres (5 inches).[4] The corners of the pitch are marked by corner flags.[5]  For international matches the field dimensions are more tightly constrained; the goal lines are between 70 and 80 yards (64 and 75 metres) wide and the touchlines are between 110 and 120 yards (100 and 110 metres) long.[4] The majority of top-level professional football pitches, including those belonging to teams in the English Premier League, measure 112 to 115 yards (102.4 to 105.2 metres) long and 70 to 75 yards (64.0 to 68.6 metres) wide.[6]  Although the term goal line is often taken to mean only that part of the line between the goalposts, in fact it refers to the complete line at either end of the pitch, from one corner flag to the other. In contrast the term byline (or by-line) is often used to refer to that portion of the goal line outside the goalposts. This term is commonly used in football commentaries and match descriptions.[7]  Goals are placed at the centre of each goal-line.[8] These consist of two upright posts placed equidistant from the corner flagposts, joined at the top by a horizontal crossbar. The inner edges of the posts are regulated to be 8 yards (7.32 metres) (wide) apart, and the lower edge of the crossbar is elevated to 8 feet (2.44 metres) above the pitch. As a result, the area that players shoot at is 192 square feet (17.84 square metres).[9] Nets are usually placed behind the goal, though are not required by the Laws.[citation needed]  Goalposts and crossbars have to be white and made of wood, metal or other approved material. Rules regarding the shape of goalposts and crossbars are somewhat more lenient, but they have to conform to a shape that does not pose a threat to players. Despite this, injuries due to goalpost collisions are still quite common, and not much research goes into this aspect of player safety.[citation needed]  Recent developments in material science, however, have shown that there are a variety of materials that can be used to coat goalposts to reduce impact on players, hence improving safety. The majority of these materials come from various mixtures of polymers with desirable properties. An example of this would be a mixture made of 63% by weight of methyl methacrylate, 32% by weight of polyethylene glycol, crosslinked with 5% by weight of ethylene glycol dimethacrylate. This has up to a 99% shape recovery rate with very heavy impacts (such as that of a high speed player hitting the post), and deform significantly enough so as to reduce the impact on the player. This significantly improves player safety, while sacrificing very little in terms of function of the goal post.[citation needed]  A goal is scored when the ball fully crosses the goal line between the goal-posts and beneath the crossbar, even if a defending player last touched the ball before it crossed the goal line (see own goal). A goal may, however, be ruled illegal (and void by the referee) if the player who scored or a member of their team commits an offence under any of the laws between the time the ball was previously out of play and the goal being scored. It is also deemed void if a player on the opposing team commits an offence before the ball has passed the line, as in the case of fouls being committed, a penalty awarded but the ball continued on a path that caused it to cross the goal line.[citation needed]  The football goal size for a junior match goal is approximately half the size of an adult sized match goal.[10]  Football goals were first described in England in the late 16th and early 17th centuries. In 1584 and 1602 respectively, John Norden and Richard Carew referred to \"goals\" in Cornish hurling. Carew described how goals were made: \"they pitch two bushes in the ground, some eight or ten foote asunder; and directly against them, ten or twelue [twelve] score off, other twayne in like distance, which they terme their Goales\".[11] The first reference to scoring a goal is in John Day's play The Blind Beggar of Bethnal Green (performed circa 1600; published 1659). Similarly in a poem in 1613, Michael Drayton refers to \"when the Ball to throw, And drive it to the Gole, in squadrons forth they goe\". Solid crossbars were first introduced by the Sheffield Rules. Football nets were invented by Liverpool engineer John Brodie in 1891,[12] and they were a necessary help for discussions about whether or not a goal had been scored.[13]  Two rectangular boxes are marked out on the pitch in front of each goal.[4]  The goal area (colloquially the \"six-yard box\"), consists of the rectangle formed by the goal-line, two lines starting on the goal-line 6 yards (5.49 metres) from the goalposts and extending 6 yards (5.49 metres) into the pitch from the goal-line, and the line joining these, i.e. they are a rectangle 6 yards (5.49 metres) by 20 yards (18.29 metres). Goal kicks and any free kick by the defending team may be taken from anywhere in this area. FIFA's laws of the game stipulates that: \"All free kicks are taken from the place where the offence occurred, except: indirect free kicks to the attacking team for an offence inside the opponents' goal area are taken from the nearest point on the goal area line which runs parallel to the goal line, and free kicks to the defending team in their goal area may be taken from anywhere in that area.\"[14]  The penalty area (colloquially \"the 18-yard box\" or just \"the box\") is similarly formed by the goal-line and lines extending from it, but its lines start 18 yards (16.46 metres) from the goalposts and extend 18 yards (16.46 metres) into the field. i.e. this is a rectangle 44 yards (40.23 metres) by 18 yards (16.46 metres).  This area has a number of functions, the most prominent being to denote where the goalkeeper may handle the ball and where a foul by a defender, usually punished by a direct free kick, becomes punishable by a penalty kick. Both the goal and penalty areas were formed as semicircles until 1902.[13]  The penalty mark (colloquially \"the penalty spot\" or just \"the spot\") is 12 yards (10.97 metres) in front of the very centre of the goal: this is the point from where penalty kicks are taken.[citation needed]  The penalty arc (colloquially \"the D\") is marked from the outside edge of the penalty area, 10 yards (9.14 metres) from the penalty mark; this, along with the penalty area, marks an exclusion zone for all players other than the penalty kicker and defending goalkeeper during a penalty kick.[15]  The centre circle is marked at 10 yards (9.14 metres) from the centre mark. Similar to the penalty arc, this indicates the minimum distance that opposing players have to keep at kick-off; the ball itself is placed on the centre mark.[13] During penalty shootouts all players other than the two goalkeepers and the current kicker are required to remain within this circle.[citation needed]  The half-way line divides the pitch in two. The half which a team defends is commonly referred to as being their half. Players have to be located within their own half at a kick-off and may not be penalised as being offside in their own half. The intersections between the half-way line and the touchline can be indicated with flags like those marking the corners \u2013 the laws consider this as an optional feature.[5]  The arcs in the corners denote the area (within 1 yard (0.91 metres) of the corner) in which the ball has to be placed for corner kicks; opposition players have to be 10 yards (9.14 metres) away during a corner, and there may be optional lines off-pitch 10 yards (9.14 metres) away from the corner arc on the goal- and touch-lines to help gauge these distances.[8]  Grass is the normal surface of play, although artificial turf may sometimes be used especially in locations where maintenance of grass may be difficult due to inclement weather. This may include areas where it is very wet, causing the grass to deteriorate rapidly; where it is very dry, causing the grass to die; and where the turf is under heavy use. Artificial turf pitches are also increasingly common in the Nordic countries, due to the amount of snow during the winter months. The strain put on grass pitches by the cold climate and subsequent snow clearing has necessitated the installation of artificial turf in the stadia of many top-tier clubs in Norway, Sweden and Finland. The latest artificial surfaces use rubber crumbs, as opposed to the previous system of sand infill. Some leagues and football associations have specifically prohibited artificial surfaces due to injury concerns and require teams' home stadia to have grass pitches. All artificial turf has to be green and also meet the requirements specified in the FIFA Quality Concept for Football Turf.[16][17][18]  Football can also be played on a dirt or gravel field. In most parts of the world dirt is used only for casual recreational play.[citation needed]  In the winter the pitch may be used for bandy (similar to ice hockey) by being filled with water which is allowed to freeze.[citation needed] "},{"title":"Football","content":"  Football is a family of team sports that involve, to varying degrees, kicking a ball to score a goal.  Unqualified, the word football normally means the form of football that is the most popular where the word is used. Sports commonly called football include association football (known as soccer in Australia, Canada, South Africa, the United States, and sometimes in Ireland and New Zealand); Australian rules football; Gaelic football; gridiron football (specifically American football, Arena football, or Canadian football); International rules football; rugby league football; and rugby union football.[1] These various forms of football share, to varying degrees, common origins and are known as \"football codes\".  There are a number of references to traditional, ancient, or prehistoric ball games played in many different parts of the world.[2][3][4] Contemporary codes of football can be traced back to the codification of these games at English public schools during the 19th century, itself an outgrowth of medieval football.[5][6] The expansion and cultural power of the British Empire allowed these rules of football to spread to areas of British influence outside the directly controlled Empire.[7] By the end of the 19th century, distinct regional codes were already developing: Gaelic football, for example, deliberately incorporated the rules of local traditional football games in order to maintain their heritage.[8] In 1888, the Football League was founded in England, becoming the first of many professional football associations. During the 20th century, several of the various kinds of football grew to become some of the most popular team sports in the world.[9]  The various codes of football share certain common elements and can be grouped into two main classes of football: carrying codes like American football, Canadian football, Australian football, rugby union and rugby league, where the ball is moved about the field while being held in the hands or thrown, and kicking codes such as association football and Gaelic football, where the ball is moved primarily with the feet, and where handling is strictly limited.[10]  Common rules among the sports include:[11]  In all codes, common skills include passing, tackling, evasion of tackles, catching and kicking.[10] In most codes, there are rules restricting the movement of players offside, and players scoring a goal must put the ball either under or over a crossbar between the goalposts.  There are conflicting explanations of the origin of the word \"football\".  It is widely assumed that the word \"football\" (or the phrase \"foot ball\") refers to the action of the foot kicking a ball.[12] There is an alternative explanation, which is that football originally referred to a variety of games in medieval Europe that were played on foot.[13] There is no conclusive evidence for either explanation.  The Chinese competitive game cuju.[14] It existed during the Han dynasty and possibly the Qin dynasty, in the second and third centuries BC, attested by descriptions in a military manual.[15][16] The game consisted on passsing the ball to each other without touching the floor, in its competitive version two teams had to pass the ball without touching to finally kick the ball throught a circular hole placed in the middle of the pitch but unlike association football the two teams didn't interact with each other and stayed in different sides of the pitch like volleyball. [17]. The Japanese version of cuju is kemari (\u8e74\u97a0), and was developed during the Asuka period.[18] This is known to have been played within the Japanese imperial court in Kyoto from about 600\u00a0AD. In kemari, several people stand in a circle and kick a ball to each other, trying not to let the ball drop to the ground (much like keepie uppie).  The Ancient Greeks and Romans are known to have played many ball games, some of which involved the use of the feet. The Roman game harpastum is believed to have been adapted from a Greek team game known as \"\u1f10\u03c0\u03af\u03c3\u03ba\u03c5\u03c1\u03bf\u03c2\" (Episkyros)[19][20] or \"\u03c6\u03b1\u03b9\u03bd\u03af\u03bd\u03b4\u03b1\" (phaininda),[21] which is mentioned by a Greek playwright, Antiphanes (388\u2013311\u00a0BC) and later referred to by the Christian theologian Clement of Alexandria (c.\u2009150 \u2013 c.\u2009215 AD). These games appear to have resembled rugby football.[22][23][24][25][26] The Roman politician Cicero (106\u201343\u00a0BC) describes the case of a man who was killed whilst having a shave when a ball was kicked into a barber's shop. Roman ball games already knew the air-filled ball, the follis.[27][28] Episkyros is described as an early form of football by FIFA.[29]  There are a number of references to traditional, ancient, or prehistoric ball games, played by indigenous peoples in many different parts of the world. For example, in 1586, men from a ship commanded by an English explorer named John Davis went ashore to play a form of football with Inuit in Greenland.[30] There are later accounts of an Inuit game played on ice, called Aqsaqtuk. Each match began with two teams facing each other in parallel lines, before attempting to kick the ball through each other team's line and then at a goal. In 1610, William Strachey, a colonist at Jamestown, Virginia recorded a game played by Native Americans, called Pahsaheman.[citation needed] Pasuckuakohowog, a game similar to modern-day association football played amongst Amerindians, was also reported as early as the 17th century.  Games played in Mesoamerica with rubber balls by indigenous peoples are also well-documented as existing since before this time, but these had more similarities to basketball or volleyball, and no links have been found between such games and modern football sports. Northeastern American Indians, especially the Iroquois Confederation, played a game which made use of net racquets to throw and catch a small ball; however, although it is a ball-goal foot game, lacrosse (as its modern descendant is called) is likewise not usually classed as a form of \"football\".[citation needed]  On the Australian continent several tribes of indigenous people played kicking and catching games with stuffed balls which have been generalised by historians as Marn Grook (Djab Wurrung for \"game ball\"). The earliest historical account is an anecdote from the 1878 book by Robert Brough-Smyth, The Aborigines of Victoria, in which a man called Richard Thomas is quoted as saying, in about 1841 in Victoria, Australia, that he had witnessed Aboriginal people playing the game: \"Mr Thomas describes how the foremost player will drop kick a ball made from the skin of a possum and how other players leap into the air in order to catch it.\" Some historians have theorised that Marn Grook was one of the origins of Australian rules football.  The M\u0101ori in New Zealand played a game called K\u012b-o-rahi consisting of teams of seven players play on a circular field divided into zones, and score points by touching the 'pou' (boundary markers) and hitting a central 'tupu' or target.[citation needed]  These games and others may well go far back into antiquity. However, the main sources of modern football codes appear to lie in western Europe, especially England.  Mahmud al-Kashgari in his D\u012bw\u0101n Lugh\u0101t al-Turk, described a game called \"tepuk\" among Turks in Central and East Asia. In the game, people try to attack each other's castle by kicking a ball made of sheep leather.[31]  The Middle Ages saw a huge rise in popularity of annual Shrovetide football matches throughout Europe, particularly in England. An early reference to a ball game played in Britain comes from the 9th-century Historia Brittonum, attributed to Nennius, which describes \"a party of boys ... playing at ball\".[32] References to a ball game played in northern France known as La Soule or Choule, in which the ball was propelled by hands, feet, and sticks,[33] date from the 12th century.[34]  The early forms of football played in England, sometimes referred to as \"mob football\", would be played in towns or between neighbouring villages, involving an unlimited number of players on opposing teams who would clash en masse,[35] struggling to move an item, such as inflated animal's bladder[36] to particular geographical points, such as their opponents' church, with play taking place in the open space between neighbouring parishes.[37] The game was played primarily during significant religious festivals, such as Shrovetide, Christmas, or Easter,[36] and Shrovetide games have survived into the modern era in a number of English towns (see below).  The first detailed description of what was almost certainly football in England was given by William FitzStephen in about 1174\u20131183. He described the activities of London youths during the annual festival of Shrove Tuesday:  After lunch all the youth of the city go out into the fields to take part in a ball game. The students of each school have their own ball; the workers from each city craft are also carrying their balls. Older citizens, fathers, and wealthy citizens come on horseback to watch their juniors competing, and to relive their own youth vicariously: you can see their inner passions aroused as they watch the action and get caught up in the fun being had by the carefree adolescents.[38] Most of the very early references to the game speak simply of \"ball play\" or \"playing at ball\". This reinforces the idea that the games played at the time did not necessarily involve a ball being kicked.  An early reference to a ball game that was probably football comes from 1280 at Ulgham, Northumberland, England:  \"Henry... while playing at ball.. ran against David\".[39] Football was played in Ireland in 1308, with a documented reference to John McCrocan, a spectator at a \"football game\" at Newcastle, County Down being charged with accidentally stabbing a player named William Bernard.[40] Another reference to a football game comes in 1321 at Shouldham, Norfolk, England: \"[d]uring the game at ball as he kicked the ball, a lay friend of his... ran against him and wounded himself\".[39]  In 1314, Nicholas de Farndone, Lord Mayor of the City of London issued a decree banning football in the French used by the English upper classes at the time. A translation reads: \"[f]orasmuch as there is great noise in the city caused by hustling over large foot balls [rageries de grosses pelotes de pee][41] in the fields of the public from which many evils might arise which God forbid: we command and forbid on behalf of the king, on pain of imprisonment, such game to be used in the city in the future.\" This is the earliest reference to football.  In 1363, King Edward III of England issued a proclamation banning \"...handball, football, or hockey; coursing and cock-fighting, or other such idle games\",[42] showing that \"football\" \u2013 whatever its exact form in this case \u2013 was being differentiated from games involving other parts of the body, such as handball.  A game known as \"football\" was played in Scotland as early as the 15th century: it was prohibited by the Football Act 1424 and although the law fell into disuse it was not repealed until 1906. There is evidence for schoolboys playing a \"football\" ball game in Aberdeen in 1633 (some references cite 1636) which is notable as an early allusion to what some have considered to be passing the ball. The word \"pass\" in the most recent translation is derived from \"huc percute\" (strike it here) and later \"repercute pilam\" (strike the ball again) in the original Latin. It is not certain that the ball was being struck between members of the same team. The original word translated as \"goal\" is \"metum\", literally meaning the \"pillar at each end of the circus course\" in a Roman chariot race. There is a reference to \"get hold of the ball before [another player] does\" (Praeripe illi pilam si possis agere) suggesting that handling of the ball was allowed. One sentence states in the original 1930 translation \"Throw yourself against him\" (Age, objice te illi).  King Henry IV of England also presented one of the earliest documented uses of the English word \"football\", in 1409, when he issued a proclamation forbidding the levying of money for \"foteball\".[39][43]  There is also an account in Latin from the end of the 15th century of football being played at Caunton, Nottinghamshire. This is the first description of a \"kicking game\" and the first description of dribbling: \"[t]he game at which they had met for common recreation is called by some the foot-ball game. It is one in which young men, in country sport, propel a huge ball not by throwing it into the air but by striking it and rolling it along the ground, and that not with their hands but with their feet... kicking in opposite directions.\" The chronicler gives the earliest reference to a football pitch, stating that: \"[t]he boundaries have been marked and the game had started.[39]  Other firsts in the medieval and early modern eras:  In the 16th century, the city of Florence celebrated the period between Epiphany and Lent by playing a game which today is known as \"calcio storico\" (\"historic kickball\") in the Piazza Santa Croce.[47] The young aristocrats of the city would dress up in fine silk costumes and embroil themselves in a violent form of football. For example, calcio players could punch, shoulder charge, and kick opponents. Blows below the belt were allowed. The game is said to have originated as a military training exercise. In 1580, Count Giovanni de' Bardi di Vernio wrote Discorso sopra 'l giuoco del Calcio Fiorentino. This is sometimes said to be the earliest code of rules for any football game. The game was not played after January 1739 (until it was revived in May 1930).  There have been many attempts to ban football, from the Middle Ages through to the modern day. The first such law was passed in England in 1314; it was followed by more than 30 in England alone between 1314 and 1667.[48]:\u200a6\u200a Women were banned from playing at English and Scottish Football League grounds in 1921, a ban that was only lifted in the 1970s. Female footballers still face similar problems in some parts of the world.  American football also faced pressures to ban the sport.  The game played in the 19th century resembled mob football that developed in medieval Europe, including a version popular on university campuses known as old division football, and several municipalities banned its play in the mid-19th century.[49][50] By the 20th century, the game had evolved to a more rugby style game.  In 1905, there were calls to ban American football in the U.S. due to its violence; a meeting that year was hosted by American president Theodore Roosevelt led to sweeping rules changes that caused the sport to diverge significantly from its rugby roots to become more like the sport as it is played today.[51]  While football continued to be played in various forms throughout Britain, its public schools (equivalent to private schools in other countries) are widely credited with four key achievements in the creation of modern football codes. First of all, the evidence suggests that they were important in taking football away from its \"mob\" form and turning it into an organised team sport. Second, many early descriptions of football and references to it were recorded by people who had studied at these schools. Third, it was teachers, students, and former students from these schools who first codified football games, to enable matches to be played between schools. Finally, it was at English public schools that the division between \"kicking\" and \"running\" (or \"carrying\") games first became clear.  The earliest evidence that games resembling football were being played at English public schools \u2013 mainly attended by boys from the upper, upper-middle and professional classes \u2013 comes from the Vulgaria by William Herman in 1519. Herman had been headmaster at Eton and Winchester colleges and his Latin textbook includes a translation exercise with the phrase \"We wyll playe with a ball full of wynde\".[52]  Richard Mulcaster, a student at Eton College in the early 16th century and later headmaster at other English schools, has been described as \"the greatest sixteenth Century advocate of football\".[53] Among his contributions are the earliest evidence of organised team football. Mulcaster's writings refer to teams (\"sides\" and \"parties\"), positions (\"standings\"), a referee (\"judge over the parties\") and a coach \"(trayning maister)\". Mulcaster's \"footeball\" had evolved from the disordered and violent forms of traditional football:  [s]ome smaller number with such overlooking, sorted into sides and standings, not meeting with their bodies so boisterously to trie their strength: nor shouldring or shuffing one an other so barbarously ... may use footeball for as much good to the body, by the chiefe use of the legges.[54] In 1633, David Wedderburn, a teacher from Aberdeen, mentioned elements of modern football games in a short Latin textbook called Vocabula. Wedderburn refers to what has been translated into modern English as \"keeping goal\" and makes an allusion to passing the ball (\"strike it here\"). There is a reference to \"get hold of the ball\", suggesting that some handling was allowed. It is clear that the tackles allowed included the charging and holding of opposing players (\"drive that man back\").[55]  A more detailed description of football is given in Francis Willughby's Book of Games, written in about 1660.[56] Willughby, who had studied at Bishop Vesey's Grammar School, Sutton Coldfield, is the first to describe goals and a distinct playing field: \"a close that has a gate at either end. The gates are called Goals.\" His book includes a diagram illustrating a football field. He also mentions tactics (\"leaving some of their best players to guard the goal\"); scoring (\"they that can strike the ball through their opponents' goal first win\") and the way teams were selected (\"the players being equally divided according to their strength and nimbleness\"). He is the first to describe a \"law\" of football: \"they must not strike [an opponent's leg] higher than the ball\".[57][58]  English public schools were the first to codify football games. In particular, they devised the first offside rules, during the late 18th century.[59] In the earliest manifestations of these rules, players were \"off their side\" if they simply stood between the ball and the goal which was their objective. Players were not allowed to pass the ball forward, either by foot or by hand. They could only dribble with their feet, or advance the ball in a scrum or similar formation. However, offside laws began to diverge and develop differently at each school, as is shown by the rules of football from Winchester, Rugby, Harrow and Cheltenham, during between 1810 and 1850.[59] The first known codes \u2013 in the sense of a set of rules \u2013 were those of Eton in 1815[60] and Aldenham in 1825.[60])  During the early 19th century, most working-class people in Britain had to work six days a week, often for over twelve hours a day. They had neither the time nor the inclination to engage in sport for recreation and, at the time, many children were part of the labour force. Feast day football played on the streets was in decline. Public school boys, who enjoyed some freedom from work, became the inventors of organised football games with formal codes of rules.  Football was adopted by a number of public schools as a way of encouraging competitiveness and keeping youths fit. Each school drafted its own rules, which varied widely between different schools and were changed over time with each new intake of pupils. Two schools of thought developed regarding rules. Some schools favoured a game in which the ball could be carried (as at Rugby, Marlborough and Cheltenham), while others preferred a game where kicking and dribbling the ball was promoted (as at Eton, Harrow, Westminster and Charterhouse). The division into these two camps was partly the result of circumstances in which the games were played. For example, Charterhouse and Westminster at the time had restricted playing areas; the boys were confined to playing their ball game within the school cloisters, making it difficult for them to adopt rough and tumble running games.[citation needed]  William Webb Ellis, a pupil at Rugby School, is said to have \"with a fine disregard for the rules of football, as played in his time [emphasis added], first took the ball in his arms and ran with it, thus creating the distinctive feature of the rugby game.\" in 1823. This act is usually said to be the beginning of Rugby football, but there is little evidence that it occurred, and most sports historians believe the story to be apocryphal. The act of 'taking the ball in his arms' is often misinterpreted as 'picking the ball up' as it is widely believed that Webb Ellis' 'crime' was handling the ball, as in modern association football, however handling the ball at the time was often permitted and in some cases compulsory,[61] the rule for which Webb Ellis showed disregard was running forward with it as the rules of his time only allowed a player to retreat backwards or kick forwards.  The boom in rail transport in Britain during the 1840s meant that people were able to travel farther and with less inconvenience than they ever had before. Inter-school sporting competitions became possible. However, it was difficult for schools to play each other at football, as each school played by its own rules. The solution to this problem was usually that the match be divided into two-halves, one half played by the rules of the host \"home\" school, and the other half by the visiting \"away\" school.  The modern rules of many football codes were formulated during the mid- or late- 19th century. This also applies to other sports such as lawn bowls, lawn tennis, etc. The major impetus for this was the patenting of the world's first lawnmower in 1830. This allowed for the preparation of modern ovals, playing fields, pitches, grass courts, etc.[62]  Apart from Rugby football, the public school codes have barely been played beyond the confines of each school's playing fields. However, many of them are still played at the schools which created them (see \u00a7\u00a0British schools).  Public schools' dominance of sports in the UK began to wane after the Factory Act of 1850, which significantly increased the recreation time available to working class children. Before 1850, many British children had to work six days a week, for more than twelve hours a day. From 1850, they could not work before 6\u00a0a.m. (7\u00a0a.m. in winter) or after 6\u00a0p.m. on weekdays (7\u00a0p.m. in winter); on Saturdays they had to cease work at 2\u00a0pm. These changes meant that working class children had more time for games, including various forms of football.  The earliest known matches between public schools are as follows:  Sports clubs dedicated to playing football began in the 18th century, for example London's Gymnastic Society which was founded in the mid-18th century and ceased playing matches in 1796.[66][64]  The first documented club to bear in the title a reference to being a 'football club' were called \"The Foot-Ball Club\" who were located in Edinburgh, Scotland, during the period 1824\u201341.[67][68] The club forbade tripping but allowed pushing and holding and the picking up of the ball.[68]  In 1845, three boys at Rugby school were tasked with codifying the rules then being used at the school. These were the first set of written rules (or code) for any form of football.[69] This further assisted the spread of the Rugby game.  The earliest known matches involving non-public school clubs or institutions are as follows:  One of the longest running football fixture is the Cordner-Eggleston Cup, contested between Melbourne Grammar School and Scotch College, Melbourne every year since 1858. It is believed by many to also be the first match of Australian rules football, although it was played under experimental rules in its first year. The first football trophy tournament was the Caledonian Challenge Cup, donated by the Royal Caledonian Society of Melbourne, played in 1861 under the Melbourne Rules.[81] The oldest football league is a rugby football competition, the United Hospitals Challenge Cup (1874), while the oldest rugby trophy is the Yorkshire Cup, contested since 1878. The South Australian Football Association (30 April 1877) is the oldest surviving Australian rules football competition. The oldest surviving soccer trophy is the Youdan Cup (1867) and the oldest national football competition is the English FA Cup (1871). The Football League (1888) is recognised as the longest running association football league. The first international Rugby football match took place between Scotland and England on 27 March 1871 at Raeburn Place, Edinburgh. The first international Association football match officially took place between sides representing England and Scotland on 30 November 1872 at Hamilton Crescent, the West of Scotland Cricket Club's ground in Partick, Glasgow under the authority of the FA.   In Europe, early footballs were made out of animal bladders, more specifically pig's bladders, which were inflated. Later leather coverings were introduced to allow the balls to keep their shape.[82] However, in 1851, Richard Lindon and William Gilbert, both shoemakers from the town of Rugby (near the school), exhibited both round and oval-shaped balls at the Great Exhibition in London. Richard Lindon's wife is said to have died of lung disease caused by blowing up pig's bladders.[a] Lindon also won medals for the invention of the \"Rubber inflatable Bladder\" and the \"Brass Hand Pump\".  In 1855, the U.S. inventor Charles Goodyear \u2013 who had patented vulcanised rubber \u2013 exhibited a spherical football, with an exterior of vulcanised rubber panels, at the Paris Exhibition Universelle. The ball was to prove popular in early forms of football in the U.S.[83]  The iconic ball with a regular pattern of hexagons and pentagons (see truncated icosahedron) did not become popular until the 1960s, and was first used in the World Cup in 1970.  The earliest reference to a game of football involving players passing the ball and attempting to score past a goalkeeper was written in 1633 by David Wedderburn, a poet and teacher in Aberdeen, Scotland.[84] Nevertheless, the original text does not state whether the allusion to passing as 'kick the ball back' ('repercute pilam') was in a forward or backward direction or between members of the same opposing teams (as was usual at this time).[85]  \"Scientific\" football is first recorded in 1839 from Lancashire[86] and in the modern game in rugby football from 1862[87] and from Sheffield FC as early as 1865.[88][89] The first side to play a passing combination game was the Royal Engineers AFC in 1869\/70.[90][91] By 1869 they were \"work[ing] well together\", \"backing up\" and benefiting from \"cooperation\".[92] By 1870 the Engineers were passing the ball: \"Lieut. Creswell, who having brought the ball up the side then kicked it into the middle to another of his side, who kicked it through the posts the minute before time was called\".[93] Passing was a regular feature of their style.[94] By early 1872 the Engineers were the first football team renowned for \"play[ing] beautifully together\".[95] A double pass is first reported from Derby school against Nottingham Forest in March 1872, the first of which is irrefutably a short pass: \"Mr Absey dribbling the ball half the length of the field delivered it to Wallis, who kicking it cleverly in front of the goal, sent it to the captain who drove it at once between the Nottingham posts\".[96] The first side to have perfected the modern formation was Cambridge University AFC;[97][98][99] they also introduced the 2\u20133\u20135 \"pyramid\" formation.[100][101]  Rugby football was thought to have been started about 1845 at Rugby School in Rugby, Warwickshire, England although forms of football in which the ball was carried and tossed date to medieval times. In Britain, by 1870, there were 49 clubs playing variations of the Rugby school game.[102] There were also \"rugby\" clubs in Ireland, Australia, Canada and New Zealand. However, there was no generally accepted set of rules for rugby until 1871, when 21 clubs from London came together to form the Rugby Football Union (RFU). The first official RFU rules were adopted in June 1871.[103] These rules allowed passing the ball. They also included the try, where touching the ball over the line allowed an attempt at goal, though drop-goals from marks and general play, and penalty conversions were still the main form of contest. Regardless of any form of football, the first international match between the national team of England and Scotland took place at Raeburn Place on 27 March 1871.  Rugby football split into Rugby union, Rugby league, American football, and Canadian football. Tom Wills played Rugby football in England before founding Australian rules football.  During the nineteenth century, several codifications of the rules of football were made at the University of Cambridge, in order to enable students from different public schools to play each other. The Cambridge Rules of 1863 influenced the decision of the Football Association to ban Rugby-style carrying of the ball in its own first set of laws.[104]  By the late 1850s, many football clubs had been formed throughout the English-speaking world, to play various codes of football. Sheffield Football Club, founded in 1857 in the English city of Sheffield by Nathaniel Creswick and William Prest, was later recognised as the world's oldest club playing association football.[105] However, the club initially played its own code of football: the Sheffield rules. The code was largely independent of the public school rules, the most significant difference being the lack of an offside rule.  The code was responsible for many innovations that later spread to association football. These included free kicks, corner kicks, handball, throw-ins and the crossbar.[106] By the 1870s they became the dominant code in the north and midlands of England. At this time, a series of rule changes by both the London and Sheffield FAs gradually eroded the differences between the two games until the adoption of a common code in 1877.  There is archival evidence of \"foot-ball\" games being played in various parts of Australia throughout the first half of the 19th century. The origins of an organised game of football known today as Australian rules football can be traced back to 1858 in Melbourne, the capital city of Victoria.  In July 1858, Tom Wills, an Australian-born cricketer educated at Rugby School in England, wrote a letter to Bell's Life in Victoria & Sporting Chronicle, calling for a \"foot-ball club\" with a \"code of laws\" to keep cricketers fit during winter.[107] This is considered by historians to be a defining moment in the creation of Australian rules football. Through publicity and personal contacts Wills was able to co-ordinate football matches in Melbourne that experimented with various rules,[108] the first of which was played on 31 July 1858. One week later, Wills umpired a schoolboys match between Melbourne Grammar School and Scotch College. Following these matches, organised football in Melbourne rapidly increased in popularity.  Wills and others involved in these early matches formed the Melbourne Football Club (the oldest surviving Australian football club) on 14 May 1859. Club members Wills, William Hammersley, J. B. Thompson and Thomas H. Smith met with the intention of forming a set of rules that would be widely adopted by other clubs. The committee debated rules used in English public school games; Wills pushed for various rugby football rules he learnt during his schooling. The first rules share similarities with these games, and were shaped to suit to Australian conditions. H. C. A. Harrison, a seminal figure in Australian football, recalled that his cousin Wills wanted \"a game of our own\".[109] The code was distinctive in the prevalence of the mark, free kick, tackling, lack of an offside rule and that players were specifically penalised for throwing the ball.  The Melbourne football rules were widely distributed and gradually adopted by the other Victorian clubs. The rules were updated several times during the 1860s to accommodate the rules of other influential Victorian football clubs. A significant redraft in 1866 by H. C. A. Harrison's committee accommodated the Geelong Football Club's rules, making the game then known as \"Victorian Rules\" increasingly distinct from other codes. It soon adopted cricket fields and an oval ball, used specialised goal and behind posts, and featured bouncing the ball while running and spectacular high marking. The game spread quickly to other Australian colonies. Outside its heartland in southern Australia, the code experienced a significant period of decline following World War I but has since grown throughout Australia and in other parts of the world, and the Australian Football League emerged as the dominant professional competition.  During the early 1860s, there were increasing attempts in England to unify and reconcile the various public school games. In 1862, J. C. Thring, who had been one of the driving forces behind the original Cambridge Rules, was a master at Uppingham School, and he issued his own rules of what he called \"The Simplest Game\" (these are also known as the Uppingham Rules). In early October 1863, another new revised version of the Cambridge Rules was drawn up by a seven member committee representing former pupils from Harrow, Shrewsbury, Eton, Rugby, Marlborough and Westminster.  At the Freemasons' Tavern, Great Queen Street, London on the evening of 26 October 1863, representatives of several football clubs in the London Metropolitan area met for the inaugural meeting of the Football Association (FA). The aim of the association was to establish a single unifying code and regulate the playing of the game among its members. Following the first meeting, the public schools were invited to join the association. All of them declined, except Charterhouse and Uppingham. In total, six meetings of the FA were held between October and December 1863. After the third meeting, a draft set of rules were published. However, at the beginning of the fourth meeting, attention was drawn to the recently published Cambridge Rules of 1863. The Cambridge rules differed from the draft FA rules in two significant areas; namely running with (carrying) the ball and hacking (kicking opposing players in the shins). The two contentious FA rules were as follows:  IX. A player shall be entitled to run with the ball towards his adversaries' goal if he makes a fair catch, or catches the ball on the first bound; but in case of a fair catch, if he makes his mark he shall not run. X. If any player shall run with the ball towards his adversaries' goal, any player on the opposite side shall be at liberty to charge, hold, trip or hack him, or to wrest the ball from him, but no player shall be held and hacked at the same time.[110] At the fifth meeting it was proposed that these two rules be removed. Most of the delegates supported this, but F. M. Campbell, the representative from Blackheath and the first FA treasurer, objected. He said: \"hacking is the true football\". However, the motion to ban running with the ball in hand and hacking was carried and Blackheath withdrew from the FA. After the final meeting on 8 December, the FA published the \"Laws of the Game\", the first comprehensive set of rules for the game later known as association football. The term \"soccer\", in use since the late 19th century, derives from an Oxford University abbreviation of \"association\".[111]  The first FA rules still contained elements that are no longer part of association football, but which are still recognisable in other games (such as Australian football and rugby football): for instance, a player could make a fair catch and claim a mark, which entitled him to a free kick; and if a player touched the ball behind the opponents' goal line, his side was entitled to a free kick at goal, from 15 yards (13.5 metres) in front of the goal line.  As was the case in Britain, by the early 19th century, North American schools and universities played their own local games, between sides made up of students. For example, students at Dartmouth College in New Hampshire played a game called Old division football, a variant of the association football codes, as early as the 1820s.[50] They remained largely \"mob football\" style games, with huge numbers of players attempting to advance the ball into a goal area, often by any means necessary. Rules were simple, violence and injury were common.[49] The violence of these mob-style games led to widespread protests and a decision to abandon them. Yale University, under pressure from the city of New Haven, banned the play of all forms of football in 1860, while Harvard University followed suit in 1861.[49] In its place, two general types of football evolved: \"kicking\" games and \"running\" (or \"carrying\") games. A hybrid of the two, known as the \"Boston game\", was played by a group known as the Oneida Football Club. The club, considered by some historians as the first formal football club in the United States, was formed in 1862 by schoolboys who played the Boston game on Boston Common.[49][112] The game began to return to American college campuses by the late 1860s. The universities of Yale, Princeton (then known as the College of New Jersey), Rutgers, and Brown all began playing \"kicking\" games during this time. In 1867, Princeton used rules based on those of the English Football Association.[49]  In Canada, the first documented football match was a practice game played on 9 November 1861, at University College, University of Toronto (approximately 400 yards west of Queen's Park). One of the participants in the game involving University of Toronto students was (Sir) William Mulock, later Chancellor of the school.[114] In 1864, at Trinity College, Toronto, F. Barlow Cumberland, Frederick A. Bethune, and Christopher Gwynn, one of the founders of Milton, Massachusetts, devised rules based on rugby football.[114] A \"running game\", resembling rugby football, was then taken up by the Montreal Football Club in Canada in 1868.[115]  On 6 November 1869, Rutgers faced Princeton in a game that was played with a round ball and, like all early games, used improvised rules. It is usually regarded as the first game of American intercollegiate football.[49][116]  Modern North American football grew out of a match between McGill University of Montreal and Harvard University in 1874. During the game, the two teams alternated between the rugby-based rules used by McGill and the Boston Game rules used by Harvard.[117][118][119] Within a few years, Harvard had both adopted McGill's rules and persuaded other U.S. university teams to do the same. On 23 November 1876, representatives from Harvard, Yale, Princeton, and Columbia met at the Massasoit Convention in Springfield, Massachusetts, agreeing to adopt most of the Rugby Football Union rules, with some variations.[120]  In 1880, Yale coach Walter Camp, who had become a fixture at the Massasoit House conventions where the rules were debated and changed, devised a number of major innovations. Camp's two most important rule changes that diverged the American game from rugby were replacing the scrummage with the line of scrimmage and the establishment of the down-and-distance rules.[120] American football still however remained a violent sport where collisions often led to serious injuries and sometimes even death.[121] This led U.S. President Theodore Roosevelt to hold a meeting with football representatives from Harvard, Yale, and Princeton on 9 October 1905, urging them to make drastic changes.[122] One rule change introduced in 1906, devised to open up the game and reduce injury, was the introduction of the legal forward pass. Though it was underutilised for years, this proved to be one of the most important rule changes in the establishment of the modern game.[123]  Over the years, Canada absorbed some of the developments in American football in an effort to distinguish it from a more rugby-oriented game. In 1903, the Ontario Rugby Football Union adopted the Burnside rules, which implemented the line of scrimmage and down-and-distance system from American football, among others.[124] Canadian football then implemented the legal forward pass in 1929.[125] American and Canadian football remain different codes, stemming from rule changes that the American side of the border adopted but the Canadian side has not.  In the mid-19th century, various traditional football games, referred to collectively as caid, remained popular in Ireland, especially in County Kerry. One observer, Father W. Ferris, described two main forms of caid during this period: the \"field game\" in which the object was to put the ball through arch-like goals, formed from the boughs of two trees; and the epic \"cross-country game\" which took up most of the daylight hours of a Sunday on which it was played, and was won by one team taking the ball across a parish boundary. \"Wrestling\", \"holding\" opposing players, and carrying the ball were all allowed.  By the 1870s, rugby and association football had started to become popular in Ireland. Trinity College Dublin was an early stronghold of rugby (see the Developments in the 1850s section above). The rules of the English FA were being distributed widely. Traditional forms of caid had begun to give way to a \"rough-and-tumble game\" which allowed tripping.  There was no serious attempt to unify and codify Irish varieties of football, until the establishment of the Gaelic Athletic Association (GAA) in 1884. The GAA sought to promote traditional Irish sports, such as hurling and to reject imported games like rugby and association football. The first Gaelic football rules were drawn up by Maurice Davin and published in the United Ireland magazine on 7 February 1887.[126] Davin's rules showed the influence of games such as hurling and a desire to formalise a distinctly Irish code of football. The prime example of this differentiation was the lack of an offside rule (an attribute which, for many years, was shared only by other Irish games like hurling, and by Australian rules football).  The International Rugby Football Board (IRFB) was founded in 1886,[127] but rifts were beginning to emerge in the code. Professionalism had already begun to creep into the various codes of football.  In England, by the 1890s, a long-standing Rugby Football Union ban on professional players was causing regional tensions within rugby football, as many players in northern England were working class and could not afford to take time off to train, travel, play and recover from injuries. This was not very different from what had occurred ten years earlier in soccer in Northern England but the authorities reacted very differently in the RFU, attempting to alienate the working class support in Northern England. In 1895, following a dispute about a player being paid broken time payments, which replaced wages lost as a result of playing rugby, representatives of the northern clubs met in Huddersfield to form the Northern Rugby Football Union (NRFU). The new body initially permitted only various types of player wage replacements. However, within two years, NRFU players could be paid, but they were required to have a job outside sport.  The demands of a professional league dictated that rugby had to become a better \"spectator\" sport. Within a few years the NRFU rules had started to diverge from the RFU, most notably with the abolition of the line-out. This was followed by the replacement of the ruck with the \"play-the-ball ruck\", which allowed a two-player ruck contest between the tackler at marker and the player tackled. Mauls were stopped once the ball carrier was held, being replaced by a play-the ball-ruck. The separate Lancashire and Yorkshire competitions of the NRFU merged in 1901, forming the Northern Rugby League, the first time the name rugby league was used officially in England.  Over time, the RFU form of rugby, played by clubs which remained members of national federations affiliated to the IRFB, became known as rugby union.  The need for a single body to oversee association football had become apparent by the beginning of the 20th century, with the increasing popularity of international fixtures. The English Football Association had chaired many discussions on setting up an international body, but was perceived as making no progress. It fell to associations from seven other European countries: France, Belgium, Denmark, Netherlands, Spain, Sweden, and Switzerland, to form an international association. The F\u00e9d\u00e9ration Internationale de Football Association (FIFA) was founded in Paris on 21 May 1904.[128] Its first president was Robert Gu\u00e9rin.[128] The French name and acronym has remained, even outside French-speaking countries.  Rugby league rules diverged significantly from rugby union in 1906, with the reduction of the team from 15 to 13 players. In 1907, a New Zealand professional rugby team toured Australia and Britain, receiving an enthusiastic response, and professional rugby leagues were launched in Australia the following year. However, the rules of professional games varied from one country to another, and negotiations between various national bodies were required to fix the exact rules for each international match. This situation endured until 1948, when at the instigation of the French league, the Rugby League International Federation (RLIF) was formed at a meeting in Bordeaux.  During the second half of the 20th century, the rules changed further. In 1966, rugby league officials borrowed the American football concept of downs: a team was allowed to retain possession of the ball for four tackles (rugby union retains the original rule that a player who is tackled and brought to the ground must release the ball immediately).  The maximum number of tackles was later increased to six (in 1971), and in rugby league this became known as the six tackle rule.  With the advent of full-time professionals in the early 1990s, and the consequent speeding up of the game, the five-metre off-side distance between the two teams became 10\u00a0metres, and the replacement rule was superseded by various interchange rules, among other changes.  The laws of rugby union also changed during the 20th century, although less significantly than those of rugby league. In particular, goals from marks were abolished, kicks directly into touch from outside the 22-metre line were penalised, new laws were put in place to determine who had possession following an inconclusive ruck or maul, and the lifting of players in line-outs was legalised.  In 1995, rugby union became an \"open\" game, that is one which allowed professional players.[129] Although the original dispute between the two codes has now disappeared \u2013 and despite the fact that officials from both forms of rugby football have sometimes mentioned the possibility of re-unification \u2013 the rules of both codes and their culture have diverged to such an extent that such an event is unlikely in the foreseeable future.  The word football, when used in reference to a specific game can mean any one of those described above. Because of this, much controversy has occurred over the term football, primarily because it is used in different ways in different parts of the English-speaking world. Most often, the word \"football\" is used to refer to the code of football that is considered dominant within a particular region (which is association football in most countries). So, effectively, what the word \"football\" means usually depends on where one says it.  In each of the United Kingdom, the United States, and Canada, one football code is known solely as \"football\", while the others generally require a qualifier. In New Zealand, \"football\" historically referred to rugby union, but more recently may be used unqualified to refer to association football. The sport meant by the word \"football\" in Australia is either Australian rules football or rugby league, depending on local popularity (which largely conforms to the Barassi Line). In francophone Quebec, where Canadian football is more popular, the Canadian code is known as le football while American football is known as le football am\u00e9ricain and association football is known as le soccer.[130]  Of the 45 national FIFA (F\u00e9d\u00e9ration Internationale de Football Association) affiliates in which English is an official or primary language, most currently use Football in their organisations' official names; the FIFA affiliates in Canada and the United States use Soccer in their names. A few FIFA affiliates have recently \"normalised\" to using \"Football\", including:  Several of the football codes are the most popular team sports in the world.[9] Globally, association football is played by over 250 million players in over 200 nations,[135] and has the highest television audience in sport,[136] making it the most popular in the world.[137] American football, with 1.1\u00a0million high school football players and nearly 70,000 college football players, is the most popular sport in the United States,[138][139] with the annual Super Bowl game accounting for nine of the top ten of the most watched broadcasts in U.S. television history.[140] The NFL has the highest average attendance (67,591) of any professional sports league in the world and has the highest revenue[141] out of any single professional sports league.[142] Thus, the best association football and American football players are among the highest paid athletes in the world.[143][144][145]  Australian rules football has the highest spectator attendance of all sports in Australia.[146][147] Similarly, Gaelic football is the most popular sport in Ireland in terms of match attendance,[148] and the All-Ireland Football Final is the most watched event of that nation's sporting year.[149]  Rugby union is the most popular sport in New Zealand, Samoa, Tonga, and Fiji.[150] It is also the fastest growing sport in the U.S.,[151][152][153][154] with college rugby being the fastest growing[clarification needed][155][156] college sport in that country.[157][dubious  \u2013 discuss]  These codes have in common the prohibition of the use of hands (by all players except the goalkeeper, though outfield players can \"throw-in\" the ball when it goes out of play), unlike other codes where carrying or handling the ball by all players is allowed  The hockey game bandy has rules partly based on the association football rules and is sometimes nicknamed as 'winter football'.  There are also motorsport variations of the game.  These codes have in common the ability of players to carry the ball with their hands, and to throw it to teammates, unlike association football where the use of hands during play is prohibited by anyone except the goalkeeper.  They also feature various methods of scoring based upon whether the ball is carried into the goal area, or kicked above the goalposts.  These codes have in common the absence of an offside rule, the prohibition of continuous carrying of the ball (requiring a periodic bounce or solo (toe-kick), depending on the code) while running, handpassing by punching or tapping the ball rather than throwing it, and other traditions.  Games still played at UK public (private) schools:  Although similar to football and volleyball in some aspects, Sepak takraw has ancient origins and cannot be considered a hybrid game. "},{"title":"Rugby football","content":"  Rugby football is the collective name for the team sports of rugby union or rugby league.  Rugby football started at Rugby School in Rugby, Warwickshire, England,[1] where the rules were first codified in 1845.[2] Forms of football in which the ball was carried and tossed date to the Middle Ages (see medieval football).[3] Rugby football spread to other English public schools in the 19th century and across the British Empire as former pupils continued to play it.  Rugby football split into two codes in 1895, when twenty-one clubs from the North of England left the Rugby Football Union to form the Northern Rugby Football Union (renamed the Rugby Football League in 1922) at the George Hotel, Huddersfield, over payments to players who took time off work to play (\"broken-time payments\"), thus making rugby league the first code to turn professional and pay players.[4] Rugby union turned professional one hundred years later, following the 1995 Rugby World Cup in South Africa.[5][6] The respective world governing bodies are World Rugby (rugby union) and the International Rugby League (rugby league).[7]  Canadian football and, to a lesser extent, American football were once considered forms of rugby football, but are seldom now referred to as such. The governing body of Canadian football, Football Canada, was known as the Canadian Rugby Union as late as 1967, more than fifty years after the sport parted ways with rugby rules.[8][9][10]  Following the 1895 split in rugby football, the two forms rugby league and rugby union differed in administration only. Soon the rules of rugby league were modified e.g. removing the line-out and replacing the ruck with the play-the-ball, resulting in two distinctly different forms of rugby.  The Olympic form of rugby is known as rugby sevens (based on rugby union format). In this form of the game, each team has seven players on the field at one time playing seven-minute halves. The rules and pitch size are the same as rugby union.[11]  Although rugby football was codified at Rugby School, many rugby playing countries had pre-existing football games similar to rugby.  Forms of traditional football similar to rugby have been played throughout Europe and beyond. Many of these involved handling of the ball, and scrummaging formations. For example, New Zealand had K\u012b-o-rahi, Australia marn grook, Japan kemari, Georgia lelo burti, the Scottish Borders Jeddart Ba' and Cornwall Cornish hurling, Central Italy Calcio Fiorentino, South Wales cnapan, East Anglia Campball, Ireland caid, an ancestor of Gaelic football, and France had La Soule.  In 1871, English clubs met to form the Rugby Football Union (RFU). In 1892, after charges of professionalism (compensation of team members) were made against some clubs for paying players for missing work, the Northern Rugby Football Union, usually called the Northern Union (NU), was formed.[12] The existing rugby union authorities responded by issuing sanctions against the clubs, players, and officials involved in the new organization. After the schism, the separate clubs were named \"rugby league\" and \"rugby union\".[13]  Walter Camp proposed at the US College Football 1880 rules convention that the contested scrummage be replaced with a \"line of scrimmage\" where the team with the ball started with uncontested possession. This change effectively started the evolution of the modern game of gridiron football away from its rugby origins.   Rugby union is both a professional and amateur game, and is dominated by the first tier unions:  New Zealand, Ireland, Wales, England, South Africa, Australia, Argentina, Scotland, Italy, France and Japan. Second and third tier unions include Belgium, Brazil, Canada, Chile, Fiji, Georgia, Germany, Hong Kong, Kenya, Namibia, the Netherlands, Portugal, Romania, Russia, Samoa, Spain, Tonga, the United States and Uruguay. Rugby Union is administered by World Rugby (WR), whose headquarters are located in Dublin, Ireland. It is the national sport in New Zealand, Fiji, Samoa, Tonga, Georgia, Wales and Madagascar, and is the most popular form of rugby globally.[20] The Olympic Games have admitted the seven-a-side version of the game, known as Rugby sevens, into the programme from Rio de Janeiro in 2016 onwards.[21] There was a possibility sevens would be a demonstration sport at the 2012 London Olympics but many sports including sevens were dropped.[22]  The premier international competition is the Rugby World Cup. Currently there are four major domestic professional leagues globally:  Rugby league is also both a professional and amateur game, administered on a global level by the Rugby League International Federation. In addition to amateur and semi-professional competitions in the United States, Russia, Lebanon, Serbia, Europe and Australasia, there are two major professional competitions\u2014the Australasian National Rugby League and the Super League. International Rugby League is dominated by Australia, England and New Zealand, though Tonga and Samoa have threatened this hegemony regularly since 2017. In Papua New Guinea, it is the national sport.[23][24][25] Other nations from the South Pacific and Europe also play in the Pacific Cup and European Cup respectively.  The premier international competition is the Rugby League World Cup, which is contested quadrennially. The premier international club comeptition is the World Club Challenge, which is contested annually in February. Currently there are two major domestic professional leagues globally:  In Canada and the United States, rugby developed into gridiron football. During the late 1800s (and even the early 1900s), the two forms of the game were very similar (to the point where the United States was able to win the gold medal for rugby union at the 1920 and 1924 Summer Olympics), but numerous rule changes have differentiated the gridiron-based game from its rugby counterpart, introduced by Walter Camp in the United States and John Thrift Meldrum Burnside in Canada. Among unique features of the North American game are   Worldwide, there are two major professional leagues of gridiron football, both domestic:  Distinctive features common to both rugby codes include the use of an oval ball and the prohibition of the forward pass. Due to the prohibition, players can gain ground only by running with the ball or by kicking it. Furthermore, unlike American and Canadian football, neither league nor union players wear any sort of protection or armour.   The two rugby codes differ as the result of changes made to the rules of rugby league. League implemented these changes with the aim of making a faster-paced and more try-oriented game than rugby union.   The main differences between the two games, besides league having teams of 13 players and union of 15, involve the tackle and its aftermath:  Set pieces of the union code include the scrum and the line-out. The scrum occurs after a minor infringement of the rules (most often a knock-on, when a player knocks the ball forward). After an infringement, packs of opposing players \"scrum\" or push against each other for possession. In a line-out, parallel lines of players from each team, arranged perpendicular to the touch-line, attempt to catch the ball thrown from touch. A rule has been added to line-outs which allows the jumper to be pulled down once a players' feet are on the ground.  In the league code, the scrum still exists albeit with greatly reduced importance. In league, the scrum involves fewer players and is rarely contested. Set pieces are generally started from the play-the-ball situation.   Many of the rugby league positions have names and requirements similar to rugby union positions. Notably, however, there are no flankers in rugby league.  In England, rugby union is widely regarded as an \"establishment\" sport, played mostly by members of the upper and middle classes. For example, many pupils at public schools and grammar schools play rugby union, although the game (which had a long history of being played at state schools until the 1980s) is becoming increasingly popular in comprehensive schools.[26] Despite this stereotype, the game, particularly in the West Country is popular amongst all classes. In contrast, rugby league has traditionally been seen as a working-class pursuit. Another exception to rugby union's upper-class stereotype is in Wales, where it has been traditionally associated with small village teams made up of coal miners and other industrial workers who played on their days off.[27] In Ireland, both rugby union and rugby league are unifying forces across the national and sectarian divide, with the Ireland international teams representing both political entities.  In Australia, support for both codes is concentrated in New South Wales, Queensland and the Australian Capital Territory (55% of the population), though rugby league is far more popular. The same perceived class barrier as exists between the two games in England also occurs in these states, fostered by rugby union's prominence and support at private schools.[28]  Exceptions to the above include New Zealand (although rugby league is still considered to be a lower class game by many or a game for 'westies' referring to lower class western suburbs of Auckland and more recently, southern Auckland where the game is also dominant), Wales, France (except Paris), Cornwall, Gloucestershire, Somerset, Scottish Borders, County Limerick (see Munster Rugby) and the Pacific Islands, where rugby union is popular in working class communities. Nevertheless, rugby league is perceived as the game of the working-class people in northern England[29] and in the Australian states of New South Wales and Queensland.[28]  In the United Kingdom, rugby union fans sometimes used the term \"rugger\" as an alternative name for the sport (see Oxford '-er'), although this archaic expression has not had currency since the 1950s or earlier.[30] New Zealanders refer to rugby union simply as either \"rugby\" or \"union\", or even simply \"football\", and to rugby league as \"rugby league\" or \"league\".[31] In the U.S., people who play rugby are sometimes called \"ruggers\", a term little used elsewhere except facetiously.  There is a strong tradition of rugby union in France, particularly in the Basque, Occitan and Catalan areas along the border with Spain. The game is very popular in South Africa, having been introduced by English-speaking settlers in the 19th century. British colonists also brought the game with them to Australia and New Zealand, where the game is widely played. It has spread since to much of Polynesia, having particularly strong followings in Fiji, Samoa, and Tonga. Rugby union continues to grow in the Americas and parts of Asia as well. French influence, and the influence of ex-pat students studying in France, expanded rugby's reach to Romania and Georgia which are the preeminent European nations behind the Six Nations Championship. British influence spread the game to Argentina, where the game took root, and the game developed in Italy thanks to influence from both France and Argentina; both Argentina and Italy have become Tier 1 nations in the sport, while Georgia. officially a Tier 2 nation, regularly ranks up with the Tier 1 countries.  About a quarter of rugby players are injured in each season.[32]  Being a high contact sport, rugby union has the highest announced rates of concussions[33] and outside England also has the highest number of catastrophic injuries[34] out of any team sport.[35][36] Research finding that during match play,[weasel\u00a0words] concussion was reported at a higher level, and during training at a lower level, but still at a higher level than most players of another sport to receive.[36]  A rugby ball is a diamond shape ball used for easier passing. Richard Lindon and Bernardo Solano started making balls for Rugby school out of hand stitched, four-panel, leather casings and pigs' bladders. The rugby ball's distinctive shape is supposedly due to the pig's bladder, although early balls were more plum-shaped than oval. The balls varied in size in the beginning depending upon how large the pig's bladder was.  In rugby union, World Rugby regulates the size and shape of the ball under Law 2 (also known as Law E.R.B); an official rugby union ball is oval and made of four panels, has a length in-line of 280\u2013300 millimetres, a circumference (end to end) of 740\u2013770 millimetres, and a circumference (in width) of 580\u2013620 millimetres. It is made of leather or suitable synthetic material and may be treated to make it water resistant and easier to grip. The rugby ball may not weigh more than 460\u00a0grams or less than 410 and has an air pressure of 65.71\u201368.75 kilopascals, or 0.67\u20130.70 kilograms per square centimetre, or 9.5\u201310.0\u00a0lbs per square inch.[37] Spare balls are allowed under the condition that players or teams do not seek an advantage by changing the ball. Smaller sized balls may also be used in games between younger players. Much larger versions of traditional balls are also available for purchase, but these are mainly for their novelty attraction.  The Rugby League World Cup was the first World Cup of either of the Rugby codes and was first held in France in 1954, and as of 2013 occurs on a 4-year cycle. It is an international tournament that is organized by the Rugby League International Federation. The event is played in the league format and features the top 16 teams from around the world. Australia won the 2017 Rugby League World Cup, played in Australia, New Zealand and Papua New Guinea. The Kangaroos backed this up by winning the 2021 tournament also.  The Rugby World Cup, which was first held in New Zealand and Australia in 1987, occurs every four years.  It is an international tournament organized by World Rugby. The event is played in the union format and features the top 20 teams from around the world. South Africa won the 2019 Rugby World Cup, which was played in Japan. Since 2013, the two World Cups alternate every two years during the four-year period.  Rugby shirts were formerly entirely made of cotton but are now made of synthetic fabric. This material has the advantage of not absorbing as much water or mud as cotton.[38]  Owing to the more aggressive nature of the game, rugby clothing, in general, is designed to be much more robust and hardwearing than that worn for association football.  The rugby jerseys are slightly different depending on the type of rugby game played. The shirts worn by rugby league footballers commonly have a large \"V\" around the neck. The players in rugby union wear jerseys with a more traditional design, sometimes completely white (Cahors Rugby in France). The number of the player and his or her surname are placed on the upper back of the jersey (often name above number, with the number being significantly larger and more central), and the logo of the team on the upper left chest.[citation needed]  With the popularity of rugby over the years, many betting establishments have made it possible for viewers of the game to place wagers on games.  The various types of wagers that can be placed on games vary, however, the main types of bets that can be placed are as follows:  Like most team sports, both forms of rugby are vulnerable to match-fixing, particularly bets involving easily manipulated outcomes such as conceding penalties and first point scorer. A recent example is a deliberate infringement by Ryan Tandy in order for the first points scored to be a penalty goal in a 2010 NRL match; the attempt backfired when instead of taking a shot at goal, a try was scored. "},{"title":"Hockey puck","content":"  A hockey puck is either an open or closed disk used in a variety of sports and games. There are designs made for use on an ice surface, such as in ice hockey, and others for the different variants of floor hockey which includes the wheeled skate variant of inline hockey (a.k.a. roller hockey). They are all designed to serve the same function a ball does in ball games.  A closed disk hockey puck having the shape of a short cylinder made of vulcanized rubber is used in the sport of ice hockey. Hockey pucks are designed for use on either an ice surface, dry floor, or underwater, though open disk designs have only been used on floors.[1]  Open disk hockey pucks have a hole, forming the shape of a toroid, for use in a particular style of floor hockey. They should not be confused with ringette rings, which are toruses, for use in the sport of ringette.  This article deals chiefly with the sport and game pucks which are closed disks.  The origin of the word puck is vague. The Oxford English Dictionary suggests the name is related to the verb to puck (a cognate of poke) used in the games of shinty and hurling for striking or pushing the ball, from the Scottish Gaelic puc or the Irish poc, meaning \"to poke, punch or deliver a blow\":[2][3]  It is possible that settlers of Nova Scotia, many of whom were Scottish and Irish who played shinty and hurling, may have introduced the word to Canada. This is supported by the prevalent use in Canada of the word \"shinny\" for an informal or \"pick-up\" game of hockey, which is also derived from the Scottish game of shinty. The first known printed reference was in Montreal, in 1876 (Montreal Gazette of February 7, 1876), just a year after the first indoor game was played there.[4]  A hockey puck is also referred to colloquially as a \"biscuit\". To put the \"biscuit in the basket\" (colloquial for the goal) is to score a goal.[5]  Ice hockey requires a hard disk of vulcanized rubber. A standard ice hockey puck is black, 1 inch (25\u00a0mm) thick, 3 inches (76\u00a0mm) in diameter, and weighs between 5.5 and 6 ounces (156 and 170\u00a0g);[6] some pucks are heavier or lighter than standard (see below). Pucks are often marked with silkscreened team or league logos on one or both faces.[6] Pucks are frozen before the game to reduce bouncing during play.[6]  The first hockey pucks[7] were made from frozen cow dung and leather liver pads. These early pucks had a lifespan of about one game before they were too soft or too hard for playability, so they were replaced with wooden ones.  The sport of bandy, prior to its first official organization in Britain, had its informal variants spread to North America where they and game concepts from lacrosse, shinty and hurling served as precursors in some format to ice hockey. These informal games utilized various types of balls while being played on ice until the latter half of 19th century Canada, after which the game of ice hockey and the ice hockey puck began to take their official shape and form.  By the 1870s, flat pucks were made of wood as well as rubber. Records from the first indoor ice hockey game (1875) used a wooden puck, to prevent it from leaving the area of play[8] though new evidence has shown that cuts from large corks have also been used.[citation needed]  At first, pucks (of either material) were made in the shape of a square. Rubber pucks were first made by slicing a rubber ball, then trimming the disk square. The original puck used first in the first organized games in Kingston on March 10, 1886 (on display at the Original Hockey Hall of Fame), was made from a cut-down lacrosse ball. It looks like a lump of coal, is made from soft rubber, and bounces far more than a modern hockey puck.[9]  The Victoria Hockey Club of Montreal is credited with making and using the first round pucks, in the 1880s.[10]  There are several variations on the standard black, 6-ounce (170\u00a0g) hockey puck. One of the most common is a blue, 4-ounce (110\u00a0g) puck that is used for training younger players who are not yet able to use a standard puck. Heavier 10-ounce (280\u00a0g) training pucks, typically reddish pink or reddish orange in colour, are also available for players looking to develop the strength of their shots or improve their stick handling skills. Players looking to increase wrist strength often practice with steel pucks that weigh 2 pounds (910\u00a0g); these pucks are not used for shooting, as they could seriously harm other players. White pucks are used for technical handling and goaltender practice. These are regulation size and weight, but made from white rubber. The colour blend in with the ice and rink and requires higher focus on the puck, making handling of the black puck at later stage easier.[11] A hollow, light-weight fluorescent orange puck is available for road or floor hockey. Other variants, some with plastic ball-bearings or glides, are available for use for road or roller hockey.[citation needed]  Two major developments have been devised to create better puck visibility on television broadcasts, but both were short-lived:  The use of a \"Firepuck\" in the early 1990s was the first attempt to improve the visibility of hockey pucks as seen on television. This invention incorporated coloured retro reflective materials of either embedded lens elements or prismatic reflectors laminated into recesses on the flat surfaces and the vertical edge of a standard hockey puck. Yellow was the preferred reflected colour. A spotlight was required to be positioned on the TV camera and focused at the centre of the viewing area.  A short demonstration tape of the Minnesota North Stars skating with the Firepuck was shown during the period break at the 1993 NHL All-Star Game in Montreal. The International Hockey League (IHL) pursued testing the Firepuck with its inventor, Donald Klassen. The next television viewing was the IHL All-Star Game in Fort Wayne, Indiana, January 1994, where the Firepuck was used for the entire game. The IHL tested the Firepuck in two more games, and finally the East Coast Hockey League used it January 17, 1997, for their all-star game.  The use of the Firepuck was discontinued because of these reasons:  The Firepuck name was branded during the 1990s but has since been discontinued.  The FoxTrax \"smart puck\" was developed by the Fox television network when it held National Hockey League (NHL) broadcasting rights for the United States. The puck had integrated electronics to track its position on screen; a blue streak traced the path of the puck across the ice. The streak would turn red if the puck was shot especially hard. This was an experiment in broadcasting intended to help viewers unfamiliar with hockey to better follow the game by making the puck more visible. It was ill-received by many traditional hockey fans, but appreciated by many of the more casual viewers.[citation needed] The system debuted with much publicity in the NHL All-Star game at the Boston Fleet Center on January 20, 1996, but the system was shelved when Fox Sports lost the NHL broadcast rights three years later.[citation needed]  During a game, pucks can reach speeds of 100 miles per hour (160\u00a0km\/h) or more when struck. The current world record is held by Denis Kulyash of KHL's Avangard Omsk, who slapped a puck at the 2011 KHL All-Star Game skills competition in St. Petersburg, Russia on 5 February 2011 with a speed of 110.3 miles per hour (177.5\u00a0km\/h).[12] Zdeno Ch\u00e1ra, whose slapshot clocked 108.8 miles per hour (175.1\u00a0km\/h) in the 2013 NHL All-Star Game SuperSkills competition, broke his own earlier record.[13]  Fast-flying pucks are potentially dangerous to players and spectators. Puck-related injuries at hockey games are not uncommon. This led to the evolution of various types of protective gear for players, most notably the goaltender mask. The most notable incident involving a spectator took place on March 18, 2002, when a 13-year-old girl, Brittanie Cecil, died two days after being struck on the head by a hockey puck deflected into the crowd at an NHL game between the Calgary Flames and Columbus Blue Jackets in Columbus. This is the only known incident of this type to have occurred in the history of the league. Partly as a result of this event, the glass or plexiglass panels that sit atop the boards of hockey rinks to protect spectators have been supplemented with mesh nets that extend above the upper edge of the glass.  NHL regulation pucks were not required for professional play until the 1990\u201391 season, but were standardized for consistent play and ease of manufacture half a century earlier, by Art Ross, in 1940.[6] Major manufacturers of pucks exist in Canada, Russia, the Czech Republic, the People's Republic of China,[6][better\u00a0source\u00a0needed] and Slovakia.[14]  The black rubber of the puck is made up of a mix of natural rubber, antioxidants, bonding materials and other chemicals to achieve a balance of hardness and resilience.[15] This mixture is then turned in a machine with metal rollers, where workers add extra natural rubber, and ensure that the mixing is even. Samples are then put into a machine that analyses if the rubber will harden at the right temperature. An automated apparatus, called a pultrusion machine,[6] extrudes the rubber into long circular logs that are 3 inches (7.6\u00a0cm) in diameter and then cut into 1 inch (2.5\u00a0cm) thick pieces while still soft. These pre-forms are then manually put into moulds that are the exact size of a finished puck.[15] There are up to 200 mould cavities per moulding palette, capable of producing up to 5,000 pucks per week.[6] The moulds are then compressed. This compression may be done cold[6] or with the moulds heated to 300\u00a0\u00b0F (149\u00a0\u00b0C) for 18 minutes,[15] depending on the proprietary methods of the manufacturer. They come out hard and then are allowed to sit for 24 hours. Each puck is manually cleaned with a trimmer machine to remove excess rubber. The moulding process adds a diamond cross-hatch texture around the edge of the puck for more friction between the stick and puck for better control and puck handling.[15]  The practice pucks are made by a similar but faster process that uses larger pre-forms, 4\u20135\u00a0in (10\u201313\u00a0cm) thick, puts them into moulds automatically, and applies more pressure and heat over a shorter period of time to compress the puck into the standard size. This allows approximately twice as many pucks to be manufactured in the same time period as the more exacting production of NHL regulation pucks. People sometimes freeze pucks to prevent them from sticking to the ice.[6]  The list of former or present-day major producers includes  Roller hockey pucks, a.k.a. in-line hockey pucks, are similar to ice-hockey pucks but are made from plastic and thus lighter. They have small ribs protruding from their tops and bottoms which limit contact with the surface, allowing better sliding motion and less friction. These pucks are mostly commonly red in color but can be found in almost any color, though light, visible colours such as red, orange, yellow, pink, and green, are typical. Roller hockey pucks were created so inline hockey and street hockey players could play with a puck instead of a ball on surfaces such as hardwood, concrete, and asphalt.  Originally known as \"squid\" in the United Kingdom and now more commonly known as \"Octopush\", underwater hockey uses a type of puck that while similar in appearance to an ice hockey puck, differs in that it has a lead core weighing approximately 3 pounds (1.4\u00a0kg) within a teflon, plastic or rubber coating. This makes the puck dense enough to sink in a swimming pool, though it can be lofted during passes, while affording some protection to the pool tiles.  A smaller and lighter version of the standard puck exists for junior competition and is approximately 1\u00a0lb 12\u00a0oz (0.80\u20130.85\u00a0kg) and of similar construction to the standard puck.  While there are numerous regional variations in colour, construction and materials all must conform to international regulations stipulating overall dimensions and weight. The regulations state that pucks should be a bright distinctive colour, for example high-visibility pink or orange, and that for World Championships these are the only acceptable colours.  Spongee[18] a.k.a. \"sponge hockey\", is an organized recreational cult game that emerged in Canada around the 1950s and is played in the Canadian city of Winnipeg. It gets its name from the puck that is used: instead of the hard vulcanized rubber puck used in regular ice hockey, a softer sponge puck is used.[19] At one point, some locals referred to it as \"tweeter\" based on the sound the original pucks made. The game is a variant of ice hockey and was influenced by Canadian road-hockey and ice-hockey players playing shinny on outdoor rinks in running shoes and winter boots. The game is played in winter strictly on outdoor rinks, does not use ice skates, and has codes involving less contact. Broomball shoes are sometimes used.  The spongee puck[19][20] originated when someone took a toy red-white-and-blue handball and cut out the center, leaving a rude approximation of a standard hockey puck. Eventually manufactured types of sponge pucks came into use, some of which were developed in Slovakia and had a spring core. Spongee pucks are softer than ice hockey pucks and have more bounce.  The term \"puck\" is sometimes also applied to similar (though often smaller) gaming discs in other sports and games, including novuss, shuffleboard, table shuffleboard, box hockey, floor hockey, and air hockey.  Ice hockey pucks of regulation 3-inch (7.6\u00a0cm) diameter and 1-inch (2.5\u00a0cm) thickness may be used as mechanical vibration dampening isolators in places such as feet for light industrial air compressors, and air conditioning units because they are of regulation materials and therefore consistent manufacture, size, and shape, and are constructed of a repeatable and consistent vulcanized rubber material.  Since the material is rubber, it may be drilled out or milled easily to a fixed depth as rubber feet or used as rubber spacer or gasket material.  A very common use of a slotted hockey puck is as an adaptor between the metal foot of a trolley jack and the sill (rocker panel) of an automobile.  The sill has a spot-welded lip which fits into the slot of the puck and would otherwise be bent or marked by the metal foot.  In November 2018, faculty of Oakland University in Michigan received hockey pucks and training to throw them as a possible last-ditch defense against active shooters.  The American Association of University Professors distributed pucks to its 800 members, and is working with student groups to distribute an additional 1,700 pucks to students.[21] "},{"title":"Quantity","content":"  Quantity or amount is a property that can exist as a multitude or magnitude, which illustrate discontinuity and continuity. Quantities can be compared in terms of \"more\", \"less\", or \"equal\", or by assigning a numerical value multiple of a unit of measurement. Mass, time, distance, heat, and angle are among the familiar examples of quantitative properties.  Quantity is among the basic classes of things along with quality, substance, change, and relation. Some quantities are such by their inner nature (as number), while others function as states (properties, dimensions, attributes) of things such as heavy and light, long and short, broad and narrow, small and great, or much and little.  Under the name of multitude comes what is discontinuous and discrete and divisible ultimately into indivisibles, such as: army, fleet, flock, government, company, party, people, mess (military), chorus, crowd, and number; all which are cases of collective nouns. Under the name of magnitude comes what is continuous and unified and divisible only into smaller divisibles, such as: matter, mass, energy, liquid, material\u2014all cases of non-collective nouns.  Along with analyzing its nature and classification, the issues of quantity involve such closely related topics as dimensionality, equality, proportion, the measurements of quantities, the units of measurements, number and numbering systems, the types of numbers and their relations to each other as numerical ratios.  In mathematics, the concept of quantity is an ancient one extending back to the time of Aristotle and earlier. Aristotle regarded quantity as a fundamental ontological and scientific category. In Aristotle's ontology, quantity or quantum was classified into two different types, which he characterized as follows:  Quantum means that which is divisible into two or more constituent parts, of which each is by nature a one and a this. A quantum is a plurality if it is numerable, a magnitude if it is measurable. Plurality means that which is divisible potentially into non-continuous parts, magnitude that which is divisible into continuous parts; of magnitude, that which is continuous in one dimension is length; in two breadth, in three depth. Of these, limited plurality is number, limited length is a line, breadth a surface, depth a solid. In his Elements, Euclid developed the theory of ratios of magnitudes without studying the nature of magnitudes, as Archimedes, but giving the following significant definitions:  A magnitude is a part of a magnitude, the less of the greater, when it measures the greater; A ratio is a sort of relation in respect of size between two magnitudes of the same kind. For Aristotle and Euclid, relations were conceived as whole numbers (Michell, 1993). John Wallis later conceived of ratios of magnitudes as real numbers:  When a comparison in terms of ratio is made, the resultant ratio often [namely with the exception of the 'numerical genus' itself] leaves the genus of quantities compared, and passes into the numerical genus, whatever the genus of quantities compared may have been. That is, the ratio of magnitudes of any quantity, whether volume, mass, heat and so on, is a number. Following this, Newton then defined number, and the relationship between quantity and number, in the following terms:  By number we understand not so much a multitude of unities, as the abstracted ratio of any quantity to another quantity of the same kind, which we take for unity. Continuous quantities possess a particular structure that was first explicitly characterized by H\u00f6lder (1901) as a set of axioms that define such features as identities and relations between magnitudes. In science, quantitative structure is the subject of empirical investigation and cannot be assumed to exist a priori for any given property. The linear continuum represents the prototype of continuous quantitative structure as characterized by H\u00f6lder (1901) (translated in Michell & Ernst, 1996). A fundamental feature of any type of quantity is that the relationships of equality or inequality can in principle be stated in comparisons between particular magnitudes, unlike quality, which is marked by likeness, similarity and difference, diversity. Another fundamental feature is additivity. Additivity may involve concatenation, such as adding two lengths A and B to obtain a third A + B. Additivity is not, however, restricted to extensive quantities but may also entail relations between magnitudes that can be established through experiments that permit tests of hypothesized observable manifestations of the additive relations of magnitudes. Another feature is continuity, on which Michell (1999, p.\u00a051) says of length, as a type of quantitative attribute, \"what continuity means is that if any arbitrary length, a, is selected as a unit, then for every positive real number, r, there is a length b such that b = ra\". A further generalization is given by the theory of conjoint measurement, independently developed by French economist G\u00e9rard Debreu (1960) and by the American mathematical psychologist R. Duncan Luce and statistician John Tukey (1964).  Magnitude (how much) and multitude (how many), the two principal types of quantities, are further divided as mathematical and physical. In formal terms, quantities\u2014their ratios, proportions, order and formal relationships of equality and inequality\u2014are studied by mathematics. The essential part of mathematical quantities consists of having a collection of variables, each assuming a set of values. These can be a set of a single quantity, referred to as a scalar when represented by real numbers, or have multiple quantities as do vectors and tensors, two kinds of geometric objects.  The mathematical usage of a quantity can then be varied and so is situationally dependent. Quantities can be used as being infinitesimal, arguments of a function, variables in an expression (independent or dependent), or probabilistic as in random and stochastic quantities. In mathematics, magnitudes and multitudes are also not only two distinct kinds of quantity but furthermore relatable to each other.  Number theory covers the topics of the discrete quantities as numbers: number systems with their kinds and relations. Geometry studies the issues of spatial magnitudes: straight lines, curved lines, surfaces and solids, all with their respective measurements and relationships.  A traditional Aristotelian realist philosophy of mathematics, stemming from Aristotle and remaining popular until the eighteenth century, held that mathematics is the \"science of quantity\". Quantity was considered to be divided into the discrete (studied by arithmetic) and the continuous (studied by geometry and later calculus). The theory fits reasonably well elementary or school mathematics but less well the abstract topological and algebraic structures of modern mathematics.[1]  Establishing quantitative structure and relationships between different quantities is the cornerstone of modern science, especially but not restricted to physical sciences. Physics is fundamentally a quantitative science; chemistry, biology and others are increasingly so. Their progress is chiefly achieved due to rendering the abstract qualities of material entities into physical quantities, by postulating that all material bodies marked by quantitative properties or physical dimensions are subject to some measurements and observations. Setting the units of measurement, physics covers such fundamental quantities as space (length, breadth, and depth) and time, mass and force, temperature, energy, and quanta.  A distinction has also been made between intensive quantity and extensive quantity as two types of quantitative property, state or relation. The magnitude of an intensive quantity does not depend on the size, or extent, of the object or system of which the quantity is a property, whereas magnitudes of an extensive quantity are additive for parts of an entity or subsystems. Thus, magnitude does depend on the extent of the entity or system in the case of extensive quantity. Examples of intensive quantities are density and pressure, while examples of extensive quantities are energy, volume, and mass.  In human languages, including English, number is a syntactic category, along with person and gender. The quantity is expressed by identifiers, definite and indefinite, and quantifiers, definite and indefinite, as well as by three types of nouns: 1. count unit nouns or countables; 2. mass nouns, uncountables, referring to the indefinite, unidentified amounts; 3. nouns of multitude (collective nouns). The word \u2018number\u2019 belongs to a noun of multitude standing either for a single entity or for the individuals making the whole. An amount in general is expressed by a special class of words called identifiers, indefinite and definite and quantifiers, definite and indefinite.[clarification needed] The amount may be expressed by: singular form and plural from, ordinal numbers before a count noun singular (first, second, third...), the demonstratives; definite and indefinite numbers and measurements (hundred\/hundreds, million\/millions), or cardinal numbers before count nouns. The set of language quantifiers covers \"a few, a great number, many, several (for count names); a bit of, a little, less, a great deal (amount) of, much (for mass names); all, plenty of, a lot of, enough, more, most, some, any, both, each, either, neither, every, no\". For the complex case of unidentified amounts, the parts and examples of a mass are indicated with respect to the following: a measure of a mass (two kilos of rice and twenty bottles of milk or ten pieces of paper); a piece or part of a mass (part, element, atom, item, article, drop); or a shape of a container (a basket, box, case, cup, bottle, vessel, jar).  Some further examples of quantities are:  Dimensionless quantities, also known as quantities of dimension one[2] are implicitly defined in a manner that prevents their aggregation into units of measurement.[3][4] Typically expressed as ratios that align with another system, these quantities do not necessitate explicitly defined units. For instance, alcohol by volume (ABV) represents a volumetric ratio. Its derivation remains independent of the specific units of volume used; any common unit may be applied. Notably, ABV is never expressed as milliliters per milliliter, underscoring its dimensionless nature.  The number one is recognized as a dimensionless base quantity.[5] Radians serve as dimensionless units for angular measurements, derived from the universal ratio of 2\u03c0 times the radius of a circle being equal to its circumference.[6] "},{"title":"Jersey","content":"  in Europe\u00a0(dark grey) Jersey (\/\u02c8d\u0292\u025c\u02d0rzi\/ JUR-zee; J\u00e8rriais: J\u00e8rri [\u0292\u025bri]), officially known as the Bailiwick of Jersey,[d][12][13][14] is an island country and self-governing British Crown Dependency near the coast of north-west France.[15][16][17] It is the largest of the Channel Islands and is 14 miles (23\u00a0km) from the Cotentin Peninsula in Normandy.[18] The Bailiwick consists of the main island of Jersey and some surrounding uninhabited islands and rocks including Les Dirouilles, Les \u00c9cr\u00e9hous, Les Minquiers, and Les Pierres de Lecq.[19]  Jersey was part of the Duchy of Normandy, whose dukes became kings of England from 1066. After Normandy was lost by the kings of England in the 13th century, and the ducal title surrendered to France, Jersey remained loyal to the English Crown, though it never became part of the Kingdom of England. Between then and the end of the Napoleonic Wars, Jersey was at the frontline of Anglo-French wars and was invaded a number of times, leading to the construction of fortifications such as Mont Orgueil Castle and a thriving smuggling industry. During the Second World War, the island was invaded and occupied for five years by Nazi Germany. The island was liberated on 9 May 1945, which is now celebrated as the island's national day.[20]  Jersey is a self-governing parliamentary democracy under a constitutional monarchy, with its own financial, legal and judicial systems,[7] and the power of self-determination.[21] Jersey's constitutional relationship is with the Crown; it is not part of the United Kingdom.[22][23][24] The bailiff is the civil head, president of the states and head of the judiciary; the lieutenant governor represents the head of state, the British monarch; and the chief minister is the head of government. Jersey's defence and international representation \u2013 as well as certain policy areas, such as nationality law \u2013 are the responsibility of the UK government, but Jersey still has a separate international identity.[25]  The island has a large financial services industry, which generates 40% of its GVA.[6] British cultural influence on the island is evident in its use of English as the main language and pound sterling as its primary currency. Additional British cultural similarities include: driving on the left, access to British television and newspapers, a school curriculum following that of England,[26] and the popularity of British sports, including cricket.[27] The island also has a strong Norman-French culture, such as its historic dialect of the Norman language, J\u00e8rriais, being one of only two places in Normandy with government status for the language (the other being Guernsey), as well as the use of standard French in legal matters and officially in use as a government language, strong cultural ties to mainland Normandy as a part of the Normandy region, and place names with French or Norman origins. The island has very close cultural links with its neighbouring islands in the Bailiwick of Guernsey, and they share a good-natured rivalry. Jersey and its people have been described as a nation.[28][29][30]  The Channel Islands are mentioned in the Antonine Itinerary as the following: Sarnia, Caesarea, Barsa, Silia and Andium, but Jersey cannot be identified specifically because none corresponds directly to the present names.[31] The name Caesarea has been used as the Latin name for Jersey (also in its French version C\u00e9sar\u00e9e) since William Camden's Britannia,[32] and is used in titles of associations and institutions today. The Latin name Caesarea was also applied to the colony of New Jersey as Nova Caesarea.[33][34]  Andium, Agna and Augia were used in antiquity.[35][36]  Scholars variously surmise that Jersey and J\u00e8rri derive from j\u01ebr\u00f0 (Old Norse for 'earth') or jarl ('earl'), or perhaps the Norse personal name Geirr (thus Geirrsey, 'Geirr's Island').[37] The ending -ey denotes an island[38][39] (as in Guernsey or Surtsey).  Humans have lived on the island since at least 12,000 BCE, with evidence of habitation in the Palaeolithic period (La Cotte de St Brelade) and Neolithic dolmens, such as La Hougue Bie. Evidence of Bronze Age and early Iron Age settlements can be found in many locations around the island.[40]  Archaeological evidence of Roman influence has been found, in particular at Les Landes.[41] Christianity was brought to the island by migrants from Brittany in c. fifth - sixth century CE.[42] In the sixth century, the island's patron saint Helier lived at the Hermitage on L'Islet (now Elizabeth Castle). Legend states that Helier was beheaded by raiders and subsequently lifted his head and walked to shore.[43]  In the ninth century the island was raided by Vikings and in 933 it was annexed to Normandy by William Longsword.[44]:\u200a22\u200a When Duke William the Conqueror became King of England in 1066, the island remained part of the Norman possessions. However, in 1204, when Normandy was returned to the French king, the island remained a possession of the English crown, though never incorporated into England.[42]:\u200a25\u200aTraditionally it is said that Jersey's self-governance originates from the Constitutions of King John, however this is disputed.[44]:\u200a25\u200a Nevertheless, the island continued to follow Norman customs and laws. The King also appointed a Bailiff and a Warden (now Lieutenant-Governor). The period of English rule was marked by wars between England and France, as such a military fortress was built at Mont Orgueil.[42]:\u200a25\u20138\u200a   During the Tudor period, the split between the Church of England and the Vatican led to islanders adopting the Protestant religion. During the reign of Elizabeth, French refugees brought strict Calvinism to the island, which remained the common religion until 1617.[42] In the late 16th century, islanders travelled across the North Atlantic to participate in the Newfoundland fisheries.[45] In recognition for help given to him during his exile in Jersey in the 1640s, King Charles II of England gave Vice Admiral Sir George Carteret, bailiff and governor, a large grant of land in the American colonies in between the Hudson and Delaware rivers, which he promptly named New Jersey. It is now a state in the United States.[46][47] In 1769, the island suffered food supply shortages, leading to an insurrection on 28 September known as the Corn Riots. The States met at Elizabeth Castle and decided to request help from the King. However, in 1771 the Crown demanded reforms to the island's governance, leading to the Code of 1771 and removed the powers of the Royal Court to make laws without the States.[42] In 1781, during the American Wars of Independence, the island was invaded by a French force which captured St Helier, but was defeated by Major Peirson's army at the Battle of Jersey.[48]  The 19th century saw the improvement of the road network under General Don,[49] the construction of two railway lines, the improvement of transport links to England, and the construction of new piers and harbours in St Helier.[42] This grew a tourism industry in the island and led to the immigration of thousands of English residents, leading to a cultural shift towards a more anglicised island culture. Island politics was divisively split between the conservative Laurel party and the progressive Rose party, as the lie of power shifted increasingly to the States from the Crown.[42] In the 1850s, the French author Victor Hugo lived in Jersey, but was expelled for insulting the Queen, so he moved on to Guernsey.[42]  During the Second World War, 6,500 Jersey residents were evacuated by their own choice to the UK out of a total population of 50,000.[50]  Jersey was occupied by Germany from 1 July 1940 until 9 May 1945, when Germany surrendered.[51] During this time the Germans constructed many fortifications using slave labour imported onto the island from many different countries occupied or at war with Germany.[52] After 1944, supplies from France were interrupted by the D-Day landings, and food on the island became scarce. The SS Vega was sent to the island carrying Red Cross supplies and news of the success of the Allied advance in Europe. During the Nazi occupation, a resistance cell was created by communist activist Norman Le Brocq and the Jersey Communist Party, whose communist ideology of forming a 'United Front' led to the creation of the Jersey Democratic Movement.[53] The Channel Islands had to wait for the German surrender to be liberated. 9 May is celebrated as the island's Liberation Day, where there are celebrations in Liberation Square. After Liberation, the States was reformed, becoming wholly democratically elected, and universal franchise was implemented. Since liberation, the island has grown in population and adopted new industries, especially the finance industry.[42]  Jersey is a Crown Dependency and is not part of the United Kingdom \u2013 it is officially part of the British Islands. As one of the Crown Dependencies, Jersey is autonomous and self-governing, with its own independent legal, administrative and fiscal systems.[54] Jersey's government has described Jersey as a \"self-governing, democratic country with the power of self-determination\".[55]  Because Jersey is a dependency of the British Crown, King Charles III reigns in Jersey.[56] \"The Crown\" is defined by the Law Officers of the Crown as the \"Crown in right of Jersey\".[57] The King's representative and adviser in the island is the Lieutenant Governor of Jersey \u2013 Vice-Admiral Jerry Kyd since 8 October 2022. He is a point of contact between Jersey ministers and the UK Government and carries out some functions in relation to immigration control, deportation, naturalisation and the issue of passports.[58]  In 1973, the Royal Commission on the Constitution set out the duties of the Crown as including: ultimate responsibility for the 'good government' of the Crown Dependencies; ratification of island legislation by Order-in-Council (royal assent); international representation, subject to consultation with the island authorities before concluding any agreement which would apply to them; ensuring the islands meet their international obligations; and defence.[59]  Jersey's unicameral legislature is the States Assembly. It includes 49 elected members: 12 conn\u00e9tables (often called \"constables\", heads of parishes) and 37 deputies (representing constituencies), all elected for four-year terms as from the October 2011 elections.[60] Jersey has one of the lowest voter turnouts internationally, with just 33% of the electorate voting in 2005, putting it well below the 77% European average for that year.[61]  From the 2022 elections, the role of senators was abolished and the eight senators were replaced with an increased number of deputies. The 37 deputies are now elected from nine super constituencies, rather than in individual parishes. Although efforts were made the remove the conn\u00e9tables, they will continue their historic role as states members.[62]  There are also five non-voting members appointed by the Crown: the bailiff, the Lieutenant Governor of Jersey, the Dean of Jersey, the attorney general and solicitor general.[63] The Bailiff is President (presiding officer) of the States Assembly,[64] head of the judiciary and as civic head of the island carries out various ceremonial roles.[65]  The Council of Ministers, consisting of a chief minister and nine ministers, makes up the leading body of the government of Jersey.[66][67] Each minister may appoint up to two assistant ministers.[68] A chief executive is head of the civil service.[69] Some governmental functions are carried out in the island's parishes.[70]  Jersey is a distinct jurisdiction for the purposes of conflict of laws, separate from the other Channel Islands, England and Wales, Scotland and Northern Ireland.[71]  Jersey law has been influenced by several different legal traditions, in particular Norman customary law, English common law and modern French civil law.[72] Jersey's legal system is therefore described as 'mixed' or 'pluralistic', and sources of law are in French and English languages, although since the 1950s the main working language of the legal system is English.[73]  The principal court is the Royal Court, with appeals to the Jersey Court of Appeal and, ultimately, to the Judicial Committee of the Privy Council.[74] The Bailiff is head of the judiciary; the Bailiff and the Deputy Bailiff are appointed by the Crown. Other members of the island's judiciary are appointed by the Bailiff.[65]  The external relations of Jersey are overseen by the External Relations Minister of the Government of Jersey.[75][76] In 2007, the chief minister and the UK Lord Chancellor signed an agreement that established a framework for the development of the international identity of Jersey.[77]  Although diplomatic representation is reserved to the Crown, Jersey has been developing its own international identity over recent years. It negotiates directly with foreign governments on various matters, for example, tax information exchange agreements (TIEAs) have been signed directly by the island with several countries.[78][79] The government maintains offices (some in partnership with Guernsey) in Caen,[80] London[81] and Brussels.[82]  Jersey is a member of the British-Irish Council,[83] the Commonwealth Parliamentary Association[84] and the Assembl\u00e9e parlementaire de la Francophonie.[85]  Jersey independence has in the past been discussed in the States Assembly. Former external relations minister, Sir Philip Bailhache, has at various times warned that the island may need to become independent.[86] It is not Jersey government policy to seek independence, but the island is prepared if needs to do so.[87][88][89]  Jersey is a third-party European country to the EU. Since 1 January 2021, Jersey has been part of the UK-EU Trade and Economic Cooperation Agreement for the purposes of goods and fishing. Goods exported from the island into Europe are not subject to tariffs and Jersey is solely responsible for management of its territorial waters, however permits may be granted to EU fishermen who have a history of fishing in the Bailiwick's waters. The management of this permit system has caused tension between the French and Jersey authorities, with the French threatening to cut off Jersey's electricity supply in May 2021.[90] Before the end of the transition period after the UK withdrew from the EU in 2020, Jersey had a special relationship with the EU.[e] It was part of the EU customs union and there was free movement of goods between Jersey and the EU but the single market in financial services and free movement of people did not apply to Jersey.[91][92]  Jersey is divided into twelve parishes (which have civil and religious functions). They are all named after their parish church. The conn\u00e9table is the head of the parish. They are elected at island general elections and sit ex oficio in the States Assembly.[70]  The parishes have various civil administrative functions, such as roads (managed by the Road Committee) and policing (through the Honorary Police). Each parish is governed through direct democracy at parish assemblies, consisting of all eligible voters resident in the parish. The Procureurs du Bien Public are the legal and financial representatives of these parishes.[70]  The parishes of Jersey are further divided into vingtaines (or, in St. Ouen, cueillettes).[93]  Jersey is an island measuring 46.2 square miles (119.6\u00a0km2) (or 66,436 verg\u00e9es),[6] including reclaimed land and intertidal zone. It lies in the English Channel, about 12 nautical miles (22\u00a0km; 14\u00a0mi) from the Cotentin Peninsula in Normandy, France, and about 87 nautical miles (161\u00a0km; 100\u00a0mi) south of Great Britain.[f] It is the largest and southernmost of the Channel Islands and part of the British Isles, with a maximum land elevation of 143\u00a0m (469\u00a0ft) above sea level.[94]  About 24% of the island is built-up. 52% of the land area is dedicated to cultivation and around 18% is the natural environment.[95]  It lies within longitude -2\u00b0 W and latitude 49\u00b0 N. It has a coastline that is 43 miles (70\u00a0km) long and a total area of 46.2 square miles (119.6\u00a0km2). It measures roughly 9 miles (14\u00a0km) from west to east and 5 miles (8\u00a0km) north to south, which gives it the affectionate name among locals of \"nine-by-five\".[96]  The island is divided into twelve parishes; the largest is St Ouen and the smallest is St Clement. The island is characterised by a number of valleys which generally run north-to-south, such as Waterworks Valley, Grands Vaux, Mont les Vaux, although a few run in other directions, such as Le Mourier Valley. The highest point on the island is Les Platons at 136\u00a0m (446\u00a0ft).[97]  There are several smaller island groups that are part of the Bailiwick of Jersey, such as Les Minquiers and Les \u00c9crehous, however unlike the smaller islands of the Bailiwick of Guernsey, none of these are permanently inhabited.[98]  The largest settlement is the town of St Helier, including the built-up area of southern St Helier and neighbouring areas such as Georgetown, which also plays host to the island's seat of government. The town is the central business district, hosting a large proportion of the island's retail and employment, such as the finance industry.[99]  Outside of the town, many islanders live in suburban and rural settlements, especially along main roads leading out of town and even the more rural areas of the island have considerable amounts of development (St Ouen, the least densely populated parish still has 270 persons per square kilometre[100]). The south and east coasts from St Aubin to Gorey are largely urbanised. The second smaller urban area is the Les Quennevais area in St Brelade, which is home to a small precinct of shops,[101] a school, a park and a leisure centre.[102]  Most people across Jersey regularly travel from the rural settlements to St Helier and from the town to the rural areas for work and leisure purposes.[103]  Housing costs in Jersey are very high. The Jersey House Price Index has at least doubled between 2002 and 2020. The mix-adjusted house price for Jersey is \u00a3567,000, higher than any UK region (UK average: \u00a3249,000) including London (average: \u00a3497,000; highest of any UK region).[104]  The island has an oceanic climate with mild winters and mild to warm summers.[105] The highest temperature recorded was 37.9\u00a0\u00b0C (100.2\u00a0\u00b0F), on 18 July 2022,[106] and the lowest temperature recorded was \u221210.3\u00a0\u00b0C (13.5\u00a0\u00b0F), on 5 January 1894. 2014 was the warmest year on record; the mean daily air temperature was 13.34\u00a0\u00b0C.[107] For tourism advertising, Jersey often claims to be \"the sunniest place in the British Isles\", as Jersey has over 1,900 hours of sunlight. In 2011, Jersey generated controversy for calling itself \"the warmest place in the British Isles\" during an advertising campaign.[108]  Average wind speeds vary between 20 kilometres per hour (12\u00a0mph) and 40 kilometres per hour (25\u00a0mph), with gusts over 60 kilometres per hour (40\u00a0mph) once every 4\u20135 years.[109]  The following table contains the official data for 1981\u20132010 at Jersey Airport, located 4.5 miles (7.2\u00a0km) from St. Helier \u2013  Jersey's economy is highly developed and services-focused, with a GDP per capita of \u00a345,320[9] in 2019. It is a mixed market economy, with free market principles and an advanced social security infrastructure.[112] 53,460 people were employed in Jersey as of December\u00a02010[update]: 24% in financial and legal services; 16% in wholesale and retail trades; 16% in the public sector; 10% in education, health and other private sector services; 10% in construction and quarrying; 9% in hotels, restaurants and bars.[6]  Thanks to specialisation in a few high-return sectors, at purchasing power parity Jersey has high economic output per capita, substantially ahead of all of the world's large developed economies. Gross national income in 2009 was \u00a33.7\u00a0billion (approximately \u00a340,000 per head of population).[6] However, this is not indicative of each individual resident's purchasing power and the actual standard of living in Jersey is comparable to that in the UK outside central London.[114]  Jersey is one of the world's largest offshore finance centres. The UK acts as a conduit for financial services between European countries and the island.[115] The growth of this sector however has not been without its controversies as Jersey has been characterised by critics and detractors as a place in which the \"leadership has essentially been captured by global finance, and whose members will threaten and intimidate anyone who dissents.\"[61]  Tourism is an important economic sector for the island, however travel to Jersey is very seasonal. Accommodation occupancy is much higher in the summer months, especially August, than in the winter months (with a low in November). The majority of visitors to the island arrive by air from the UK.[116] On 18 February 2005, Jersey was granted Fairtrade Island status.[117]  In 2017, 52% of the Island's area was agricultural land (a decrease since 2009).[95] Major agricultural products are potatoes and dairy produce.[6] Jersey cattle are a small breed of cow widely known for their rich milk and cream; the quality of their meat is also appreciated on a small scale.[118][119] The herd total in 2009 was 5,090 animals.[6] Fisheries and aquaculture make use of Jersey's marine resources to a total value of over \u00a36\u00a0million in 2009.[6]  Along with Guernsey, Jersey has its own lottery called the Channel Islands Lottery, which was launched in 1975.[120]  Jersey is not a tax-free jurisdiction. Taxes are levied on properties (known as 'rates') and a Personal Income Tax, Corporate Income Tax and goods and services tax exist.[121] Before 2008, Jersey had no value-added tax (VAT). Many companies, such as Amazon and Play.com, took advantage of this and a loophole in European law, known as low-value consignment relief, to establish a tax-free fulfilment industry from Jersey.[122] This loophole was closed by the European Union in 2012, resulting in the loss of hundreds of jobs.[122]  There is a 20% standard rate for Income Tax and a 5% standard rate for GST. The island has a 0% default tax rate for corporations; however, higher rates apply to financial services, utility companies and large corporate retailers.[121] Jersey is considered to be a tax haven. The island, until March 2019, was on the EU tax haven blacklist, but no longer features.[123] In January 2021, the chair of the EU Tax Matters Subcommittee, Paul Tang, criticised the list for not including such \"renowned tax havens\" as Jersey.[124] In 2020, Tax Justice ranked Jersey as the 16th on the Financial Secrecy Index, below larger countries such as the UK, however still placing at the lower end of the 'extreme danger zone' for offshore secrecy'. The island accounts of 0.46% of the global offshore finance market, making a small player in the total market.[125] In 2020, the Corporate Tax Haven Index ranked Jersey eighth for 2021 with an haven score (a measure of the jurisdiction's systems to be used for corporate tax abuse) of 100 out of 100; however, the island only has 0.51% on the Global Scale Weight ranking.[126]  The primary mode of transport on the island is the motor vehicle. Jersey has a road network consisting of 346 miles (557\u00a0km) of roads and there are a total of 124,737 motor vehicles registered on the island as of 2016.[127] Jersey has a large network of lanes, some of which are classified as green lanes, which have a 15\u00a0mph speed limit and where priority is afforded to pedestrians, cyclists and horse riders.[128]  The public bus network in Jersey has been regulated by the Government since 2002, replacing a de-regulated, commercial service. It is operated on a sole-operator franchise model, currently contracted to LibertyBus, a company owned by Kelsian Group. LibertyBus also operate the school bus services.[129] There is also a taxi network and an electronic bike scheme (EVie).[130] Jersey has an airport and a number of ports, which are operated by Ports of Jersey.[131]  Jersey's monetary policy is linked to the Bank of England. The official currency of Jersey is the pound sterling. Jersey issues its own postage stamps, banknotes (including a \u00a31 note which is not issued in the UK) and coins that circulate alongside all other sterling coinage. Jersey currency is not legal tender outside Jersey; however it is \"acceptable tender\" in the UK and can be surrendered at banks in exchange for UK currency.[132]  In July 2014, the Jersey Financial Services Commission approved the establishment of the world's first regulated Bitcoin fund, at a time when the digital currency was being accepted by some local businesses.[133]   Censuses have been undertaken in Jersey since 1821. In the 2021 census, the total resident population was estimated to be 103,267, of whom 35% live in Saint Helier, the island's only town.[134] Approximately half the island's population was born in Jersey; 29% of the population were born elsewhere in the British Isles, 8% in continental Portugal or Madeira, 9% in other European countries and 5% elsewhere.[135] Jersey people are the native nation on the island,[28][29][30] however do not form a majority of the population.[135] Jersey people are often called Islanders or, in individual terms, Jerseyman or Jerseywoman. Jersey people did not generally identify themselves as English prior to the Union of Britain. Jersey was culturally and geographically much closer to Normandy and there were limited cross-Channel links. However, wars with France, including invasions of Jersey, grew loyalty to Britain over time and the French came more and more to be seen as a distinct people. By the start of the 19th century, Jersey people generally identified as British, which can be seen through the treatment of the Breton immigrants of the time as a distinct nation. Furthermore, the growth of the British migrant population strengthened the role of English and the British cultural influence. Finally, the introduction of compulsory education - which was exclusively in English - and the period of the Occupation reduced the traditional and Norman cultural influences and increased British cultural practices and pride in British nationhood among the island population.[136]  Nationality law in Jersey is conferred by the British Nationality Act 1981 extended to the island by an Order in Council with the consent of the States of Jersey. British nationality law confers British citizenship onto those with suitable connections to Jersey.[137][25] The Lieutenant Governor's office issues British passports (specifically the Jersey variant) to British citizens with a connection to Jersey by residency or birth.[138][139]  Jersey is constitutionally entitled to restrict immigration[140] by non-Jersey residents, but control of immigration at the point of entry cannot be introduced for British, certain Commonwealth and EEA nationals without change to existing international law.[141]  Jersey is part of the Common Travel Area (CTA),[142] a border control-free zone which encompasses the Crown Dependencies, the United Kingdom and the Republic of Ireland. This means a passport is not required to travel from Jersey to any of these territories (or vice versa) though the Government recommends all travellers bring photo ID since it may need to be checked by customs or police officers and is generally required by commercial transport providers into the island.[143] Due to the CTA, Jersey-born British citizens in the rest of the CTA and British and Irish citizens in Jersey have the right to access social benefits, access healthcare, access social housing support and to vote in general elections.[144]  For non-CTA travel, Jersey maintains its own immigration[145] and border controls (although most travel into the Bailiwick is from the rest of the CTA), however UK immigration legislation may be extended to Jersey (subject to exceptions and adaptations) following consultation with Jersey and with Jersey's consent.[146]  To control population numbers, Jersey operates a system of registration which restricts the right to live and work in the island according to certain requirements. In order to move to Jersey or work in Jersey, everyone (including Jersey-born people) must be registered and have a registration card. There are a number of statuses:  Until the 19th centuries, there was generally limited immigration to the island, especially from English people. Jersey was a distant territory to the British mainland (taking days to travel between England and the islands) and culturally distinct (the locals predominantly speaking Norman French).[136] However, from the 16th to 19th centuries, Jersey became home to French religious refugees, particularly Protestants following the Edict of Nantes.[148]  From the early 19th century, the island's economic boom attracted economic migrants. By 1841, of the 47,544 population, 11,338 were born in the British Isles outside of Jersey. From the 1840s onwards, agricultural workers came from neighbouring Brittany and mainland Normandy, both due to the booming economy of Jersey and the economic situation in northern France. Furthermore, the new potato season coincided with the time of least agricultural activity in Brittany and Normandy. While many returned to France, some settled in the island.[148]  Between 1851 and 1921, the Jersey population fell by 12.8% (possibly up to 18%). The economic boom ended in the 1850s leading to significant emigration, including on to British colonies. A 1901 report by the States concluded that by 1921, the number of births to foreign-born fathers would be equal to those to Jersey-born fathers, describing the immigration situation as a 'formidable invasion, although peaceful', and predicted this would have a large impact on the island's socio-political situation.[148]  After World War II, when the island had only 55,244 residents, it saw a period of rapid population increase. By 1991, the population was 84,082. The booming tourism industry required a large volume of relatively low cost labour, so the island turned to Madeira for seasonal staff. Between 1961 and 1981, the Portuguese-born population grew 0.2% to 3.1% of the population. In 2021, this figure was 8%. Since the fall of the Berlin Wall, the new source of cheap labour for the island has been Polish people, whose population has grown from non-existent to 3%.[148]  Immigration has helped give aspects of Jersey a distinct urban character, particularly in and around the parish of St Helier, which contributes much to ongoing debates between development and sustainability throughout the island.[149]  Jersey's patron saint is St Helier, after whom the capital town is named.[150] From the fifth century, the island was under the Bishop of Coutances, until being transferred to the Diocese of Winchester in 1568.[151] As of 2022, the island is planned to be transferred to the Diocese of Salisbury.[152] The established church is the Church of England, presided over in the island by the Dean, who is ex officio a States Member, but has no vote.[151] The primary churches are the parish churches, which are 12 ancient Anglican churches in each of the parish centre, though other churches do exist.[153]  According to a 2015 survey of islanders, 54% of adults have a religion. Christianity is the predominant religion in the island, with over half of islanders identifying as Christian in some form. The largest religious group is Anglicans, with 23% of the population.[154]  The Battle of Flowers is a carnival, which has been held annually in August since 1902.[155] Other festivals include La F\u00eate d\u00e9 Nou\u00e9[156] (Christmas festival), La Fa\u00ees'sie d'Cidre (cidermaking festival),[157] the Battle of Britain air display,[158] Weekender Music Festival,[159] food festivals, and parish events.  The Jersey Eisteddfod is an annual festival celebrating local culture. It is split into performing arts (e.g. dance, music, modern languages) and creative arts (e.g. needlework, photography, craft).[160]  Archaeologists have discovered stone planquettes with abstract designs made by the Magdalenians and dating to the Upper Palaeolithic; these are the oldest pieces of art discovered in the British Isles as of 2023.[161][162]  The island has produced a number of notable artists. John St Helier Lander (1868\u20131944) was a portrait painter born in St Helier in 1868; he was a portraitist for the Royal Family.[163] Edmund Blampied also lived around the same period; he was known for his etchings and drypoint.[164] Other famous historic artists include John Le Capelain, John Everett Millais and Philip Ouless. There are also several contemporary Jersey artists, such as Ian Rolls, known for painting quirky landscape paintings.[165]  Jersey also has historic connections to French art. French artist Ren\u00e9 Lalique created the stained glass windows at St Matthew's Church. No similar Lalique commission survives elsewhere in the world.[166] Artist partners Claude Cahun and Marcel Moore were born in France but moved to and died in the island.[167]  BBC Radio Jersey provides a radio service, and BBC Channel Islands News provides a joint television news service with Guernsey. ITV Channel Television is a regional ITV franchise shared with the Bailiwick of Guernsey but with its headquarters in Jersey. Radio services are also provided by Channel 103, among other companies.  Bailiwick Express is one of Jersey's digital online news sources. Jersey has only one newspaper, the Jersey Evening Post, which is printed six days a week, and has been in publication since 1890.[168]  Little is known of the history of music in the islands, though fieldwork has recorded folk songs from the Channel Islands, mostly in French.[170] The folk song Chanson de Peirson is unique to the island.[171]  In contemporary music, Guru Josh, who was born in Jersey, produced house and techno music. He was most notable for his internationally successful debut hit Infinity and its re-releases, reaching number one in numerous European countries.[172] Furthermore, rock and pop artist Nerina Pallot was raised on the island and has enjoyed international success, and has written songs for famous artists like Kylie Minogue.[173]  The island has a summer music festival scene stretching from mid-June to late September including Good Vibrations, Out-There, the Weekender (the largest festival in the Channel Islands) and Electric Park.[174]  There are two theatres on the island: the Jersey Opera House and the Jersey Arts Centre.[175] Lillie Langtry is probably the most famous actress from the island. She was born in Jersey and became an actress on the West End in the late 19th century. She was the first socialite to appear on stage and the first celebrity to endorse a commercial product.[176][177] She was also famous for her relationships with notable figures, including the Prince of Wales, later Edward VII.[178] She is buried in St Saviour's Church graveyard.[179]  In 1909, T. J. West established the first cinema in the Royal Hall in St. Helier, which became known as West's Cinema in 1923 and was demolished in 1977. The first talking picture, The Perfect Alibi, was shown on 30 December 1929 at the Picture House in St. Helier. The Jersey Film Society was founded on 11 December 1947 at the Caf\u00e9 Bleu, West's Cinema. The large Art Deco Forum Cinema was opened in 1935 \u2013 during the German occupation this was used for German propaganda films.[180]  The Odeon Cinema was opened 2 June 1952 and, was later rebranded in the early 21st century as the Forum cinema. Its owners, however, struggled to meet tough competition from the Cineworld Cinemas group, which opened a 10 screen multiplex on the waterfront centre in St. Helier on reclaimed land in December 2002 and the Odeon closed its doors in late 2008. The Odeon is now a listed building.[181][182]  First held in 2008, the Branchage Jersey International Film Festival[183] attracts filmmakers from all over the world. The 2001 movie The Others was set on the island in 1945 shortly after liberation.  Seafood has traditionally been important to the cuisine of Jersey: mussels (called moules in the island), oysters, lobster and crabs \u2013 especially spider crabs \u2013 ormers and conger.[184]  Jersey milk being very rich, cream and butter have played a large part in insular cooking.[185] Jersey Royal potatoes are the local variety of new potato, and the island is famous for its early crop of Chats (small potatoes) from the south-facing c\u00f4tils (steeply sloping fields). They were originally grown using vraic as a natural fertiliser, giving them their own individual taste; only a small portion of those grown in the island still use this method. They are eaten in a variety of ways, often simply boiled and served with butter or when not as fresh fried in butter.[186]  Apples historically were an important crop. Bourd\u00e9lots are apple dumplings, but the most typical speciality is black butter (l\u00e9 ni\u00e8r beurre), a dark spicy spread prepared from apples, cider and spices. Cider used to be an important export. After decline and near-disappearance in the late 20th century, apple production is being increased and promoted. Besides cider, apple brandy is produced. Other production of alcohol drinks includes wine,[187] and in 2013 the first commercial vodkas made from Jersey Royal potatoes were marketed.[188]  Among other traditional dishes are cabbage loaf, Jersey wonders (les m\u00e8rvelles), fliottes, bean crock (les pais au fou), nettle (ortchie) soup, and vraic buns.[184][189]  In its own right Jersey participates in the Commonwealth Games and in the biennial Island Games, which it first hosted in 1997 and more recently in 2015.[190]  The Jersey Football Association supervises football in Jersey. As of 2022, the Jersey Football Combination has nine teams in its top division.[191] Jersey national football team plays in the annual Muratti competition against the other Channel Islands.[192] Rugby union in Jersey comes under the auspices of the Jersey Rugby Association (JRA), which is a member of the Rugby Football Union of England. Jersey Reds compete in the English rugby union system;[193] after four promotions in five seasons, the last three of which were consecutive, they competed in the second-level RFU Championship in 2012\u201313.[194]  Jersey Cricket Board is the official governing body of the sport of cricket in Jersey. Jersey Cricket Board is Jersey's representative at the International Cricket Council (ICC). It has been an ICC member since 2005 and an associate member since 2007.[195] The Jersey cricket team plays in the Inter-insular match, as well as in ICC tournaments around the world in One Day Internationals and Twenty20 Internationals.  For Horse racing, Les Landes Racecourse can be found at Les Landes in St. Ouen next to the ruins of Grosnez Castle.[196]  Jersey has two public indoor swimming pools: AquaSplash, St Helier[197] and Les Quennevais, St Brelade.[198] Swimming in the sea, windsurfing and other marine sports are practised. Jersey Swimming Club has organised an annual swim from Elizabeth Castle to Saint Helier Harbour for over 50 years. A round-island swim is a major challenge: the record for the swim is Ross Wisby, who circumnavigated the island in 9 hours 26 minutes in 2015.[199] The Royal Channel Island Yacht Club is based in St Brelade.[200]  Two professional golfers from Jersey have won the Open Championship seven times between them; Harry Vardon won six times and Ted Ray won once, both around the turn of the 20th century. Vardon and Ray also won the U.S. Open once each. Harry Vardon's brother, Tom Vardon, had wins on various European tours.  Jersey Sport, an independent body that promotes sports in Jersey and support clubs, was launched in 2017[201]  Until the 19th century, indigenous J\u00e8rriais \u2013 a variety of Norman \u2013 was the language of the island though French was used for official business. During the 20th century, British cultural influence saw an intense language shift take place and Jersey today is predominantly English-speaking.[27] J\u00e8rriais nonetheless survives; around 2,600 islanders (three per cent) are thought to be habitual speakers, and some 10,000 (12 per cent) in all claim some knowledge of the language, particularly amongst the elderly in rural parishes. There have been efforts to revive J\u00e8rriais in schools.[202]  The dialects of J\u00e8rriais differ in phonology and, to a lesser extent, lexis between parishes, with the most marked differences to be heard between those of the west and east. Many place names are in J\u00e8rriais, and French and English place names are also to be found. Anglicisation of the place names increased apace with the migration of English people to the island.[203]  Wace was a 12th-century poet born in Jersey. He is the earliest known Jersey writer, authoring Roman de Brut and Roman de Rou, among others. Some believe him to be the earliest J\u00e8rriais writer and he is known as the founder of Jersey literature, but the language in which he wrote is very different from modern J\u00e8rriais.[15]  As J\u00e8rriais was not an official language in Jersey, it had no standard written form, which meant that Jersey literature is very varied, written in multiple forms of J\u00e8rriais alongside Standard English and French.[17]  Matthew Le Geyt was the first poet to publish in J\u00e8rriais after the introduction of printing to the island in the 18th century.[204] Philippe Le Sueur Mourant wrote in J\u00e8rriais in the 19th century.[18] Jerseyman George d'la Forge is named the 'Guardian of the Jersey Norman Heritage'. Though he lived in America for most of his life, he felt a strong attachment to Jersey and his native language. His works were turned into books in the 1980s.[19]  After the failure of the 1848 revolution, thirty-nine French revolutionaries were exiled in Jersey, including the famous French author Victor Hugo, as Jersey's culture had a relation to their native French.[22] Gerald Durrell, the famous zoologist who set up Jersey Zoo, was also an author, writing novels, non-fiction and children's books. He was writing as a means to fund and further his conservation work.[24]  Education in the island is managed by the Department for Children, Young People, Education and Skills of the Government of Jersey. The education system in Jersey is based on the English system. Full time education is compulsory for children aged 5 to 16.[205] Furthermore, the Government provides limited pre-school education free to parents.[206] Jersey schools must teach the Jersey Curriculum, which is based on the English National Curriculum, with differences to account for Jersey's unique position.[207]  As of 2022, there are 24 States primary schools, seven private primary or preparatory schools, four comprehensive States secondary schools, two fee-paying States secondary schools, two private secondary schools and one provided grammar school and sixth form, Hautlieu School.[208] Furthermore, Highlands College provides alternative post-16 and all post-18 education available on the island. However, higher education facilities are limited, so many students study off-island. In the UK, Jersey students pay the same rate as Home students.[209]  Three areas of land are protected for their ecological or geological interest as Sites of Special Interest (SSI). Jersey has four designated Ramsar sites: Les Pierres de Lecq, Les Minquiers, Les \u00c9cr\u00e9hous and Les Dirouilles and the south east coast of Jersey (a large area of intertidal zone).[211]  Jersey is the home of the Jersey Zoo (formerly known as the Durrell Wildlife Park[212]) founded by the naturalist, zookeeper and author Gerald Durrell.  Four species of small mammal are considered native:[213] the wood mouse (Apodemus sylvaticus), the Jersey bank vole (Myodes glareolus caesarius), the lesser white-toothed shrew (Crocidura suaveolens) and the French shrew (Sorex coronatus). Three wild mammals are well-established introductions: the rabbit (introduced in the mediaeval period), the red squirrel and the hedgehog (both introduced in the 19th century). The stoat (Mustela erminea) became extinct in Jersey between 1976 and 2000. The green lizard (Lacerta bilineata) is a protected species of reptile; Jersey is its only native habitat in the British Isles.[214]  The red-billed chough (Pyrrhocorax pyrrhocorax) became extinct in Jersey around 1900, when changes in farming and grazing practices led to a decline in the coastal slope habitat required by this species. Birds on the Edge, a project between the Government of Jersey, Durrell Wildlife Conservation Trust and National Trust for Jersey, is working to restore Jersey's coastal habitats and reinstate the red-billed chough (and other bird species) to the island[215]  Jersey is the only place in the British Isles where the agile frog (Rana dalmatina) is found.[216] The remaining population of agile frogs on Jersey is very small and is restricted to the south west of the island. The species is the subject of an ongoing programme to save it from extinction in Jersey via a collaboration between the Government of Jersey, Durrell Wildlife Conservation Trust and Jersey Amphibian and Reptile Group (JARG), with support and sponsorship from several other organisations. The programme includes captive breeding and release, public awareness and habitat restoration activities.[217]  Trees generally considered native are the alder (Alnus glutinosa), silver birch (Betula pendula), sweet chestnut (Castanea sativa), hazel (Corylus avellana), hawthorn (Crataegus monogyna), beech (Fagus sylvatica), ash (Fraxinus excelsior), aspen (Populus tremula), wild cherry (Prunus avium), blackthorn (Prunus spinosa), holm oak (Quercus ilex), oak (Quercus robur), sallow (Salix cinerea), elder (Sambucus nigra), elm (Ulmus spp.) and medlar (Mespilus germanica). Among notable introduced species, the cabbage palm (Cordyline australis) has been planted in coastal areas and may be seen in many gardens.[218]  Notable marine species[219] include the ormer, conger, bass, undulate ray, grey mullet, ballan wrasse and garfish. Marine mammals include the bottlenosed dolphin[220] and grey seal.[221]  Historically the island has given its name to a variety of overly-large cabbage, the Jersey cabbage, also known as Jersey kale or cow cabbage.[222]  Japanese knotweed (Reynoutria japonica) is an invasive species that threatens Jersey's biodiversity.[223] It is easily recognisable and has hollow stems with small white flowers that are produced in late summer.[224] Other non-native species on the island include the Colorado beetle, burnet rose and oak processionary moth.[223]  Health services on the island are overseen by the Department for Health and Social Care. Jersey does not have a nationalised health service and the service is not part of the National Health Service. Many healthcare treatments are not free at the point of use, however treatment in the accident and emergency department is free. For residents, prescriptions and some hospital treatments are free, but GP services cost money.[225]  Emergency services[226] are provided by the States of Jersey Police with the support of the Honorary Police as necessary, States of Jersey Ambulance Service,[227] Jersey Fire and Rescue Service[228] and the Jersey Coastguard.[229] The Jersey Fire and Rescue Service, Jersey Lifeboat Association and the Royal National Lifeboat Institution operate an inshore rescue and lifeboat service; Channel Islands Air Search provides rapid response airborne search of the surrounding waters.[230]  The States of Jersey Fire Service was formed in 1938 when the States took over the Saint Helier Fire Brigade, which had been formed in 1901. The first lifeboat was equipped, funded by the States, in 1830. The RNLI established a lifeboat station in 1884.[231] Border security and customs controls are undertaken by the States of Jersey Customs and Immigration Service. Jersey has adopted the 112 emergency number alongside its existing 999 emergency number.[232]  Water supplies in Jersey are managed by Jersey Water. Jersey Water supply water from two water treatment works, around 7.2 billion litres in 2018. Water in Jersey is almost exclusively from rainfall-dependent surface water. The water is collected and stored in six reservoirs and there is also a desalination plant that produces up to 10.8 million litres per day (around half of the Island's average daily usage). In 2017, 101 water pollution incidents were reported, an increase of 5% on 2016. Another estimated 515,700 m3 of water is abstracted for domestic purposes from private sources (around 9% of the population).[233]  Electricity in Jersey is provided by a sole supplier, Jersey Electricity, of which the States of Jersey is the majority shareholder.[234] Jersey imports 95 per cent of its power from France.[235] 35% of the imported power derives from hydro-electric sources and 65% from nuclear sources. Jersey Electricity claims the carbon intensity of its electricity supply is 35g CO2 e \/ kWh compared to 352g CO2 e \/ kWh in the UK.[236]  49\u00b011\u203224\u2033N 2\u00b06\u203236\u2033W\ufeff \/ \ufeff49.19000\u00b0N 2.11000\u00b0W\ufeff \/ 49.19000; -2.11000 "},{"title":"Backboard (basketball)","content":"A backboard is a piece of basketball equipment. It is a raised vertical board with an attached basket consisting of a net suspended from a hoop. It is made of a flat, rigid piece of, often Plexiglas or tempered glass which also has the properties of safety glass when accidentally shattered. It is usually rectangular as used in NBA, NCAA and international basketball. In recreational environments, a backboard may be oval or a fan-shape, particularly in non-professional games.  The top of the hoop is 10 feet (3.05\u00a0m) above the ground. Regulation backboards are 6 feet (1.83\u00a0m) wide by 3.5 feet (1.07\u00a0m) tall. All basketball rims (hoops) are 18 inches (46\u00a0cm) in diameter. The inner rectangle on the backboard is 24 inches (61\u00a0cm) wide by 18 inches (46\u00a0cm) tall, and helps a shooter determine the proper aim and banking for either a layup or distance shot.[1][2]  In addition to those markings and those of its manufacturer, leagues and governing bodies often place other decals on the edge of the backboard on the glass, including the logo of the league or organization, and a national flag. On top of the backboard, a league or team's web address or sponsor logo is affixed to take advantage of the high television camera angle utilized for instant replay of slam dunks and other shots above the rim.  In professional and most higher college settings, the backboard is part of a portable wheeled stanchion that can be moved out of the way and stored to allow the venue to host multiple other sports and events, though in most high schools and examples such as Stanford University's Maples Pavilion and Cameron Indoor Stadium at Duke University, backboards are mounted as part of a suspended system using the venue's ceiling joists to support the goal and allow them to be put out of the way in the ceiling support system via a system of pulleys when not in use, along with the more common wall-mounted system. Practice or gym class-utilized sideline backboards are generally of the permanently wall-mounted variety, and usually have opaque fiberglass or thick metal boards instead, along with most outdoor municipal park boards.  In intervening years, the portable stanchion containing the backboard has also taken on cabling and sensors within its core, along with the structure of a game clock and shot clock above it, which makes the setup of one as involved as an arena's basketball floor, to the point of requiring a replacement backboard being on standby if it and\/or the rim is ever taken out of level or broken.[3]  The first glass backboard was used by the Indiana Hoosiers men's basketball team at the Men's Gymnasium at Indiana University.[4] After the first few games at their new facility in 1917, spectators complained that they could not see the game because of opaque wooden backboards. As a result, the Nurre Mirror Plate Company in Bloomington was employed to create new backboards that contained 1+1\u20442-inch-thick (3.8\u00a0cm) plate glass so that fans could see games without an obstructed view. It was the first facility in the country to use glass backboards.[4]  Professional glass backboards used to break from 625 pounds (283\u00a0kg) of force or more. Modern professional and higher-level college play backboards do not have the glass absorbing any weight to avoid breaking the glass and backboard as a whole.[5] "},{"title":"Handball (Australian rules football)","content":"  The Handball or handpass is a ball-passing skill in the sport of Australian rules football. As throwing the ball is not allowed in Australian football, passing to a fellow player are executed either by kicking, or by a controlled \"punch\" with one hand holding the ball while the other knocking it into flight (typically in a fashion similar to an uppercut or an underhand volleyball serve). Handballing is the primary means of disposing the ball quickly and over short distances in Australian football.  Handball revolutionized the game in the 1980s, moving it from the classic kick-and-mark style of play (which runs the risk of the pass being contested and intercepted by opposing players) to a fast run-and-carry style that emphasizes on maintaining possession and rapid ball movements down the field, which has typified the game since. The most prolific handballers in the history of the Australian Football League: Lachie Neale, Greg Williams, Scott Pendlebury, Josh Kennedy and Adam Treloar have averaged more than 13 handballs a game.  Handball is the most frequently used alternative of moving the football among players to kicking. In order to be a legal method to dispose of the ball, the player holds the ball with one hand and punches the ball away with the clenched fist of the other hand. A player typically punches with his dominant hand, thus holding the ball with the left hand and punching with the right hand is considered a right-handed handball.   When a player receives a handpass from another player, play continues. This is unlike the kick, where if a player catches the ball on the full from a kick (a mark), he is entitled to take his next kick unimpeded. Failure to execute a handball correctly is deemed a throw or illegal disposal and results in a free kick to the nearest opposition player. Moving the hand that holds the ball excessively in the direction of the handpass, using an open hand instead of a clenched fist to tap the ball away, punching the ball out of mid-air after having thrown or otherwise lost it from the carrying hand, or handing the ball directly to a teammate will all attract a free kick for illegal disposal.  The rule defines it similarly to the open hand tap\/handpass in Gaelic football but differentiates the hand skills from other codes of football. Unlike Gaelic football, punching the oval ball was more frequently used as it was the most effective technique to move the heavier ball larger distances.  Although the rules allowed for the handball, for most Australian football leagues the handball was largely a secondary skill to the kick and used as a last resort when a player had no time to kick. Strategically, Australian football was viewed as a territorial sport, where the prime aim was not so much possession, but to cover as much distance through the air as possible. As the holding hand could not move, this was best achieved by means of kicking the ball as far as possible.  The principally used handpass was top-spin in nature. This was used with the belief that the ball could be contained more locally and executed more quickly off the hands when the ball was held in preparation for kicking, as smaller handpasses were originally used mainly when in trouble. The other thought was that, as in tennis, a top-spun ball was more easily directed, dipped faster and possessed more stability in the air.  One notable variant of the handpass which began to develop was known as the flick pass, in which a player used his open hand instead of his fist to propel the ball. The legality of the flick pass has varied throughout the history of the game: it began to gain prominence in the early 1920s, before the Australian National Football Council (ANFC) voted to abolish it before the 1925 season, making the handpass with a clenched fist (sometimes termed a punch pass to distinguish it from the flick pass) the only legal form of handpass. This was not widely popular, as the style of punch pass used at the time a much more cumbersome disposal than a flick pass, and it resulted in the game being played at a slower pace.[1] The flick pass was re-instated before the 1934 season.[2] In the late 1950s and early 1960s it re-emerged as a common technique to achieve centre square clearances from scrimmages, particularly at VFL club Fitzroy.[3] Of the 88 handballs executed during the 1961 VFL Grand Final, 18 were flick passes.[4] The flick pass was abolished permanently in 1966.[5]  The flick pass had the significant drawback that its action was close to that of a throw, and different umpires had different interpretations of what was legal. In 1938, motivated by a desire to eliminate this inconsistency, and to speed up the game further, the Victorian Football Association (VFA) legalised throwing the ball, provided the throw was with two hands and both hands were below shoulder-height. The throw-pass was legal in the VFA and in some other competitions affiliated with it from 1938 until 1949, but it was never legal under ANFC rules.[6][7][8]  The emergence of the handball as a more widely used skill for attacking took place in the 1960s and 1970s. Legendary coach Ron Barassi, Jr. credits Len Smith (coach at Fitzroy between 1958 and 1962) as being the first coach to encourage attacking use of handball in Victoria.[9] A running handball game emerged in the South Australian National Football League (SANFL) with Sturt coach Jack Oatey credited with encouraging the skill through the late 1960s, leading to Sturt winning five premierships from 1966 to 1970. In Western Australia, Graham 'Polly' Farmer and Barry Cable brought a new dimension to the game using handball, with Farmer often looking for a runner to handpass to after each mark, to speed up the ball movement. The 1970 VFL Grand Final became particularly notable for its use of handball, as Carlton's extensive attacking use of handball at coach Barassi's direct and famous half time instructions helped it recover from a 44-point half-time deficit to win the game; the game is sometimes apocryphally referred to as the \"birth of modern football\" in recognition of the significant effect that a modern handballing game had on its result, although the style of play was already common before the game.[4]  The modern handpass technique, known as the rocket handball, was pioneered by Kevin Sheedy.[10] It is executed so that the ball rotates backwards in an end-to-end fashion, similar to the drop punt. The ball is held on a slight angle with the fist ending up in or close to the other open hand. This enables a handpass to achieve distance and speed comparable to a short kick and is easier for teammates to catch. Professional Australian footballers are typically competent at handballing using either punching arm. Other handball variations include the underground handball, which is similar to a bounce pass in basketball or netball, and the dubious hospital handball (so called because of its potential for putting the intended recipient in hospital due to opponents closing in on the target player, usually caused by a high pass to a closely guarded player).  With the wide adoption of the handball in the 1980s, midfielders such as Greg Williams and Dale Weightman became handball specialists, renowned their playmaking ability by preferring to handball in the midfield. In the 1980s, Richmond Football Club wingman Kevin Bartlett became famous for a style of play which involved use of the handball to dispose of the ball before an opponent was about to tackle.  Although rules were uniform across the country, local interpretations and customs varied. South Australian players became known for a very localised style of play in which players excelled in quickly releasing the ball. The style, known pejoratively interstate as a crow throw (derived from croweaters, a popular term for South Australians), became damaging to opposition sides in interstate matches, as well as a potent weapon for the Adelaide Crows when the club first entered the Australian Football League in the 1991 AFL season. The legality of the technique was frequently brought into question in the AFL. The South Australian style featured a significantly shorter swinging distance between the punching hand and holding hand, allowing it to be executed in almost any stance. This also made it more difficult for a tackler to attack the swinging arm. As had been a problem with the flick pass, it was more difficult for spectators and umpires to interpret whether or not the correct punching method is being used. Andrew Jarman was the most notable exponent, although it resulted in many free kicks against him when playing outside the SANFL.  Since 2000, the number of handpasses used in AFL matches has grown substantially, double that of the 1970s. The focus of the modern game was to use chains of handballs to break through defensive zones, and to avoid kicking to contests.  Handball competitions are often used to test the accuracy of handpasses. A handball competition typically uses a board or vertically hung material with a target consisting of multiple coloured concentric bands worth different points. The centre is usually cut out to let the ball through and is worth maximum points (typically ten).  Handball competitions often occur at local clubs, Auskick clinics and on television, most notably on the shows World of Sport and The Sunday Footy Show (both hosted by Lou Richards). Such competitions take place between Australian Football League players known for their handpassing skills, and often utilise moving targets. "},{"title":"Goal (sports)","content":"  In sport, a goal may refer to either an instance of scoring, or to the physical structure or area where an attacking team must send the ball or puck in order to score points. The structure of a goal varies from sport to sport, and one is placed at or near each end of the playing field for each team to defend. For many sports, each goal structure usually consists of two vertical posts, called goal posts, supporting a horizontal crossbar. A goal line marked on the playing surface between the goal posts demarcates the goal area. Thus, the objective is to send the ball or puck between the goal posts, under or over the crossbar (depending on the sport), and across the goal line. Other sports may have other types of structures or areas where the ball or puck must pass through, such as the basketball hoop. Sports which feature goal scoring are also commonly known as invasion games.[1][2]  In several sports, sending the ball or puck into the opponent's goal structure or area is the sole method of scoring, and thus the final score is expressed in the total number of goals scored by each team. In other sports, a goal may be one of several scoring methods, and thus may be worth a different set number of points than the others.  In some sports, the goal is the sole method of scoring. In these sports, the final score is expressed as the number of goals scored by each team, with the winner being the team that accumulated more over the specified time period.  In other sports, a goal is not the sole method of scoring. In these sports, the goal is worth a set number of points but there are other methods of scoring which may be worth more, the same, or fewer points. In these sports, the score is expressed as the total number of points earned by each team.  In Australian rules football the score is expressed by listing the quantity of each team's \"goals\" and \"behinds\" followed by the total number of points.  The structure of a goal varies from sport to sport. Most often, it is a rectangular structure that is placed at each end of the playing field. Each structure usually consists of two vertical posts, called goal posts (side bar or uprights) supporting a horizontal crossbar. A goal line marked on the playing surface between the goal posts demarcates the goal area.  In some games, such as association football or hockey, the object is to pass the ball between the posts below the crossbar, while in others, such as those based on rugby, the ball must pass over the crossbar instead. In Gaelic football and hurling, in which the goalposts are similar to those used in rugby, the ball can be kicked either under the crossbar for a goal, or over the crossbar between the posts for a point. In Australian rules football, there is no crossbar but four uprights instead. In basketball, netball or korfball, goals are ring-shaped. The structure is often accompanied with an auxiliary net, which stops or slows down the ball when a goal is scored. In netball, a single post at each end of the court supports a horizontal hoop that the ball must fall through. In basketball, the hoop and net used for scoring can be supported on a post or mechanism at each end, or on structures attached directly to the wall.  The goal is the only method of scoring in several games. In each of these cases, the winner is the team that scores the most goals within the specified time.  In association football, the goal is the only method of scoring. It is also used to refer to the scoring structure. An attempt on goal is referred to as a \"shot\". To score a goal, the ball must pass completely over the goal line between the goal posts and under the crossbar and no rules may be violated on the play (such as touching the ball with the hand or arm).[3] See also offside.  The goal structure is defined as a frame 24\u00a0feet (7.32\u00a0m) wide by 8\u00a0feet (2.44\u00a0m) tall. In most organized levels of play a net is attached behind the goal frame to catch the ball and indicate that a goal has been scored; but the Laws of the Game do not mandate the use of a net and only require that any net used not interfere with the goalkeeper.[4]  In bandy, which has much of its structure from association football, the only way of scoring is to make a goal and the goal is also used to refer to the scoring structure. If neither of the teams has scored during a match, or if both teams have made the same number of goals, there is a draw. If not otherwise decided in the Bandy Playing Rules set up by the Federation of International Bandy,[5] an approved goal is made when the ball is played in a regular manner and the whole ball has passed the inner definition of the goal line between the two goal posts and the cross-bar. This is stated in section 9 of the Rules. A goal can be made directly from a stroke-off, penalty-shot, a free-stroke, a face-off or a corner stroke. Centered at each short-line of the bandy field is a 3.5\u00a0m (11\u00a0ft) wide and 2.1\u00a0m (6\u00a0ft 11\u00a0in) high goal cage, regulated to size, form, material and other properties in section 1.4 of the Bandy Playing Rules. The cage has a net to stop the ball when it has crossed the goal-line. The cage shall be of an approved model. In front of the goal cage is a half-circular penalty area with a 17\u00a0m (56\u00a0ft) radius. A penalty spot is located 12 metres (39\u00a0ft) in front of the goal and there are two free-stroke spots at the penalty area line, each surrounded by a 5\u00a0m (16\u00a0ft) circle.  The goal structure in field hockey is 3.66 metres (12.0\u00a0ft) wide by 2.14 metres (7.0\u00a0ft) tall. Like association football, a goal is scored when the ball passes completely over the goal line under the crossbar and between the goal posts. Nets are required to hold the ball in.[6] A goal is only scored if shot from with a semicircle 14.63 metres (48.0\u00a0ft) from the goal.[6]  A goal in handball is scored when the ball is thrown completely over the goal line, below the crossbar and between the goal posts.[7] The goal structure in team handball is 2\u00a0metres high and 3\u00a0metres wide. A net is required to catch the ball.[7]  In ice hockey, the puck must be put completely over the goal line between the posts and under the bar either off an offensive player's stick or off any part of a defensive player's body. The puck may not be kicked, batted, or thrown into the goal, though a goal may be awarded if the puck is inadvertently deflected off an offensive player's skate or body into the goal.[citation needed] The goal structure is a frame 4 feet (1.2\u00a0m) tall and 6 feet (1.8\u00a0m) wide with a net attached. In most higher levels of play the goal structure is attached to the ice surface by flexible pegs and will break away for safety when hit by a player. The goal is placed within the playing surface, and players may play the puck behind the goal.[8]  Lacrosse goals are scored when the ball travels completely past the goal line. Goals can be disallowed if there is an infraction by the offensive team. The goal in lacrosse is 6 feet (1.8\u00a0m) tall and 6 feet (1.8\u00a0m) wide and a net is used to prevent the ball from reentering the field of play. Lacrosse goals are not positioned on the end boundary line; play often occurs behind the goal.[9]  In netball, a goal is scored when the ball is shot through a goal ring on a pole.  In polo, a goal is scored if the ball passes completely between the goal posts, regardless of how far off the ground the ball is.  The ball must be between the goal posts or the imaginary lines extending above the inside edges of the posts.  A ball passing directly over a goal post does not score a goal.[10]  The goal structure in Polo consists of two poles, at least 10 feet (3.0\u00a0m) high and exactly 8 yards apart.  There is no crossbar and no net is required. The height at which a goal may be scored is infinite.[10]  In Hardcourt Bike Polo, a goal is scored if the ball passes completely over the goal line and the shot originated as a \"shot\" as defined by the rules. A shot is made with either end of the mallet head similar to swinging a hammer whereas a shuffle is made with the long side like pushing a broom. Traditionally when using a non-netted goal such as two traffic cones the play is continued if the ball is shuffled through the goal of pass through the goal from the opposite direction. These non-netted goals are no long regulation[11][12] in competitive play but are common depending on the resources of a club.  In shinty, a goal is scored if the ball goes over the goal line and under the crossbar. A goal can only be scored with a stick called a \"caman\"; no goal is scored if the ball is kicked, carried, or propelled by an attacking player's hand or arm.  A goal in water polo is scored when the ball passes completely across the goal line, under the crossbar and between the goal posts.  A goal may be scored through contact with any part of the attacker's body except a clenched fist.[13] The goal structure in water polo is dependent upon the depth of the water.  The goal mouth measures 3\u00a0metres across and is either 0.9\u00a0metres above the surface of the water or 2.4\u00a0metres above the floor of the pool, whichever is higher.  Nets are required.[13]  The following games have more than one possible method of scoring where the goal is the primary method, i.e. the method that scores the most points. In most cases the score is shown as the number of goals, plus the number of secondary scores (usually 1 point), plus the total number of points. The side with the higher number of total points is the winner.  In Australian rules football a goal is scored when the ball is kicked by an attacking player completely between the two tall goal posts. To be awarded a goal, the ball may not contact or pass over the goal post, or touch any player on any part of the body other than the foot or lower leg of an attacker. In such cases, the score is a behind (1 point). The ball may be punted, drop kicked, or kicked off the ground (soccered). The ball may cross the goal line at any height from ground level up and may bounce before crossing the line. A goal scores six points. The behind, which scores one point; is awarded if the ball passes between the point posts or is not awarded a goal by the above provisions when passing through the goal posts.[14] The goal structure consists of two posts at least 6\u00a0metres in height and spaced 6.4\u00a0metres apart. There is no crossbar and no net.[14]  The primary object of basketball is to score by shooting (i.e., throwing) the ball into a goal officially called the basket. A basket is scored when the ball passes completely through the basket ring from above; however, the number of points scored with each basket depends on where on the court the ball was shot from, and a team does not necessarily need to score the most baskets to win the game. Basketball scores are expressed in total points.[15]  A basket scored during normal play is called a field goal and is worth two points if shot from within or on the three-point line, and three points if shot from beyond the three-point line. The three-point line's distance from the basket varies by level. Points are also awarded to the shooting team if the defensive team commits goaltending or basket interference while the ball is in flight towards the basket or is directly over it.  A basketball team can also score by free throws, which score one point each. Free throws are awarded to a team after the opponent commits a foul in certain scenarios. The player taking the free throws (usually the player who was fouled) is entitled to take a specified number of shots unopposed with both feet behind the free throw line.  The basket consists of a metal ring 18 inches (46\u00a0cm) in internal diameter, suspended horizontally 10 feet (3.0\u00a0m) above the floor such that the center of the ring is equidistant from each sideline and 5\u00a0feet 3\u00a0inches (1.60\u00a0m) from the end line. The basket ring has a net attached below to briefly check the ball's downward progress and indicate a score. The ring is fastened to a rectangular backboard 6 feet (1.8\u00a0m) wide by 3.5 feet (1.1\u00a0m) tall,[16][17] though in lower levels of play or recreational use the backboard may be smaller and\/or fan-shaped. The entire structure is supported from behind and anchored to the floor beyond the end line at higher levels of play; the structure may be anchored to a wall or ceiling at lower levels of play.[17] The ring, net, and the front, top, bottom, and sides of the backboard are all considered inbounds, while the back of the backboard and the support structure \u2013 even those parts suspended over inbounds areas of the court \u2013 are considered out of bounds.[citation needed]  In Gaelic football a goal is scored when the ball passes completely beyond the goal line, between the goal posts and under the cross bar. The ball can be played with the hands, but a goal cannot be scored by hand. A ball travelling between the goal posts and over the cross bar is awarded one pointed called an \"over\". Overs are the most common scoring method with goals heavily defended.[18] A goal is worth three points.  In hurling the ball must pass completely beyond the goal line.  The ball may be played by any legal method except by the hand of the attacker.  A ball in flight may be deflected into the goal off the hand of an attacker. Hurling and Gaelic football use the same goal structure.  It is a 6.4\u00a0meter wide frame with a net attached.  The goal posts are at least 6\u00a0meters high, and the crossbar is 2.44\u00a0meters above the ground.  A goal is scored when the ball crosses below the crossbar and a point is scored when the ball passes above it.[18]  At each end of the field in the following games, there is both a marked scoring area and a separate goal post structure. In these games, the term \"goal\" is only used for the secondary scoring method of putting the ball through the goal post structure.  In American and Canadian football, there is a scoring area marked at each end of the field called an end zone, and a separate goal post structure.  The primary method of scoring is a touchdown. Whether running, passing, returning a kickoff or punt, or recovering a turnover, a team scores a touchdown by advancing the ball into the end zone. A touchdown scores 6 points in both versions of the sport. The front line of the end zone is the \"goal line\", its back line is the \"end line\", and each corner is marked with a pylon. Each end zone in American football is about 10 by 53.33 yards (9.14\u00a0m \u00d7\u00a048.76\u00a0m) wide, while each end zone in Canadian football is about 20 by 65 yards (18\u00a0m \u00d7\u00a059\u00a0m) wide. Unlike other sports which require the ball\/puck to pass completely over the goal line to count as a score, both Canadian and American football merely need any part of the ball to break the vertical plane of the outer edge of the goal line to count as a touchdown.  A field goal is a secondary method of scoring; it is scored when the ball is place kicked or drop kicked completely over the crossbar and between or directly over the goal posts. A field goal scores 3 points in both versions of the sport. In the American game, the now rarely used fair catch kick, if successfully made, also scores 3 points. A goal kicked during a try following a touchdown is worth one point.[19][20] These are the only methods of putting the ball through the goal posts that award points to the kicking team; no points are scored if the ball is punted or thrown through the goal posts, or if the ball goes through the goal posts on a kickoff (except, in the latter case, in indoor American football, where some leagues award a single point).  In both sports, the goal structure consists of a horizontal crossbar suspended ten feet (3.05\u00a0m) above the ground and vertical goal posts (\"uprights\") placed 18\u00a0feet 6\u00a0inches (5.64\u00a0m) apart and extending at least 35 feet (10.67\u00a0m) above the crossbar. In lower levels of play the goal posts may be placed further apart and\/or not extend as far above the crossbar; for example, in high school football the posts are 23\u00a0feet 4\u00a0inches (7.11\u00a0m) apart. NFL and CFL rules mandate that a ribbon be attached to the top of each goal post.[21][22] Goals are centered on the field, but on different lines: in American football, they lie on the \"end line\" (far end of the end zone) and in Canadian football, on the \"goal line\" (beginning of the end zone). A retractable net may be placed behind the goal posts, well beyond the field of play, to prevent the ball from entering spectator areas.  Until the mid-1960s, the goal posts were similar in design to rugby posts, with the crossbar and uprights supported by stanchions installed directly underneath the uprights (in the shape of the letter 'H'). A transitional design from this time retained the twin set of stanchions but placed them behind the crossbar. In this design, the crossbar and uprights were supported by a set of horizontal, vertical, and diagonal stanchions behind each upright. This design was last used professionally in the first Super Bowl in January 1967. The modern goal posts supported by a single \"goose-necked\" stanchion (in the shape of the letter 'Y') made their debut in the 1966 CFL playoffs and were adopted by all three professional leagues (CFL, NFL, and AFL) the following year, with many (but not all) college teams following suit in the years since.[23] The NFL, which merged with the AFL in 1970, had its crossbar over the goal line until\u00a01974.  In arena football, a field goal also scores three points, unless it is drop kicked, in which case it scores four points.[24] The goal structure in arena football is much smaller than the outdoor game; it consists of a crossbar 15 feet (4.57\u00a0m) above the playing surface and 9.5 feet (2.90\u00a0m) wide; this size is also used for most other indoor leagues as well.  Uniquely in arena football, the goal posts are attached to nets on either side of the crossbar which are taut to allow the ball to rebound back onto the field of play. The nets are 30 feet (9.14\u00a0m) wide and 37 feet (11.28\u00a0m) high. These nets do not represent a scoring area, but keep the ball in play and prevent it from entering the crowd.[24]  Canadian football also offers a secondary form of goal, the rouge or single point; it is awarded if a ball enters the end zone by way of any kick (either a missed field goal or a punt) and is not returned by the opposing team; this is not offered in American football (such a play results in a touchback instead).    In both rugby codes, there is a scoring area marked at each end of the field called an in-goal area, and a separate H-shaped goal structure. The primary scoring method is a try, worth 5 points in rugby union and worth 4 points in rugby league. A try is scored by grounding the ball in the in-goal area.  A goal is scored in either rugby code by place kicking or drop kicking a ball over the crossbar and between the uprights of H-shaped goalposts.[25][26] The goalposts are positioned centrally on the goal line (the front line of the in-goal area). The crossbar is 3 metres (9.8\u00a0ft) from the ground; the uprights are 5.5 metres (18\u00a0ft) apart in rugby league and 5.6 metres (18\u00a0ft) in rugby union.  In the early years of rugby, only goals counted in scoring, and a \"try\" counted only if \"converted\" into a goal. The official name \"goal from a try\" for a converted try persisted until 1979.  Celebrating the scoring of a goal is common. It is normally performed by the goalscorer, and may involve his or her teammates, the manager or coaching staff and\/or the supporters of the team. Whilst referring to the celebration of a goal in general, the term can also be applied to specific actions, such as a player removing his shirt or performing a somersault.  The expression \"moving the goalposts\", which means to make a set of goals more difficult just as they are being met, is often used in business but is derived from association football.[28] It is commonly used to imply bad faith on the part of those setting goals for others to meet, by arbitrarily making additional demands just as the initial ones are about to be met.  In business, the concept is more abstract, with some performance measure or target being set as a goalpost while achieving the target is often known as achieving a goal. "},{"title":"Ball","content":"  A ball is a round object (usually spherical, but can sometimes be ovoid)[1] with several uses. It is used in ball games, where the play of the game follows the state of the ball as it is hit, kicked or thrown by players. Balls can also be used for simpler activities, such as catch or juggling. Balls made from hard-wearing materials are used in engineering applications to provide very low friction bearings, known as ball bearings. Black-powder weapons use stone and metal balls as projectiles.  Although many types of balls are today made from rubber, this form was unknown outside the Americas until after the voyages of Columbus. The Spanish were the first Europeans to see the bouncing rubber balls (although solid and not inflated) which were employed most notably in the Mesoamerican ballgame. Balls used in various sports in other parts of the world prior to Columbus were made from other materials such as animal bladders or skins, stuffed with various materials.  As balls are one of the most familiar spherical objects to humans, the word \"ball\" may refer to or describe spherical or near-spherical objects.  \"Ball\" is used metaphorically sometimes to denote something spherical or spheroid, e.g., armadillos and human beings curl up into a ball, making a fist into a ball.  The first known use of the word ball in English in the sense of a globular body that is played with was in 1205 in La\u021damon's Brut, or Chronicle of Britain in the phrase, \"Summe heo driuen balles wide \u021deond \u00dea feldes.\" The word came from the Middle English bal (inflected as ball-e, -es, in turn from Old Norse b\u00f6llr (pronounced [b\u0254l\u02d0r]; compare Old Swedish baller, and Swedish boll) from Proto-Germanic ballu-z (whence probably Middle High German bal, ball-es, Middle Dutch bal), a cognate with Old High German ballo, pallo, Middle High German balle from Proto-Germanic *ballon (weak masculine), and Old High German ball\u00e2, pall\u00e2, Middle High German balle, Proto-Germanic *ball\u00f4n (weak feminine). No Old English representative of any of these is known. (The answering forms in Old English would have been beallu, -a, -e\u2014compare bealluc, ballock.) If ball- was native in Germanic, it may have been a cognate with the Latin foll-is in sense of a \"thing blown up or inflated.\" In the later Middle English spelling balle the word coincided graphically with the French balle \"ball\" and \"bale\" which has hence been erroneously assumed to be its source. French balle (but not boule) is assumed to be of Germanic origin, itself, however. In Ancient Greek the word \u03c0\u03ac\u03bb\u03bb\u03b1 (palla) for \"ball\" is attested[2] besides the word \u03c3\u03c6\u03b1\u03af\u03c1\u03b1 (sfa\u00edra), sphere.[3]  A ball, as the essential feature in many forms of gameplay requiring physical exertion, must date from the very earliest times. A rolling object appeals not only to a human baby, but to a kitten and a puppy. Some form of game with a ball is found portrayed on Egyptian monuments.[citation needed]  In Homer, Nausicaa was playing at ball with her maidens when Odysseus first saw her in the land of the Phaeacians (Od. vi. 100). And Halios and Laodamas performed before Alcinous and Odysseus with ball play, accompanied with dancing (Od. viii. 370).[4] The most ancient balls in Eurasia have been discovered in Karasahr, China and are 3000 years old. They were made of hair-filled leather.[5]  Among the ancient Greeks, games with balls (\u03c3\u03c6\u03b1\u1fd6\u03c1\u03b1\u03b9) were regarded as a useful subsidiary to the more violent athletic exercises, as a means of keeping the body supple, and rendering it graceful, but were generally left to boys and girls. Of regular rules for the playing of ball games, little trace remains, if there were any such. The names in Greek for various forms, which have come down to us in such works as the \u1f48\u03bd\u03bf\u03bc\u03b1\u03c3\u03c4\u03b9\u03ba\u03cc\u03bd of Julius Pollux, imply little or nothing of such; thus, \u1f00\u03c0\u03cc\u03c1\u03c1\u03b1\u03be\u03b9\u03c2 (aporraxis) only means the putting of the ball on the ground with the open hand, \u03bf\u1f50\u03c1\u03b1\u03bd\u03af\u03b1 (ourania), the flinging of the ball in the air to be caught by two or more players; \u03c6\u03b1\u03b9\u03bd\u03af\u03bd\u03b4\u03b1 (phaininda) would seem to be a game of catch played by two or more, where feinting is used as a test of quickness and skill. Pollux (i. x. 104) mentions a game called episkyros (\u1f10\u03c0\u03af\u03c3\u03ba\u03c5\u03c1\u03bf\u03c2), which has often been looked on as the origin of football. It seems to have been played by two sides, arranged in lines; how far there was any form of \"goal\" seems uncertain.[4] It was impossible to produce a ball that was perfectly spherical;[6] children usually made their own balls by inflating pig's bladders and heating them in the ashes of a fire to make them rounder,[6] although Plato (fl. 420s BC \u2013 340s BC) described \"balls which have leather coverings in twelve pieces\".[7]  Among the Romans, ball games were looked upon as an adjunct to the bath, and were graduated to the age and health of the bathers, and usually a place (sphaeristerium) was set apart for them in the baths (thermae). There appear to have been three types or sizes of ball, the pila, or small ball, used in catching games, the paganica, a heavy ball stuffed with feathers, and the follis, a leather ball filled with air, the largest of the three. This was struck from player to player, who wore a kind of gauntlet on the arm. There was a game known as trigon, played by three players standing in the form of a triangle, and played with the follis, and also one known as harpastum, which seems to imply a \"scrimmage\" among several players for the ball. These games are known to us through the Romans, though the names are Greek.[4]  The various modern games played with a ball or balls and subject to rules are treated under their various names, such as polo, cricket, football, etc.[4]  In sports, many modern balls are pressurized. Some are pressurized at the factory (e.g. tennis, squash (sport)) and others are pressurized by users (e.g. volleyball, basketball, football). Almost all pressurized balls gradually leak air. If the ball is factory pressurized, there is usually a rule about whether the ball retains sufficient pressure to remain playable.[8][9] Depressurized balls lack bounce and are often termed \"dead\". In extreme cases a dead ball becomes flaccid. If the ball is pressured on use, there are generally rules about how the ball is pressurized before the match, and when (or whether) the ball can be repressurized or replaced.   Due to the ideal gas law, ball pressure is a function of temperature, generally tracking ambient conditions. Softer balls that are struck hard (especially squash balls) increase in temperature due to inelastic collision.   In outdoor sports, wet balls play differently than dry balls. In indoor sports, balls may become damp due to hand sweat. Any form of humidity or dampness will affect a ball's surface friction, which will alter a player's ability to impart spin on the ball. The action required to apply spin to a ball is governed by the physics of angular momentum. Spinning balls travelling through air (technically a fluid) will experience the Magnus effect, which can produce lateral deflections in addition to the normal up-down curvature induced by a combination of wind resistance and gravity.  Several sports use a ball in the shape of a prolate spheroid: "},{"title":"Water polo","content":"  Water polo is a competitive team sport played in water between two teams of seven players each. The game consists of four quarters in which the teams attempt to score goals by throwing the ball into the opposing team's goal. The team with the most goals at the end of the game wins the match. Each team is made up of six field players and one goalkeeper. Excluding the goalkeeper, players participate in both offensive and defensive roles. It is typically played in an all-deep pool where players cannot touch the bottom.  A game consists mainly of the players swimming to move about the pool, treading water (mainly using the eggbeater kick), passing the ball, and shooting at the goal. Teamwork, tactical thinking and awareness are also highly important aspects. Water polo is a highly physical and demanding sport and has frequently been cited as one of the most difficult to play.[1][2][3]  Special equipment for water polo includes a water polo ball, a ball of varying colors which floats on the water; numbered and coloured caps; and two goals, which either float in the water or are attached to the sides of the pool.  The game is thought to have originated in Scotland in the mid-19th century; specifically, William Wilson is thought to have developed it in the 1870s as a sort of \"water rugby\". The game further developed with the formation of the London Water Polo League and has since expanded, becoming popular in parts of Europe, the United States, Brazil, China, Canada and Australia.  The history of water polo as a team sport began as a demonstration of strength and swimming skill in mid-19th century England and Scotland, where water sports and racing exhibitions were a feature of county fairs and festivals.[4][5] Men's water polo was among the first team sports introduced at the modern Olympic games in 1900. The present-day game involves teams of seven players (plus up to six substitutes), with a water polo ball similar in size to a soccer ball but constructed of air-tight nylon.  One of the earliest recorded viewings of water polo was conducted at the 4th Open Air Fete of the London Swimming Club, held at the Crystal Palace, London on 15 September 1873.[6] Another antecedent of the modern game of water polo was a game of water 'handball' played at Bournemouth on 13 July 1876.[7] This was a game between 12 members of the Premier Rowing Club, with goals being marked by four flags placed in the water near to the midpoint of Bournemouth Pier. The game started at 6:00 pm and lasted for 15 minutes (when the ball burst) watched by a large crowd; with plans being made for play on a larger scale the following week.  The rules of water polo were originally developed in the late nineteenth century in Great Britain by William Wilson. Wilson is believed to have been the First Baths Master of the Arlington Baths Club in Glasgow. The first games of 'aquatic football' were played at the Arlington in the late 1800s (the club was founded in 1870), with a ball constructed of India rubber. This \"water rugby\" came to be called \"water polo\" based on the English pronunciation of the Balti word for ball, pulu.[8][9] Early play allowed brute strength, wrestling and holding opposing players underwater to recover the ball. Players held underwater for lengthy periods usually surrendered possession. The goalie stood outside the playing area and defended the goal by jumping in on any opponent attempting to score by placing the ball on the deck.  Water polo is now popular in many countries around the world, notably Europe (particularly in Spain, France, Netherlands, Germany, Italy, Croatia, Hungary, Serbia, Montenegro, Greece and Romania), Australia, Brazil, Canada and the United States.  Some countries have two principal competitions: a more prestigious league which is typically a double round-robin tournament restricted to the elite clubs, and a cup which is a single-elimination tournament open to both the elite and lesser clubs.  The rules of water polo cover the play, procedures, equipment and officiating of water polo. These rules are similar throughout the world, although slight variations to the rules occur regionally and depending on the governing body. Governing bodies of water polo include FINA, the international governing organization; LEN, which governs international European matches; the NCAA, which governs collegiate matches in the United States; the NFHS, which governs high schools in the US, and the IOC, which governs Olympic events.  There are seven players in the water from each team at one time. There are six players that play out and one goalkeeper. Unlike most common team sports, there is little positional play; field players will often fill several positions throughout the game as situations demand. These positions usually consist of a center forward, a center back, the two wing players and the two drivers. Players who are skilled in all positions of offense or defense are called utility players. Utility players tend to come off of the bench, though this is not absolute. Certain body types are more suited for particular positions, and left-handed players are especially coveted on the right-hand side of the field, allowing teams to launch two-sided attacks.  The offensive positions include: one center forward (also called a \"set\", \"hole-set\", \"center\", \"setter\", \"hole\", or \"2-meter man\", located on or near the 2-meter, roughly in the center of the goal), two wings (located on or near the 2-meter, just outside of the goal posts, respectively), two drivers (also called \"flats\", located on or near the 5-meter, roughly at the goal posts, respectively), and one \"point\" (usually just behind the 5 meter, roughly in the center of the goal, respectively), positioned farthest from the goal. The wings, drivers and point are often called the perimeter players; while the hole-set directs play. There is a typical numbering system for these positions in U.S. NCAA men's division one polo. Beginning with the offensive wing to the opposing goalie's right side is called one. The flat in a counter clockwise from one is called two. Moving along in the same direction the point player is three, the next flat is four, the final wing is five, and the hole set is called six. Additionally, the position in which a player is can give advantages based on a player's handedness, to improve a shooting or passing angle (for example, the right wing is often left handed).  The center sets up in front of the opposing team's goalie and scores the most individually (especially during lower level play where flats do not have the required strength to effectively shoot from outside or to penetrate and then pass to teammates like the point guard in basketball, or center midfield player in soccer). The center's position nearest to the goal allows explosive shots from close-range.  Defensive positions are often the same, but just switched from offence to defence. For example, the centre forward or hole set, who directs the attack on offence, on defence is known as \"hole D\" (also known as set guard, hole guard, hole check, pit defence or two-metre defence), and guards the opposing team's centre forward (also called the hole). Defence can be played man-to-man or in zones, such as a 2\u20134 (four defenders along the goal line). It can also be played as a combination of the two in what is known as an \"M drop\" defence, in which the point defender moves away (\"sloughs off\") his man into a zone in order to better defend the centre position. In this defence, the two wing defenders split the area furthest from the goal, allowing them a clearer lane for the counter-attack if their team recovers the ball.  The goalkeeper has the main role in blocking shots against the goal as well as guiding and informing their defense of imposing threats and gaps in the defense. The goalkeeper usually begins the offensive play by passing the ball across the pool to an attacker. It is not unusual for a goalkeeper to make an assisting pass to a goal on a break away.  The goalkeeper is given several privileges above those of the other players, but only within the five-meter area in front of their own goal:[10]  In general, a foul that would cause an ejection of a field player might bring on a five-metre shot on the goalkeeper.[10] Also, if a goalkeeper pushes the ball under water, the action will not be punished with a turnover like with field players, but with a penalty shot.  Player positioning  The most basic positional set up is known as a \"3\u20133\", so called because there are two lines in front of the opponent's goal. Another set up, used more by professional teams, is known as an \"arc\", \"umbrella\", or \"mushroom\"; perimeter players form the shape of an arc around the goal, with the hole set as the handle or stalk. Yet another option for offensive set is called a 4\u20132 or double hole; there are two center forward offensive players in front of the goal. Double hole is most often used in \"man up\" situations, or when the defense has only one skilled \"hole D\", or to draw in a defender and then pass out to a perimeter player for a shot (\"kick out\").  Another, albeit less common offense, is the \"motion c\", sometimes nicknamed \"washing machine offence\", in which two \"weak-side\" (to the right of the goal for right-handed players) perimeter players set up as a wing and a flat. The remaining four players swim in square pattern in which a player swims from the point to the hole and then out to the strong side wing. The wing moves to the flat and the flat to the point. The weak side wing and flat then control the tempo of play and try to make passes into the player driving towards the centre forward who can then either shoot or pass. This form of offence is used when no dominate hole set is available, or the hole defence is too strong. It is also seen much more often in women's water polo where teams may lack a player of sufficient size or strength to set up in the centre forward. The best advantage to this system is it makes man-coverage much more difficult for the defender and allows the offence to control the game tempo better once the players are \"set up\". The main drawback is this constant motion can be very tiring as well as somewhat predictable as to where the next pass is going to go.  Advancing the ball  When the offence takes possession of the ball, the strategy is to advance the ball down the field of play and to score a goal. Players can move the ball by throwing it to a teammate or swimming with the ball in front of them (dribbling). If an attacker uses their arm to push away a defending player and free up space for a pass or shot, the referee will rule a turnover and the defence will take possession of the ball. If an attacker advances inside the 2-metre line without the ball or before the ball is inside the 2-metre area, they are ruled offside and the ball is turned over to the defence. This is often overlooked if the attacker is well to the side of the pool or when the ball is at the other side of the pool.  Setting the ball  The key to the offence is to accurately pass (or \"set\") the ball into the centre forward or hole set, positioned directly in front of the goal (\"the hole\"). Any field player may throw the hole set a \"wet pass\". A wet pass is one that hits the water just outside the hole set's reach. A dry pass may also be used. This is where the hole set receives the ball directly in his hand and then attempts a shot at the cage. This pass is much more difficult because if the pass is not properly caught, the officials will be likely to call an offensive foul resulting in a change of ball possession. The hole set attempts to take possession of the ball [after a wet pass], to shoot at the goal, or to draw a foul from his defender. A minor foul is called if his defender (called the \"hole D\") attempts to impede movement before the hole set has possession. The referee indicates the foul with one short whistle blow and points one hand to the spot of the foul and the other hand in the direction of the attack of the team to whom the free throw has been awarded. The hole set then has a \"reasonable amount of time\" (typically about three seconds; there is no FINA rule on this issue) to re-commence play by making a free pass to one of the other players. The defensive team cannot hinder the hole set until the free throw has been taken, but the hole set cannot shoot a goal once the foul has been awarded until the ball has been played by at least one other player. If the hole set attempts a goal without the free throw, the goal is not counted and the defence takes possession of the ball, unless the shot is made outside the 5-metre line. As soon as the hole set has a free pass, the other attacking players attempt to swim (or drive) away from their defenders towards the goal. The players at the flat position will attempt to set a screen (also known as a pick) for the driver. If a driver gets free from a defender, the player calls for the pass from the hole set and attempts a shot at the goal.  Man-Up (5 on 6)  If a defender interferes with a free throw, holds or sinks an attacker who is not in possession or splashes water into the face of an opponent, the defensive player is excluded from the game for twenty seconds, known as a 'kick out' or an ejection. The attacking team typically positions 4 players on the 2 metre line, and 2 players on 5 metre line (4\u20132), passing the ball around until an open player attempts a shot. Other formations include a 3\u20133 (two lines of three attackers each) or arc (attackers make an arc in front of the goal and one offensive player sits in the 'hole' or 'pit' in front of the goal). The five defending players try to pressure the attackers, block shots and prevent a goal being scored for the 20 seconds while they are a player down. The other defenders can only block the ball with one hand to help the goalkeeper. The defensive player is allowed to return immediately if the offence scores, or if the defence recovers the ball before the twenty seconds expires.  On defence, the players work to regain possession of the ball and to prevent a goal in their own net. The defence attempts to knock away or steal the ball from the offense or to commit a foul in order to stop an offensive player from taking a goal shot. The defender attempts to stay between the attacker and the goal, a position known as inside water.  Goalkeeper  Even with good backup from the rest of the defenders, stopping attacks can prove very difficult if the goalkeeper remains in the middle of the goal. The most defensible position is along a semicircular line connecting the goalposts and extending out in the centre. Depending on the ball carrier's location, the goalkeeper is positioned along that semicircle roughly a metre out of the goal to reduce the attacker's shooting angle. The goalkeeper stops using their hands to tread water once the opponent enters at about the 7-metre mark and starts to lift their upper body using the eggbeater technique to prepare to block the shot. Finally, the goalkeeper tries to block the ball down, which is often hard for the longer reaches, but prevents an offensive rebound and second shot. As is the case with other defensive players, a goalkeeper who aggressively fouls an attacker in position to score can be charged with a penalty shot for the other team. The goalkeeper can also be ejected for twenty seconds if a major foul is committed. Also, inside the five metre mark, the goalie can swing at the ball with a closed fist without being penalised.  Advantage rule If an offensive player, such as the centre forward, has possession of the ball in front of the goal, the defensive player tries to steal the ball or to keep the centre from shooting or passing. If the defender cannot achieve these aims, he may commit a foul intentionally. The hole set then is given a free throw but must pass off the ball to another offensive player, rather than making a direct shot at the goal. Defensive perimeter players may also intentionally cause a minor foul and then move toward the goal, away from their attacker, who must take a free throw. This technique, called sloughing, allows the defense an opportunity to double-team the hole set and possibly steal the inbound pass. The referee may refrain from declaring a foul, if in his judgment this would give the advantage to the offender's team. This is known as the Advantage Rule.[11]  Water polo is a contact sport, with little protective gear besides swimsuits and caps with ear protectors, and thus injuries are common. Among the most frequent serious injuries are those affecting the head and shoulders. Those induced to the head are usually caused by elbows or the ball itself, while shoulder injuries are a result of grabbing and pushing while throwing the ball or simply of repetitive overexertion of joints and muscles when taking hard shots.[12]  The hands and fingers are vulnerable areas, due to contact when opponents attempt to steal the ball, or when players block shots.[13]  Other injuries take place underwater, such as leg and groin injuries, as many actions cannot be seen from above the surface and not much padding is used to protect the players.[12]  Sunburn is a common minor injury in outdoor matches. Players often don't apply sunscreen as it makes their skin, and hence the ball, slippery; FINA and most state governing bodies forbid the use of copious sunscreen to make the body harder for the opposing team to grip.  Inner tube water polo is a style of water polo in which players, excluding the goalkeeper, are required to float in inner tubes. By floating in an inner tube players expend less energy than traditional water polo players, not having to tread water. This allows casual players to enjoy water polo without undertaking the intense conditioning required for conventional water polo.  Surf polo, another variation of water polo, is played on surfboards.[14] First played on the beaches of Waikiki in Hawaii in the 1930s and 1940s, it is credited to Louis Kahanamoku, Duke Kahanamoku's brother.  Canoe polo or kayak polo is one of the eight disciplines of canoeing pursued in the UK, known simply as \"polo\" by its aficionados. Polo combines paddling and ball handling skills with a contact team game, where tactics and positional play are as important as the speed and fitness of the individual athletes.  Flippa ball is a precursor variant intended for younger and beginner players to learn the basics of polo.[15][16][17] It is played in shallow water and permits touching the bottom of the pool.[16][18] Players rotate positions after each score.[16][18]  Little player equipment is needed to play water polo. Items required in water polo include:  Men's water polo at the Olympics was the first team sport introduced at the 1900 games, along with cricket, rugby, football, polo (with horses), rowing and tug of war.[19] Women's water polo became an Olympic sport at the 2000 Sydney Olympic Games after political protests from the Australian women's team.[20]  One of the most historically known matches often referred to as the Blood in the Water match, was a 1956 Summer Olympics semi-final match between Hungary and the Soviet Union, played in Melbourne. As the athletes left for the games, the Hungarian revolution began, and the Soviet army crushed the uprising. The Hungarians defeated the Soviets 4\u20130 before the game was called off in the final minute to prevent angry Hungarians in the crowd reacting to Valentin Prokopov punching Ervin Z\u00e1dor.  Every 2 to 4 years since 1973, a men's Water Polo World Championship is organized within the FINA World Aquatics Championships. Women's water polo was added in 1986. A second tournament series, the FINA Water Polo World Cup, has been held every other year since 1979. In 2002, FINA organised the sport's first international league, the FINA Water Polo World League.  There is also a European Water Polo Championship that is held every other year.  Professional water polo is played in many Southern and Eastern European countries like Croatia, Greece, Hungary, Italy, Montenegro, Russia, Serbia, Spain, etc. with the LEN Euroleague tournament played amongst the best teams.  There is also a World Club Water Polo Challenge.[21] "},{"title":"Alba","content":"    Alba (\/\u02c8\u00e6lb\u0259, \u02c8\u00e6lv\u0259\/ AL-b\u0259, AL-v\u0259,[1][2] Scottish Gaelic: [\u02c8al\u032a\u02e0\u0259p\u0259] \u24d8) is the Scottish Gaelic name for Scotland. It is also, in English-language historiography, used to refer to the polity of Picts and Scots united in the ninth century as the Kingdom of Alba,[3] until it developed into the Kingdom of Scotland of the late Middle Ages following the absorption of Strathclyde and English-speaking Lothian in the 12th century.[4] It is cognate with the Irish term Alba (gen. Alban, dat. Albain) and the Manx term Nalbin, the two other Goidelic Insular Celtic languages, as well as contemporary words used in Cornish (Alban) and Welsh (Yr Alban), both of which are Brythonic Insular Celtic languages. The third surviving Brythonic language, Breton, instead uses Bro-Skos, meaning 'country of the Scots'. In the past, these terms were names for Great Britain as a whole, related to the Brythonic name Albion.  The term first appears in classical texts as \u1f08\u03bb\u03b2\u03af\u03c9\u03bd Alb\u00ed\u014dn[5] or \u1f08\u03bb\u03bf\u03c5\u0390\u03c9\u03bd Alou\u00ed\u014dn (in Ptolemy's writings in Greek), and later as Albion in Latin documents. Historically, the term refers to Britain as a whole and is ultimately based on the Indo-European root for \"white\".[6] It later came to be used by Gaelic speakers in the form of Alba (dative Albainn, genitive Albann, now obsolete) as the name given to the former kingdom of the Picts which, when first used in this sense (around the time of king Causant\u00edn mac \u00c1eda (Constantine II, 943\u2013952)), had expanded. The region of Breadalbane (Br\u00e0ghad Albann, the upper part of \"Alba\") takes its name from it as well.  As time passed, that kingdom incorporated other territories to its south. It became re-Latinised in the High Medieval period as \"Albania\" (it is unclear whether it may ultimately share the same etymon as the modern Albania). This latter word was employed mainly by Celto-Latin writers, and most famously by Geoffrey of Monmouth. It was this word which passed into Middle English as Albany, although very rarely was this used for the Kingdom of Scotland, but rather for the notional Duchy of Albany. It is from the latter that Albany, the capital of the US state of New York, and Albany, Western Australia, take their names.  It also appears in the anglicised literary form of Albyn, as in Byron's Childe Harold:  BBC Alba, a television channel broadcasting mainly in Scottish Gaelic, was launched in September 2008 as a joint venture between the British Broadcasting Corporation (BBC) and Gaelic company MG Alba. A new version of Runrig's song Alba (originally on their album, The Cutter and the Clan) was featured on the channel's launch.  In the mid-1990s, the Celtic League started a campaign to have the word \"Alba\" on the Scottish football and rugby tops. Since 2005, the SFA have supported the use of Scottish Gaelic by adding Alba on the back of the official team strip.[7] However, as of 2008, the SRU is still being lobbied to have Alba added to the national rugby union strip.[8]  In 2007, the then Scottish Executive re-branded itself as \"The Scottish Government\" and started to use a bilingual logo with the Gaelic name Riaghaltas na h-Alba. However, the Gaelic version from the outset had always been Riaghaltas na h-Alba.[clarification needed] The Scottish Parliament, likewise, uses the Gaelic name P\u00e0rlamaid na h-Alba.  A new welcome sign on the historic A7 route into Scotland was erected in 2009, with the text F\u00e0ilte gu Alba.  Phrases such as Alba gu br\u00e0th may be used as a catch-phrase or rallying cry. It was used in the movie Braveheart as William Wallace encouraged the troops at the Battle of Stirling Bridge.  In March 2021, former first minister of Scotland and leader of the SNP Alex Salmond launched the pro-independence Alba Party, set to contest the 2021 Scottish Parliament elections.[9] "},{"title":"Wales","content":"  \u2013\u00a0in Europe\u00a0(green &\u00a0dark grey)\u2013\u00a0in the United Kingdom\u00a0(green) Wales (Welsh: Cymru [\u02c8k\u0259m.r\u0268] \u24d8) is a country that is part of the United Kingdom. It is bordered by the Irish Sea to the north and west, England to the east, the Bristol Channel to the south, and the Celtic Sea to the south-west. As of the 2021 census, it had a population of 3,107,494.[1] It has a total area of 21,218 square kilometres (8,192\u00a0sq\u00a0mi) and over 2,700 kilometres (1,680\u00a0mi) of coastline.[7] It is largely mountainous with its higher peaks in the north and central areas, including Snowdon (Yr Wyddfa), its highest summit.[13] The country lies within the north temperate zone and has a changeable, maritime climate. The capital and largest city is Cardiff.  A distinct Welsh culture emerged among the Celtic Britons after the Roman withdrawal from Britain in the 5th century, and Wales was briefly united under Gruffydd ap Llywelyn in 1055. After over 200 years of war, the conquest of Wales by King Edward I of England was completed by 1283, though Owain Glynd\u0175r led the Welsh Revolt against English rule in the early 15th century, and briefly re-established an independent Welsh state with its own national parliament (Welsh: senedd). In the 16th century the whole of Wales was annexed by England and incorporated within the English legal system under the Laws in Wales Acts 1535 and 1542. Distinctive Welsh politics developed in the 19th century. Welsh Liberalism, exemplified in the early 20th century by David Lloyd George, was displaced by the growth of socialism and the Labour Party. Welsh national feeling grew over the century: a nationalist party, Plaid Cymru, was formed in 1925, and the Welsh Language Society in 1962. A governing system of Welsh devolution is employed in Wales, of which the most major step was the formation of the Senedd (Welsh Parliament, formerly the National Assembly for Wales) in 1998, responsible for a range of devolved policy matters.  At the dawn of the Industrial Revolution, development of the mining and metallurgical industries transformed the country from an agricultural society into an industrial one; the South Wales Coalfield's exploitation caused a rapid expansion of Wales's population. Two-thirds of the population live in South Wales, including Cardiff, Swansea, Newport and the nearby valleys. The eastern region of North Wales has about a sixth of the overall population, with Wrexham being the largest northern city. The remaining parts of Wales are sparsely populated. Now that the country's traditional extractive and heavy industries have gone or are in decline, the economy is based on the public sector, light and service industries, and tourism. Agriculture in Wales is largely livestock based, making Wales a net exporter of animal produce, contributing towards national agricultural self-sufficiency.  The country has a distinct national and cultural identity and from the late 19th century onwards Wales acquired its popular image as the \"land of song\", in part due to the eisteddfod tradition and rousing choir singing. Both Welsh and English are official languages. A majority of the population in most areas speaks English whilst the majority of the population in parts of the north and west speak Welsh, with a total of 538,300 Welsh speakers across the entire country.  The English words \"Wales\" and \"Welsh\" derive from the same Old English root (singular Wealh, plural W\u0113alas), a descendant of Proto-Germanic **Walhaz, which was itself derived from the name of the Gauls known to the Romans as Volcae. This term was later used to refer indiscriminately to inhabitants of the Western Roman Empire.[14] Anglo-Saxons came to use the term to refer to the Britons in particular; the plural form W\u0113alas evolved into the name for their territory, Wales.[15][16] Historically in Britain, the words were not restricted to modern Wales or to the Welsh but were used to refer to anything that Anglo-Saxons associated with Britons, including other non-Germanic territories in Britain (e.g. Cornwall) and places in Anglo-Saxon territory associated with Britons (e.g. Walworth in County Durham and Walton in West Yorkshire).[17]  The modern Welsh name for themselves is Cymry, and Cymru is the Welsh name for Wales. These words (both of which are pronounced [\u02c8k\u0259m.r\u0268]) are descended from the Brythonic word combrogi, meaning \"fellow-countrymen\",[18][19] and probably came into use before the 7th century.[20] In literature, they could be spelt Kymry or Cymry, regardless of whether it referred to the people or their homeland.[18] The Latinised forms of these names, Cambrian, Cambric and Cambria, survive as names such as the Cambrian Mountains and the Cambrian geological period.[21]  Wales has been inhabited by modern humans for at least 29,000 years.[22] Continuous human habitation dates from the end of the last ice age, between 12,000 and 10,000\u00a0years before present (BP), when Mesolithic hunter-gatherers from Central Europe began to migrate to Great Britain. At that time, sea levels were much lower than today. Wales was free of glaciers by about 10,250\u00a0BP, the warmer climate allowing the area to become heavily wooded. The post-glacial rise in sea level separated Wales and Ireland, forming the Irish Sea. By 8,000 BP the British Peninsula had become an island.[23] By the beginning of the Neolithic (c.\u20096,000 BP) sea levels in the Bristol Channel were still about 33 feet (10 metres) lower than today.[24] The historian John Davies theorised that the story of Cantre'r Gwaelod's drowning and tales in the Mabinogion, of the waters between Wales and Ireland being narrower and shallower, may be distant folk memories of this time.[25]  Neolithic colonists integrated with the indigenous people, gradually changing their lifestyles from a nomadic life of hunting and gathering, to become settled farmers about 6,000\u00a0BP \u2013 the Neolithic Revolution.[25][26] They cleared the forests to establish pasture and to cultivate the land, developed new technologies such as ceramics and textile production, and built cromlechs such as Pentre Ifan, Bryn Celli Ddu, and Parc Cwm long cairn between about 5,800\u00a0BP and 5,500\u00a0BP.[27] Over the following centuries they assimilated immigrants and adopted ideas from Bronze Age and Iron Age Celtic cultures. Some historians, such as John T. Koch, consider Wales in the Late Bronze Age as part of a maritime trading-networked culture that included other Celtic nations.[28] This \"Atlantic-Celtic\" view is opposed by others who hold that the Celtic languages derive their origins from the more easterly Hallstatt culture.[29] By the time of the Roman invasion of Britain the area of modern Wales had been divided among the tribes of the Deceangli (north-east), Ordovices (north-west), Demetae (south-west), Silures (south-east), and Cornovii (east).[25][30]  The Roman conquest of Wales began in AD 48 and took 30 years to complete; the occupation lasted over 300 years. The campaigns of conquest were opposed by two native tribes: the Silures and the Ordovices. Caractacus or Caradog, leader of the Ordovices, had initial success in resisting Roman invasions of north Wales but was eventually defeated.[31][32] Roman rule in Wales was a military occupation, save for the southern coastal region of south Wales, where there is a legacy of Romanisation.[33] The only town in Wales founded by the Romans, Caerwent, is in south east Wales.[34] Both Caerwent and Carmarthen, also in southern Wales, became Roman civitates.[35] Wales had a rich mineral wealth. The Romans used their engineering technology to extract large amounts of gold, copper and lead, as well as lesser amounts of zinc and silver.[36] No significant industries were located in Wales in this time;[36] this was largely a matter of circumstance as Wales had none of the necessary materials in suitable combination, and the forested, mountainous countryside was not amenable to industrialisation. Latin became the official language of Wales, though the people continued to speak in Brythonic. While Romanisation was far from complete, the upper classes came to consider themselves Roman, particularly after the ruling of 212 that granted Roman citizenship to all free men throughout the Empire.[37] Further Roman influence came through the spread of Christianity, which gained many followers when Christians were allowed to worship freely; state persecution ceased in the 4th\u00a0century, as a result of Constantine the Great issuing an edict of toleration in 313.[37]  Early historians, including the 6th-century cleric Gildas, have noted 383 as a significant point in Welsh history.[38] In that year, the Roman general Magnus Maximus, or Macsen Wledig, stripped Britain of troops to launch a successful bid for imperial power, continuing to rule Britain from Gaul as emperor, and transferring power to local leaders.[39] The earliest Welsh genealogies cite Maximus as the founder of several royal dynasties,[40] and as the father of the Welsh Nation.[38] He is given as the ancestor of a Welsh king on the Pillar of Eliseg, erected nearly 500 years after he left Britain, and he figures in lists of the Fifteen Tribes of Wales.[41]  The 400-year period following the collapse of Roman rule is the most difficult to interpret in the history of Wales.[37] After the Roman departure in AD 410, much of the lowlands of Britain to the east and south-east was overrun by various Germanic peoples, commonly known as Anglo-Saxons. Some have theorized that the cultural dominance of the Anglo-Saxons was due to apartheid-like social conditions in which the Britons were at a disadvantage.[42] By AD 500 the land that would become Wales had divided into a number of kingdoms free from Anglo-Saxon rule.[37] The kingdoms of Gwynedd, Powys, Dyfed, Caredigion, Morgannwg, the Ystrad Tywi, and Gwent emerged as independent Welsh successor states.[37] Archaeological evidence, in the Low Countries and what was to become England, shows early Anglo-Saxon migration to Great Britain reversed between 500 and 550, which concurs with Frankish chronicles.[43] John Davies notes this as consistent with a victory for the Celtic Britons at Badon Hill against the Saxons, which was attributed to Arthur by Nennius.[43]  Having lost much of what is now the West Midlands to Mercia in the 6th and early 7th centuries, a resurgent late-7th-century Powys checked Mercian advances. \u00c6thelbald of Mercia, looking to defend recently acquired lands, had built Wat's Dyke. According to Davies, this had been with the agreement of king Elisedd ap Gwylog of Powys, as this boundary, extending north from the valley of the River Severn to the Dee estuary, gave him Oswestry.[44] Another theory, after carbon dating placed the dyke's existence 300 years earlier, is that it was built by the post-Roman rulers of Wroxeter.[45] King Offa of Mercia seems to have continued this initiative when he created a larger earthwork, now known as Offa's Dyke (Clawdd Offa). Davies wrote of Cyril Fox's study of Offa's Dyke: \"In the planning of it, there was a degree of consultation with the kings of Powys and Gwent. On the Long Mountain near Trelystan, the dyke veers to the east, leaving the fertile slopes in the hands of the Welsh; near Rhiwabon, it was designed to ensure that Cadell ap Brochwel retained possession of the Fortress of Penygadden.\" And, for Gwent, Offa had the dyke built \"on the eastern crest of the gorge, clearly with the intention of recognizing that the River Wye and its traffic belonged to the kingdom of Gwent.\"[44] However, Fox's interpretations of both the length and purpose of the Dyke have been questioned by more recent research.[46]   In 853, the Vikings raided Anglesey, but in 856, Rhodri Mawr defeated and killed their leader, Gorm.[47] The Celtic Britons of Wales made peace with the Vikings and Anarawd ap Rhodri allied with the Norsemen occupying Northumbria to conquer the north.[48] This alliance later broke down and Anarawd came to an agreement with Alfred, king of Wessex, with whom he fought against the west Welsh. According to Annales Cambriae, in 894, \"Anarawd came with the Angles and laid waste to Ceredigion and Ystrad Tywi.\"[49] The southern and eastern parts of Great Britain lost to English settlement became known in Welsh as Lloegyr (Modern Welsh Lloegr), which may have referred to the kingdom of Mercia originally and which came to refer to England as a whole.[d] The Germanic tribes who now dominated these lands were invariably called Saeson, meaning \"Saxons\". The Anglo-Saxons called the Romano-British *Walha, meaning 'Romanised foreigner' or 'stranger'.[50] The Welsh continued to call themselves Brythoniaid (Brythons or Britons) well into the Middle Ages, though the first written evidence of the use of Cymru and y Cymry is found in a praise poem to Cadwallon ap Cadfan (Moliant Cadwallon, by Afan Ferddig) c.\u2009633.[15] In Armes Prydein, believed to be written around 930\u2013942, the words Cymry and Cymro are used as often as 15 times.[51] However, from the Anglo-Saxon settlement onwards, the people gradually begin to adopt the name Cymry over Brythoniad.[52]  From 800 onwards, a series of dynastic marriages led to Rhodri Mawr's (r. 844\u201377) inheritance of Gwynedd and Powys. His sons founded the three dynasties of (Aberffraw for Gwynedd, Dinefwr for Deheubarth and Mathrafal for Powys). Rhodri's grandson Hywel Dda (r. 900\u201350) founded Deheubarth out of his maternal and paternal inheritances of Dyfed and Seisyllwg in 930, ousted the Aberffraw dynasty from Gwynedd and Powys and then codified Welsh law in the 940s.[53]  Gruffydd ap Llywelyn was the only ruler to unite all of Wales under his rule, described by one chronicler after his death as king of Wales. In 1055 Gruffydd ap Llywelyn killed his rival Gruffydd ap Rhydderch in battle and recaptured Deheubarth.[54] Originally king of Gwynedd, by 1057 he was ruler of Wales and had annexed parts of England around the border. He ruled Wales with no internal battles.[55] His territories were again divided into the traditional kingdoms.[56] John Davies states that Gruffydd was \"the only Welsh king ever to rule over the entire territory of Wales... Thus, from about 1057 until his death in 1063, the whole of Wales recognised the kingship of Gruffydd ap Llywelyn. For about seven brief years, Wales was one, under one ruler, a feat with neither precedent nor successor.\"[2] Owain Gwynedd (1100\u20131170) of the Aberffraw line was the first Welsh ruler to use the title princeps Wallensium (prince of the Welsh), a title of substance given his victory on the Berwyn range, according to Davies.[57] During this time, between 1053 and 1063, Wales lacked any internal strife and was at peace.[58]  Within four years of the Battle of Hastings (1066), England had been completely subjugated by the Normans.[2] William I of England established a series of lordships, allocated to his most powerful warriors, along the Welsh border, their boundaries fixed only to the east (where they met other feudal properties inside England).[59] Starting in the 1070s, these lords began conquering land in southern and eastern Wales, west of the River Wye. The frontier region, and any English-held lordships in Wales, became known as Marchia Wallie, the Welsh Marches, in which the Marcher lords were subject to neither English nor Welsh law.[60] The extent of the March varied as the fortunes of the Marcher lords and the Welsh princes ebbed and flowed.[61]  Owain Gwynedd's grandson Llywelyn Fawr (the Great, 1173\u20131240), received the fealty of other Welsh lords in 1216 at the council at Aberdyfi, becoming in effect the first prince of Wales.[62] His grandson Llywelyn ap Gruffudd secured the recognition of the title Prince of Wales from Henry III with the Treaty of Montgomery in 1267.[63] Subsequent disputes, including the imprisonment of Llywelyn's wife Eleanor, culminated in the first invasion by King Edward I of England.[64] As a result of military defeat, the Treaty of Aberconwy exacted Llywelyn's fealty to England in 1277.[64] Peace was short-lived, and, with the 1282 Edwardian conquest, the rule of the Welsh princes permanently ended. With Llywelyn's death and his brother prince Dafydd's execution, the few remaining Welsh lords did homage to Edward I of England.[65] The Statute of Rhuddlan in 1284 provided the constitutional basis for a post-conquest government of the Principality of North Wales from 1284 until 1535\/36.[66] It defined Wales as \"annexed and united\" to the English Crown, separate from England but under the same monarch. The king ruled directly in two areas: the Statute divided the north and delegated administrative duties to the Justice of Chester and Justiciar of North Wales, and further south in western Wales the King's authority was delegated to the Justiciar of South Wales. The existing royal lordships of Montgomery and Builth Wells remained unchanged.[67] To maintain his dominance, Edward constructed a series of castles: Beaumaris, Caernarfon, Harlech and Conwy. His son, the future Edward II, was born at Caernarfon in 1284.[68] He became the first English prince of Wales in 1301, which at the time provided an income from northwest Wales known as the Principality of Wales.[69]  After the failed revolt in 1294\u20131295 of Madog ap Llywelyn \u2013 who styled himself Prince of Wales in the Penmachno Document \u2013 and the rising of Llywelyn Bren (1316), the last uprising was led by Owain Glynd\u0175r, against Henry IV of England. In 1404, Owain was crowned prince of Wales in the presence of emissaries from France, Spain (Castille) and Scotland.[70] Glynd\u0175r went on to hold parliamentary assemblies at several Welsh towns, including a Welsh parliament (Welsh: senedd) at Machynlleth. The rebellion was eventually defeated by 1412. Having failed Owain went into hiding and nothing was known of him after 1413.[71][72] The penal laws against the Welsh of 1401\u201302 passed by the English parliament made the Welsh second-class citizens. With hopes of independence ended, there were no further wars or rebellions against English colonial rule and the laws remained on the statute books until 1624.[73]  Henry Tudor (born in Wales in 1457) seized the throne of England from Richard III of England in 1485, uniting England and Wales under one royal house. The last remnants of Celtic-tradition Welsh law were abolished and replaced by English law by the Laws in Wales Acts 1535 and 1542 during the reign of Henry VII's son, Henry VIII.[74] In the legal jurisdiction of England and Wales, Wales became unified with the kingdom of England; the \"Principality of Wales\" began to refer to the whole country, though it remained a \"principality\" only in a ceremonial sense.[66][75] The Marcher lordships were abolished, and Wales began electing members of the Westminster parliament.[76]  In 1536 Wales had around 278,000 inhabitants, which increased to around 360,000 by 1620. This was primarily due to rural settlement, where animal farming was central to the Welsh economy. Increase in trade and increased economic stability occurred due to the increased diversity of the Welsh economy. Population growth however outpaced economic growth and the standard of living dropped.[77]  Prior to the Industrial Revolution in Wales, there were small-scale industries scattered throughout Wales.[78] These ranged from those connected to agriculture, such as milling and the manufacture of woollen textiles, through to mining and quarrying.[78] Agriculture remained the dominant source of wealth.[78] The emerging industrial period saw the development of copper smelting in the Swansea area. With access to local coal deposits and a harbour that connected it with Cornwall's copper mines in the south and the large copper deposits at Parys Mountain on Anglesey, Swansea developed into the world's major centre for non-ferrous metal smelting in the 19th century.[78] The second metal industry to expand in Wales was iron smelting, and iron manufacturing became prevalent in both the north and the south of the country.[79] In the north, John Wilkinson's Ironworks at Bersham was a major centre, while in the south, at Merthyr Tydfil, the ironworks of Dowlais, Cyfarthfa, Plymouth and Penydarren became the most significant hub of iron manufacture in Wales.[79] By the 1820s, south Wales produced 40 per cent of all Britain's pig iron.[79]  By the 18th century, lawyers, doctors, estate agents and government officials formed a bourgeoisie with sizeable houses.[77] In the late 18th century, slate quarrying began to expand rapidly, most notably in North Wales. The Penrhyn quarry, opened in 1770 by Richard Pennant, 1st Baron Penrhyn, was employing 15,000 men by the late 19th century,[80] and along with Dinorwic quarry, it dominated the Welsh slate trade. Although slate quarrying has been described as \"the most Welsh of Welsh industries\",[81] it is coal mining which became the industry synonymous with Wales and its people. Initially, coal seams were exploited to provide energy for local metal industries but, with the opening of canal systems and later the railways, Welsh coal mining saw an explosion in demand. As the South Wales Coalfield was exploited, Cardiff, Swansea, Penarth and Barry grew as world exporters of coal. By its height in 1913, Wales was producing almost 61 million tons of coal.[82]  Historian Kenneth Morgan described Wales on the eve of the First World War as a \"relatively placid, self-confident and successful nation\". The output from the coalfields continued to increase, with the Rhondda Valley recording a peak of 9.6\u00a0million tons of coal extracted in 1913.[83] The First World War (1914\u20131918) saw a total of 272,924 Welshmen under arms, representing 21.5 per cent of the male population. Of these, roughly 35,000 were killed,[84] with particularly heavy losses of Welsh forces at Mametz Wood on the Somme and the Battle of Passchendaele.[85] The first quarter of the 20th century also saw a shift in the political landscape of Wales. Since 1865, the Liberal Party had held a parliamentary majority in Wales and, following the general election of 1906, only one non-Liberal Member of Parliament, Keir Hardie of Merthyr Tydfil, represented a Welsh constituency at Westminster. Yet by 1906, industrial dissension and political militancy had begun to undermine Liberal consensus in the southern coalfields.[86] In 1916, David Lloyd George became the first Welshman to become Prime Minister of Britain.[87] In December 1918, Lloyd George was re-elected at the head of a Conservative-dominated coalition government, and his poor handling of the 1919 coal miners' strike was a key factor in destroying support for the Liberal party in south Wales.[88] The industrial workers of Wales began shifting towards the Labour Party. When in 1908 the Miners' Federation of Great Britain became affiliated to the Labour Party, the four Labour candidates sponsored by miners were all elected as MPs. By 1922, half the Welsh seats at Westminster were held by Labour politicians\u2014the start of a Labour dominance of Welsh politics that continued into the 21st century.[89]  After economic growth in the first two decades of the 20th century, Wales's staple industries endured a prolonged slump from the early 1920s to the late 1930s, leading to widespread unemployment and poverty.[90] For the first time in centuries, the population of Wales went into decline; unemployment reduced only with the production demands of the Second World War.[91] The war saw Welsh servicemen and women fight in all major theatres, with some 15,000 of them killed. Bombing raids brought high loss of life as the German Air Force targeted the docks at Swansea, Cardiff and Pembroke. After 1943, 10 per cent of Welsh conscripts aged 18 were sent to work in the coal mines, where there were labour shortages; they became known as Bevin Boys. Pacifist numbers during both World Wars were fairly low, especially in the Second World War, which was seen as a fight against fascism.[92]  Plaid Cymru was formed in 1925, seeking greater autonomy or independence from the rest of the UK.[93] The term \"England and Wales\" became common for describing the area to which English law applied, and in 1955 Cardiff was proclaimed as Wales's capital. Cymdeithas yr Iaith Gymraeg (The Welsh Language Society) was formed in 1962, in response to fears that the language might soon die out.[94] Nationalist sentiment grew following the flooding of the Tryweryn valley in 1965 to create a reservoir to supply water to the English city of Liverpool.[95] Although 35 of the 36 Welsh MPs voted against the bill (one abstained), Parliament passed the bill and the village of Capel Celyn was submerged, highlighting Wales's powerlessness in her own affairs in the face of the numerical superiority of English MPs in Parliament.[96] Separatist groupings, such as the Free Wales Army and Mudiad Amddiffyn Cymru were formed, conducting campaigns from 1963.[97] Prior to the investiture of Charles in 1969, these groups were responsible for a number of bomb attacks on infrastructure.[98] At a by-election in 1966, Gwynfor Evans won the parliamentary seat of Carmarthen, Plaid Cymru's first Parliamentary seat.[99]  By the end of the 1960s, the policy of bringing businesses into disadvantaged areas of Wales through financial incentives had proven very successful in diversifying the industrial economy.[100] This policy, begun in 1934, was enhanced by the construction of industrial estates and improvements in transport communications,[100] most notably the M4 motorway linking south Wales directly to London. It was believed that the foundations for stable economic growth had been firmly established in Wales during this period, but this was shown to be optimistic after the recession of the early 1980s saw the collapse of much of the manufacturing base that had been built over the preceding forty years.[101]  The Welsh Language Act 1967 repealed a section of the Wales and Berwick Act and thus \"Wales\" was no longer part of the legal definition of England. This essentially defined Wales as a separate entity legally (but within the UK), for the first time since before the Laws in Wales Acts 1535 and 1542 which defined Wales as a part of the Kingdom of England. The Welsh Language Act 1967 also expanded areas where use of Welsh was permitted, including in some legal situations.[102]  In a referendum in 1979, Wales voted against the creation of a Welsh assembly with an 80 per cent majority. In 1997, a second referendum on the same issue secured a very narrow majority (50.3 per cent).[103] The National Assembly for Wales (Cynulliad Cenedlaethol Cymru) was set up in 1999 (under the Government of Wales Act 1998) with the power to determine how Wales's central government budget is spent and administered, although the UK Parliament reserved the right to set limits on its powers.[103] The governments of the United Kingdom and of Wales almost invariably define Wales as a country.[104] The Welsh Government says: \"Wales is not a Principality. Although we are joined with England by land, and we are part of Great Britain, Wales is a country in its own right.\"[105][e]  The Government of Wales Act 2006 (c 32) is an Act of the Parliament of the United Kingdom that reformed the National Assembly for Wales and allows further powers to be granted to it more easily. The Act creates a system of government with a separate executive drawn from and accountable to the legislature.[107] Following a successful referendum in 2011 on extending the law making powers of the National Assembly it is now able to make laws, known as Acts of the Assembly, on all matters in devolved subject areas, without needing the UK Parliament's agreement.[107]  In the 2016 referendum, Wales voted in support of leaving the European Union, although demographic differences became evident. According to Danny Dorling, professor of geography at Oxford University, votes for Leave may have been boosted by the large proportion (21 per cent) of retired English people living in Wales.[108]   After the Senedd and Elections (Wales) Act 2020, the National Assembly was renamed \"Senedd Cymru\" (in Welsh) and the \"Welsh Parliament\" (in English), which was seen as a better reflection of the body's expanded legislative powers.[109] In 2016, YesCymru was launched. A non party-political campaign for an independent Wales which held its first rally in Cardiff in 2019.[110] An opinion poll in March 2021 showed a record 39 per cent support for Welsh independence when excluding don't knows.[111]  The Welsh language (Welsh: Cymraeg) is an Indo-European language of the Celtic family;[112] the most closely related languages are Cornish and Breton. Most linguists believe that the Celtic languages arrived in Britain around 600 BCE.[113] The Brythonic languages ceased to be spoken in England and were replaced by the English language, a Germanic language which arrived in Wales around the end of the eighth century due to the defeat of the Kingdom of Powys.[114]  The Bible translations into Welsh and the Protestant Reformation, which encouraged use of the vernacular in religious services, helped the language survive after Welsh elites abandoned it in favour of English in the fifteenth and sixteenth centuries.[115]  Successive Welsh Language Acts, in 1942, 1967 and 1993, improved the legal status of Welsh.[116] The Welsh Language (Wales) Measure 2011 modernised the 1993 Welsh Language Act and gave Welsh an official status in Wales for the first time, a major landmark for the language. The Measure also created the post of Welsh Language Commissioner, replacing the Welsh Language Board.[117] Following the referendum in 2011, the Official Languages Act became the first Welsh law to be created in 600 years, according to the First Minister at the time, Carwyn Jones. This law was passed by Welsh Assembly members (AMs) only and made Welsh an official language of the National Assembly.[118]  Starting in the 1960s, many road signs have been replaced by bilingual versions.[119] Various public and private sector bodies have adopted bilingualism to a varying degree and (since 2011) Welsh is the only official (de jure) language in any part of Great Britain.[120]  Wales is a country that is part of the sovereign state of the United Kingdom.[13] Constitutionally, the UK is a de jure unitary state, with a parliament and government in Westminster.[121] Wales has a devolved, unicameral legislature known as the Senedd (Senedd Cymru - Welsh Parliament) which holds devolved powers from the UK Parliament via a reserved powers model.[122] For the purposes of local government, Wales has been divided into 22 council areas since 1996. These \"principal areas\"[123] are responsible for the provision of all local government services.[124]  In the House of Commons \u2013 the 650-member lower house of the UK Parliament \u2013 there are 40 members of Parliament (MPs) who represent Welsh constituencies. At the 2019 general election, 22 Labour and Labour Co-op MPs were elected, along with 14 Conservative MPs and 4 Plaid Cymru MPs from Wales.[121] The Wales Office is a department of the UK government responsible for Wales, whose minister, the secretary of state for Wales (Welsh secretary), sits in the UK cabinet.[125]  Following devolution in 1997, the Government of Wales Act 1998 created a Welsh devolved assembly, the National Assembly for Wales, with the power to determine how Wales's central government budget is spent and administered.[126] Eight years later, the Government of Wales Act 2006 reformed the National Assembly for Wales and allowed further powers to be granted to it more easily. The Act also created a system of government with a separate executive, the Welsh Government, drawn from and accountable to the legislature, the National Assembly. Following a successful referendum in 2011, the National Assembly was empowered to make laws, known as Acts of the Assembly, on all matters in devolved subject areas, without requiring the UK Parliament's approval of legislative competence. It also gained powers to raise taxes.[127]:\u200a33\u201334\u200a In May 2020, the National Assembly was renamed \"Senedd Cymru\" or \"the Welsh Parliament\", commonly known as the Senedd in both English and Welsh.[127]:\u200a18,\u200a33\u201334\u200a  Devolved areas of responsibility include agriculture, economic development, education, health, housing, local government, social services, tourism, transport and the Welsh language.[128] The Welsh Government also promotes Welsh interests abroad.[129]  By tradition, Welsh Law was compiled during an assembly held at Whitland around 930 by Hywel Dda, king of most of Wales between 942 and his death in 950. The 'law of Hywel Dda' (Welsh: Cyfraith Hywel), as it became known, codified the previously existing folk laws and legal customs that had evolved in Wales over centuries. Welsh Law emphasised the payment of compensation for a crime to the victim, or the victim's kin, rather than punishment by the ruler.[130] Other than in the Marches, where March law was imposed by the Marcher Lords, Welsh Law remained in force in Wales until the Statute of Rhuddlan in 1284. Edward I of England annexed the Principality of Wales following the death of Llywelyn ap Gruffudd, and Welsh Law was replaced for criminal cases under the Statute. Marcher Law and Welsh Law (for civil cases) remained in force until Henry VIII of England annexed the whole of Wales under the Laws in Wales Acts 1535 and 1542 (often referred to as the Acts of Union of 1536 and 1543), after which English law applied to the whole of Wales.[131][132] The Wales and Berwick Act 1746 provided that all laws that applied to England would automatically apply to Wales (and the Anglo-Scottish border town of Berwick) unless the law explicitly stated otherwise; this Act was repealed with regard to Wales in 1967. English law has been the legal system of England and Wales since 1536.[133]  English law is regarded as a common law system, with no major codification of the law and legal precedents are binding as opposed to persuasive. The court system is headed by the Supreme Court of the United Kingdom which is the highest court of appeal in the land for criminal and civil cases. The Senior Courts of England and Wales is the highest court of first instance as well as an appellate court. The three divisions are the Court of Appeal, the High Court of Justice, and the Crown Court. Minor cases are heard by magistrates' courts or the County Court. In 2007 the Wales and Cheshire Region (known as the Wales and Cheshire Circuit before 2005) came to an end when Cheshire was attached to the North-Western England Region. From that point, Wales became a legal unit in its own right, although it remains part of the single jurisdiction of England and Wales.[134]  The Senedd has the authority to draft and approve laws outside of the UK Parliamentary system to meet the specific needs of Wales. Under powers approved by a referendum held in March 2011, it is empowered to pass primary legislation, at the time referred to as an Act of the National Assembly for Wales but now known as an Act of Senedd Cymru in relation to twenty subjects listed in the Government of Wales Act 2006 such as health and education. Through this primary legislation, the Welsh Government can then also enact more specific subordinate legislation.[135]  Wales is served by four regional police forces: Dyfed-Powys Police, Gwent Police, North Wales Police, and South Wales Police.[136] There are five prisons in Wales: four in the southern half of the country, and one in Wrexham. Wales has no women's prisons: female inmates are imprisoned in England.[137]  Wales is a generally mountainous country on the western side of central southern Great Britain.[138] It is about 170 miles (270\u00a0km) north to south.[139] The oft-quoted \"size of Wales\" is about 20,779\u00a0km2 (8,023\u00a0sq\u00a0mi).[140] Wales is bordered by England to the east and by sea in all other directions: the Irish Sea to the north and west, St George's Channel and the Celtic Sea to the southwest and the Bristol Channel to the south.[141][142] Wales has about 1,680 miles (2,700\u00a0km) of coastline (along the mean high water mark), including the mainland, Anglesey and Holyhead.[143] Over 50 islands lie off the Welsh mainland, the largest being Anglesey, in the north-west.[144]  Much of Wales's diverse landscape is mountainous, particularly in the north and central regions. The mountains were shaped during the last ice age, the Devensian glaciation. The highest mountains in Wales are in Snowdonia (Eryri), of which five are over 1,000\u00a0m (3,300\u00a0ft). The highest of these is Snowdon (Yr Wyddfa), at 1,085\u00a0m (3,560\u00a0ft).[145][146] The 14 Welsh mountains, or 15 if including Carnedd Gwenllian\u00a0\u2013 often discounted because of its low topographic prominence\u00a0\u2013 over 3,000 feet (910 metres) high are known collectively as the Welsh 3000s and are located in a small area in the north-west.[147] The highest outside the 3000s is Aran Fawddwy, at 905 metres (2,969 feet), in the south of Snowdonia.[148] The Brecon Beacons (Bannau Brycheiniog) are in the south (highest point Pen y Fan, at 886 metres (2,907 feet)),[149] and are joined by the Cambrian Mountains in Mid Wales (highest point Pumlumon, at 752 metres (2,467 feet)).[150]  Wales has three national parks: Snowdonia, Brecon Beacons, and Pembrokeshire Coast (Arfordir Penfro). It has five Areas of Outstanding Natural Beauty: Anglesey, the Clwydian Range and Dee Valley, the Gower Peninsula, the Ll\u0177n Peninsula, and the Wye Valley.[151] The Gower Peninsula was the first area in the United Kingdom to be designated as an Area of Outstanding Natural Beauty, in 1956. As of 2019, the coastline of Wales had 40 Blue Flag beaches, three Blue Flag marinas and one Blue Flag boat operator.[152] Despite its heritage and award-winning beaches, the south and west coasts of Wales, along with the Irish and Cornish coasts, are frequently blasted by Atlantic westerlies\/south-westerlies that, over the years, have sunk and wrecked many vessels. In 1859 over 110 ships were destroyed off the coast of Wales in a hurricane that saw more than 800 lives lost across Britain.[153] The greatest single loss occurred with the sinking of the Royal Charter off Anglesey in which 459 people died.[154] The 19th century saw over 100 vessels lost with an average loss of 78 sailors per year.[155] Wartime action caused losses near Holyhead, Milford Haven and Swansea.[155] Because of offshore rocks and unlit islands, Anglesey and Pembrokeshire are still notorious for shipwrecks, most notably the Sea Empress oil spill in 1996.[156]  The first border between Wales and England was zonal, apart from around the River Wye, which was the first accepted boundary.[157] Offa's Dyke was supposed to form an early distinct line but this was thwarted by Gruffudd ap Llewellyn, who reclaimed swathes of land beyond the dyke.[157] The Act of Union of 1536 formed a linear border stretching from the mouth of the Dee to the mouth of the Wye.[157] Even after the Act of Union, many of the borders remained vague and moveable until the Welsh Sunday Closing act of 1881, which forced local businesses to decide which country they fell within to accept either the Welsh or English law.[157]  The earliest geological period of the Palaeozoic era, the Cambrian, takes its name from the Cambrian Mountains, where geologists first identified Cambrian remnants.[158][159] In the mid-19th century, Roderick Murchison and Adam Sedgwick used their studies of Welsh geology to establish certain principles of stratigraphy and palaeontology. The next two periods of the Palaeozoic era, the Ordovician and Silurian, were named after ancient Celtic tribes from this area.[160][161]  Wales lies within the north temperate zone. It has a changeable, maritime climate and is one of the wettest countries in Europe.[163][164] Welsh weather is often cloudy, wet and windy, with warm summers and mild winters.[163][165]  Wales's wildlife is typical of Britain with several distinctions. Because of its long coastline, Wales hosts a variety of seabirds. The coasts and surrounding islands are home to colonies of gannets, Manx shearwater, puffins, kittiwakes, shags and razorbills. In comparison, with 60 per cent of Wales above the 150m contour, the country also supports a variety of upland-habitat birds, including raven and ring ouzel.[171][172] Birds of prey include the merlin, hen harrier and the red kite, a national symbol of Welsh wildlife.[173] In total, more than 200 different species of bird have been seen at the RSPB reserve at Conwy, including seasonal visitors.[174] Larger mammals, including brown bears, wolves and wildcats, died out during the Norman period. Today, mammals include shrews, voles, badgers, otters, stoats, weasels, hedgehogs and fifteen species of bat. Two species of small rodent, the yellow-necked mouse and the dormouse, are of special Welsh note being found at the historically undisturbed border area.[175] The pine marten, which has been sighted occasionally, has been reintroduced in parts of Wales since 2015, having previously not been officially recorded since the 1950s.[176] The polecat was nearly driven to extinction in Britain, but hung on in Wales and is now rapidly spreading. Feral goats can be found in Snowdonia.[177] In March 2021, Natural Resources Wales (NRW) granted a licence to release up to six beavers in the Dyfi Valley, the first official beaver release in Wales.[178]  Believed to be home to some of Wales's rarest land invertebrates, some 2,500 disused coal tips are the subject of study by the Welsh Government; the tips are home to a wide variety of other wildlife.[179]  The waters of south-west Wales of Gower, Pembrokeshire and Cardigan Bay attract marine animals, including basking sharks, Atlantic grey seals, leatherback turtles, dolphins, porpoises, jellyfish, crabs and lobsters. Pembrokeshire and Ceredigion, in particular, are recognised as an area of international importance for bottlenose dolphins, and New Quay has the only summer residence of bottlenose dolphins in the whole of the UK. River fish of note include char, eel, salmon, shad, sparling and Arctic char, whilst the gwyniad is unique to Wales, found only in Bala Lake. Wales is known for its shellfish, including cockles, limpet, mussels and periwinkles. Herring, mackerel and hake are the more common of the country's marine fish.[180] The north facing high grounds of Snowdonia support a relict pre-glacial flora including the iconic Snowdon lily \u2013 Gagea serotina \u2013 and other alpine species such as Saxifraga cespitosa, Saxifraga oppositifolia and Silene acaulis. Wales has a number of plant species not found elsewhere in the UK, including the spotted rock-rose Tuberaria guttata on Anglesey and Draba aizoides on the Gower.[181]  Over the last 250 years, Wales has been transformed from a predominantly agricultural country to an industrial, and then to a post-industrial economy.[182] In the 1950s, Wales's GDP was twice as big as Ireland\u2019s; by the 2020s, Ireland's economy was four times that of Wales. Since the Second World War, the service sector has come to account for the majority of jobs, a feature typifying most advanced economies.[183] in 2018, according to OECD and Eurostat data, gross domestic product (GDP) in Wales was \u00a375\u00a0billion, an increase of 3.3 per cent from 2017. GDP per head in Wales in 2018 was \u00a323,866, an increase of 2.9 per cent on 2017. This compares to Italy\u2019s GDP\/capita of \u00a325,000, Spain \u00a322,000, Slovenia \u00a320,000 and New Zealand \u00a330,000.[184][185] In the three months to December 2017, 72.7 per cent of working-age adults were employed, compared to 75.2 per cent across the UK as a whole.[186] For the 2018\u201319 fiscal year, the Welsh fiscal deficit accounts for 19.4 per cent of Wales's estimated GDP.[187]  In 2019, Wales was a net exporter of electricity. It produced 27.9 TWh of electricity while only consuming 14.7 TWh.[188] In 2021, the Welsh government said that more than half the country's energy needs were being met by renewable sources, 2 per cent of which was from 363 hydropower projects.[189]  By UK law, Wales contributes to items that do not directly benefit Wales e.g. over \u00a35 billion for HS2 \"which will damage the Welsh economy by \u00a3200m pa\", according to the UK and Welsh Government's transport adviser Mark Barry. Wales also pays more in military costs than most similar-sized countries e.g. Wales pays twice the amount Ireland spends on the military.[190] The UK government spends \u00a31.75bn per year on the military in Wales, which is almost as much as Wales spends on education every year (\u00a31.8 billion in 2018\/19) and five times as much as the total amount spent on the police in Wales (\u00a3365 million).[191]  From the middle of the 19th century until the post-war era, the mining and export of coal was the dominant industry. At its peak of production in 1913, nearly 233,000 men and women were employed in the South Wales coalfield, mining 56 million tons of coal.[192] Cardiff was once the largest coal-exporting port in the world and, for a few years before the First World War, handled a greater tonnage of cargo than either London or Liverpool.[193] In the 1920s, over 40 per cent of the male Welsh population worked in heavy industry.[194] According to Phil Williams, the Great Depression \"devastated Wales\", north and south, because of its \"overwhelming dependence on coal and steel\".[194] From the mid-1970s, the Welsh economy faced massive restructuring with large numbers of jobs in heavy industry disappearing and being replaced eventually by new ones in light industry and in services. In the late 1970s and early 1980s, Wales was successful in attracting an above average share of foreign direct investment in the UK.[195] Much of the new industry was essentially of a \"branch (or \"screwdriver\") factory\" type where a manufacturing plant or call centre is in Wales but the most highly-paid jobs in the company are elsewhere.[196][197]  Poor-quality soil in much of Wales is unsuitable for crop-growing, so livestock farming has been the focus of farming. About 78 per cent of the land surface is used for agriculture.[198] The Welsh landscape, with its three national parks and Blue Flag beaches, attracts large numbers of tourists, who bolster the economy of rural areas.[199] Wales, like Northern Ireland, has relatively few high value-added employment in sectors such as finance and research and development, attributable in part to a comparative lack of \"economic mass\" (i.e. population) \u2013 Wales lacks a large metropolitan centre.[197] The lack of high value-added employment is reflected in lower economic output per head relative to other regions of the UK: in 2002 it stood at 90 per cent of the EU25 average and around 80 per cent of the UK average.[197] In June 2008, Wales made history by becoming the first nation to be awarded Fairtrade status.[200]  The pound sterling is the currency used in Wales. Numerous Welsh banks issued their own banknotes in the 19th century: the last bank to do so closed in 1908. Since then the Bank of England has had a monopoly on the issue of banknotes in Wales.[201] The Commercial Bank of Wales, established in Cardiff by Sir Julian Hodge in 1971, was taken over by the Bank of Scotland in 1988 and absorbed into its parent company in 2002.[202] The Royal Mint, which issues the coinage circulating through the whole of the UK, has been based at a single site in Llantrisant since 1980.[203] Since decimalisation, in 1971, at least one of the coins in circulation emphasises Wales such as the 1995 and 2000 one pound coin (above). As at 2012, the last designs devoted to Wales saw production in 2008.[204]  During 2020, and well into 2021, the restrictions and lockdowns necessitated by the COVID-19 pandemic affected all sectors of the economy and \"tourism and hospitality suffered notable losses from the pandemic\" across the UK.[205] As of 6 April 2021, visitors from \"red list\" countries were still not allowed to enter unless they were UK residents. Restrictions will \"likely be in place until the summer\", one report predicted, with June being the most likely time for tourism from other countries to begin a rebound.[206] On 12 April 2021, many tourist facilities were still closed in Wales but non-essential travel between Wales and England was finally permitted. Wales also allowed non-essential retail stores to open.[207]\u00a0  The M4 motorway running from West London to South Wales links Newport, Cardiff and Swansea. Responsibility for the section of the motorway within Wales, from the Second Severn Crossing to Pont Abraham services, sits with the Welsh Government.  [208] The A55 expressway has a similar role along the North Wales coast, connecting Holyhead and Bangor with Wrexham and Flintshire. It also links to northwest England, principally Chester.[209] The main north-south Wales link is the A470, which runs from Cardiff to Llandudno.[210] Rail transport in Wales includes the Wales & Borders franchise, which is overseen by the Welsh Government with most passenger services operated by Transport for Wales Rail.[211] The Cardiff region has its own urban rail network. Beeching cuts in the 1960s mean that most of the remaining network is geared toward east-west travel connecting with the Irish Sea ports for ferries to Ireland.[212] Services between north and south Wales operate through the English cities of Chester and Hereford and towns of Shrewsbury, Gobowen for Oswestry and along the Welsh Marches Line, with trains on the Heart of Wales Line from Swansea to Llandovery, Llandrindod and Knighton connecting the Welsh March Line in Craven Arms. Trains in Wales are mainly diesel-powered but the South Wales Main Line branch of the Great Western Main Line used by services from London Paddington to Cardiff is undergoing electrification, although the programme has experienced significant delays and costs-overruns.[213] A North-South railway has been suggested to better link North and South Wales.[214][215][216]  Cardiff Airport is the international airport of Wales. Providing links to European, African and North American destinations, it is about 12 miles (19\u00a0km) southwest of Cardiff city centre, in the Vale of Glamorgan. Intra-Wales flights used to run between Anglesey (Valley) and Cardiff, and were operated since 2017 by Eastern Airways.,[217] those flights are no longer, as of 2022, available. Other internal flights operate to northern England, Scotland and Northern Ireland.[218] Wales has four commercial ferry ports. Regular ferry services to Ireland operate from Holyhead, Pembroke Dock and Fishguard. The Swansea to Cork service was cancelled in 2006, reinstated in March 2010, and withdrawn again in 2012.[219]   A distinct education system has developed in Wales.[221] Formal education before the 18th century was the preserve of the elite. The first grammar schools were established in Welsh towns such as Ruthin, Brecon and Cowbridge.[221] One of the first successful schooling systems was started by Griffith Jones, who introduced the circulating schools in the 1730s; these are believed to have taught half the country's population to read.[222] In the 19th century, with increasing state involvement in education, Wales was forced to adopt an education system that was English in ethos even though the country was predominantly Non-conformist, Welsh-speaking and demographically uneven because of the economic expansion in the south.[222] In some schools, to ensure Welsh children spoke English at school, the Welsh Not was employed as corrective punishment; this was much resented,[223] although the extent of its use is difficult to determine.[224] State and local governmental edicts resulted in schooling in the English language which, following the 1847 Inquiry into the State of Education in Wales \u2013 an event subsequently referred to as the Treachery of the Blue Books (Welsh: Brad y Llyfrau Gleision) \u2013 was seen as more academic and worthwhile for children.[225]  The University College of Wales opened in Aberystwyth in 1872. Cardiff and Bangor followed, and the three colleges came together in 1893 to form the University of Wales.[222] The Welsh Intermediate Education Act of 1889 created 95 secondary schools. The Welsh Department for the Board of Education followed in 1907, which gave Wales its first significant educational devolution.[222] A resurgence in Welsh-language schools in the latter half of the 20th century at nursery and primary level saw attitudes shift towards teaching in the medium of Welsh.[226] Welsh is a compulsory subject in all of Wales's state schools for pupils aged 5\u201316 years old.[227] While there has never been an exclusively Welsh-language college, Welsh-medium higher education is delivered through the individual universities and has since 2011 been supported by the Coleg Cymraeg Cenedlaethol (Welsh National College) as a delocalised federal institution. In 2021\u20132022, there were 1,470 maintained schools in Wales.[228] In 2021\u201322, the country had 471,131 pupils taught by 25,210 full-time equivalent teachers.[229][230]  Public healthcare in Wales is provided by NHS Wales (GIG Cymru), through seven local health boards and three all-Wales trusts. It was originally formed as part of the NHS structure for England and Wales by the National Health Service Act 1946, but with powers over the NHS in Wales coming under the Secretary of State for Wales in 1969.[231] Responsibility for NHS Wales passed to the Welsh Assembly under devolution in 1999, and is now the responsibility of the Minister for Health and Social Services.[232] Historically, Wales was served by smaller 'cottage' hospitals, built as voluntary institutions.[233] As newer, more expensive, diagnostic techniques and treatments became available, clinical work has been concentrated in newer, larger district hospitals.[233] In 2006, there were seventeen district hospitals in Wales.[233] NHS Wales directly employs over 90,000 staff, making it Wales's biggest employer.[234] The National Survey for Wales in 2021\u201322 reported that 72 per cent of adults surveyed had good or very good general health, 19 per cent had fair general health and 8 had bad or very bad general health.[235] The survey recorded that 46 per cent of Welsh adults had a long-standing illness, such as arthritis, asthma, diabetes or heart disease.[236] The survey also reported that 13 per cent of the adult population were smokers, 16 per cent admitted drinking alcohol above weekly recommended guidelines, while 56 per cent undertook the recommended 150 minutes of physical activity each week.[237] According to the survey, 30 per cent of adults in Wales reported to have eaten at least 5 portions of fruit or vegetables the previous day and 36 per cent reported a healthy weight.[238]  The population of Wales doubled from 587,000 in 1801 to 1,163,000 in 1851 and had reached 2,421,000 by 1911. Most of the increase came in the coal mining districts, especially Glamorganshire, which grew from 71,000 in 1801 to 232,000 in 1851 and 1,122,000 in 1911.[242] Part of this increase can be attributed to the demographic transition seen in most industrialising countries during the Industrial Revolution, as death rates dropped and birth rates remained steady. However, there was also large-scale migration into Wales during the Industrial Revolution. The English were the most numerous group, but there were also considerable numbers of Irish and smaller numbers of other ethnic groups,[243] including Italians, who migrated to South Wales.[244] Wales also received immigration from various parts of the British Commonwealth of Nations in the 20th century, and African-Caribbean and Asian communities add to the ethnocultural mix, particularly in urban Wales. Many of these self-identify as Welsh.[245]  The population in 1972 stood at 2.74 million and remained broadly static for the rest of the decade. However, in the early 1980s, the population fell due to net migration out of Wales. Since the 1980s, net migration has generally been inward, and has contributed more to population growth than natural change.[246] The resident population of Wales in 2021 according to the census was 3,107,500 (1,586,600 female and 1,521,000 male), an increase of 1.4 per cent over 2011. A decreased change from the 5 per cent increase between 2001 and 2011.[247] Wales accounted for 5.2 per cent of the population of England and Wales in 2021. Wales has seven cities, those being Cardiff, Newport, Swansea, and Wrexham, with the communities of Bangor, St Asaph and St Davids also having city status in the United Kingdom.[248] Wrexham, north Wales's largest settlement, became Wales's newest and seventh city in September 2022.[249]  Welsh is an official language in Wales as legislated by the Welsh Language (Wales) Measure 2011.[251] Both Welsh and English are also official languages of the Senedd.[252] The proportion of the Welsh population able to speak the Welsh language fell from just under 50 per cent in 1901 to 43.5 per cent in 1911, and continued to fall to a low of 18.9 per cent in 1981.[253] The results of the 2001 Census showed an increase in the number of Welsh speakers to 21 per cent of the population aged 3 and older, compared with 18.7 per cent in 1991 and 19 per cent in 1981. This compares with a pattern of steady decline indicated by census results during the 20th century.[254] In the 2011 census it was recorded that the proportion of people able to speak Welsh had dropped from 20.8 per cent to 19 per cent (still higher than 1991). Despite an increase in the overall size of the Welsh population this still meant that the number of Welsh speakers in Wales dropped from 582,000 in 2001 to 562,000 in 2011. However this figure was still much higher than 508,000 or 18.7 per cent of people who said they could speak Welsh in the 1991 census.[255]  According to the 2021 census, the Welsh-speaking population of Wales aged three or older was 17.8 per cent (538,300 people) and nearly three quarters of the population in Wales said they had no Welsh language skills.[256] Other estimates suggest that 29.7 per cent (899,500) of people aged three or older in Wales could speak Welsh in June 2022.[257]  English is spoken by almost all people in Wales and is the main language in most of the country. Code-switching is common in all parts of Wales and is known by various terms, though none is recognised by professional linguists.[258] \"Wenglish\" is the Welsh English language dialect. It has been influenced significantly by Welsh grammar and includes words derived from Welsh.[259] Northern and western Wales retain many areas where Welsh is spoken as a first language by the majority of the population, and English learnt as a second language. Although monoglotism in young children continues, life-long monoglotism in Welsh no longer occurs.[260]  Since Poland joined the European Union, Wales has seen a significant increase in Polish immigrants. This has made Polish the most common main language in Wales after English or Welsh, at 0.7 per cent of the population.[261]  Forms of Christianity have dominated religious life in what is now the Wales for more than 1,400 years.[262][263] The 2021 census recorded 46.5 per cent had \"No religion\", more than any single religious affiliation and up from 32.1 per cent in 2011.[264] The largest religion in Wales is Christianity, with 43.6 per cent of the population describing themselves as Christian in the 2021 census.[264] The patron saint of Wales is Saint David (Dewi Sant), with Saint David's Day (Dydd G\u0175yl Dewi Sant) celebrated annually on 1 March.[265] The early 20th century saw a religious revival, the 1904\u20131905 Welsh Revival, which started through the evangelism of Evan Roberts and brought large numbers of converts, sometimes whole communities, to non-Anglican Christianity.[266]  The Church in Wales with 56,000 adherents has the largest attendance of the denominations.[267] It is a province of the Anglican Communion, and was part of the Church of England until disestablishment in 1920 under the Welsh Church Act 1914. The first Independent Church in Wales was founded at Llanvaches in 1638 by William Wroth. The Presbyterian Church of Wales was born out of the Welsh Methodist revival in the 18th century and seceded from the Church of England in 1811.[268] The second largest attending faith in Wales is Roman Catholic, with an estimated 43,000 adherents.[267]  Non-Christian religions are small in Wales, making up approximately 2.7 per cent of the population.[269] Islam is the largest, with 24,000 (0.8 per cent) reported Muslims in the 2011 census.[269] There are also communities of Hindus and Sikhs, mainly in the south Wales cities of Newport, Cardiff and Swansea, while the largest concentration of Buddhists is in the western rural county of Ceredigion.[270] Judaism was the first non-Christian faith to be established in Wales since Roman times, though by 2001 the community had declined to approximately 2,000[271] and as of 2019 only numbers in the hundreds.[272]  The 2021 census showed that 93.8 per cent of the population of Wales identified as \"White\", compared to 95.6 per cent in 2011. 90.6 per cent of the population identified as \"White: Welsh, English, Scottish, Northern Irish or British\" in 2021. The second-highest ethnicity in 2021 was \"Asian, Asian Welsh or Asian British\" at 2.9 per cent of the population, compared to 2.3 per cent in 2011. 1.6 per cent of the population identified as \"Mixed or multiple ethnic groups\", compared to 1.0 per cent in 2011; 0.9 per cent of the population identified as \"Black, Black Welsh, Black British, Caribbean or African\", compared to 0.6 per cent in 2011; and 0.9 per cent identified as \"Other ethnic group\" compared to 0.5 per cent in 2011. The local authorities with the highest proportions of \"high-level\" ethnic groups other than \"White\" were mainly urban areas including Cardiff, Newport and Swansea. 5.3 per cent of households in Wales were multiple ethnic group households, up from 4.2 per cent in 2011.[273]  In 2021, the first statue of a named, non-fictional woman outdoors was raised for Wales's first black headteacher, Betty Campbell. In 2023, Patti Flynn (a contemporary of Shirley Bassey, both of Tiger Bay, Cardiff) became the first black Welsh woman to be awarded a purple plaque.[274]  The 2021 census showed that 55.2 per cent identified as \"Welsh only\" and 8.1 per cent identified as \"Welsh and British\", giving the combined proportion of 63.3 per cent for people identifying as Welsh.[275] The Welsh Annual Population Survey showed that the proportion of people who identified as Welsh versus another identity was 62.3 per cent in 2022, compared to 69.2 per cent in 2001.[276] A 2022 YouGov poll found that 21 per cent considered themselves Welsh not British, 15 per cent more Welsh than British, 24 per cent equally Welsh and British, 7 per cent more British than Welsh, 20 per cent British and not Welsh, and 8 per cent other; a total of 67 per cent thus considered themselves Welsh to some degree.[277]  Wales has a distinctive culture including its own language, customs, holidays and music. There are four UNESCO World Heritage Sites in Wales: The Castles and Town Walls of King Edward I in Gwynedd; Pontcysyllte Aqueduct and Canal; the Blaenavon Industrial Landscape; and The Slate Landscape of Northwest Wales.[278]  Remnants of native Celtic mythology of the pre-Christian Britons was passed down orally by the cynfeirdd (the early poets).[279] Some of their work survives in later medieval Welsh manuscripts: the Black Book of Carmarthen and the Book of Aneirin (both 13th-century); the Book of Taliesin and the White Book of Rhydderch (both 14th-century); and the Red Book of Hergest (c.\u00a01400).[279] The prose stories from the White and Red Books are known as the Mabinogion.[280] Poems such as Cad Goddeu (The Battle of the Trees) and mnemonic list-texts like the Welsh Triads and the Thirteen Treasures of the Island of Britain, also contain mythological material.[281] These texts include the earliest forms of the Arthurian legend and the traditional history of post-Roman Britain.[279] Other sources of Welsh folklore include the 9th-century Latin historical compilation Historia Britonum (the History of the Britons) and Geoffrey of Monmouth's 12th-century Latin chronicle Historia Regum Britanniae (the History of the Kings of Britain), and later folklore, such as The Welsh Fairy Book by W. Jenkyn Thomas.[282]  Wales has one of the oldest unbroken literary traditions in Europe[283] going back to the sixth century and including Geoffrey of Monmouth and Gerald of Wales, regarded as among the finest Latin authors of the Middle Ages.[283] The earliest body of Welsh verse, by poets Taliesin and Aneirin, survive not in their original form, but in much-changed, medieval versions.[283] Welsh poetry and native lore and learning survived through the era of the Poets of the Princes (c.\u20091100\u20131280) and then the Poets of the Gentry (c.\u20091350\u20131650). The former were professional poets who composed eulogies and elegies to their patrons while the latter favoured the cywydd metre.[284] The period produced one of Wales's greatest poets, Dafydd ap Gwilym.[285] After the Anglicisation of the gentry the tradition declined.[284]  Despite the extinction of the professional poet, the integration of the native elite into a wider cultural world did bring other literary benefits.[286] Renaissance scholars such as William Salesbury and John Davies brought humanist ideals from English universities.[286] In 1588 William Morgan became the first person to translate the Bible into Welsh.[286] From the 16th century the proliferation of the 'free-metre' verse became the most important development in Welsh poetry, but from the middle of the 17th century a host of imported accentual metres from England became very popular.[286] By the 19th century the creation of a Welsh epic, fuelled by the eisteddfod, became an obsession with Welsh-language writers.[287] The output of this period was prolific in quantity but unequal in quality.[288] Initially excluded, religious denominations came to dominate the competitions, with bardic themes becoming scriptural and didactic.[288]  Developments in 19th-century Welsh literature include Lady Charlotte Guest's translation into English of the Mabinogion, one of the most important medieval Welsh prose works of Celtic mythology. 1885 saw the publication of Rhys Lewis by Daniel Owen, credited as the first novel written in the Welsh language. The 20th century saw a move from the verbose Victorian Welsh style, with works such as Thomas Gwynn Jones's Ymadawiad Arthur.[287] The First World War had a profound effect on Welsh literature with a more pessimistic style championed by T. H. Parry-Williams and R. Williams Parry.[287] The industrialisation of south Wales saw a further shift with the likes of Rhydwen Williams who used the poetry and metre of a bygone rural Wales but in the context of an industrial landscape. The inter-war period is dominated by Saunders Lewis, for his political and reactionary views as much as his plays, poetry and criticism.[287]  The careers of some 1930s writers continued after World War Two, including those of Gwyn Thomas, Vernon Watkins, and Dylan Thomas, whose most famous work Under Milk Wood was first broadcast in 1954. Thomas was one of the most notable and popular Welsh writers of the 20th century and one of the most innovative poets of his time.[289] The attitude of the post-war generation of Welsh writers in English towards Wales differs from the previous generation, with greater sympathy for Welsh nationalism and the Welsh language. The change is linked to the nationalism of Saunders Lewis and the burning of the Bombing School on the Ll\u0177n Peninsula in 1936.[290] In poetry R. S. Thomas (1913\u20132000) was the most important figure throughout the second half of the twentieth century. He \"did not learn the Welsh language until he was 30 and wrote all his poems in English\".[291] Major writers in the second half of the twentieth century include Emyr Humphreys (1919\u20132020), who during his long writing career published over twenty novels,[292] and Raymond Williams (1921\u20131988).[293]  Amgueddfa Cymru \u2013 Museum Wales was founded by royal charter in 1907 as the National Museum of Wales. It operates at seven sites: National Museum Cardiff, St Fagans National History Museum, Big Pit National Coal Museum, National Wool Museum, National Slate Museum, National Roman Legion Museum, and the National Waterfront Museum. Entry to all sites is free.[294] The National Library of Wales, based in Aberystwyth, houses important collections of printed works, including the Sir John Williams Collection and the Shirburn Castle collection,[295] as well as art collections including portraits and photographs, ephemera and Ordnance Survey maps.[295]  Works of Celtic art have been found in Wales.[296] In the Early Medieval period, the Celtic Christianity of Wales was part of the Insular art of the British Isles. A number of illuminated manuscripts from Wales survive, including the 8th-century Hereford Gospels and Lichfield Gospels. The 11th-century Ricemarch Psalter (now in Dublin) is certainly Welsh, made in St David's, and shows a late Insular style with unusual Viking influence.[297]  Some Welsh artists of the 16th\u201318th centuries tended to leave the country to work, moving to London or Italy. Richard Wilson (1714\u20131782) is arguably the first major British landscapist; although more notable for his Italian scenes, he painted several Welsh scenes on visits from London. By the late 18th century, the popularity of landscape art grew and clients were found in the larger Welsh towns, allowing more Welsh artists to stay in their homeland. Artists from outside Wales were also drawn to paint Welsh scenery, at first because of the Celtic Revival.[298]  An Act of Parliament in 1857 provided for the establishment of a number of art schools throughout the United Kingdom, and the Cardiff School of Art opened in 1865. Graduates still very often had to leave Wales to work, but Betws-y-Coed became a popular centre for artists, and its artists' colony helped to form the Royal Cambrian Academy of Art in 1881.[299] The sculptor Sir William Goscombe John made works for Welsh commissions, although he had settled in London. Christopher Williams, whose subjects were mostly resolutely Welsh, was also based in London. Thomas E. Stephens[300] and Andrew Vicari had very successful careers as portraitists, based respectively in the United States and France.[301]  Welsh painters gravitated towards the art capitals of Europe. Augustus John and his sister Gwen John lived mostly in London and Paris. However, the landscapists Sir Kyffin Williams and Peter Prendergast lived in Wales for most of their lives, while remaining in touch with the wider art world. Ceri Richards was very engaged in the Welsh art scene as a teacher in Cardiff and even after moving to London; he was a figurative painter in international styles including Surrealism. Various artists have moved to Wales, including Eric Gill, the London-Welshman David Jones, and the sculptor Jonah Jones. The Kardomah Gang was an intellectual circle in Swansea, centred on the poet Dylan Thomas and the poet and artist Vernon Watkins, which also included the painter Alfred Janes.[302]  South Wales had several notable potteries, one of the first important sites being the Ewenny Pottery in Bridgend, which began producing earthenware in the 17th century.[303] In the 18th and 19th centuries, with more scientific methods becoming available, more refined ceramics were produced: this was led by the Cambrian Pottery (1764\u20131870, also known as \"Swansea pottery\"), and later Nantgarw Pottery near Cardiff, which was in operation from 1813 to 1820 making fine porcelain, and then utilitarian pottery from 1833 until 1920.[303] Portmeirion Pottery, founded in 1960 by Susan Williams-Ellis (daughter of Clough Williams-Ellis, creator of the Italianate village of Portmeirion, Gwynedd) is based in Stoke-on-Trent, England.[304]  Wales is regarded as a modern Celtic nation which contributes to its national identity,[30][305] with Welsh artists regularly appearing at Celtic festivals.[306] The red dragon is the principal symbol of national identity and pride, personifying the fearlessness of the Welsh nation.[307] The dragon is first referenced in literature as a symbol of the people in the Historia Brittonum. Vortigern (Welsh: Gwrtheyrn), King of the Celtic Britons, is interrupted whilst attempting to build a fort at Dinas Emrys. He is told by Ambrosius[f] to dig up two dragons beneath the castle. He discovers a red dragon representing the Celtic Britons, and a white dragon representing Anglo-Saxons. Ambrosius prophesies that the Celtic Britons will reclaim the island and push the Anglo-Saxons back to the sea.[309]  As an emblem, the red dragon of Wales has been used since the reign of Cadwaladr, King of Gwynedd from around 655AD, and is present on the national flag of Wales, which became an official flag in 1959.[310] The banner of Owain Glynd\u0175r is associated with Welsh nationhood; it was carried into battle by Welsh forces during Glynd\u0175r's battles against the English, and includes four lions on red and gold.[311] The standard is similar to the arms of Llywelyn ap Gruffudd (Llywelyn the Last), the last Prince of Wales before the conquest of Wales by Edward I of England. The design may also be influenced by the arms of Glyndwr's parents, both of whom had lions in their arms. Owain Glynd\u0175r Day is celebrated on 16 September in Wales and there have been calls to make it a national bank holiday.[312][313][314] The Prince of Wales's feathers is also used in Wales: it consists of three white feathers emerging from a gold coronet, and the German motto Ich dien (I serve). Several Welsh representative teams, including the Welsh rugby union, and Welsh regiments in the British Army, including the Royal Welsh, use the badge or a stylised version of it.[315][316][g]  On 1 March, Welsh people celebrate Saint David's Day, commemorating the death of the country's patron saint in 589.[318] It is not a recognised bank holiday although there have been calls to make it so.[319][320][321] The day is celebrated by schools and cultural societies across Wales, and customs include the wearing of a leek or a daffodil, which are two national emblems of Wales. Children also wear the national costume.[322] The origins of the leek can be traced to the 16th century, while the daffodil became popular in the 19th century, encouraged by David Lloyd George.[323] This is attributed to confusion (or association) between the Welsh for leek, cenhinen, and that for daffodil, cenhinen Bedr or St. Peter's leek.[138] A report in 1916 gave preference to the leek, which has appeared on British pound coins.[323] Other Welsh festivals include Mabsant when parishes would celebrate the patron saint of their local church, although this is now rarely observed,[324] and a more modern celebration, Dydd Santes Dwynwen (St Dwynwen's Day), observed on 25 January in a similar way to St Valentine's Day.[325]  \"Hen Wlad Fy Nhadau\" (English: Land of My Fathers) is the National Anthem of Wales, and is played at events such as football or rugby matches involving the Wales national team, as well as the opening of the Senedd and other official occasions.[326] \"Cymru am byth\" (\"Wales forever\") is a popular Welsh motto.[327] Another Welsh motto \"Y Ddraig Goch Ddyry Cychwyn\" (\"the red dragon inspires action\") has been used on the Royal Badge of Wales when it was created in 1953.[328]  More than 50 national governing bodies regulate and organise their sports in Wales.[329] Most of those involved in competitive sports select, organise and manage individuals or teams to represent their country at international events or fixtures against other countries. Wales is represented at major world sporting events such as the FIFA World Cup, Rugby World Cup, Rugby League World Cup and the Commonwealth Games. At the Olympic Games, Welsh athletes compete alongside those of Scotland, England and Northern Ireland as part of a Great Britain team. Wales has hosted several international sporting events.[330] These include the 1958 Commonwealth Games,[331] the 1999 Rugby World Cup, the 2010 Ryder Cup and the 2017 UEFA Champions League Final.[330][332]  Although football has traditionally been the more popular sport in North Wales, rugby union is seen as a symbol of Welsh identity and an expression of national consciousness.[333] The Wales national rugby union team takes part in the annual Six Nations Championship and has also competed in every Rugby World Cup, hosting the tournament in 1999. The five professional sides that replaced the traditional club sides in major competitions in 2003 were replaced in 2004 by the four regions: Cardiff Blues, Dragons, Ospreys and Scarlets.[334] The Welsh regional teams play in the United Rugby Championship,[335] the Heineken Champions Cup if they qualify[336] and the European Rugby Challenge Cup, again dependent on qualification.[337] Rugby league in Wales dates back to 1907. A professional Welsh League existed from 1908 to 1910.[338]  Wales has had its own football league, the Welsh Premier League, since 1992.[339] For historical reasons, five Welsh clubs play in the English football league system: Cardiff City, Swansea City, Newport County, Wrexham, and Merthyr Town.[340] The country has produced a considerable number of footballers who have played at international level.[341] At UEFA Euro 2016, the Wales national team achieved their best ever finish, reaching the semi-finals.[342]  In international cricket, Wales and England field a single representative team, administered by the England and Wales Cricket Board (ECB), called the England cricket team, or simply 'England'.[343] Occasionally, a separate Wales team play limited-overs competitions. Glamorgan County Cricket Club is the only Welsh participant in the England and Wales County Championship.[344] Wales has produced notable participants of individual sports including snooker,[345] track and field,[346] cycling,[347][348] and boxing.[349][350]  Wales became the UK's first digital television nation in 2010.[351] BBC Cymru Wales is the national broadcaster,[352] producing both television and radio programmes in Welsh and English.[353] It has also produced programmes such as Life on Mars, Doctor Who and Torchwood for BBC's network audience across the United Kingdom.[352][354] ITV, the UK's main commercial broadcaster, has a Welsh-orientated service branded ITV Cymru Wales.[355] S4C began broadcasting in 1982. Its output was mostly in Welsh at peak hours, but shared English-language content with Channel 4 at other times. Since the digital switchover the channel has broadcast exclusively in Welsh.[356] BBC Radio Cymru is the BBC's Welsh-language radio service, which broadcasts throughout Wales.[352] A number of independent radio stations broadcast in the Welsh regions, predominantly in English. In 2006, several regional radio stations broadcast in Welsh: output ranged from two two-minute news bulletins each weekday (Radio Maldwyn) to over 14 hours of Welsh-language programmes weekly (Swansea Sound) to essentially bilingual stations such as Heart Cymru and Radio Ceredigion.[357]  Most of the newspapers sold and read in Wales are national newspapers available throughout Britain. The Western Mail is Wales's only print national daily newspaper.[358] Wales-based regional daily newspapers include the Daily Post (which covers North Wales), the South Wales Evening Post (Swansea), the South Wales Echo (Cardiff), and the South Wales Argus (Newport).[358] Y Cymro is a Welsh-language newspaper, published weekly.[359] Wales on Sunday is the only Welsh Sunday newspaper that covers the whole of Wales.[360] The Books Council of Wales is the Welsh-Government-funded body tasked with promoting Welsh literature in Welsh and English.[361] The BCW provides publishing grants for qualifying English- and Welsh-language publications.[362] Around 650 books are published each year, by some of the dozens of Welsh publishers.[363][364] Wales's main publishing houses include Gomer Press, Gwasg Carreg Gwalch, Honno, the University of Wales Press and Y Lolfa.[363] Journals with a Welsh focus include Cambria (a Welsh affairs magazine published bi-monthly in English),[365] Planet, and Poetry Wales.[366] Welsh-language magazines include the current affairs titles Golwg (\"View\"), published weekly, and Barn (\"Opinion\"), published monthly.[359] Y Wawr (\"The Dawn\") is published quarterly by Merched y Wawr, the national organisation for women.[359] Y Traethodydd (\"The Essayist\"), a quarterly publication by the Presbyterian Church of Wales, first appeared in 1845 and is the oldest Welsh publication still in print.[359]  Traditional Welsh dishes include laverbread (made from Porphyra umbilicalis, an edible seaweed), bara brith (fruit bread), cawl (a lamb stew), cawl cennin (leek soup), and Welsh cakes.[367] Cockles are sometimes served as a traditional breakfast with bacon and laverbread.[368] Although Wales has its own traditional food and has absorbed much of the cuisine of England, Welsh diets now owe more to the countries of India, China and the United States. Chicken tikka masala is the country's favourite dish, while hamburgers and Chinese food outsell fish and chips as takeaways.[369]  Wales, \"the land of song\", is notable for its solo artists, its male voice choirs and its harpists.[370] The annual National Eisteddfod is the country's main performance festival. The Llangollen International Eisteddfod provides an opportunity for the singers and musicians of the world to perform. The Welsh Folk Song Society publishes collections of historical songs and tunes.[371] Traditional instruments of Wales include the telyn deires (triple harp), fiddle, crwth (bowed lyre) and the pibgorn (hornpipe).[372] Male voice choirs emerged in the 19th century, formed as the tenor and bass sections of chapel choirs, and embraced the popular secular hymns of the day.[373] Welsh congregations and choirs were known for singing in a rousing four-voice style, becoming characteristic of the country.[374] Many of the historic choirs survive in modern Wales, singing a mixture of traditional and popular songs.[373]  The BBC National Orchestra of Wales performs in Wales and internationally. The Welsh National Opera is based at the Wales Millennium Centre in Cardiff Bay, while the National Youth Orchestra of Wales was the first of its type in the world.[375] Wales has a tradition of producing notable singers in both the classical and pop arenas,[376] as well as some popular bands.[377][378][379] The Welsh folk music scene has enjoyed a resurgence in the 21st century.[380]  The earliest surviving Welsh plays are two medieval miracle plays, Y Tri Brenin o Gwlen (\"The three Kings from Cologne\") and Y Dioddefaint a'r Atgyfodiad (\"The Passion and the Resurrection\").[381] A recognised Welsh tradition of theatre emerged during the 18th century, in the form of an interlude, a metrical play performed at fairs and markets.[382] Drama in the early 20th century thrived, but the country established neither a Welsh National Theatre nor a national ballet company.[383] After the Second World War, the substantial number of amateur theatre companies reduced by two thirds.[384] Competition from television in the mid-20th century led to greater professionalism in the theatre.[384] Plays by Emlyn Williams and Alun Owen and others were staged, while Welsh actors, including Richard Burton and Anthony Hopkins, were establishing international reputations.[384][385][386] Wales has also produced some well-known comedians.[387]  Traditional dances include Welsh folk dancing and clog dancing. The first mention of dancing in Wales is in a 12th-century account by Giraldus Cambrensis, but by the 19th century traditional dance had all but died out due to religious opposition.[383] In the 20th century a revival was led by Lois Blake (1890\u20131974).[383] Clog dancing was preserved and developed by Hywel Wood (1882\u20131967) and others who perpetuated the art on local and national stages.[388] The Welsh Folk Dance Society was founded in 1949.[388] Contemporary dance grew out of Cardiff in the 1970s.[388] The National Dance Company Wales, formed in 1983, is now resident at the Wales Millennium Centre.[389]  Citations  Sources  52\u00b018\u2032N 3\u00b048\u2032W\ufeff \/ \ufeff52.3\u00b0N 3.8\u00b0W\ufeff \/ 52.3; -3.8 "},{"title":"Midtown Manhattan","content":"  Midtown Manhattan is the central portion of the New York City borough of Manhattan and serves as the city's primary central business district. Midtown is home to some of the city's most prominent buildings, including the Empire State Building, the Chrysler Building, the Hudson Yards Redevelopment Project, the headquarters of the United Nations, Grand Central Terminal, and Rockefeller Center, as well as several prominent tourist destinations including Broadway, Times Square, and Koreatown. Penn Station in Midtown Manhattan is the busiest transportation hub in the Western Hemisphere.[5]  Midtown Manhattan is one of the largest central business districts in the world, and has been ranked as the densest central business district in the world in terms of employees at 606,108 per square mile (234,020\/km2).[6] Midtown also ranks among the world's most expensive locations for real estate; Fifth Avenue in Midtown Manhattan has commanded the world's highest retail rents, with average annual rents at US$3,000 per square foot ($32,000\/m2) in 2017.[7] However, due to the high price of retail spaces in Midtown, there are also many vacant storefronts in the neighborhood.[8] Midtown is the country's largest commercial, entertainment, and media center, and also a growing financial and fintech center.[9]  The majority of New York City's skyscrapers, including its tallest hotels and apartment towers, are in Midtown. The area hosts commuters and residents working in its offices, hotels, and retail establishments, tourists and students. Times Square, the brightly illuminated hub of the Broadway Theater District,[10][11][12][13][14] is a major center of the world's entertainment industry.[15] Sixth Avenue also has the headquarters of three of the four major U.S. television networks.  Midtown is part of Manhattan Community District 5.[2] It is patrolled by the 14th and 18th precincts of the New York City Police Department.  Geographically, the northern boundary of Midtown Manhattan is commonly defined to be 59th Street; its southern boundary is less clear, and variously taken to be 34th Street, 23rd Street, or even 14th Street. Midtown spans the entire island of Manhattan along an east\u2013west axis, bounded by the East River on its east and the Hudson River to its west. The Encyclopedia of New York City defines Midtown as extending from 34th Street to 59th Street and from 3rd Avenue to 8th Avenue.[16]  In addition to its central business district, Midtown Manhattan encompasses many neighborhoods, including Hell's Kitchen and Chelsea on the West Side, and Murray Hill, Kips Bay, Turtle Bay, and Gramercy Park on the East Side. It is sometimes broken into \"Midtown East\" and \"Midtown West\", or north and south as in the New York City Police Department's Midtown North and Midtown South precincts.  Neighborhoods in the Midtown area include the following:  Midtown is the original district in the United States to bear the name and included historical but now defunct neighborhoods such as the Ladies' Mile, along Fifth Avenue from 14th to 23rd Street; and the Tenderloin, from 23rd to 42nd Street and from Fifth Avenue to Seventh Avenue.  Important streets and thoroughfares  The border of Midtown Manhattan is nebulous and further confused by the fact that the term \"Midtown Manhattan\" can be used to refer either to a district or a group of neighborhoods and districts in Manhattan:  Midtown Manhattan, along with Lower Manhattan, is one of the world's leading financial centers.  Midtown Manhattan is the one of the world's largest central business district, with 400\u00a0million square feet (37.2\u00a0million m2) of office space in 2018.[19] Midtown contains the headquarters of major companies, including 4Kids Entertainment (formerly),[20] Barnes & Noble,[21] Bloomberg L.P.,[22] Ernst & Young,[23] Calvin Klein,[24] Cantor Fitzgerald,[25] CBS Corporation,[26] Citigroup,[27] Colgate-Palmolive,[28] Cushman & Wakefield,[29] DC Comics,[30] Deloitte,[31] Duane Reade,[32] Est\u00e9e Lauder Companies,[33] Foot Locker,[34] Frederator Studios,[35] JPMorgan Chase,[36] Hess Corporation,[37] Kroll Inc.,[38] L-3 Communications,[39] Marsh & McLennan Companies,[40] Marvel Entertainment,[41] MetLife,[42] MidOcean Partners,[43] Morgan Stanley,[44] Nasdaq, Inc.,[45] NBC Universal,[46] The New York Times Company,[47] NexCen Brands,[48] Paramount Global,[49] Pfizer,[50] Polo Ralph Lauren,[51] Saks Incorporated (Saks Fifth Avenue),[52] The Sharper Image,[53] Simon & Schuster,[26] Six Flags,[54] TBWA Worldwide,[55] Thomson Reuters,[56] Time Warner,[57] Time Warner Cable,[58] The Travelers Companies, and Univision Communications.[59] The New York Institute of Finance is located in Midtown Manhattan.[60]  Haier operates its United States offices in the Haier Building at 1356 Broadway, formerly the headquarters of the Greenwich Savings Bank. Haier held the opening ceremony on March 4, 2002.[61] Sumitomo Corporation operates its New York Office, the headquarters of the corporation's United States operations, at 600 Third Avenue, 10016 in the Murray Hill neighborhood.[62] El Al's North American headquarters are in Midtown.[63] The Air France USA regional headquarters are in 125 West 55th Street in Midtown Manhattan.[64][65] Hachette Book Group USA has its headquarters in 237 Park Avenue.[66] In 1994 Alitalia considered moving its USA headquarters from Midtown to Lower Manhattan, but decided to keep the offices where they were at the last minute.[67] Global Infrastructure Partners has an office in Midtown Manhattan.[68]  Silicon Alley, the common metonym for New York City's high tech sector, is based in Midtown South, specifically the Flatiron District. Prominent Silicon Alley companies in Midtown include AppNexus, Blue Apron, Gilt, Betterment, Oscar, SoFi, Rent the Runway, Warby Parker, and WeWork. The technology sector has been expanding across Midtown Manhattan since 2010.[69] The biotechnology sector is also growing in Midtown Manhattan based upon the city's strength in academic scientific research and public and commercial financial support. By mid-2014, Accelerator, a biotech investment firm, had raised more than US$30\u00a0million from investors, including Eli Lilly and Company, Pfizer, and Johnson & Johnson, for initial funding to create biotechnology startups at the Alexandria Center for Life Science, which encompasses more than 700,000 square feet (65,000\u00a0m2) on East 29th Street and promotes collaboration among scientists and entrepreneurs at the center and with nearby academic, medical, and research institutions. The New York City Economic Development Corporation's Early Stage Life Sciences Funding Initiative and venture capital partners, including Celgene, General Electric Ventures, and Eli Lilly, committed a minimum of US$100\u00a0million to help launch 15 to 20 ventures in life sciences and biotechnology.[70]  Real estate is a major force in Midtown Manhattan's economy, and indeed the city's, as the total value of all New York City property was estimated at US$914.8\u00a0billion for the 2015 fiscal year.[71] Manhattan has perennially been home to some of the nation's, as well as one of the world's, most marketable real estate, including the Time Warner Center, which had the highest-listed market value in the city in 2006 at US$1.1\u00a0billion,[72] to be subsequently surpassed in October 2014 by the Waldorf Astoria New York, which became the most expensive hotel ever sold after being purchased by the Anbang Insurance Group, based in China, for US$1.95 billion.[73] When 450 Park Avenue was sold on July 2, 2007, for US$510\u00a0million, about US$1,589 per square foot (US$17,104\/m2), it broke the barely month-old record for an American office building of US$1,476 per square foot (US$15,887\/m2) based on the sale of 660 Madison Avenue.[74] In 2014, Manhattan was home to six of the top ten zip codes in the United States by median housing price.[75] In 2019, the most expensive home sale ever in the United States achieved completion in Midtown Manhattan, at a selling price of US$238\u00a0million, for a 24,000 square feet (2,200\u00a0m2) penthouse apartment overlooking Central Park at 220 Central Park South.[76]  The COVID-19 pandemic and hybrid work models have prompted consideration of commercial-to-residential conversion within the neighborhood's real estate sector.[77] In August 2023, Mayor Eric Adams announced a program aimed at creating \"a 24\/7, live-work, mixed-use neighborhood\" in Midtown South though the conversion of commercial and office space to residential, as part of an effort to create 20,000 new residences citywide in a decade.[78][79]  According to The Broadway League, shows on Broadway sold approximately US$1.27\u00a0billion worth of tickets in the 2013\u20132014 season, an increase of 11.4% from US$1.139\u00a0billion in the 2012\u20132013 season; attendance in 2013\u20132014 stood at 12.21\u00a0million, a 5.5% increase from the 2012\u20132013 season's 11.57\u00a0million.[80]  Companies that used to have their headquarters in Midtown Manhattan include American Airlines,[81][82] American Comics Group,[83] American Overseas Airlines,[84] Central Park Media,[85][86] Eastern Air Lines,[87] GoodTimes Entertainment,[88] LJN,[89] NewKidCo,[90] Pan American World Airways,[91] Philip Morris Companies (now Altria Group),[92][93] Trans Caribbean Airways,[94] and Trans World Airlines.[95][96][97] In 1997, Aer Lingus announced that it was moving its North American headquarters from Midtown to Melville, New York, in Suffolk County on Long Island.[98]  Based on data from the 2010 United States Census, the population of Midtown Manhattan was 28,630, a change of 2,823 (9.9%) from the 25,807 counted in 2000. Covering an area of 692.81 acres (280.37\u00a0ha), the neighborhood had a population density of 41.3 inhabitants per acre (26,400\/sq\u00a0mi; 10,200\/km2).[99] The racial makeup of the neighborhood was 64.1% (18,351) White, 4.6% (1,310) African American, 0.1% (34) Native American, 20.8% (5,942) Asian, 0% (8) Pacific Islander, 0.3% (92) from other races, and 2% (569) from two or more races. Hispanic or Latino residents of any race were 8.1% (2,324) of the population.[4]  The entirety of Community District 5, which comprises Midtown Manhattan, had 53,120 inhabitants as of NYC Health's 2018 Community Health Profile, with an average life expectancy of 84.8 years.[100]:\u200a2,\u200a20\u200a This is higher than the median life expectancy of 81.2 for all New York City neighborhoods.[101]:\u200a53\u200a[102] Most inhabitants are adults: a plurality (45%) are between the ages of 25 and 44, while 22% are between 45 and 64, and 13% are 65 or older. The ratio of youth and college-aged residents was lower, at 7% and 12% respectively.[100]:\u200a2\u200a  As of 2017, the median household income in Community Districts 4 and 5 (including Chelsea and Hell's Kitchen) was $101,981,[103] though the median income in Midtown individually was $120,854.[3] In 2018, an estimated 11% of Midtown Manhattan residents lived in poverty, compared to 14% in all of Manhattan and 20% in all of New York City. One in twenty residents (5%) were unemployed, compared to 7% in Manhattan and 9% in New York City. Rent burden, or the percentage of residents who have difficulty paying their rent, is 41% in Midtown Manhattan, compared to the boroughwide and citywide rates of 45% and 51% respectively. Based on this calculation, as of 2018[update], Midtown Manhattan is considered to be high-income relative to the rest of the city and not gentrifying.[100]  Midtown Manhattan is patrolled by two precincts of the NYPD.[104] Midtown North is patrolled by the 18th Precinct,[a] located at 306 West 54th Street,[105] while Midtown South is patrolled by the 14th Precinct,[a] located at 357 West 35th Street.[107] The precincts ranked 69th safest out of 69 patrol areas for per-capita crime in 2010. The high per-capita crime rate can be attributed to the low population of the area, as well as the high number of crimes committed against tourists.[108] As of 2018[update], with a non-fatal assault rate of 25 per 100,000 people, Midtown Manhattan's rate of violent crimes per capita is less than that of the city as a whole. The incarceration rate of 297 per 100,000 people is lower than that of the city as a whole.[100]:\u200a8\u200a  The 18th Precinct has a lower crime rate than it did in the 1990s, with crimes across all categories having decreased by 82.1% between 1990 and 2022. The precinct reported 1 murder, 22 rapes, 154 robberies, 185 felony assaults, 205 burglaries, 2,065 grand larcenies, and 116 grand larcenies auto in 2022.[109] The 14th Precinct also has a lower crime rate than in the 1990s, with crimes across all categories having decreased by 81.2% between 1990 and 2022. The precinct reported 8 murders, 23 rapes, 653 robberies, 502 felony assaults, 660 burglaries, 2,375 grand larcenies, and 68 grand larcenies auto in 2022.[110]  The main part of midtown Manhattan, between 34th and 59th Streets from Lexington Avenue to Eighth Avenue, is served by five fire stations of the New York City Fire Department (FDNY):[111]  The greater Midtown area between 14th Street and 59th Street contains seven additional fire stations.[111]  As of 2018[update], preterm births and births to teenage mothers in Midtown Manhattan are lower than the city average. In Midtown Manhattan, there were 67 preterm births per 1,000 live births (compared to 87 per 1,000 citywide), and 4 births to teenage mothers per 1,000 live births (compared to 19.3 per 1,000 citywide).[100]:\u200a11\u200a Midtown Manhattan has a low population of residents who are uninsured. In 2018, this population of uninsured residents was estimated to be 11%, slightly less than the citywide rate of 12%.[100]:\u200a14\u200a  The concentration of fine particulate matter, the deadliest type of air pollutant, in Midtown Manhattan is 0.0113 milligrams per cubic metre (1.13\u00d710\u22128\u00a0oz\/cu\u00a0ft), more than the city average.[100]:\u200a9\u200a Eleven percent of Midtown Manhattan residents are smokers, which is less than the city average of 14% of residents being smokers.[100]:\u200a13\u200a In Midtown Manhattan, 10% of residents are obese, 5% are diabetic, and 18% have high blood pressure\u2014compared to the citywide averages of 24%, 11%, and 28% respectively.[100]:\u200a16\u200a In addition, 9% of children are obese, compared to the citywide average of 20%.[100]:\u200a12\u200a  Ninety-one percent of residents eat some fruits and vegetables every day, which is higher than the city's average of 87%. In 2018, 86% of residents described their health as \"good\", \"very good\", or \"excellent\", more than the city's average of 78%.[100]:\u200a13\u200a For every supermarket in Midtown Manhattan, there are 11 bodegas.[100]:\u200a10\u200a  The nearest major hospitals are Mount Sinai West in Hell's Kitchen; Beth Israel Medical Center in Stuyvesant Town; the Bellevue Hospital Center and NYU Langone Medical Center in Kips Bay; and NewYork\u2013Presbyterian Hospital in the Upper East Side.[117][118]  Midtown Manhattan is located within six primary ZIP Codes. West of Fifth Avenue, Midtown is located in 10018 between 34th and 41st Streets, 10036 between 41st and 48th Streets, and 10019 between 48th and 59th Streets. East of Fifth Avenue, Midtown is located in 10016 between 34th and 40th Streets, 10017 between 40th and 49th Streets, and 10022 between 49th and 59th Streets. The area southwest of Fifth Avenue and 34th Street, sometimes considered to be in Midtown, is part of 10001. Other areas between 14th and 34th Streets are covered by ZIP Codes 10003, 10009, 10010, and 10011, though these are generally not considered to be part of Midtown proper.[119] There are also thirty-three ZIP Codes assigned to individual buildings or building complexes.[121]  The United States Postal Service operates six post offices in Midtown:  The James A. Farley Station, the city's main post office, is located at 421 8th Avenue.[128] The post office stopped 24-hour service in 2009 due to decreasing mail traffic.[129]  Midtown Manhattan generally has a higher rate of college-educated residents than the rest of the city as of 2018[update]. A majority of residents age 25 and older (78%) have a college education or higher, while 6% have less than a high school education and 17% are high school graduates or have some college education. By contrast, 64% of Manhattan residents and 43% of city residents have a college education or higher.[100]:\u200a6\u200a The percentage of Midtown Manhattan students excelling in math rose from 61% in 2000 to 80% in 2011 and reading achievement increased from 66% to 68% during the same time period.[130]  Midtown Manhattan's rate of elementary school student absenteeism is lower than the rest of New York City. In Midtown Manhattan, 19% of elementary school students missed twenty or more days per school year, less than the citywide average of 20%.[101]:\u200a24 (PDF p. 55)\u200a[100]:\u200a6\u200a Additionally, 92% of high school students in Midtown Manhattan graduate on time, more than the citywide average of 75%.[100]:\u200a6\u200a  There are no public elementary or middle schools in Midtown.[131]  The New York City Department of Education operates the following public high schools in Midtown, serving grades 9-12:[131]  Private schools include The Beekman School, Rebecca School, and a number of private languages and music centers (e.g. Berlitz, American Language Communication Center, New York Language Center,[137] Swan Music School, and the New York Youth Symphony). The La Scuola d'Italia Guglielmo Marconi Italian international school moved to West Midtown in 2016.[138]  The New York Public Library (NYPL) operates the Stephen A. Schwarzman Building (also the Main Branch), a reference branch at 476 Fifth Avenue. The four-story building, constructed in 1911, is known worldwide for its architecture and has several million items in its collections.[139] There are also five circulating branches in Midtown:[140][141]  Two campuses of the City University of New York (CUNY)\u2014the doctorate-granting CUNY Graduate Center and the Stella and Charles Guttman Community College\u2014are located in Midtown, while Baruch College, also of the City University of New York, is located in Midtown South. Mercy College is situated at Herald Square.  Pennsylvania Station and Grand Central Terminal are the two major railroad stations located in Midtown Manhattan. Penn Station serves Amtrak, NJ Transit, and the Long Island Rail Road (LIRR), while Grand Central serves the Metro-North Railroad and also serves the LIRR at Grand Central Madison.[149] Penn Station is considered to be the busiest transportation hub in the Western Hemisphere, servicing around 650,000 people per day.[150][151]  The Port Authority Bus Terminal, located at Eighth Avenue and 41st Street at the western edge of Midtown, is the city's main intercity bus terminal and the world's busiest bus station, serving 250,000 passengers on 7,000 buses each workday. The building opened in 1950 and had been designed to accommodate 60,000 daily passengers. A 2021 plan announced by the Port Authority would spend $10 billion to expand capacity and modernize the facility.[152][153][154]  The New York City Subway and MTA Regional Bus Operations each operate several routes that go through Midtown. Additionally, the PATH train to New Jersey terminates at 33rd Street and Sixth Avenue in Midtown.[155][156]  Traffic congestion is common, especially for crosstown traffic. In 2011, a new system of traffic light control, known as \"Midtown in Motion\" was announced, with the aim of reducing traffic congestion.[157] Approximately 750,000 vehicles enter Midtown Manhattan on a fall business day.[158] According to the 2011 Traffic Data Report for New York State, 777,527 vehicles a day went through select toll facilities into Manhattan.[159]  The New York Supreme Court, Appellate Division, First Department, is located at the Appellate Division Courthouse at 25th Street and Madison Avenue was completed in 1900 by architect James Brown Lord, who used a third of the construction budget to decorate the building with statues and murals.[160] The Puerto Rico Federal Affairs Administration operates its New York office on the 22nd floor at 135 West 50th Street.[161]  Several countries, including Algeria,[162] Argentina, The Bahamas,[163] China,[164] Costa Rica,[165] Germany,[166] Ireland,[167] Israel,[168] Jamaica,[169] Japan,[170] Luxembourg,[171] Mexico,[172] Morocco,[173] Saudi Arabia,[174] Singapore,[175] South Africa,[176] South Korea,[177] United Kingdom,[178] and Ukraine,[179] have Permanent Missions accredited to the United Nations, and consulates-general accredited to the United States, in Midtown Manhattan. In addition, the Taipei Economic and Cultural Office of the Republic of China (Taiwan) is in Midtown Manhattan.[180] "},{"title":"Irish Sea","content":"  The Irish Sea[a] is a 46,007\u00a0km2 (17,763\u00a0sq\u00a0mi) body of water that separates the islands of Ireland and Great Britain. It is linked to the Celtic Sea in the south by St George's Channel and to the Inner Seas off the West Coast of Scotland[4] in the north by the North Channel. Anglesey, North Wales, is the largest island in the Irish Sea, followed by the Isle of Man. The term Manx Sea may occasionally be encountered (Welsh: M\u00f4r Manaw, Irish: Muir Meann[5] Manx: Mooir Vannin, Scottish Gaelic: Muir Mhanainn).[6][7][8]  On its shoreline are Scotland to the north, England to the east, Wales to the southeast, Northern Ireland and the Republic of Ireland to the west. The Irish Sea is of significant economic importance to regional trade, shipping and transport, as well as fishing and power generation in the form of wind power and nuclear power plants. Annual traffic between Great Britain and Ireland amounts to over 12 million passengers and 17\u00a0million tonnes (17,000,000 long tons; 19,000,000 short tons) of traded goods.  The Irish Sea joins the North Atlantic at both its northern and southern ends. To the north, the connection is through the North Channel between Scotland and Northern Ireland and the Malin Sea. The southern end is linked to the Atlantic through the St George's Channel between Ireland and Pembrokeshire, and the Celtic Sea. It is composed of a deeper channel about 300\u00a0km (190\u00a0mi) long and 30\u201350\u00a0km (20\u201330\u00a0mi) wide on its western side and shallower bays to the east. The depth of the western channel ranges from 80 metres (260\u00a0ft) to 275\u00a0m (900\u00a0ft).  Cardigan Bay in the south, and the waters to the east of the Isle of Man, are less than 50\u00a0m (160\u00a0ft) deep. With a total water volume of 2,430\u00a0km3 (580\u00a0cu\u00a0mi) and a surface area of 47,000\u00a0km2 (18,000\u00a0sq\u00a0mi), 80% is to the west of the Isle of Man. The largest sandbanks are the Bahama and King William Banks to the east and north of the Isle of Man and the Kish Bank, Codling Bank, Arklow Bank and Blackwater Bank near the coast of Ireland. The Irish Sea, at its greatest width, is 200\u00a0km (120\u00a0mi) and narrows to 75\u00a0km (47\u00a0mi).[9]  The International Hydrographic Organization defines the limits of the Irish Sea (with St George's Channel) as follows,  The Irish Sea has undergone a series of dramatic changes over the last 20,000 years as the last glacial period ended and was replaced by warmer conditions. At the height of the glaciation, the central part of the modern sea was probably a long freshwater lake. As the ice retreated 10,000 years ago, the lake reconnected to the sea.  The Irish Sea was formed in the Neogene era.[10] Notable crossings include several invasions from Britain. The Norman invasion of Ireland took place in stages during the late 12th century from Porthclais near St. Davids, Wales, in Hulks, Snekkars, Keels and Cogs[11] to Wexford Harbour, Leinster.[12] The Tudors crossed the Irish Sea to invade in 1529 in caravels and carracks.[11] In 1690 the English fleet set sail for the Williamite War in Ireland from Hoylake, Wirral, the departure becoming permanently known as King's Gap as a result.[citation needed]  Because Ireland has neither tunnel nor bridge to connect it with Great Britain, the vast majority of heavy goods trade is done by sea. Northern Ireland ports handle 10\u00a0million tonnes (9,800,000 long tons; 11,000,000 short tons) of goods trade with the rest of the United Kingdom annually; the ports in the Republic of Ireland handle 7.6\u00a0million tonnes (7,500,000 long tons; 8,400,000 short tons), representing 50% and 40% respectively of total trade by weight.  The Port of Liverpool handles 32\u00a0million tonnes (31,000,000 long tons; 35,000,000 short tons) of cargo and 734,000 passengers a year.[13] Holyhead port handles most of the passenger traffic from Dublin and D\u00fan Laoghaire ports, as well as 3.3\u00a0million tonnes (3,200,000 long tons; 3,600,000 short tons) of freight.[14]  Ports in the Republic handle 3,600,000 travellers crossing the sea each year, amounting to 92% of all Irish Sea travel.[15]  Ferry connections from Wales to Ireland across the Irish Sea include Fishguard Harbour and Pembroke to Rosslare, Holyhead to D\u00fan Laoghaire and Holyhead to Dublin. From Scotland, Cairnryan connects with both Belfast and Larne. There is also a connection between Liverpool and Belfast via the Isle of Man or direct from Birkenhead. The world's largest car ferry, Ulysses, is operated by Irish Ferries on the Dublin Port\u2013Holyhead route; Stena Line also operates between Britain and Ireland.  \"Irish Sea\" is also the name of one of the BBC's Shipping Forecast areas defined by the coordinates:  Transport for Wales Rail, Iarnr\u00f3d \u00c9ireann, Irish Ferries, Stena Line, Northern Ireland Railways, Stena Line and ScotRail promote SailRail with through rail tickets for the train and the ferry.[16]  The British ship LCT 326 sank in the Irish sea and was discovered in March 2020. In September 2021, the British Navy ship HMS Mercury was discovered; it sank in 1940. The British ship SS Mesaba was sunk by the Imperial German Navy U-118 in 1918 and discovered in 2022. [17] This ship is well known for sailing near the Titanic and for attempting to warn the Titanic about dangerous icebergs.  The Caernarfon Bay basin contains up to 7 cubic kilometres (1.7\u00a0cu\u00a0mi) of Permian and Triassic syn-rift sediments in an asymmetrical graben that is bounded to the north and south by Lower Paleozoic massifs.[18] Only two exploration wells have been drilled so far, and there remain numerous undrilled targets in tilted fault block plays.[19] As in the East Irish Sea Basin, the principal target reservoir is the Lower Triassic, Sherwood Sandstone, top-sealed by younger Triassic mudstones and evaporites. Wells in the Irish Sector to the west have demonstrated that pre-rift, Westphalian coal measures are excellent hydrocarbon source rocks, and are at peak maturity for gas generation (Maddox et al., 1995). Seismic profiles clearly image these strata continuing beneath a basal Permian unconformity into at least the western part of the Caernarfon Bay Basin.  The timing of gas generation presents the greatest exploration risk. Maximum burial of, and primary gas migration from, the source rocks could have terminated as early as the Jurassic, whereas many of the tilted fault blocks were reactivated or created during Paleogene inversion of the basin. However, it is also possible that a secondary gas charge occurred during regional heating associated with intrusion of Paleogene dykes, such as those that crop out nearby on the coastline of north Wales. (Floodpage et al., 1999) have invoked this second phase of Paleogene hydrocarbon generation as an important factor in the charging of the East Irish Sea Basin's oil and gas fields. It is not clear as yet whether aeromagnetic anomalies in the southeast of Caernarfon Bay are imaging a continuation of the dyke swarm into this area too, or whether they are instead associated with deeply buried Permian syn-rift volcanics. Alternatively, the fault block traps could have been recharged by exsolution of methane from formation brines as a direct result of the Tertiary uplift (cf. Dor\u00e9 and Jensen, 1996).  The Cardigan Bay Basin forms a continuation into British waters of Ireland's North Celtic Sea Basin, which has two producing gas fields. The basin comprises a south-easterly deepening half-graben near the Welsh coastline, although its internal structure becomes increasingly complex towards the southwest. Permian to Triassic, syn-rift sediments within the basin are less than 3\u00a0km (1.9\u00a0mi) thick and are overlain by up to 4\u00a0km (2.5\u00a0mi) of Jurassic strata, and locally also by up to 2\u00a0km (1.2\u00a0mi) of Paleogene fluvio-deltaic sediments. The basin has a proven petroleum system, with potentially producible gas reserves at the Dragon discovery near the UK\/ROI median line, and oil shows in a further three wells. The Cardigan Bay Basin contains multiple reservoir targets, which include the Lower Triassic (Sherwood Sandstone), Middle Jurassic shallow marine sandstones and limestone (Great Oolite), and Upper Jurassic fluvial sandstone, the reservoir for the Dragon discovery.  The most likely hydrocarbon source rocks are Early Jurassic marine mudstones. These are fully mature for oil generation in the west of the British sector and are mature for gas generation nearby in the Irish sector. Gas-prone, Westphalian pre-rift coal measures may also be present at depth locally. The Cardigan Bay Basin was subjected to two Tertiary phases of compressive uplift, whereas maximum burial that terminated primary hydrocarbon generation was probably around the end of the Cretaceous, or earlier if Cretaceous strata, now missing, were never deposited in the basin. Despite the Tertiary structuration, the Dragon discovery has proved that potentially commercial volumes of hydrocarbons were retained at least locally in Cardigan Bay. In addition to undrilled structural traps, the basin contains the untested potential for stratigraphic entrapment of hydrocarbons near synsedimentary faults, especially in the Middle Jurassic section.[19][20]  The Liverpool Bay Development is BHP Billiton Petroleum's largest operated asset. It comprises the integrated development of five offshore oil and gas fields in the Irish Sea:  Oil is produced from the Lennox and Douglas fields. It is then treated at the Douglas Complex and piped 17\u00a0km (11\u00a0mi) to an oil storage barge ready for export by tankers. Gas is produced from the Hamilton, Hamilton North and Hamilton East reservoirs. After initial processing at the Douglas Complex the gas is piped by subsea pipeline to the Point of Ayr gas terminal for further processing. The gas is then sent by onshore pipeline to PowerGen's combined cycle gas turbine power station at Connah's Quay. PowerGen is the sole purchaser of gas from the Liverpool Bay development.  The Liverpool Bay development comprises four offshore platforms. Offshore storage and loading facilities. The onshore gas processing terminal at Point of Ayr. Production first started at each field as follows: Hamilton North in 1995, Hamilton in 1996, Douglas in 1996, Lennox (oil only) in 1996 and Hamilton East 2001. The first contract gas sales were in 1996.  The quality of the water in Liverpool Bay was historically contaminated by dumping of sewage sludge at sea[21] but this practice became illegal in December 1988 and no further sludge was deposited after that date.[22]  With 210\u00a0billion cubic metres (7.5\u00a0trillion cubic feet) of natural gas and 176\u00a0million barrels (28,000,000\u00a0m3) of petroleum estimated by the field operators as initially recoverable hydrocarbon reserves from eight producing fields (DTI, 2001), the East Irish Sea Basin is at a mature exploration phase. Early Namurian basinal mudstones are the source rocks for these hydrocarbons. Production from all fields is from fault-bounded traps of the Lower Triassic formation, principally the aeolian Sherwood Sandstone reservoir, top-sealed by younger Triassic continental mudstones and evaporites. Future mineral exploration will initially concentrate on extending this play, but there remains largely untested potential also for gas and oil within widespread Carboniferous fluvial sandstone reservoirs. This play requires intraformational mudstone seal units to be present, as there is no top-seal for reservoirs sub cropping the regional base Permian unconformity in the east of the basin, and Carboniferous strata crop out at the sea bed in the west.  Previous exploration drilling in the Kish Bank Basin has confirmed the potential for petroleum generation with oil shows seen in a number of wells together with natural hydrocarbon seeps recorded from airborne surveys. New[when?] analysis of vintage 2-D seismic data has revealed the presence of a large undrilled structural closure at Lower Triassic level situated about 10 kilometres (6\u00a0mi) offshore Dublin. This feature, known as the Dalkey Island exploration prospect, may be prospective for oil, as there are prolific oil productive Lower Triassic reservoirs nearby in the eastern Irish Sea offshore Liverpool. Whilst the Dalkey Island exploration prospect could contain about 870\u00a0million barrels (140,000,000\u00a0m3) of oil in place, this undrilled prospect still has significant risk and the partners are currently advancing a focused work programme in order to better understand and hopefully mitigate these risks. However, given its location in shallow water and close proximity to shore, the prospect is of great interest as exploration drilling, together with any future development costs, are likely to be low.[citation needed]  Below is a list of cities and towns around the Irish Sea coasts in order of size:  The most accessible and possibly the greatest wildlife resource of the Irish Sea lies in its estuaries: particularly the Dee Estuary, the Mersey Estuary, the Ribble Estuary, Morecambe Bay, the Solway Firth, the Firth of Clyde, Belfast Lough, Strangford Lough, Carlingford Lough, Dundalk Bay, Dublin Bay and Wexford Harbour. However, a lot of wildlife also depends on the cliffs, salt marshes and sand dunes of the adjoining shores, the seabed and the open sea itself.  The information on the invertebrates of the seabed of the Irish Sea is rather patchy because it is difficult to survey such a large area, where underwater visibility is often poor and information often depends upon looking at material brought up from the seabed in mechanical grabs. However, the groupings of animals present depend to a large extent on whether the seabed is composed of rock, boulders, gravel, sand, mud or even peat. In the soft sediments seven types of community have been provisionally identified, variously dominated by brittle-stars, sea urchins, worms, mussels, tellins, furrow-shells, and tower-shells.  Parts of the bed of the Irish Sea are very rich in wildlife. The seabed southwest of the Isle of Man is particularly noted for its rarities and diversity,[26] as are the horse mussel beds of Strangford Lough. Scallops and queen scallops are found in more gravelly areas. In the estuaries, where the bed is more sandy or muddy, the number of species is smaller but the size of their populations is larger. Brown shrimp, cockles and edible mussels support local fisheries in Morecambe Bay and the Dee Estuary and the estuaries are also important as nurseries for flatfish, herring and sea bass. Muddy seabeds in deeper waters are home to populations of the Dublin Bay prawn, also known as \"scampi\".[27]  The open sea is a complex habitat in its own right. It exists in three spatial dimensions and also varies over time and tide. For example, where freshwater flows into the Irish Sea in river estuaries its influence can extend far offshore as the freshwater is lighter and \"floats\" on top of the much larger body of salt water until wind and temperature changes mix it in. Similarly, warmer water is less dense and seawater warmed in the inter-tidal zone may \"float\" on the colder offshore water. The amount of light penetrating the seawater also varies with depth and turbidity. This leads to differing populations of plankton in different parts of the sea and varying communities of animals that feed on these populations. However, increasing seasonal storminess leads to greater mixing of water and tends to break down these divisions, which are more apparent when the weather is calm for long periods.  Plankton includes bacteria, plants (phytoplankton) and animals (zooplankton) that drift in the sea. Most are microscopic, but some, such as the various species of jellyfish and sea gooseberry, can be much bigger.  Diatoms and dinoflagellates dominate the phytoplankton. Although they are microscopic plants, diatoms have hard shells and dinoflagellates have little tails that propel them through the water. Phytoplankton populations in the Irish Sea have a spring \"bloom\" every April and May, when the seawater is generally at its greenest.  Crustaceans, especially copepods, dominate the zooplankton. However, many animals of the seabed, the open sea and the seashore spend their juvenile stages as part of the zooplankton. The whole plankton \"soup\" is vitally important, directly or indirectly, as a food source for most species in the Irish Sea, even the largest. The enormous basking shark, for example, lives entirely on plankton and the leatherback turtle's main food is jellyfish.  A colossal diversity of invertebrate species live in the Irish Sea and its surrounding coastline, ranging from flower-like fan-worms to predatory swimming crabs to large chameleon-like cuttlefish.[27] Some of the most significant for other wildlife are the reef-building species like the inshore horse mussel of Strangford Lough, the inter-tidal honeycomb worm of Morecambe Bay, Cumbria and Lancashire, and the sub-tidal honeycomb worm of the Wicklow Reef. These build up large structures over many years and, in turn, provide surfaces, nooks and crannies where other marine animals and plants may become established and live out some or all of their lives.  There are quite regular records of live and stranded leatherback turtles in and around the Irish Sea. This species travels north to the waters off the British Isles every year following the swarms of jellyfish that form its prey. Loggerhead turtle, ridley sea turtle and green turtle are found very occasionally in the Irish Sea but are generally unwell or dead when discovered. They have strayed or been swept out of their natural range further south into colder waters.[28][29]  The estuaries of the Irish Sea are of international importance for birds. They are vital feeding grounds on migration flyways for shorebirds travelling between the Arctic and Africa. Others depend on the milder climate as a refuge when continental Europe is in the grip of winter.[27]  Twenty-one species of seabird are reported as regularly nesting on beaches or cliffs around the Irish Sea. Huge populations of the sea duck, common scoter, spend winters feeding in shallow waters off eastern Ireland, Lancashire and North Wales.[27]  Whales, dolphins and porpoises all frequent the Irish Sea, but knowledge of how many there may be and where they go is somewhat sketchy. About a dozen species have been recorded since 1980, but only three are seen fairly often. These are the harbour porpoise, bottlenose dolphin and common dolphin. The more rarely seen species are minke whale, fin whale, sei whale, humpback whale, North Atlantic right whales[30] which are now considered to be almost extinct in eastern North Atlantic, sperm whale, northern bottlenose whale, long-finned pilot whale, orca, white-beaked dolphin, striped dolphin and Risso's dolphin.[27] In 2005, a plan to reintroduce grey whales by airlifting 50 of them from the Pacific Ocean to the Irish Sea was claimed to be logically and ethically feasible;[31] it has not been implemented as of 2013.  The common or harbour seal and the grey seal are both resident in the Irish Sea. Common seals breed in Strangford Lough, grey seals in southwest Wales and, in small numbers, on the Isle of Man. Grey seals haul out, but do not breed, off Hilbre and Walney islands, Merseyside, the Wirral, St Annes, Barrow-in-Furness Borough, and Cumbria.[27]  The Irish Sea has been described by Greenpeace as the most radioactively contaminated sea in the world with some \"eight million litres of nuclear waste\" discharged into it each day from Sellafield reprocessing plants, contaminating seawater, sediments and marine life.[32]  Low-level radioactive waste has been discharged into the Irish Sea as part of operations at Sellafield since 1952. The rate of discharge began to accelerate in the mid- to late 1960s, reaching a peak in the 1970s and generally declining significantly since then. As an example of this profile, discharges of plutonium (specifically 241Pu) peaked in 1973 at 2,755 terabecquerels (74,500\u00a0Ci)[33] falling to 8.1\u00a0TBq (220\u00a0Ci) by 2004.[34] Improvements in the treatment of waste in 1985 and 1994 resulted in further reductions in radioactive waste discharge although the subsequent processing of a backlog resulted in increased discharges of certain types of radioactive waste. Discharges of technetium in particular rose from 6.1\u00a0TBq (160\u00a0Ci) in 1993 to a peak of 192\u00a0TBq (5,200\u00a0Ci) in 1995 before dropping back to 14\u00a0TBq (380\u00a0Ci) in 2004.[33][34] In total 22 petabecquerels (590\u00a0kCi) of 241Pu was discharged over the period 1952 to 1998.[35] Current rates of discharge for many radionuclides are at least 100 times lower than they were in the 1970s.[36]  Analysis[37][38] of the distribution of radioactive contamination after discharge reveals that mean sea currents result in much of the more soluble elements such as caesium being flushed out of the Irish Sea through the North Channel about a year after discharge. Measurements of technetium concentrations post-1994 has produced estimated transit times to the North Channel of around six months with peak concentrations off the northeast Irish coast occurring 18\u201324 months after peak discharge. Less soluble elements such as plutonium are subject to much slower redistribution. Whilst concentrations have declined in line with the reduction in discharges they are markedly higher in the eastern Irish Sea compared to the western areas. The dispersal of these elements is closely associated with sediment activity, with muddy deposits on the seabed acting as sinks, soaking up an estimated 200\u00a0kg (440\u00a0lb) of plutonium.[39] The highest concentration is found in the eastern Irish Sea in sediment banks lying parallel to the Cumbrian coast. This area acts as a significant source of wider contamination as radionuclides are dissolved once again. Studies have revealed that 80% of current seawater contamination by caesium is sourced from sediment banks, whilst plutonium levels in the western sediment banks between the Isle of Man and the Irish coast are being maintained by contamination redistributed from the eastern sediment banks.  The consumption of seafood harvested from the Irish Sea is the main pathway for exposure of humans to radioactivity.[40] The environmental monitoring report for the period 2003 to 2005 published by the Radiological Protection Institute of Ireland (RPII) reported that in 2005 average quantities of radioactive contamination found in seafood ranged from less than 1\u00a0Bq\/kg (12\u00a0pCi\/lb) for fish to under 44\u00a0Bq\/kg (540\u00a0pCi\/lb) for mussels.[41] Doses of man-made radioactivity received by the heaviest consumers of seafood in Ireland in 2005 was 1.10\u00a0\u03bcSv (0.000110\u00a0rem).[42] This compares with a corresponding dosage of radioactivity naturally occurring in the seafood consumed by this group of 148\u00a0\u03bcSv (0.0148\u00a0rem) and a total average dosage in Ireland from all sources of 3,620\u00a0\u03bcSv (0.362\u00a0rem).[43] In terms of risk to this group, heavy consumption of seafood generates a 1 in 18 million chance of causing cancer. The general risk of contracting cancer in Ireland is 1 in 522. In the UK, the heaviest seafood consumers in Cumbria received a radioactive dosage attributable to Sellafield discharges of 220\u00a0\u03bcSv (0.022\u00a0rem) in 2005.[44] This compares to average annual dose of naturally sourced radiation received in the UK of 2,230\u00a0\u03bcSv (0.223\u00a0rem).[45]  Discussions of linking Britain to Ireland began in 1895,[46] with an application for \u00a315,000 towards the cost of carrying out borings and soundings in the North Channel to see if a tunnel between Ireland and Scotland was viable. Sixty years later, Harford Montgomery Hyde, Unionist MP for North Belfast, called for the building of such a tunnel.[47] A tunnel project has been discussed several times in the Irish parliament.[48][49][50][51] The idea for a 34-kilometre (21\u00a0mi) long rail bridge or tunnel continues to be mooted. Several potential projects have been proposed, including one between Dublin and Holyhead put forward in 1997 by the British engineering firm Symonds. At 80\u00a0km (50\u00a0mi), it would have been by far the longest rail tunnel on earth with an estimated cost approaching \u00a320 billion.[52]  An offshore wind farm was developed on the Arklow Bank,[53] Arklow Bank Wind Park, about 10\u00a0km (6.2\u00a0mi) off the coast of County Wicklow in the south Irish Sea. The site currently has seven GE 3.6\u00a0MW turbines, each with 104-metre (341\u00a0ft) diameter rotors, the world's first commercial application of offshore wind turbines over three megawatts in size. The operating company, Airtricity, has indefinite plans for nearly 100 further turbines on the site.   Further wind turbine sites include: "},{"title":"Projectile","content":"A projectile is an object that is propelled by the application of an external force and then moves freely under the influence of gravity and air resistance.[1][2] Although any objects in motion through space are projectiles, they are commonly found in warfare and sports (for example, a thrown baseball, kicked football, fired bullet, shot arrow, stone released from catapult).[3][4]  In ballistics mathematical equations of motion are used to analyze projectile trajectories through launch, flight, and impact.  Blowguns and pneumatic rifles use compressed gases, while most other guns and cannons utilize expanding gases liberated by sudden chemical reactions by propellants like smokeless powder. Light-gas guns use a combination of these mechanisms.  Railguns utilize electromagnetic fields to provide a constant acceleration along the entire length of the device, greatly increasing the muzzle velocity.  Some projectiles provide propulsion during flight by means of a rocket engine or jet engine. In military terminology, a rocket is unguided, while a missile is guided. Note the two meanings of \"rocket\" (weapon and engine): an ICBM is a guided missile with a rocket engine.  An explosion, whether or not by a weapon, causes the debris to act as multiple high velocity projectiles. An explosive weapon or device may also be designed to produce many high velocity projectiles by the break-up of its casing; these are correctly termed fragments.  In projectile motion the most important force applied to the \u2018projectile\u2019 is the propelling force, in this case the propelling forces are the muscles that act upon the ball to make it move, and the stronger the force applied, the more propelling force, which means the projectile (the ball) will travel farther. See pitching, bowling.  Many projectiles, e.g. shells, may carry an explosive charge or another chemical or biological substance. Aside from explosive payload, a projectile can be designed to cause special damage, e.g. fire (see also early thermal weapons), or poisoning (see also arrow poison).  A kinetic energy weapon (also known as kinetic weapon, kinetic energy warhead, kinetic warhead, kinetic projectile, kinetic kill vehicle) is a projectile weapon based solely on a projectile's kinetic energy to inflict damage to a target, instead of using any explosive, incendiary\/thermal, chemical or radiological payload. All kinetic weapons work by attaining a high flight speed \u2014 generally supersonic or even up to hypervelocity \u2014 and collide with their targets, converting its kinetic energy and relative impulse into destructive shock waves, heat and cavitation. In kinetic weapons with unpowered flight, the muzzle velocity or launch velocity often determines the effective range and potential damage of the kinetic projectile.  Kinetic weapons are the oldest and most common ranged weapons used in human history, with the projectiles varying from blunt projectiles such as rocks and round shots, pointed missiles such as arrows\/bolts, dart and javelins, to modern tapered high-velocity impactors such as bullets, flechettes and penetrators. Typical kinetic weapons accelerate their projectiles mechanically (by muscle power, mechanical advantage devices, elastic energy or pneumatics) or chemically (by propellant combustion, as with firearms), but newer technologies are enabling the development of potential weapons using electromagnetically launched projectiles, such as railguns, coilguns and mass drivers. There are also concept weapons that are accelerated by gravity, as in the case of kinetic bombardment weapons designed for space warfare.   Some projectiles stay connected by a cable to the launch equipment after launching it:  An object projected at an angle to the horizontal has both the vertical and horizontal components of velocity. The vertical component of the velocity on the y-axis is given as      V  y   = U sin \u2061 \u03b8   {\\displaystyle V_{y}=U\\sin \\theta }   while the horizontal component of the velocity is      V  x   = U cos \u2061 \u03b8   {\\displaystyle V_{x}=U\\cos \\theta }  . There are various calculations for projectiles at a specific angle     \u03b8   {\\displaystyle \\theta }  :  1. Time to reach maximum height. It is symbolized as (    t   {\\displaystyle t}  ), which is the time taken for the projectile to reach the maximum height from the plane of projection. Mathematically, it is given as     t = U sin \u2061 \u03b8  \/  g   {\\displaystyle t=U\\sin \\theta \/g}   where     g   {\\displaystyle g}   = acceleration due to gravity (app 9.81\u00a0m\/s\u00b2),     U   {\\displaystyle U}   = initial velocity (m\/s) and     \u03b8   {\\displaystyle \\theta }   = angle made by the projectile with the horizontal axis.  2. Time of flight (    T   {\\displaystyle T}  ): this is the total time taken for the projectile to fall back to the same plane from which it was projected. Mathematically it is given as     T = 2 U sin \u2061 \u03b8  \/  g   {\\displaystyle T=2U\\sin \\theta \/g}  .  3. Maximum Height (    H   {\\displaystyle H}  ): this is the maximum height attained by the projectile OR the maximum displacement on the vertical axis (y-axis) covered by the projectile. It is given as     H =  U  2    sin  2   \u2061 \u03b8  \/  2 g   {\\displaystyle H=U^{2}\\sin ^{2}\\theta \/2g}  .  4. Range (    R   {\\displaystyle R}  ): The Range of a projectile is the horizontal distance covered (on the x-axis) by the projectile. Mathematically,     R =  U  2   sin \u2061 2 \u03b8  \/  g   {\\displaystyle R=U^{2}\\sin 2\\theta \/g}  . The Range is maximum when angle     \u03b8   {\\displaystyle \\theta }   = 45\u00b0, i.e.     sin \u2061 2 \u03b8 = 1   {\\displaystyle \\sin 2\\theta =1}  . "},{"title":"Safety glass","content":"Safety glass is glass with additional safety features that make it less likely to break, or less likely to pose a threat when broken. Common designs include toughened glass (also known as tempered glass), laminated glass, and wire mesh glass (also known as wired glass). Toughened glass was invented in 1874 by Francois Barthelemy Alfred Royer de la Bastie.[1] Wire mesh glass was invented in 1892 by Frank Shuman.[2][3] Laminated glass was invented in 1903 by the French chemist \u00c9douard B\u00e9n\u00e9dictus (1878\u20131930).[4]  These three approaches can easily be combined, allowing for the creation of glass that is at the same time toughened, laminated, and contains a wire mesh. However, combination of a wire mesh with other techniques is unusual, as it typically betrays their individual qualities. In many developed countries[which?] safety glass is part of the building regulations making properties safer.[5]  Toughened glass is processed by controlled thermal or chemical treatments to increase its strength compared with normal glass.[6] Tempering, by design, creates balanced internal stresses which causes the glass sheet, when broken, to crumble into small granular chunks of similar size and shape instead of splintering into random, jagged shards. The granular chunks are less likely to cause injury.  As a result of its safety and strength, tempered glass is used in a variety of demanding applications, including passenger vehicle windows, shower doors, architectural glass doors and tables, refrigerator trays, as a component of bulletproof glass, for diving masks, and various types of plates and cookware. In the United States, since 1977 Federal law has required safety glass located within doors and tub and shower enclosures.[7]  Laminated glass is composed of layers of glass and plastic held together by an interlayer.[8] When laminated glass is broken, it is held in place by an interlayer, typically of polyvinyl butyral (PVB), between its two or more layers of glass, which crumble into small pieces. The interlayer keeps the layers of glass bonded even when broken, and its toughening prevents the glass from breaking up into large sharp pieces.[9] This produces a characteristic \"spider web\" cracking pattern (radial and concentric cracks) when the impact is not enough to completely pierce the glass.[10]  Laminated glass is normally used when there is a possibility of human impact or where the glass could fall if shattered. Skylight glazing and automobile windshields typically use laminated glass. In geographical areas requiring hurricane-resistant construction, laminated glass is often used in exterior storefronts, curtain walls and windows. The PVB interlayer also gives the glass a much higher sound insulation rating, due to the damping effect, and also blocks most of the incoming UV radiation (88% in window glass and 97.4% in windscreen glass).[11]    Wire mesh glass (also known as Georgian Wired Glass) has a grid or mesh of thin metal wire embedded within the glass. Wired glass is used in the US for its fire-resistant abilities, and is well-rated to withstand both heat and hose streams.  This is why wired glass exclusively is used on service elevators to prevent fire ingress to the shaft, and also why it is commonly found in institutional settings which are often well-protected and partitioned against fire.[12][failed verification]  The wire prevents the glass from falling out of the frame even if it cracks under thermal stress, and is far more heat-resistant than a laminating material.  Wired glass, as it is typically described, does not perform the function most individuals associate with it. The presence of the wire mesh appears to be a strengthening component, as it is metallic, and conjures up the idea of rebar in reinforced concrete or other such examples. Despite this belief, wired glass is actually weaker than unwired glass due to the incursions of the wire into the  structure of the glass. Wired glass often may cause heightened injury in comparison to unwired glass, as the wire amplifies the irregularity of any fractures. This has led to a decline in its use institutionally, particularly in schools.[13]  In recent years, new materials have become available that offer both fire-ratings and safety ratings so the continued use of wired glass is being debated worldwide. The US International Building Code effectively banned wired glass in 2006.[14]  Canada's building codes still permit the use of wired glass but the codes are being reviewed and traditional wired glass is expected to be greatly restricted in its use.[15] Australia has no similar review taking place.[16] "},{"title":"Great Depression in Canada","content":"The worldwide Great Depression of the early 1930s was a social and economic shock that left millions of Canadians unemployed, hungry and often homeless. Few countries were affected as severely as Canada during what became known as the \"Dirty Thirties\", due to Canada's heavy dependence on raw material and farm exports, combined with a crippling Prairies drought known as the Dust Bowl. Widespread losses of jobs and savings ultimately transformed the country by triggering the birth of social welfare, a variety of populist political movements, and a more activist role for government in the economy.  In 1930-1931 the Canadian government responded to the Great Depression by applying severe restrictions to entry into Canada. New rules limited immigration to British and American subjects or agriculturalists with money, certain classes of workers, and immediate family of the Canadian residents. A large number of unemployed immigrants were also deported.[1]  By 1930, 30% of the labour force was out of work, and one fifth of the population became dependent on government assistance. Wages fell, as did prices. Gross National Expenditure had declined 42% from the 1929 levels. In some areas, the decline was far worse. In the rural areas of the prairies, two thirds of the population were on relief.  Further damage was the reduction of investment: both large companies and individuals were unwilling and unable to invest in new ventures.  In 1932, industrial production was only at 58% of the 1929 level, the second lowest level in the world after the United States, and well behind nations such as Britain, which only saw it fall to 83% of the 1929 level. Total national income fell to 55% of the 1929 level, again worse than any nation other than the U.S.[2]  Canada's economy at the time was just starting to shift from primary industry (farming, fishing, mining and logging) to manufacturing. Exports of raw materials plunged, and employment, prices and profits fell in every sector. Canada was the worst-hit  because of its economic position. It was further affected as its main trading partners were Britain and the U.S., both of which were badly affected by the worldwide depression.[2]  One of the areas not affected was bush flying, which, thanks to a mining and exploration boom, continued to thrive throughout this period.[3] Even so, most bush flying companies lost money, impacted by the government's cancellation of airmail contracts in 1931-2.[4]  Urban unemployment nationwide was 19%; Toronto's rate was 17%, according to the census of 1931. Farmers who stayed on their farms were not considered unemployed.[5] By 1933, 30% of the labour force was out of work, and one-fifth of the population became dependent on government assistance. Wages fell as did prices. In some areas, such as mining and lumbering areas, the decline was far worse.  The Prairie Provinces and Western Canada were the hardest-hit. In the rural areas of the prairies, two thirds of the population were on relief. The region fully recovered after 1939. The fall of wheat prices drove many farmers to the towns and cities, such as Calgary, Alberta; Regina, Saskatchewan; and Brandon, Manitoba. Population in the prairie provinces fell below natural replacement level. There was also migration from the southern prairies affected by Dust Bowl conditions such as the Palliser's Triangle to aspen parkland in the north.[6]  During the depression, there was a rise of working class militancy organized by the Communist Party. The labour unions largely retreated in response to the ravages of the depression at the same time that significant portions of the working class, including the unemployed, clamoured for collective action.  Numerous strikes and protests were led by the Communists, many of which culminated in violent clashes with the police. Some notable ones include a coal miners strike that resulted in the Estevan Riot in Estevan, Saskatchewan that left three strikers dead by RCMP bullets in 1931, a waterfront strike in Vancouver that culminated with the \"Battle of Ballantyne Pier\" in 1935, and numerous unemployed demonstrations up to and including the On-to-Ottawa Trek that left one Regina police constable and one protester dead in the \"Regina Riot\". Although the actual number of Communist Party militants remained small, their impact was far disproportionate to their numbers, in large part because of the anticommunist reaction of the government, especially the policies of Prime Minister R. B. Bennett who vowed to crush Communism in Canada with an \"iron heel of ruthlessness\".[7]  These conflicts diminished after 1935, when the Communist Party shifted strategies and Bennett's Conservatives were defeated. Agitation and unrest nonetheless persisted throughout the depression, marked by periodic clashes, such as a sit-down strike in Vancouver that ended with \"Bloody Sunday\". These developments had far-reaching consequences in shaping the postwar environment, including the domestic cold war climate, the rise of the welfare state, and the implementation of an institutional framework for industrial relations.  Women's primary role were as housewives; without a steady flow of family income, their work became much harder in dealing with food and clothing and medical care. The birthrates fell everywhere, as children were postponed until families could financially support them. The average birthrate for 14 major countries fell 12% from 19.3 births per thousand population in 1930, to 17.0 in 1935.[8] In Canada, half of Roman Catholic women defied Church teachings and used contraception to postpone births.[9]  Among the few women in the labor force, layoffs were less common in the white-collar jobs and they were typically found in light manufacturing work. However, there was a widespread demand to limit families to one paid job, so that wives might lose employment if their husband was employed.[10][11][12]  Housewives updated strategies their mothers used when they were growing up in poor families. Cheap foods were used, such as soups, beans and noodles. They purchased the cheapest cuts of meat\u2014sometimes even horse meat\u2014and recycled the Sunday roast into sandwiches and soups. They sewed and patched clothing, traded with their neighbors for outgrown items, and made do with colder homes. New furniture and appliances were postponed until better days. These strategies show that women's domestic labor\u2014cooking, cleaning, budgeting, shopping, childcare\u2014was essential to the economic maintenance of the family and offered room for economies. Many women also worked outside the home, or took boarders, did laundry for trade or cash, and did sewing for neighbors in exchange for something they could offer. Extended families used mutual aid\u2014extra food, spare rooms, repair-work, cash loans\u2014to help cousins and in-laws.[13][14]  Women held 25-30% of the jobs in the cities.[15] Few women were employed in heavy industry, railways or construction. Many were household workers or were employed in restaurants and family-owned shops. Women factory workers typically handled clothing and food. Educated women had a narrow range of jobs, such as clerical work and teaching.  It was expected that a woman give up a good job when she married.[16]  Srigley emphasizes the wide range of background factors and family circumstances, arguing that gender itself was typically less important than race, ethnicity, or class.[17]  School budgets were cut a lot across the country, although enrollments went up and up because dropouts could not find jobs. To save money the districts consolidated nearby schools, dropped staff lines, postponed new construction, and increased class size. Middle-class well-educated teachers were squeezed by the financial crisis facing their employers. In Ontario, new teachers were not hired so the average age and experience increased. However, their salaries fell and men who otherwise would have taken higher status business jobs increasingly competed against women. Married women were not hired on the grounds it was unfair for one family to have two scarce jobs that breadwinners needed. Women teachers, who had made major gains in the 1910-20 era, saw themselves discriminated against.[18] The teacher's unions were practically helpless in the crisis, even in Ontario where they were strongest.[19] After prosperity returned in the 1940s, however, money was available again, there was a shortage of teachers, and the unions proved more effective. For example, in Quebec, the Corporation G\u00e9n\u00e9ral des Instituteurs et des Institutrices Catholics (CIC) was founded in 1946 (it became the Centrale de l'Enseignement du Qu\u00e9bec (CEQ) in 1967). It sought higher pensions and salaries and better working conditions, while insisting the teachers were full-fledged professionals.[20]  In remote rural areas professionalization was uncommon; local school boards tightly controlled the one-room schools, typically hiring local women with a high school education or a year at university as teachers, so their meagre salaries would remain in the community.[21]  Case studies of four Canadian textile firms\u2014two cotton and two hosiery and knitting\u2014demonstrate the range  business response to the economic crisis. Each faced a different array of conditions, and each devised the appropriate restructuring strategies. The large corporations responded by investing in more expensive machinery and automation, hiring less skilled workers  to tend the automated equipment, and tweaking their product lines to changing consumer tastes. However the smaller hosiery and knitting firms lacked the capital to invest or the research needed to monitor consumer tastes. They used time-tested \"Taylorized\" scientific management or made piecemeal changes. Power shifted upward to management, as strikes were too risky in the early 1930s and the opportunity to find a better job had drastically narrowed.[22] By 1935, however, the influence of militant American unions spilled over the border and Canadian unions became more forceful and harmonious. The activity was most notable in Ontario's automobile factories, beginning in Windsor in late 1936, where the new Automobile Workers of America (UAW) chartered its first Canadian local at the Kelsey-Hayes factory.[23]  The Stock Market crash in New York led people to hoard their money; as consumption fell, the American economy steadily contracted, 1929-32. Given the close economic links between the two countries, the collapse quickly affected Canada. Added to the woes of the prairies were those of Ontario and Quebec, whose manufacturing industries were now victims of overproduction. Massive lay-offs occurred and other companies collapsed into bankruptcy. This collapse was not as sharp as that in the United States, but was the second sharpest collapse in the world.  Canada did have some advantages over other countries, especially its extremely stable banking system that had no failures during the entire depression, compared to over 9,000 small banks that collapsed in the United States.  Canada was hurt badly because of its reliance on base commodities, whose prices fell by over 50%, and because of the importance of international trade.  In the 1920s about 25% of the Canadian Gross National Product was derived from exports. The first reaction of the U.S. was to raise tariffs via the Smoot-Hawley Tariff Act, passed into law June 17, 1930. This hurt the Canadian economy more than most other countries in the world, and Canada retaliated by raising its own rates on American exports and by switching business to the Empire.[24]  In an angry response to Smoot\u2013Hawley, Canada welcomed the British introduction of trade protectionism and a system of Commonwealth preference during the winter of 1931-32. It helped Canada avoid external default on their public debt during the Great Depression. Canada had a high degree of exposure to the international economy, which left Canada susceptible to any international economic downturn. The onset of the depression created critical balance of payment deficits, and it was largely the extension of imperial protection by Britain that gave Canada the opportunity to increase their exports to the British market. By 1938 Britain was importing more than twice the 1929 volume of products from Australia, while the value of products shipped from Canada more than doubled, despite the dramatic drop in prices. Thus, the British market played a vital role in helping Canada and Australia stabilize their balance of payments in the immensely difficult economic conditions of the 1930s.[25]  At the Depression, the provincial and municipal governments were already in debt after an expansion of infrastructure and education during the 1920s. It thus fell to the federal government to try to improve the economy. When the Depression began Mackenzie King was Prime Minister. He believed that the crisis would pass, refused to provide federal aid to the provinces, and only introduced moderate relief efforts. The government's reaction to The Great Depression is the focus of the 2013 documentary Catch The Westbound Train from Prairie Coast Films.  The Bennett Government, which defeated Mackenzie King in the 1930 election, initially refused to offer large-scale aid or relief to the provinces, much to the anger of provincial premiers, but it eventually gave in and started a Canadian \"New Deal\" type of relief by 1935. By 1937, the worst of the Depression had passed, but it left its mark on the country's economic landscape. Atlantic Canada was especially hard hit. Newfoundland (an independent dominion at the time) was bankrupt economically and politically and gave up responsible government by reverting to direct British control.  First World War veterans built on a history of postwar political activism to play an important role in the expansion of state-sponsored social welfare in Canada. Arguing that their wartime sacrifices had not been properly rewarded, veterans claimed that they were entitled to state protection from poverty and unemployment on the home front. The rhetoric of patriotism, courage, sacrifice, and duty created powerful demands for jobs, relief, and adequate pensions that should, veterans argued, be administered as a right of social citizenship and not a form of charity. At the local, provincial, and national political levels, veterans fought for compensation and recognition for their war service, and made their demands for jobs and social security a central part of emerging social policy.[26]  The Liberal Party lost the 1930 election to the Conservative Party, led by R.B. Bennett. Bennett, a successful western businessman, campaigned on high tariffs and large-scale spending. Make-work programs were begun, and welfare and other assistance programs became vastly larger. This led to a large federal deficit, however. Bennett became wary of the budget shortfalls by 1932, and cut back severely on federal spending. This only deepened the depression as government employees were put out of work and public works projects were cancelled.  One of the greatest burdens on the government was the Canadian National Railway (CNR). The federal government had taken over a number of defunct and bankrupt railways during the First World War and the 1920s. The debt the government assumed was over $2 billion, a massive sum at the time, but during the boom years it seemed payable. The Depression turned this debt into a crushing burden. Due to the decrease in trade, the CNR also began to lose substantial amounts of money during the Depression, and had to be further bailed out by the government.  With falling support and the depression only getting worse, Bennett attempted to introduce policies based on the New Deal of Franklin Delano Roosevelt in the United States. Bennett thus called for a minimum wage, unemployment insurance, and other such programs. This effort was largely unsuccessful; the provinces challenged the rights of the federal government to manage these programs. Some of the federal efforts were successful: the Companies' Creditors Arrangement Act and Farmers' Creditors Arrangement Act, which provided alternatives to bankruptcy for distressed businesses, were held to be constitutional by the Reference Re Farmers' Creditors Arrangement Act.  The judicial and political failure of Bennett's New Deal legislation shifted the struggle to reconstitute capitalism to the provincial and municipal levels of the state. Attempts to deal with the dislocations of the Great Depression in Ontario focused on the \"sweatshop crisis\" that came to dominate political and social discourse after 1934. Ontario's 1935 Industrial Standards Act (ISA) was designed to bring workers and employers together under the auspices of the state to establish minimum wages and work standards. The establishment of New Deal style industrial codes was premised on the mobilization of organized capital and organized labour to combat unfair competition, stop the spread of relief-subsidized labour, and halt the predations of sweatshop capitalism. Although the ISA did not bring about extensive economic regulation, it excited considerable interest in the possibility of government intervention. Workers in a diverse range of occupations, from asbestos workers to waitresses, attempted to organize around the possibility of the ISA. The importance of the ISA lies in what it reveals about the nature of welfare, wage labour, the union movement, competitive capitalism, business attitudes toward industrial regulation, and the role of the state in managing the collective affairs of capitalism. The history of the ISA also suggests that \"regulatory unionism\", as described by Colin Gordon in his work on the American New Deal, may have animated key developments in Canadian social, economic, and labour history.[27]  The failure to help the economy led to the federal Conservatives' defeat in the 1935 election when the Liberals, still led by Mackenzie King, returned to power.  The public at large lost faith in both the Liberal Party of Canada and the Conservative Party of Canada. This caused the rise of a third party: the Cooperative Commonwealth Federation (a socialist party that achieved some success before joining the Canadian Labour Congress in 1961, becoming the New Democratic Party).  With the worst of the Depression over, the government implemented some relief programs such as the National Housing Act and National Employment Commission, and it established Trans-Canada Airlines (1937, the predecessor to Air Canada). However, it took until 1939 and the outbreak of war for the Canadian economy to return to 1929 levels.  After 1936 the prime minister lost patience when westerners preferred radical alternatives such as the CCF (Co-operative Commonwealth Federation) and Social Credit to his middle-of-the-road liberalism. Indeed, he came close to writing off the region with his comment that the prairie dust bowl was \"part of the U.S. desert area. I doubt if it will be of any real use again.\"[28]  Instead he paid more attention to the industrial regions and the needs of Ontario and Quebec regarding the proposed St. Lawrence Seaway project with the United States.  As for the unemployed, he was hostile to federal relief and reluctantly accepted a Keynesian solution that involved federal deficit spending, tax cuts and subsidies to the housing market.[29]  Mackenzie King returned as prime minister, serving until his retirement in 1948. During all but the last two years he was also secretary of state for external affairs, taking personal charge of foreign policy.  Social Credit (often called SoCred) was a populist political movement strongest in Alberta and neighbouring British Columbia, 1930s-1970s.  Social Credit was based on the economic theories of an Englishman, C. H. Douglas. His theories became very popular across the nation in the early 1930s. A central proposal was the free distribution of dividends (or social credit), called \"funny money\" by the opposition.[30]  During the Great Depression in Canada the demand for radical action peaked around 1934, after the worst period was over and the economy was recovering. Mortgage debt was significant because farmers could not meet their interest payments. The insecurity of farmers, whose debts were increasing and who had no legal protection against foreclosure, was a potent factor in creating a mood of political desperation. The radical farmers party, UFA was baffled by the depression and Albertans demanded new leadership.  Prairie farmers had always believed that they were being exploited by Toronto and Montreal.  What they lacked was a prophet who would lead them to the promised land.[31] The Social Credit movement began in Alberta in 1932; it became a political movement in 1935 and suddenly burned like a prairie fire.[further explanation needed]  The prophet and new premier was radio evangelist William Aberhart (1878\u20131943). The message was biblical prophecy.  Aberhart was a fundamentalist, preaching the revealed word of God and quoting the Bible to find a solution for the evils of the modern, materialistic world: the evils of sophisticated academics and their biblical criticism, the cold formality of middle-class congregations, the vices of dancing and movies and drink. \"Bible Bill\" preached that the capitalist economy was rotten because of its immorality; specifically it produced goods and services but did not provide people with sufficient purchasing power to enjoy them. This could be remedied by the giving out money in the form of \"social credit\", or $25 a month for every man and woman.  This pump priming was guaranteed to restore prosperity, he prophesied to the 1600 Social Credit clubs he formed in the province.  Alberta's businessmen, professionals, newspaper editors and the traditional middle-class leaders vehemently protested Aberhart's crack-pot ideas, but they had not solved any problems and spoke not of the promised land ahead.  Aberhart's new party in 1935 elected 56 members to the Alberta Assembly, compared to 7 for all the other parties.[32]  Alberta's Social Credit Party remained in power for 36 years until 1971. It was re-elected by popular vote no less than 9 times, achieving success by moving from left to the right.[33]  Once in office in Alberta, Aberhart gave a high priority to balancing the provincial budget. He reduced expenditures and increased the sales tax and the income tax.  The poor and unemployed got nothing.[34] The $25 monthly social dividend never arrived, as Aberhart decided nothing could be done until the province's financial system was changed, and 1936 Alberta defaulted on its bonds.  He did pass a Debt Adjustment Act that cancelled all the interest on mortgages since 1932 and limited all interest rates on mortgages to 5%, in line with similar laws passed by other provinces. In 1937 backbenchers passed a radical banking law that was disallowed by the national government (banking was a federal responsibility). Efforts to control the press were also disallowed.  The party was authoritarian and tried to exert detailed control over its officeholders; those who rebelled were purged or removed from office by the new device of recall elections.  Although Aberhart was hostile to banks and newspapers, he was basically in favour of capitalism and did not support socialist policies as did the Cooperative Commonwealth Federation (CCF) in Saskatchewan.[35]  By 1938 the Social Credit government abandoned its notions about the $25 payouts, but its inability to break with UFA policies led to disillusionment and heavy defections from the party. Aberhart's government was re-elected in the 1940 election, carrying 43% of the vote. The prosperity of the Second World War relieved the economic fears and hatreds that had fuelled farmer unrest. Aberhart died in 1943, and was succeeded as Premier by his student at the Prophetic Bible Institute and lifelong close disciple, Ernest C. Manning (1908\u20131996).  The Social Credit party, now firmly on the right, governed Alberta until 1968 under Manning.  The Canadian recovery from the Great Depression proceeded slowly. Economists Pedro Amaral and James MacGee find that the Canadian recovery has important differences with the United States.[36]  In the U.S. productivity recovered quickly while the labour force remained depressed throughout the decade.  In Canada employment quickly recovered but productivity remained well below trend.  Amaral and MacGee suggest that this decline is due to the sustained reduction in international trade during the 1930s.  In the midst of the Great Depression, the Crown-in-Council attempted to uplift the people, and created two national corporations: the Canadian Radio Broadcasting Commission (CRBC), and the Bank of Canada. The former, established in 1932, was seen as a means to keep the country unified and uplifted in these harsh economic times. Many poor citizens found radio as an escape and used it to restore their own faiths in a brighter future. Broadcasting coast to coast mainly in English, with some French, primarily in Quebec, the CRBC played a vital role in keeping the morale up for Canadians everywhere. The latter was used to regulate currency and credit which had been horribly managed amongst Canadian citizens in the prior years. It was also set up to serve as a private banker\u2019s bank and to assist and advise the Canadian government on its own debts and financial matters. The bank played an important role to help steer government spending in the right direction. The bank's effort took place through the tough years of the depression and on to the prosperity that followed into and after the Second World War.  Both of these corporations were seen as positive moves by the Canadian government to help get the economy back on track. 1937 was an important year in the recovery from the Great Depression. The Bank of Canada was nationalized in that year, and the Canadian Radio Broadcasting Commission (CRBC) became the Canadian Broadcasting Corporation (CBC) in that same year. Both corporations were successful aids in the cultural and financial recovery of the Canadian economy during the Great depression.  It took the outbreak of World War II to pull Canada out of the depression. From 1939, an increased demand in Europe for materials, and increased spending by the Canadian government created a strong boost for the economy. Unemployed men enlisted in the military. By 1939, Canada was in the first prosperity period in the business cycle in a decade. This coincided with the recovery in the American economy, which created a better market for exports and a new inflow of much needed capital. "},{"title":"National Basketball Association","content":"  The National Basketball Association (NBA) is a professional basketball league in North America composed of 30 teams (29 in the United States and 1 in Canada). It is one of the major professional sports leagues in the United States and Canada and is considered the premier professional basketball league in the world.[3]  The league was founded in New York City on June 6, 1946, as the Basketball Association of America (BAA).[1] It changed its name to the National Basketball Association on August 3, 1949, after merging with the competing National Basketball League (NBL).[4] In 1976, the NBA and the American Basketball Association (ABA) merged, adding four franchises to the NBA. The NBA's regular season runs from October to April, with each team playing 82 games. The league's playoff tournament extends into June, culminating with the NBA Finals championship series. As of 2020[update], NBA players are the world's best paid athletes by average annual salary per player.[5][6][7]  The NBA is an active member of USA Basketball (USAB),[8] which is recognized by the FIBA (International Basketball Federation) as the national governing body for basketball in the United States. The league's several international as well as individual team offices are directed out of its head offices in Midtown Manhattan, while its NBA Entertainment and NBA TV studios are directed out of offices located in Secaucus, New Jersey. In North America, the NBA is the third wealthiest professional sport league after the National Football League (NFL) and Major League Baseball (MLB) by revenue, and among the top four in the world.[9]  The Boston Celtics and the Los Angeles Lakers are tied for the most NBA championships with 17 each. The reigning league champions are the Denver Nuggets, who defeated the Miami Heat in the 2023 NBA Finals.  The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada. On November 1, 1946, in Toronto, Ontario, Canada, the Toronto Huskies hosted the New York Knickerbockers at Maple Leaf Gardens, in a game the NBA now refers to as the first game played in NBA history.[10] The first basket was made by Ossie Schectman of the Knickerbockers. Although there had been earlier attempts at professional basketball leagues, including the American Basketball League (ABL) and the NBL, the BAA was the first league to attempt to play primarily in large arenas in major cities. During its early years, the quality of play in the BAA was not significantly better than in competing leagues or among leading independent clubs such as the Harlem Globetrotters. For instance, the 1948 ABL finalist Baltimore Bullets moved to the BAA and won that league's 1948 title, and the 1948 NBL champion Minneapolis Lakers won the 1949 BAA title. Prior to the 1948\u201349 season, however, NBL teams from Fort Wayne, Indianapolis, Minneapolis, and Rochester jumped to the BAA, which established the BAA as the league of choice for collegians looking to turn professional.[11]  On August 3, 1949, the remaining NBL teams (Syracuse, Anderson, Tri-Cities, Sheboygan, Denver, and Waterloo) merged into the BAA. In deference to the merger and to avoid possible legal complications, the league name was changed to the present National Basketball Association, even though the merged league retained the BAA's governing body, including Maurice Podoloff as president.[11] To this day, the NBA claims the BAA's history as its own. It now reckons the arrival of the NBL teams as an expansion, not a merger, and does not recognize NBL records and statistics.[12]  The new league had seventeen franchises located in a mix of large and small cities,[13] as well as large arenas and smaller gymnasiums and armories. In 1950, the NBA consolidated to eleven franchises, a process that continued until 1954\u201355, when the league reached its smallest size of eight franchises: the New York Knicks, Boston Celtics, Philadelphia Warriors, Minneapolis Lakers, Rochester Royals, Fort Wayne Pistons, Milwaukee Hawks, and Syracuse Nationals, all of which remain in the league today, although the latter six all did eventually relocate. The process of contraction saw the league's smaller-city franchises move to larger cities. The Hawks had shifted from the Tri-Cities to Milwaukee in 1951, and later shifted to St. Louis in 1955. In 1957, the Rochester Royals moved from Rochester, New York, to Cincinnati and the Pistons moved from Fort Wayne, Indiana, to Detroit.[14]  Japanese-American Wataru Misaka broke the NBA color barrier in the 1947\u201348 season when he played for the New York Knicks. He remained the only non-white player in league history prior to the first African-American, Harold Hunter, signing with the Washington Capitols in 1950.[15][16] Hunter was cut from the team during training camp,[15][17] but several African-American players did play in the league later that year, including Chuck Cooper with the Celtics, Nathaniel \"Sweetwater\" Clifton with the Knicks, and Earl Lloyd with the Washington Capitols. During this period, the Minneapolis Lakers, led by center George Mikan, won five NBA Championships and established themselves as the league's first dynasty.[18] To encourage shooting and discourage stalling, the league introduced the 24-second shot clock in 1954.[19]  In 1957, rookie center Bill Russell joined the Boston Celtics, which already featured guard Bob Cousy and coach Red Auerbach, and went on to lead the franchise to eleven NBA titles in thirteen seasons. Center Wilt Chamberlain entered the league with the Warriors in 1959 and became a dominant individual star of the 1960s, setting new single-game records in scoring (100) and rebounding (55). Russell's rivalry with Chamberlain became one of the greatest rivalries in the history of American team sports.[20]  The 1960s were dominated by the Celtics. Led by Russell, Cousy, and Auerbach, Boston won eight straight championships in the NBA from 1959 to 1966. This championship streak is the longest in the history of American professional sports.[21] They did not win the title in 1966\u201367, but regained it in the 1967\u201368 season and repeated in 1969. The domination totaled nine of the ten championship banners of the 1960s.[22]  Through this period, the NBA continued to evolve with the shift of the Minneapolis Lakers to Los Angeles, the Philadelphia Warriors to San Francisco, the Syracuse Nationals to Philadelphia to become the Philadelphia 76ers, and the St. Louis Hawks moving to Atlanta, as well as the addition of its first expansion franchises. The Chicago Packers (now Washington Wizards) became the ninth NBA team in 1961. From 1966 to 1968, the league expanded from 9 to 14 teams, introducing the Chicago Bulls, Seattle SuperSonics (now Oklahoma City Thunder), San Diego Rockets (who moved to Houston four years later), Milwaukee Bucks, and Phoenix Suns.  In 1967, the league faced a new external threat with the formation of the American Basketball Association (ABA). The leagues engaged in a bidding war.[23][24] The NBA landed the most important college star of the era, Kareem Abdul-Jabbar (then known as Lew Alcindor). However, the NBA's leading scorer, Rick Barry, jumped to the ABA, as did four veteran referees\u2014Norm Drucker, Earl Strom, John Vanak, and Joe Gushue.[25]  In 1969, Alan Siegel, who oversaw the design of Jerry Dior's Major League Baseball logo a year prior, created the modern NBA logo inspired by the MLB's. It incorporates the silhouette of Jerry West, based on a photo by Wen Roberts. The NBA would not confirm that a particular player was used because, according to Siegel, \"They want to institutionalize it rather than individualize it. It's become such a ubiquitous, classic symbol and focal point of their identity and their licensing program that they don't necessarily want to identify it with one player.\" The logo debuted in 1971 (with a small change to the typeface on the NBA wordmark in 2017) and would remain a fixture of the NBA brand.[26]  The ABA succeeded in signing a number of major stars in the 1970s, including Julius Erving of the Virginia Squires, in part because it allowed teams to sign college undergraduates. The NBA expanded rapidly during this period. From 1966 to 1974, the NBA grew from nine franchises to 18.[23] In 1970, the Portland Trail Blazers, Cleveland Cavaliers, and Buffalo Braves (now the Los Angeles Clippers) all made their debuts expanding the league to 17.[27] The New Orleans Jazz (now in Utah) came aboard in 1974 bringing the total to 18. Following the 1976 season, the leagues reached a settlement that provided for the addition of four ABA franchises to the NBA, raising the number of franchises in the league at that time to 22. The franchises added were the San Antonio Spurs, Denver Nuggets, Indiana Pacers, and New York Nets (now the Brooklyn Nets). Some of the biggest stars of this era were Abdul-Jabbar, Barry, Dave Cowens, Erving, Elvin Hayes, Walt Frazier, Moses Malone, Artis Gilmore, George Gervin, Dan Issel, and Pete Maravich. The end of the decade, however, saw declining TV ratings, low attendance and drug-related player issues \u2013 both perceived and real \u2013 that threatened to derail the league.[28]  The league added the ABA's three-point field goal beginning in 1979.[29] That same year, rookies Larry Bird and Magic Johnson joined the Boston Celtics and Los Angeles Lakers respectively, initiating a period of significant growth of fan interest in the NBA.[30] The two had faced each other in the 1979 NCAA Division I Basketball Championship Game, and they later played against each other in three NBA Finals (1984, 1985, and 1987).[30] In the 10 seasons of the 1980s, Johnson led the Lakers to five titles[31] while Bird led the Celtics to three titles.[32] Also in the early 1980s, the NBA added one more expansion franchise, the Dallas Mavericks,[33] bringing the total to 23 teams. Later on, Larry Bird won the first three three-point shooting contests.[34] On February 1, 1984 David Stern became commissioner of the NBA.[35] Stern has been recognized as playing a major role in the growth of the league during his career.[36][37]  Michael Jordan entered the league in 1984 with the Chicago Bulls, spurring more interest in the league.[38] In 1988 and 1989, four cities got their wishes as the Charlotte Hornets, Miami Heat, Orlando Magic, and Minnesota Timberwolves made their NBA debuts, bringing the total to 27 teams.[39] The Detroit Pistons won the back-to-back NBA Championships in 1989 and 1990, led by coach Chuck Daly and guard Isiah Thomas.[40] Jordan and Scottie Pippen led the Bulls to two three-peats in eight years during the 1991\u20131998 seasons.[41][42] Hakeem Olajuwon won back-to-back titles with the Houston Rockets in 1994 and 1995.[43]  The 1992 Olympic basketball Dream Team, the first to use current NBA stars, featured Michael Jordan as the anchor, along with Bird, Johnson, David Robinson, Patrick Ewing, Scottie Pippen, Clyde Drexler, Karl Malone, John Stockton, Chris Mullin, Charles Barkley, and star NCAA amateur Christian Laettner.[44] The team was elected to the Naismith Memorial Basketball Hall of Fame, while 11 of the 12 players (along with three out of four coaches) have been inducted as individuals in their own right.[45]  In 1995, the NBA expanded to Canada with the addition of the Vancouver Grizzlies and the Toronto Raptors.[46][47] In 1996, the NBA created a women's league, the Women's National Basketball Association (WNBA).[48]  In 1998, the NBA owners began a lockout that suspended all league business until a new labor agreement could be reached, which led to the season being shortened in half.[49][50] The San Antonio Spurs won the championship at the end of the 1998\u201399 season, becoming the first former ABA team to win the NBA championship.[51]  After the breakup of the Chicago Bulls championship roster in the summer of 1998, the Western Conference dominated much of the next two decades. The Los Angeles Lakers, coached by Phil Jackson, and the San Antonio Spurs, coached by Gregg Popovich, combined to make 13 Finals in 16 seasons, with 10 titles. Tim Duncan and David Robinson won the 1999 championship with the Spurs, and Shaquille O'Neal and Kobe Bryant started the 2000s with three consecutive championships for the Lakers. The Spurs reclaimed the title in 2003 against the Nets. In 2004, the Lakers returned to the Finals, only to lose in five games to the Detroit Pistons.  The league's image was marred by a violent incident between players and fans in a November 2004 game between the Indiana Pacers and Detroit Pistons.[52] In response, players were suspended for a total of 146 games with $11\u00a0million total lost in salary, and the league tightened security and limited the sale of alcohol.[52]  On May 19, 2005, Commissioner Stern testified before the U.S. House of Representatives' Committee on Government Reform about the NBA's actions to combat the use of steroids and other performance-enhancing drugs. The NBA started its drug-testing program in 1983 and substantially improved it in 1999. In the 1999\u20132000 season, all players were randomly tested during training camp, and all rookies were additionally tested three more times during the regular season. Of the nearly 4,200 tests for steroids and performance-enhancing drugs conducted over six seasons, only three players were confirmed positive for NBA's drug program, all were immediately suspended, and as of the time of the testimony, none were playing in the NBA.[53]  After the Spurs won the championship again in 2005, the 2006 Finals featured two franchises making their inaugural Finals appearances. The Miami Heat, led by their star shooting guard, Dwyane Wade, and Shaquille O'Neal, who had been traded from the Lakers during summer 2004, won the series over the Dallas Mavericks. The Lakers\/Spurs dominance continued in 2007 with a four-game sweep by the Spurs over the LeBron James-led Cleveland Cavaliers. The 2008 Finals saw a rematch of the league's highest profile rivalry, the Boston Celtics and Los Angeles Lakers, with the Celtics winning their 17th championship. The Lakers won back-to-back championships in 2009 and 2010, against the Orlando Magic and the Celtics.[54][55] The 2010 NBA All-Star Game was held at Cowboys Stadium in front of the largest crowd ever, 108,713.[56]  A referee lockout began on September 1, 2009, when the contract between the NBA and its referees expired. The first preseason games were played on October 1, 2009, and replacement referees from the WNBA and NBA Development League were used, the first time replacement referees had been used since the beginning of the 1995\u201396 season. The NBA and the regular referees reached a deal on October 23, 2009.[57][58]  At the start of the 2010\u201311 season, free agents LeBron James and Chris Bosh signed with the Miami Heat, joining Dwyane Wade to form the \"Big Three\". The Heat dominated the league, reaching the Finals for four straight years. In 2011, they faced a re-match with the Dallas Mavericks but lost to the Dirk Nowitzki-led team. They won back-to-back titles in 2012 and 2013 against the Oklahoma City Thunder and the Spurs, and lost in a re-match with the Spurs in the 2014 Finals.  The 2011\u201312 season began with another lockout, the league's fourth.[59] After the first few weeks of the season were canceled, the players and owners ratified a new collective bargaining agreement on December 8, 2011, setting up a shortened 66-game season.[60] On February 1, 2014, commissioner David Stern retired after 30 years in the position, and was succeeded by his deputy, Adam Silver.[61]  After four seasons with the Miami Heat, LeBron James returned to the Cleveland Cavaliers for the 2014\u201315 season. He led the team to their second Finals appearance with the help of Kyrie Irving and Kevin Love. The Golden State Warriors defeated the Cavaliers in six games, led by the \"Splash Brothers\" Stephen Curry and Klay Thompson. The Cavaliers and the Warriors faced each other in the Finals a record four consecutive times. In the 2015\u201316 season, the Warriors finished the season 73\u20139, the best season record in NBA history.[62] However, the Cavaliers overcame a 3\u20131 deficit in the Finals to win their first championship that season.[63] In the 2016\u201317 season, the Warriors recruited free agent Kevin Durant and went on to win the 2017 and 2018 Finals against the Cavaliers.  After the departure of James in free agency in 2018, the Cavaliers' streak of playoff and Finals appearances ended. The Warriors returned for a fifth consecutive Finals appearance in 2019 but lost to the Toronto Raptors, who won their first championship after acquiring Kawhi Leonard in a trade.[64]  The 2019\u201320 season was suspended indefinitely on March 11, 2020, due to the COVID-19 pandemic, after Utah Jazz center Rudy Gobert tested positive for the coronavirus.[65][66] On June 4, 2020, the NBA Board of Governors voted to resume the season in a 22-team format with 8 seeding games per team and a regular playoffs format, with all games played in a \"bubble\" in Walt Disney World without any fans present.[67][68][69]  This era also saw the continuous near year-over-year decline in NBA viewership. Between 2012 and 2019, the league lost 40 to 45 percent of its viewership. While some of it can be attributed to \"cable-cutting\", other professional leagues, like the NFL and MLB have retained stable viewership demographics. The opening game of the 2020 Finals between the Los Angeles Lakers and Miami Heat brought in only 7.41\u00a0million viewers to ABC, according to The Hollywood Reporter. That is reportedly the lowest viewership seen for the Finals since at least 1994, when total viewers began to be regularly recorded and is a 45 percent decline from game one between the Golden State Warriors and Toronto Raptors, which had 13.51\u00a0million viewers a year earlier. Some attribute this decline to the political stances the league and its players are taking, while others consider load management, the uneven talent distribution between the conferences and the cord-cutting of younger viewers as the main reason for the decline.[70][71][72][73][74]  During the 2020\u201321 and 2021\u201322 seasons, the Milwaukee Bucks would defeat the Phoenix Suns in the 2021 NBA Finals, securing their second NBA championship since 1971, and the Golden State Warriors made their sixth appearance in the finals defeating the Boston Celtics in the 2022 NBA Finals, their fourth championship in eight years.[75][76]  The 2022\u201323 season saw the Denver Nuggets, led by center Nikola Joki\u0107, make the franchise's first NBA Finals appearance and defeat the Miami Heat in five games to win their first NBA championship.[77]  Following pioneers like Vlade Divac (Serbia) and Dra\u017een Petrovi\u0107 (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Since 2006, the NBA has faced EuroLeague teams in exhibition matches in the NBA Europe Live Tour, and since 2009, in the EuroLeague American Tour.  The 2013\u201314 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20 percent of the league.[78] The NBA defines \"international\" players as those born outside the 50 United States and Washington, D.C. This means that:  The beginning of the 2017\u201318 season saw a record 108 international players representing 42 countries marking 4 consecutive years of at least 100 international players and each team having at least one international player.[79] In 2018, the Phoenix Suns hired Serbian coach Igor Koko\u0161kov as their new head coach, replacing Canadian interim coach Jay Triano, making Koko\u0161kov the first European coach to become a head coach for a team in the NBA.  In the 2023\u201324 season, the Mavericks and the Thunder each had eight international players on their roster.[80] From the 2018 to 2023 season, the MVP award has been given to an international player every year.[80]  In 2001, an affiliated minor league, the National Basketball Development League, now called the NBA G League, was created.[81]  Two years after the Hornets' move to New Orleans, the NBA returned to North Carolina, as the Charlotte Bobcats were formed as an expansion team in 2004.  The Hornets temporarily moved to Oklahoma City in 2005 for two seasons because of damage caused by Hurricane Katrina. The team returned to New Orleans in 2007.  A new official game ball was introduced on June 28, 2006, for the 2006\u201307 season, marking the first change to the ball in over 35 years and only the second ball in 60 seasons.[82] Manufactured by Spalding, the new ball featured a new design and new synthetic material that Spalding claimed offered a better grip, feel, and consistency than the original ball. However, many players were vocal in their disdain for the new ball, saying that it was too sticky when dry, and too slippery when wet.  Commissioner Stern announced on December 11, 2006, that beginning January 1, 2007, the NBA would return to the traditional leather basketball in use prior to the 2006\u201307 season. The change was influenced by frequent player complaints and confirmed hand injuries (cuts) caused by the microfiber ball.[83] The Players' Association had filed a suit on behalf of the players against the NBA over the new ball.[84] As of the 2017\u201318 season[update], the NBA team jerseys are manufactured by Nike, replacing the previous supplier, Adidas. All teams will wear jerseys with the Nike logo except the Charlotte Hornets, whose jerseys will instead have the Jumpman logo associated with longtime Nike endorser Michael Jordan, who owns the Hornets.[85]  The Federal Bureau of Investigation (FBI) began an investigation on July 19, 2007, over allegations that veteran NBA referee Tim Donaghy bet on basketball games he officiated over the past two seasons and that he made calls affecting the point spread in those games.[86] On August 15, 2007, Donaghy pleaded guilty to two federal charges related to the investigation. Donaghy claimed in 2008 that certain referees were friendly with players and \"company men\" for the NBA, and he alleged that referees influenced the outcome of certain playoff and finals games in 2002 and 2005. NBA commissioner David Stern denied the allegations and said Donaghy was a convicted felon and a \"singing, cooperating witness\".[87] Donaghy served 15 months in prison and was released in November 2009.[88] According to an independent study by Ronald Beech of Game 6 of the 2002 Western Conference Finals between the Los Angeles Lakers and Sacramento Kings, although the refs increased the Lakers' chances of winning through foul calls during the game, there was no collusion to fix the game. On alleged \"star treatment\" during Game 6 by the referees toward certain players, Beech claimed, \"there does seem to be issues with different standards and allowances for different players.\"[89]  The NBA Board of Governors approved the request of the Seattle SuperSonics to move to Oklahoma City on April 18, 2008.[90] The team, however, could not move until it had settled a lawsuit filed by the city of Seattle, which was intended to keep the SuperSonics in Seattle for the remaining two seasons of the team's lease at KeyArena. Following a court case, the city of Seattle settled with the ownership group of the SuperSonics on July 2, 2008, allowing the team to move to Oklahoma City immediately in exchange for terminating the final two seasons of the team's lease at KeyArena.[91] The Oklahoma City Thunder began playing in the 2008\u201309 season.  The first outdoor game in the modern era of the league was played at the Indian Wells Tennis Garden on October 11, 2008, between the Phoenix Suns and the Denver Nuggets.[92]  The first official NBA league games on European ground took place in 2011. In two matchups, the New Jersey Nets faced the Toronto Raptors at the O2 Arena in London in front of over 20,000 fans.  After the 2012\u201313 season, the New Orleans Hornets were renamed the Pelicans.[93] During the 2013\u201314 season, Stern retired as commissioner after 30 years, and deputy commissioner Adam Silver ascended to the position of commissioner. During that season's playoffs, the Bobcats officially reclaimed the Hornets name, and by agreement with the league and the Pelicans, also received sole ownership of all history, records, and statistics from the Pelicans' time in Charlotte. As a result, the Hornets are now officially considered to have been founded in 1988, suspended operations in 2002, and resumed in 2004 as the Bobcats, while the Pelicans are officially treated as a 2002 expansion team.[94] (This is somewhat similar to the relationship between the Cleveland Browns and Baltimore Ravens in the NFL.)  Donald Sterling, who was then-owner of the Los Angeles Clippers, received a lifetime ban from the NBA on April 29, 2014, after racist remarks he made became public. Sterling was also fined US$2.5\u00a0million, the maximum allowed under the NBA Constitution.[95]  Becky Hammon was hired by the San Antonio Spurs on August 5, 2014, as an assistant coach, becoming the second female coach in NBA history but the first full-time coach.[96][97] This also makes her the first full-time female coach in any of the four major professional sports in North America.[97]  The NBA announced on April 15, 2016, that it would allow all 30 of its teams to sell corporate sponsor advertisement patches on official game uniforms, beginning with the 2017\u201318 season. The sponsorship advertisement patches would appear on the left front of jerseys, opposite Nike's logo, marking the first time a manufacturer's logo would appear on NBA jerseys, and would measure approximately 2.5 by 2.5 inches. The NBA would become the first major North American professional sports league to allow corporate sponsorship logos on official team uniforms, and the last to have a uniform manufacturer logo appear on its team uniforms.[98] The first team to announce a jersey sponsorship was the Philadelphia 76ers, who agreed to a deal with StubHub.[99]  On July 6, 2017, the NBA unveiled an updated rendition of its logo; it was largely identical to the previous design, except with revised typography and a \"richer\" color scheme. The league began to phase in the updated logo across its properties during the 2017 NBA Summer League.[100]  The NBA also officially released new Nike uniforms for all 30 teams beginning with the 2017\u201318 season. The league eliminated \"home\" and \"away\" uniform designations. Instead, each team would have four or six uniforms: the \"Association\" edition, which is the team's white uniform, the \"Icon\" edition, which is the team's color uniform, and the \"Statement\" and \"City\" uniforms, which most teams use as an alternate uniform.[101] In 2018, the NBA also released the \"Earned\" uniform.[102]  In 2018, Adam Silver showed support in the Supreme Court's decision to overturn a federal ban on sports betting. Silver thought it would bring greater transparency and integrity as well as business opportunities.[103] Before naming DraftKings and FanDuel co-official sports betting partners of the NBA in 2021, the NBA first named MGM as the exclusive official gaming partner of the NBA and WNBA\u2014the first major American sports league to do so.[104][105] With a deal between the 76ers and then-sportsbook FOX Bet as the first agreement between an NBA team and a sportsbook app, more teams partnered with operators thereafter.[106] This early acceptance of sports betting translated to basketball being the most bet on sport in the United States over football in 2023.[107]  Download coordinates as:  The NBA originated in 1946 with 11 teams, and through a sequence of team expansions, reductions and relocations consists of 30 teams \u2013 29 in the United States and 1 in Canada.  The current league organization divides 30 teams into two conferences of three divisions with five teams each. The current divisional alignment was introduced in the 2004\u201305 season. Reflecting the population distribution of the United States and Canada as a whole, most teams are in the eastern half of the country: 13 teams are in the Eastern Time Zone, nine in the Central, three in the Mountain, and five in the Pacific.  Notes:  Following the summer break, teams begin training camps in late September.[108] Training camps allow the coaching staff to evaluate players (especially rookies), scout the team's strengths and weaknesses, prepare the players for the rigorous regular season and determine the 12-man active roster (and a 3-man inactive list) with which they will begin the regular season. Teams have the ability to assign players with less than two years of experience to the NBA G League. After training camp, a series of preseason exhibition games are held. Preseason matches are sometimes held in non-NBA cities, both in the United States and overseas. The NBA regular season begins in the last week of October.  During the regular season, each team plays 82 games, 41 each home and away.[109] A team faces opponents in its own division four times a year (16 games).[109] Each team plays six of the teams from the other two divisions in its conference four times (24 games), and the remaining four teams three times (12 games).[109] Finally, each team plays all the teams in the other conference twice apiece (30 games).[109] This asymmetrical structure means the strength of schedule will vary between teams (but not as significantly as the NFL or MLB). Over five seasons, each team will have played 80 games against their division (20 games against each opponent, 10 at home, 10 on the road), 180 games against the rest of their conference (18 games against each opponent, 9 at home, 9 on the road), and 150 games against the other conference (10 games against each team, 5 at home, 5 on the road).  Starting the 2023\u201324 season, the regular season included an in-season tournament, in which all games in the tournament (except for the final) counted towards the regular season.[110]  The NBA is also the only league that regularly schedules games on Christmas Day.[111] The league has been playing games regularly on the holiday since 1947,[112] though the first Christmas Day games were not televised until 1983\u201384.[113] Games played on this day have featured some of the best teams and players.[111][112][113] Christmas is also notable for NBA on television, as the holiday is when the first NBA games air on network television each season.[112][113] Games played on this day have been some of the highest-rated games during a particular season.  The NBA has also played games on MLK Day every year since the holiday was first observed in 1986.[114]  In February, the regular season pauses to celebrate the annual NBA All-Star Game. Fans vote throughout the United States, Canada, and on the Internet, and the top vote-getters in each conference are named captains. Fan votes determine the rest of the allstar starters. Coaches vote to choose the remaining 14 All-Stars. The player with the best performance during the game is rewarded with a Game MVP award. Other attractions of the All-Star break include the Rising Stars Challenge (originally Rookie Challenge), where the top rookies and second-year players in the NBA play in a 5-on-5 basketball game, with the current format pitting U.S. players against those from the rest of the world; the Skills Challenge, where players compete to finish an obstacle course consisting of shooting, passing, and dribbling in the fastest time; the Three Point Contest, where players compete to score the highest number of three-point field goals in a given time; and the NBA Slam Dunk Contest, where players compete to dunk the ball in the most entertaining way according to the judges. These other attractions have varying names which include the names of the various sponsors who have paid for naming rights.  Shortly after the All-Star break is the trade deadline, which is set to fall on the 16th Thursday of the season (usually in February) at 3\u00a0pm Eastern Time.[115] After this date, teams are not allowed to exchange players with each other for the remainder of the season, although they may still sign and release players. Major trades are often completed right before the trading deadline, making that day a hectic time for general managers.  Around the middle of April, the regular season ends. It is during this time that voting begins for individual awards, as well as the selection of the honorary, league-wide, postseason teams. The Sixth Man of the Year Award is given to the best player coming off the bench (must have more games coming off the bench than actual games started). The Rookie of the Year Award is awarded to the most outstanding first-year player. The Most Improved Player Award is awarded to the player who is deemed to have shown the most improvement from the previous season. The Defensive Player of the Year Award is awarded to the league's best defender. The Coach of the Year Award is awarded to the coach that has made the most positive difference to a team. The Most Valuable Player Award is given to the player deemed the most valuable for (his team) that season. Additionally, Sporting News awards an unofficial (but widely recognized) Executive of the Year Award to the general manager who is adjudged to have performed the best job for the benefit of his franchise.  The postseason teams are the All-NBA Team, the All-Defensive Team, and the All-Rookie Team; each consists of five players. There are three All-NBA teams, consisting of the top players at each position, with first-team status being the most desirable. There are two All-Defensive teams, consisting of the top defenders at each position. There are also two All-Rookie teams, consisting of the top first-year players regardless of position.[116][117]  The NBA playoffs begin in April after the conclusion of the regular season and play-in tournament with the top eight teams in each conference, regardless of divisional alignment, competing for the league's championship title, the Larry O'Brien Championship Trophy. Seeds are awarded in strict order of regular season record (with a tiebreaker system used as needed).  Having a higher seed offers several advantages. Since the first seed begins the playoffs playing against the eighth seed, the second seed plays the seventh seed, the third seed plays the sixth seed, and the fourth seed plays the fifth seed, having a higher seed typically means a team faces a weaker opponent in the first round. The team in each series with the better record has home-court advantage, including the First Round.   The league began using its current format, with the top eight teams in each conference advancing regardless of divisional alignment, in the 2015\u201316 season. Previously, the top three seeds went to the division winners.[118]  The playoffs follow a tournament format. Each team plays an opponent in a best-of-seven series, with the first team to win four games advancing into the next round, while the other team is eliminated from the playoffs. In the next round, the successful team plays against another advancing team of the same conference. All but one team in each conference are eliminated from the playoffs. Since the NBA does not re-seed teams, the playoff bracket in each conference uses a traditional design, with the winner of the series matching the first- and eighth-seeded teams playing the winner of the series matching the fourth- and fifth-seeded teams, and the winner of the series matching the second- and seventh-seeded teams playing the winner of the series matching the third- and sixth-seeded teams. In every round, the best-of-7 series follows a 2\u20132\u20131\u20131\u20131 home-court pattern, meaning that one team will have home court in games 1, 2, 5, and 7, while the other plays at home in games 3, 4, and 6. From 1985 to 2013, the NBA Finals followed a 2\u20133\u20132 pattern, meaning that one team had home court in games 1, 2, 6, and 7, while the other played at home in games 3, 4, and 5.[119]  The final playoff round, a best-of-seven series between the victors of both conferences, is known as the NBA Finals and is held annually in June (sometimes, the series will start in late May). The winner of the NBA Finals receives the Larry O'Brien Championship Trophy. Each player and major contributor\u2014including coaches and the general manager\u2014on the winning team receive a championship ring. In addition, the league awards the Bill Russell NBA Finals Most Valuable Player Award to the best performing player of the series.  The Los Angeles Lakers and the Boston Celtics are tied for the most championships with each having 17 NBA Finals wins.[120] The Golden State Warriors and Chicago Bulls have the third- and fourth-most, respectively, with seven and six titles.  Current teams that have no NBA Finals appearances:  As one of the major sports leagues in North America, the NBA has a long history of partnerships with television networks in the United States. The NBA signed a contract with DuMont Television Network in its eighth season, the 1953\u201354 season, marking the first year the NBA had a national television broadcaster. Similar to the National Football League, the lack of television stations led to NBC taking over the rights from the 1954\u201355 season until April 7, 1962\u2013NBC's first tenure with the NBA. Currently in the U.S., the NBA has a contract with ESPN (and ABC) and TNT through the 2024\u201325 season.[121] Games that are not broadcast nationally are usually aired over regional sports networks specific to the area where the teams are located.  The National Basketball Association has sporadically participated in international club competitions. The first international competition involving the NBA was a 1978 exhibition game in Tel Aviv, Israel between the Washington Bullets and Israeli club Maccabi Tel Aviv.[122] From 1987 to 1999 an NBA team played against championship club teams from Asia, Europe and South America in the McDonald's Championship. This tournament was won by the NBA invitee every year it was held.[123]  In 2022, an average ticket cost $77.75.[124] Depending on the market and stage of the season\u2014preseason, regular season, postseason\u2014a ticket can range from $10 to $100,000.[a][125][126]  In 2020, ticket prices for the NBA All Star Game became more expensive than ever before, averaging around $2,600, and even more on the secondary market.[127]  According to Nielsen's survey, in 2013 the NBA had the youngest audience, with 45 percent of its viewers under 35. As of 2022[update], the league remains the least likely to be watched by women, who make up only 30% of the viewership.[128] As of 2014[update], 45 percent of its viewers were black, while 40 percent of viewers were white, making it the only top North American sport that does not have a white majority audience.[129]  As of 2017[update], the NBA's popularity further declined among White Americans, who during the 2016\u201317 season, made up only 34% of the viewership. At the same time, the black viewership increased to 47 percent, while Hispanic (of any race) stood at 11% and Asian viewership stood at 8%. According to the same poll, the NBA was favored more strongly by Democrats than Republicans.[130]  Outside the U.S., the NBA's biggest international market is in China,[131][132] where an estimated 800 million viewers watched the 2017\u201318 season.[133] NBA China is worth approximately $4\u00a0billion.[131][132]  The NBA has been involved in a number of controversies over the years and has received a significant amount of criticism.[134][135][136]  Following pioneers like Vlade Divac (Serbia) and Dra\u017een Petrovi\u0107 (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Below is a short list of foreign players who have won NBA awards or have been otherwise recognized for their contributions to basketball, either currently or formerly active in the league:  On some occasions, young players, most but not all from the English-speaking world, have attended U.S. colleges before playing in the NBA. Notable examples are:  The league has a global social responsibility program, NBA Cares, that is responsible for the league's stated mission of addressing important social issues worldwide.[149]  1961  1966  1967  1968  1970  1974  1980  1988  1989  1995  2004 "},{"title":"Holding the ball","content":"  Holding the ball is an infraction in Australian rules football. The rule results in a free kick being awarded against a player who fails to correctly dispose of the football upon being tackled by an opponent, although not under all circumstances. The rule provides the defending team a means to dispossess a player who is running with the football, and prevents players from slowing the play.  The holding the ball rule dates to the formative years of the game. It has a long history as one of the most contentious rules in the game and one of the most difficult to umpire consistently, in large part due to the several points of umpire discretion involved in its interpretation.[1]  Under the 2021 release of the Laws of Australian Football, holding the football is covered by Law 18.6.[2] Four specific clauses apply, mostly depending upon how the player came to be in possession of the ball. The wording of these variations in the laws is as follows:  A Prior Opportunity is defined in Law 1.1 (Definitions and Interpretation) as a player who has possession of the ball and:  Also relevant is the definition of possession in Law 1.1, which states that a player is still in possession of the ball while executing a running bounce, even during the period of time when the ball is not in the player's hands.[2] The practical consequence of this on the holding the ball law is that a player who is tackled while bouncing the ball is considered 'holding the ball', even if the tackler releases the player during the skill.[3]  The umpire signals holding the ball by leaning forward and sweeping both arms below his body and out to his sides. Customarily, spectators will shout \"Ball!\" when they believe a holding the ball free kick should be paid.  Although it has long been commonly understood that a player assumes prior opportunity at some stage shortly after he has taken possession of the ball, it was not until the 2019 rewrite of the Laws of the Game that a comprehensive definition of prior opportunity was formally enshrined in the Laws.[4][5][6] Prior to 2018, other than a few specific scenarios which were prescribed in the laws, the general duty to define and interpret what constituted a prior opportunity was left to the discretion of the umpires, acting on the direction of the umpiring coaches. There remains no explicit definition within the rules for a \"reasonable time\" to dispose of the ball, nor for a \"genuine attempt\" to dispose of the ball, and so these remain fully at the discretion of the umpire and at the direction of the umpiring coaches.  Perhaps in no sport is there a rule which has given rise to more discussion, or caused more difficulty in its interpretation than this law of the Australian game.  The Advertiser, 1927.[7] Most football supporters endorse the view that the holding-the-ball-holding-the-man rule is the most contentious in the law book governing the national code.  The Advertiser, 1951.[8] High on the list of criticisms is one of the game's perennial debates \u2013 the holding the man\/holding the ball rule.  The Canberra Times, 1989.[9] Holding the ball remains Australian football's most complicated and annoying rule.  The Advertiser, 2014.[1] Holding the ball, and at times its pairing with the holding the man rule, has been one of the most contentious rules in Australian rules football throughout almost the entire history of the sport, for a wide variety of reasons. Confusion and inconsistency are the chief causes of this contention, which in large part arises from the many different facets of the rule, the amount of discretion and judgement umpires must exercise, the fact that different field umpires may interpret the same scenario in different manners, and the lack of formal definitions for 'prior opportunity', 'reasonable opportunity' and 'genuine attempt'.[1] Specific points which often cause contention include:  Another point of contention among football observers regards how stringently the rule should be applied to make for an optimum spectacle. Applying the rule less strictly will tend to lead to congested play and an increase in the number of stoppages, because players who are tackled after having won the contested ball would rather hold it to force a neutral stoppage than kick the ball into a potential turnover.[4][10] Applying the rule more strictly leads to a scenario which discourages players from trying to win the contested ball, as they find that it is more profitable to wait for an opponent to win the ball, then earn a free kick by tackling them; such a practice is considered to be against the spirit of the game as a contest.[11] Changes to the rule throughout history have generally been brought about by moving undesirably close to one of these extremes, but many observers have differing opinions on which is the less desirable outcome and what the optimum interpretation would be.  The holding the ball rule has its origins in Rule 8 of the Melbourne rules, the rule which placed limitations on a player's freedom to run with the ball. By the early 1870s, it had become common practice that a player running with the ball should drop it upon being held by an opponent;[12] this was enshrined in the rules by 1876, with Rule 8 including the stipulation \"in the event of a player with the ball in hand trying to pass an adversary, and being held by him, he must at once drop the ball,\" with a free kick to be paid for a breach of the rule.[13]  Application of the law in the early years and throughout the first half of the 20th century would appear extremely stringent to a spectator familiar with the modern application of the rule. In general, the tackler needed to do little more than grip an opponent by the guernsey with one hand, not necessarily even retarding his progress, to earn a free kick. The full body tackle which would be seen in modern playing style was not necessary, and was very uncommonly seen because executing one would almost always result in conceding a holding the man free kick \u2013 that rule was also applied very stringently at the time, so a full body tackle would almost always linger for some time after the player had dropped the ball, and therefore would always be penalised.[14] Until even the 1950s, full body tackling was thought of by the football-going public as a \"rugby tackle\": and while it was legal within the rules, it was so scarcely seen that many thought it to be illegal.[15][16]  One of the early difficulties encountered by the Australasian Football Council, which owned and administered the laws of the game from 1906 onwards, was in establishing a consistent interpretation the holding the ball rule between the different states. Sportswriters noted a particularly wide disparity between the interpretations of the rule in South Australia and Victoria: in South Australia, the rule was applied extremely stringently, with a defending player needing to do little more than touch a player running with the ball to force him to drop it, making it almost impossible for a player to run with the ball in the vicinity of opponents; but that in Victoria, a more significant hold or tackle was required to earn a free kick, resulting in players more willing to run through packs of opponents. These wide differences often led to difficulties in interstate matches.[17][18]  Particularly under the stricter interpretations of the rule, a problem emerged in that players were finding that standing back and allowing an opponent to win the ball before immediately tackling him to win a free kick was more profitable than attempting to win the ball and risking being tackled himself. This practice, known in those times as \"malingering\", was and still is considered undesirable, as it was believed that a rule which discouraged players from winning contested ball was against the spirit of the game.[11] The banning of the flick pass in 1925, forcing players to use the more cumbersome punch pass, exacerbated this by making it more difficult to dispose of the ball.[19]  Several attempts were made during the 1920s to standardise and clarify the rules. In 1920, the Australasian Football Council amended its wording of the rule, replacing the word \"caught\" with \"held\" when describing the act of tackling, to attempt to make it clear that the defending player must do more than simply touch the ball-carrier to win a free kick.[20] The rule was then rewritten entirely in 1928, when it was removed from the original Rule 8 (which by this time had been renumbered) and was added as a stand-alone rule. The new rule, intended to be less stringent, read: \"A free kick shall be given against a player who, while being held by an opponent, and being in possession of the ball, does not at once kick, handball or drop it so as to relinquish possession of it. The free kick shall be given to the player who holds him. A player shall not be deemed to be held within the meaning of the foregoing paragraphs unless he is held firmly enough to stop him or to retard his progress.\"[21]  An undesirable style of close-in play had emerged by the 1930s: a player with the ball would be tackled, would drop the ball at his feet, wait for his opponent to release him, then bend down and regather the ball, with this sequence of events repeated over and over with both men trying to win a free kick \u2013 either for holding the ball or holding the man \u2013 rather than actively trying to move the football. These contests then attracted other players and formed scrimmages which slowed the game down. To eliminate this style of play, the concept of \"no-drop holding the ball\" was developed. This took away the provision for a player to drop the ball upon being tackled, and required him to dispose of the ball by kick or handpass; it was intended that the kick or handpass would clear the ball away from scrimmages around the tackled player.[22] This change was a major change to the Laws of the Game, eliminating the sixty-year-old provision to drop the ball when tackled, but was a change which is fundamental to the modern interpretation of the rule.  The Australian National Football Council first introduced no-drop holding the ball nationally prior to the 1930 season,[23] although some small competitions had played under the rule earlier (the Victorian Junior Football Association, for example, introduced the rule in 1927).[24] It was unpopular in the early months, and was blamed for an increase in congested play and an increase in injuries caused by players attempting wild kicks when previously they would have dropped the ball.[25] Consequently, the change was hastily repealed after only two months.[26]  No-drop holding the ball was next introduced by the Victorian Football Association (VFA) in 1938. The VFA, which did not come under the National Council's influence, introduced the rule as part of a suite of novel rule changes, which also included the legalisation of throwing the ball as a type of handpass.[27] The VFA's combination of the no-drop rule and throwing the ball had the immediate effect of reducing congestion, as it gave players the easy option to throw the ball into open space when tackled, instead of dropping the ball at their feet and causing a scrimmage to form around it.[28][29]  \"In my day [the early 1920s], when a good player got his hands on the ball, it was almost certain he would get a kick some way or another. He could drop the ball when grabbed by an opponent, or play it in front of him and snatch it up again, all the time battling physically and with his wits to beat his opponent. Nowadays it doesn't matter how good a man is, as soon as he is touched he has to get rid of the ball, often hurriedly and without direction. The game is called up too much and there are too many pauses.\"  \u2014 South Australian champion Dan Moriarty on the no-drop rule, The News, 1946[30] The National Council quickly followed the VFA's lead, re-instating the no-drop rule from the 1939 season, but it did not pair it with the throwing the ball rule.[31] The no-drop rule again proved to be unpopular. Without the ability to execute a drop or a VFA-style throw, players were forced to rely on the more cumbersome disposal methods of a kick or a handpass; because umpires had conventionally called holding the ball penalties almost immediately when a player was tackled, it was very difficult (and sometimes impossible, depending upon the quickness of the presiding umpire) to execute either of these skills before conceding a free kick, and those who did manage to dispose of the ball often committed turnovers in doing so.[32][33] Consequently, players favoured malingering over winning the contested ball more so than ever before. South Australian umpire Frank Armstrong commented that the no-drop rule became known as \"the Bludger's Rule\" among umpires during this time, since the rule so heavily favoured the tackler over the ball-winner.[34]  To rectify the problems, a more liberal interpretation of the rule was gradually adopted by the state leagues during the mid-1940s, then was formally codified into the Laws nationally in 1948. The new rules eliminated the requirement for the player to dispose of the ball \"immediately\", and replaced it with the stipulation \"umpires must give the player who is in possession of the ball a reasonable chance of disposing of it before free kicking him,\"[35] first introducing the concept of a 'reasonable chance\/time' which remains enshrined in the modern laws. Giving a reasonable chance, according to the VFL umpires' coaches in 1951, meant that a player who had bent down to pick up the ball would be given enough time to stand up and execute a disposal, or a player who collected the ball in full stride would be given time to balance himself.[36] Additionally, five scenarios were specifically written into the 1948 Laws which were not to be considered 'holding the ball':[35]  These changes helped to reduce malingering and provide incentive to win the hard ball; but, they introduced further points of discretion and sources of inconsistency to the umpire.  The wording of the holding the ball rule remained more or less unchanged for the next forty or fifty years, but the interpretation of the rule was adapted to suit changes to the game. As full body tackling became a fundamental part of the game, the interpretations of holding the ball (including what constituted a 'reasonable opportunity' to dispose of the ball) and holding the man were adjusted to suit.  Adjustments made to the rules in the late 1970s created definitions removing the ability for players to bounce the ball or handpass to themselves as ways to avoid holding the ball free kicks or win holding the man free kicks. Richmond footballer Kevin Bartlett was particularly well known for using these tactics to avoid being penalised for holding the ball, and the rule changes are generally associated with his play.[37]  The next and last major change to the holding the ball rule was the introduction of the 'prior opportunity' rule. The rule was initially introduced in 1986 and known as the \"perfect tackle rule\": tackling a player who had an opportunity to dispose of the ball before being tackled was defined as a perfect tackle, and the provision for a perfectly tackled player to have a reasonable time to dispose of the ball before being penalised was eliminated. The rule was introduced to speed up the game.[38] This later became the modern 'prior opportunity' rule in 1996,[39] and it was the first time that different holding the ball interpretations had been applied on the basis of what had taken place before the tackle was laid. As part of this change, the five specific scenarios which did not attract a free kick from the 1948 Laws were divided: scenarios (a) and (b) were still not considered 'holding the ball' under any circumstances; scenarios (c\u2013e) were now considered 'holding the ball' if there was prior opportunity, but not 'holding the ball' without.[5]  Since then, only small adjustments have been made to the holding the ball rules. A rule under which a ruckman was considered to have assumed prior opportunity immediately upon catching the ball on the full in a ruck contest was added to the Laws of the Game in 2003, then removed in 2019.[39][40] The definition under which a player ducking and driving his head into an opponent is considered to have had a prior opportunity was introduced in 2015.[41] Finally, in 2019, the increasingly unwieldy law was copyedited and its wordcount in the laws was reduced by more than half, without significantly changing its intent: among the changes, the five scenarios added in 1948 were removed from the rules and replaced with the two more general clarifications in the present Law 18.6.3; and a paragraph which clarified the scenario of the ball being held to an opponent's body by the tackler was removed.[5][6]  Laws of Australian Football (Australian Football League)  Spirit of the Laws (Australian Football League) "},{"title":"List of islands of Scotland","content":"    This is a list of islands of Scotland, the mainland of which is part of the island of Great Britain. Also included are various other related tables and lists. The definition of an offshore island used in this list is \"land that is surrounded by seawater on a daily basis, but not necessarily at all stages of the tide, excluding human devices such as bridges and causeways\".[Note 1]  Scotland has around 900 offshore islands,[1] most of which are to be found in four main groups: Shetland, Orkney, and the Hebrides, sub-divided into the Inner Hebrides and Outer Hebrides.[2] There are also clusters of islands in the Firth of Clyde, Firth of Forth, and Solway Firth, and numerous small islands within the many bodies of fresh water in Scotland including Loch Lomond and Loch Maree. The largest island is Lewis and Harris which extends to 2,179\u00a0square kilometres, and there are a further 200 islands which are greater than 40 hectares in area. Of the remainder, several such as Staffa and the Flannan Isles are well known despite their small size.[2] Some 94 Scottish islands are permanently inhabited, of which 89 are offshore islands. Between 2001 and 2011 Scottish island populations as a whole grew by 4% to 103,702.[3]  The geology and geomorphology of the islands is varied. Some, such as Skye and Mull, are mountainous, while others like Tiree and Sanday are relatively low lying. Many have bedrock made from ancient Archaean Lewisian Gneiss which was formed 3 billion years ago; Shapinsay and other Orkney islands are formed from Old Red Sandstone, which is 400 million years old; and others such as R\u00f9m from more recent Tertiary volcanoes.[4] Many of the islands are swept by strong tides, and the Corryvreckan tide race between Scarba and Jura is one of the largest whirlpools in the world.[5] Other strong tides are to be found in the Pentland Firth between mainland Scotland and Orkney, and another example is the \"Grey Dog\" between Scarba and Lunga.[2]  The culture of the islands has been affected by the successive influences of Celtic, Norse and English speaking peoples and this is reflected in names given to the islands. Many of the Hebrides have names with Scots Gaelic derivations, whilst those of the Northern Isles tend to be derived from the Viking names. A few have Brythonic, Scots and even perhaps pre-Celtic roots.[2] A feature of modern island life is the low crime rate and they are considered to be amongst the safest places to live in Britain.[6] Orkney was rated as the best place to live in Scotland in both 2013 and 2014 according to the Halifax Quality of Life survey.[7]  Rockall is a small rocky islet in the North Atlantic which was declared part of Scotland by the Island of Rockall Act 1972.[8][9] However, despite no possession by any other state and other precedents, the legality of the claim is disputed by the Republic of Ireland, Denmark and Iceland and some say, it may be unenforceable in international law.[10][11]  The 2011 census records 94 Scottish islands as having a usually resident population of which 89 are offshore islands. There are however various complications with both the definitions of an \"island\" and occasional habitation and the National Records of Scotland also list a further 17 islands that were inhabited in 2001 but not 2011, or are \"included in the NRS statistical geography for inhabited islands but had no usual residents at the time of either the 2001 or 2011 censuses\".[13] There are a small number of other islands that are evidently inhabited but which are not recorded in this list.[Note 2]  The local government council areas with the most inhabited islands are Argyll and Bute with 23, Orkney with 20, Shetland with 16 and Highland and Comhairle nan Eilean Siar with 14 each. There are also three in North Ayrshire and one each in Fife, Perth and Kinross, Stirling and West Dunbartonshire. The last three named plus two islands in Argyll and Bute are freshwater rather than offshore.[13]  In the past many smaller islands that are uninhabited today had permanent populations. Losses were severe in many areas during the 19th century when islands such as Pabbay and Fuaigh M\u00f2r were subject to forcible evictions during the Highland Clearances.[15] Mass emigration from the Hebridean islands was at its height in the mid-19th century but it commenced as early as the 1770s in some areas.[16] The crofting counties held 20% of Scotland's population in 1755 but by 1961 this figure had declined to 5%.[17] Other examples include Mingulay, Noss and the St Kilda archipelago, which were abandoned during the course of the 20th century. Declines have been particularly significant in the more remote outlying islands, some of which remain vulnerable to ongoing losses.[18]  The following table shows population trends for the ten most populous islands as of the last census. The overall trends are typically growth in populations in the early part of the modern period, followed by declines from the mid 19th century onwards. In every case except Orkney the highest population was recorded prior to 1932 and the lowest post-industrial revolution figure after 1960. Subsequently, there has been modest growth overall, although some islands are continuing to show a decline. Between 1991 and 2001, the population of the islands as a whole fell by 3% to 99,739, although there were 35 islands whose population increased.[19] By contrast, between 2001 and 2011 Scottish island populations as a whole grew by 4% to 103,702.[3] The Scottish Community Alliance noted that \"the largest rate of increase has been in the Western Isles (6%) where local people now own approximately 60% of the landmass. Where populations have fallen (Bute, Arran and Islay) community ownership is virtually non-existent.\"[20]  The following table compares the populations of the main Scottish archipelagos with that of the Faroe Islands for a similar time frame to the above.[Note 3]  In July 2013, the Scottish Government made the Lerwick Declaration, indicating an intention to decentralise power to the three island council areas of Orkney, Shetland and the Western Isles and later that year made a commitment to do so.[37] In 2017 an Islands bill was introduced to make \"island proofing\" (including for uninhabited islands) a statutory requirement for public bodies. The Bill completed Stage 1 on 8 February 2018.[38]  This is a list of Scottish islands that either have an area greater than 40\u00a0hectares (approximately 100\u00a0acres) and\/or are inhabited. The main groups, from Haswell-Smith (2004), in many cases provide a more useful guide to location than local authority areas. These groups are: Firth of Clyde, Islay, Firth of Lorn, Mull, Small Isles, Skye, Lewis and Harris, Uists and Barra, St Kilda, Orkney, Shetland and Firth of Forth. In a few cases where the island is part of either a recognisable smaller group or an archipelago, or is located away from the main groups, an archipelago, local authority or other descriptive name is used instead. \"F\" designates a freshwater island.  Scotland's islands include thirteen Munros (mountains with a height over 3,000\u00a0feet or 914.4\u00a0metres), twelve of them found on Skye, and a total of 227 Marilyns (hills with a relative height of at least 150\u00a0metres, regardless of absolute height).[39]  Four islands were recorded as inhabited in 2011 that were not mentioned in the 2001 census: Eilean d\u00e0 Mh\u00e8inn, Eilean Tioram, Holm of Grimbister and Inner Holm.[13]  These following are listed by the National Records of Scotland as \"included in the NRS statistical geography for inhabited islands but had no usual residents at the time of either the 2001 or 2011 censuses.\"[13] None except Lamb Holm are greater than 40 ha in area.  There are numerous other freshwater islands, of which the more notable include Lochindorb Castle Island, Loch Leven Castle Island, St Serf's Inch, and Inchmahome, each of which have played an important part in Scottish history.  Inchmurrin is the largest freshwater island in the British Isles.[46][47] It is in Loch Lomond, which contains over sixty other islands.[47] Loch Maree also contains several islands, the largest of which are Eilean S\u00f9bhainn, Garbh Eilean and Eilean Ruairidh M\u00f2r but aren't as big as others.  This is a continuing list of uninhabited Scottish islands smaller than 40 hectares in size.  There are various small archipelagos which may be better known than the larger islands they contain. These include:  The following is a list of places which were formerly islands, but which are no longer so due to silting up, harbour building etc.  Many of Scotland's islands are connected to the mainland and\/or other islands by bridge or causeway. Although some people consider them no longer to be islands, they are generally treated as such.  Outer Hebrides  Many of the islands of the southern Outer Hebrides have been joined to other islands by causeways and bridges. These include:  To the north, Scalpay and Great Bernera are connected to Lewis and Harris.  Inner Hebrides  Orkney Islands  Similarly, four Orkney islands are joined to the Orkney Mainland by a series of causeways known as the Churchill Barriers. They are:  Hunda is in turn connected to Burray via a causeway.  South Walls and Hoy are connected by a causeway called the Ayre. The islands are treated as one entity (Hoy) by the UK census.  An undersea tunnel between the archipelago and Caithness, at a length of about 9\u201310 miles (14\u201316\u00a0km) and a tunnel connecting Orkney Mainland to Shapinsay have been discussed,[57][58] although little has come of it.  Shetland Islands  Several Shetland islands are joined to the Shetland Mainland:  There is also a bridge from Housay to Bruray.  Others  Various other islands are also connected by bridges or causeways, to the mainland or other islands, including:  There are a large number of small tidal islands in Scotland. The more notable ones include:  Oronsay means \"ebb island\" and there are several tidal islands of this name.[61]  The three main islands of the Monach Islands (Heisgeir), Ceann Iar, Ceann Ear and Shivinish are connected at low tides. It is said that at one time it was also possible to walk all the way to Baleshare, and on to North Uist, five miles (eight kilometres) away at low tide. In the 16th century, a large tidal wave was said to have washed the route away.[2]  St Ninian's Isle is connected to Mainland Shetland by a tombolo. Although greater than 40 hectares in size it fails to meet the definition of an island used in this list as it is only surrounded by water during occasional spring tides and storms.[62]  D\u00f9n in St Kilda is separated from Hirta by a shallow strait about 50 metres (160 feet) wide. This is normally impassable but is reputed to dry out on rare occasions.[2]  There are a number of offshore islands that defy easy classification.  There are several small Scottish islands that are dominated by a castle or other fortification. The castle is often better known than the island, and the islands are often tidal or bridged. Due to their picturesque nature some of them are well known from postcards and films. Examples are:  Many of the Islands of the Forth and southern Orkney Islands have fortifications from the two world wars. Rosyth Castle stands on a former island.  A large number of the islands of Scotland have some kind of culdee\/church connection, and\/or are dominated by a church. The more notable include:  Brother Isle's name is not ecclesiastical in origin as is sometimes stated.  This is a list of islands, which are known to be named after someone. In some cases such as North Ronaldsay this status may not be obvious (it isn't named after a \"Ronald\", unlike South Ronaldsay). This list omits names such as Hildasay, where the person in question is mythological, or Ailsa Craig, where the individual in question is not known, and also Colonsay & Egilsay where the derivation is disputed.  Iqbal Singh, the owner of Vacsay, has also expressed wishes to rename it after Robert Burns.  Some places in Scotland with names including \"isle\" or \"island\" are not islands. They include:  Lewis and Harris are separated by a range of hills but form one island, and are sometimes referred to as \"Lewis and Harris\". Isle of Whithorn and the Black Isle are peninsulas, and Isleornsay is a village which looks out onto the island of Ornsay. There is no commonly accepted derivation for \"Burntisland\" which had numerous other forms in the past, such as \"Brintilun\" and \"Ye Brint Eland\".[63]  Gluss Isle at the western entrance to Sullom Voe is one of the many promontories in Orkney and Shetland connected to a larger body of land by an ayre.  The name \"Inch\" (Innis) can mean island (e.g. Inchkenneth, Inchcolm), but is also used for terra firma surrounded by marsh e.g. Markinch, Insch.  Eilean is Gaelic for \"island\". However, Inistrynich, Eilean na Maodail, Eilean Dubh and Liever Island are all promontories on Loch Awe as opposed to islands, despite their names. Likewise Eilean Aoidhe on Loch Fyne. The Black Isle is also An t-Eilean Dubh in Gaelic, while Eilean Glas is part of Scalpay.  \"-holm\" is also common as a suffix in various landlocked placenames, especially in the far south of mainland Scotland e.g. Langholm, Kirk Yetholm, Holmhead (by Cumnock), Holmhill (next to Thornhill, Nithsdale). Some of these were river islands in their time, or dry land surrounded by marsh. \"Holm\" can be found in an element in Holmsgarth, now a suburb of Lerwick and the Parish of Holm on Mainland Shetland and Mainland Orkney respectively. Neither of these is an island in its own right.  Likewise, occasionally an island may be named after a location on the nearby mainland, or a major neighbouring island - or vice versa. Examples of this include: Vementry, which was originally the name of an island, but whose name has been transferred to a nearby farm on Mainland Shetland; Oldany Island, whose name has been transferred to Oldany; Cramond Island which is named after neighbouring Cramond (a district of Edinburgh); and Eilean Mhealasta in the Outer Hebrides, which is named after Mealista on Lewis.  The name Easdale appears to be the combination of eas, which is Gaelic for \"waterfall\" and dal, the Norse for \"valley\".[64] However, it is not clear why either description should apply to this tiny island which is low lying and has no waterfalls and the name may have come from the nearby village of the same name on Seil.[65]  It has been estimated that there are about 275 sea stacks in Scotland of which circa 110 are located around the coasts of Shetland.[66] The highest are Stac an Armin and Stac Lee,[67] St Kilda. In July 1967 15 million people watched the climbing of the Old Man of Hoy live on BBC television.[68] However, for many of the remoter stacks especially in Shetland, there is no record of there having been any attempt by rock climbers to ascend them.[69]  Crannogs are prehistoric artificial islands created in lochs. There are several hundred sites in Scotland. Today, crannogs typically appear as small, circular islands, between 10 and 30 metres (30\u2013100\u00a0feet) in diameter.[70] Scottish crannogs include:  Notes  Specific references  General references   Media related to Islands of Scotland at Wikimedia Commons "},{"title":"International Football Association Board","content":"  The International Football Association Board (IFAB) is an international self-regulatory body of association football that is known for determining the Laws of the Game, the regulations for the gameplay of football. It was founded in 1886 in order to establish standardised regulations or \"Laws\" for the gameplay of international competition, and has since acted as the primary maintainer (\"Guardian\") of these Laws. FIFA, a prominent governing body for football, has recognised IFAB's jurisdiction over its Laws since its establishment in 1904.[1]  IFAB is a distant body from FIFA, although FIFA is represented on the board and holds 50% of the voting power. The founding football associations (FAs) of IFAB, England, Scotland, Northern Ireland and Wales each have permanent seats on the organisation. Amendments to the Laws mandate a three-quarter supermajority vote, meaning that FIFA's support is necessary but not sufficient for a motion to pass.  Although the rules of football had largely been standardised by the early 1880s, England's Football Association (The FA), the Scottish Football Association (SFA), the Football Association of Wales (FAW) and the Irish Football Association (IFA) had conflicting rules. When international matches were played, the rules of the home team's national association were used. While this solution was technically feasible, it was impractical. To remedy this, the FAs initialised a meeting on 6 December 1882 in Queen\u2019s Hotel, Manchester in order to systematise a set of rules that could be applied uniformly to matches between the UK football associations' national teams. This was later named the \u201cInternational Football Conference\u201d.  In the summer of 1885, the English FA declared that it legalised professionalism.[2]  The Scottish FA responded that it would refuse to allow professionals in its own national team, and would refuse to play international matches against an England team containing professionals.[3] The Irish FA attempted to arbitrate by proposing that \"an international conference should be held each year, say, in August, to be called in turn by each national association to deal with the laws of the game, and discuss other matters of interest to Association football, and at which international disputes could be adjusted\".[4]  The initial meeting of IFAB took place at The FA's offices at Holborn Viaduct in London on 2 June 1886.[5] The FA, SFA, FAW and IFA each had equal voting rights. It was chaired by Sir Francis Marindin, and attended by Charles W. Alcock acting as Secretary.[6] The meeting was notable for Marindin\u2019s proposal, which outlined \"That no player shall wear any kind of projection on the soles of heels of his boots with the exception of flat leather bars of an approved pattern\".[6]  During IFAB\u2019s annual general meeting (AGM) on 8 June 1912, the secretary, J.K. McDowall, scrutinised a letter that was attributed to the recently established FIFA, requesting that IFAB would invite a member of FIFA to sit on the Board. [7]The petition was analysed, and IFAB concluded that it wasn\u2019t the right time to establish FIFA as a member, and McDowall proceeded to write a response to the organisation explaining the consensus. At a special meeting held on 25 January 1913 in Wrexham, IFAB approved FIFA\u2019s request after a proposition by The FA was made proposing that two members from FIFA should attend the board, making FIFA the fifth member of IFAB.   For the first four post-war IFAB meetings (1920, 1921, 1922, and 1923), FIFA was once again excluded, on account of a dispute between FIFA and the home nations regarding payments to amateur players. From 1924, the dispute had been reconciled, and FIFA resumed attendance of IFAB meetings. In 1958, the Board agreed on a voting system that would be used to this day.[8]  Since Irish partition in 1921, the IFA has evolved to become the organising body for football in Northern Ireland, with football in the Republic of Ireland being organised by the FAI.  A request for the FAI to become a member of IFAB was denied at the 1923 annual general meeting.[9]  The IFAB is made up of representatives from England's Football Association (The FA), the Scottish Football Association (SFA), the Football Association of Wales (FAW) and Northern Ireland's Irish Football Association (IFA)\u2014and the F\u00e9d\u00e9ration Internationale de Football Association (FIFA, the International Association Football Federation), the international governing body for football. Each British association has one vote and FIFA has four. IFAB deliberations must be approved by three-quarters of the vote, or at least six of the eight votes.[10] Thus, FIFA's approval is necessary for any IFAB decision, but FIFA alone cannot change the Laws of the Game\u2014they need to be agreed by at least two of the UK members. As of 2016, all members must be present for a binding vote to proceed.[10]  The Board meets twice a year, once to decide on possible changes to the rules governing the game of Football (the Annual General Meeting (AGM)) and once to deliberate on its internal affairs (the Annual Business Meeting (ABM)). In FIFA World Cup years, the AGM is held at FIFA's offices; otherwise, it rotates between Northern Ireland, Wales, England and Scotland in that order.[10] Four weeks before the AGM, the member associations must send their written proposals to the secretary of the host association. FIFA then prints a list of suggestions that are distributed to all other associations for examination. The AGM is held either in February or March and the ABM is held between September and October.[11] In cases of necessity, the Board can meet in a Special Meeting in addition to the two ordinary annual meetings. As of December 2012, the last Special Meeting was hosted by FIFA in Z\u00fcrich on 5 July 2012.[12]  The decisions of each year's Annual General Meeting of the Board regarding changes to the Laws of the Game enter into force from 1 July (and are binding on FIFA and on the other members of the Board, and, given that FIFA's Statutes establish that FIFA and its member associations and affiliates adhere to the Laws of the Game laid down by IFAB, those changes bind also FIFA's other member associations, FIFA's continental confederations of member associations, and the subnational entities of the national associations) but confederations, member associations and other bodies whose current season has not ended by 1 July may delay the introduction of the adopted alterations to the Laws of the Game in their competitions until the beginning of their next season.[13] As well as permanent changes to the Laws, IFAB also authorises trials of potential amendments.[14] "},{"title":"Crown Dependencies","content":"  The Crown Dependencies[c] are three offshore island territories in the British Islands that are self-governing possessions of the British Crown: the Bailiwick of Guernsey and the Bailiwick of Jersey, both located in the English Channel and together known as the Channel Islands, and the Isle of Man in the Irish Sea between Great Britain and Ireland.  They are not parts of the United Kingdom (UK) nor are they British Overseas Territories.[1][2] They have the status of \"territories for which the United Kingdom is responsible\", rather than sovereign states.[3] As a result, they are not member states of the Commonwealth of Nations.[4] However, they do have relationships with the Commonwealth and other international organizations, and are members of the British\u2013Irish Council. They have their own teams in the Commonwealth Games.  Each island's political development has been largely independent from, though often parallel with, that of the UK,[5] and they are akin to \"miniature states with wide powers of self-government\".[6]  As the Crown Dependencies are not sovereign states, the power to pass legislation affecting the islands ultimately rests with the King-in-Council (though this power is rarely exercised without the consent of the dependencies, and the right to do so is disputed). However, they each have their own legislative assembly, with power to legislate on many local matters with the assent of the Crown (Privy Council, or, in the case of the Isle of Man, in certain circumstances the lieutenant-governor or, in the case of the Bailiwick of Guernsey, the Lieutenant-Governor).[7] In Jersey and the Isle of Man, the head of government is called the chief minister. In Guernsey, the head representative of the committee-based government is the President of the Policy and Resources Committee.  The term 'Crown Dependencies' has been disputed by Gavin St Pier, former Chief Minister of Guernsey. He argues that the term was an administrative invention of Whitehall, which incorrectly implies that the Islands are dependent upon the Crown, and advocates instead the use of the term 'Crown Dominion'.[8]  Charles III    William, Prince of Wales    Charles III(King-in-Council)    Sunak ministry (C)  Rishi Sunak (C)  Oliver Dowden (C)  (King-in-Parliament)   Charles III    The Lord McFall of Alcluith    Sir Lindsay Hoyle  Sir Keir Starmer (L)    The Lord Reed  The Lord Hodge  Andrew Bailey  Monetary Policy Committee              Since 1290,[17] the Channel Islands have been governed as:  Each Bailiwick is a Crown dependency and each is headed by a Bailiff, with a Lieutenant Governor representing the Crown in each Bailiwick. Each Bailiwick has its own legal and healthcare systems and its own separate immigration policy, with \"local status\" in one Bailiwick having no validity in the other. The two Bailiwicks exercise bilateral double taxation treaties. Since 1961, the Bailiwicks have had separate courts of appeal, but generally, the Bailiff of each Bailiwick has been appointed to serve on the panel of appellate judges for the other Bailiwick.  The Bailiwick of Guernsey comprises three separate jurisdictions:  The parliament of Guernsey is the States of Deliberation, the parliament of Sark is called the Chief Pleas, and the parliament of Alderney is called the States of Alderney. The three parliaments together can also approve joint Bailiwick-wide legislation that applies in those parts of the Bailiwick whose parliaments approve it. There are no political parties in any of the parliaments; candidates stand for election as independents.[18]  The Bailiwick of Jersey consists of the island of Jersey and a number of surrounding uninhabited islands.  The parliament is the States Assembly, the first known mention of which is in a document of 1497.[19] The States of Jersey Law 2005 introduced the post of Chief Minister of Jersey, abolished the Bailiff's power of dissent to a resolution of the States and the Lieutenant Governor's power of veto over a resolution of the States, and established that any Order in Council or Act of the United Kingdom proposed to apply to Jersey must be referred to the States so that the States can express their views on it.[20] There are few political parties, as candidates generally stand for election as independents.  The Isle of Man's Tynwald claims to be the world's oldest parliament in continuous existence, dating back to 979. (However, it does not claim to be the oldest parliament, as Iceland's Althing dates back to 930.) It consists of a popularly elected House of Keys and an indirectly elected Legislative Council, which may sit separately or jointly to consider pieces of legislation, which, when passed into law, are known as \"Acts of Tynwald\". Candidates mostly stand for election to the Keys as independents, rather than being selected by political parties. There is a Council of Ministers headed by a chief minister.[21]  Unlike the other Crown Dependencies, the Isle of Man has a Common Purse Agreement with the United Kingdom.  As overseas territories were added to the land conquered by the British, a number of towns and villages began to request formal recognition to validate their importance, and would be accorded a status if deemed to be deserving such as a borough or as a more prestigious city by the monarch. Many cities were designated over several centuries, and as Anglican dioceses began to be created the process of city creation became aligned to that used in England, being linked to the presence of a cathedral.[22]  Despite this, St Patrick's Isle on the Isle of Man which had a medieval cathedral was never granted privileges to become a city. Peel Cathedral was later built but only raised to the status of a cathedral in the 1980s. In the Channel Islands, these at first were part of a mainland French diocese, and then came under the Bishop of Winchester after the English Reformation, there was no cathedral situated amongst these islands.  Since the second Millennium, competitions have been arranged by the UK government to grant city status to settlements. In 2021, submissions for city status were invited to mark the Platinum Jubilee of Elizabeth II, with Crown Dependencies and British Overseas Territories being allowed to take part for the first time.[23] In the Dependencies, the only applicants were Douglas and Peel, both on the Isle of Man,[24] and Douglas was later granted the honour, making it the first formal city.[25]  According to the 1973 Kilbrandon Report, the Crown Dependencies are 'like miniature states'.[26][27] According to a 2010 Commons Justice Committee, they are independent from the UK and from each other and their relationship is with the Crown. The UK's responsibilities derive from that fact.[26]  All \"insular\" legislation has to receive the approval of the \"King in Council\", in effect, the Privy Council in London.[28] Certain types of domestic legislation in the Isle of Man and The Bailiwick of Guernsey, however, may be signed into law by the Lieutenant Governor, using delegated powers, without having to pass through the Privy Council. In Jersey, provisional legislation of an administrative nature may be adopted by means of triennial regulations (renewable after three years), without requiring the assent of the Privy Council.[29] Much legislation, in practice, is effected by means of secondary legislation under the authority of prior laws or Orders in Council.  A unique constitutional position has arisen in the Channel Islands as successive monarchs have confirmed the liberties and privileges of the Bailiwicks, often referring to the so-called Constitutions of King John, a legendary document supposed to have been granted by King John in the aftermath of 1204. Governments of the Bailiwicks have generally tried to avoid testing the limits of the unwritten constitution by avoiding conflict with British governments. Following the restoration of King Charles II, who had spent part of his exile in Jersey, the Channel Islands were given the right to set their own customs duties, referred to by the Jersey Legal French term as imp\u00f4ts.  The monarch is represented by a Lieutenant Governor in each Crown dependency, but this post is largely ceremonial. Since 2010 the Lieutenant Governors of each Crown dependency have been recommended to the Crown by a panel in each respective Crown dependency; this replaced the previous system of the appointments being made by the Crown on the recommendation of UK ministers.[30][31] In 2005, it was decided in the Isle of Man to replace the Lieutenant Governor with a Crown Commissioner, but this decision was reversed before it was implemented.  \"The Crown\" is defined differently in each Crown Dependency. Legislation of the Isle of Man defines the \"Crown in right of the Isle of Man\" as being separate from the \"Crown in right of the United Kingdom\".[32] In the Isle of Man the British monarch is styled Lord of Mann, a title variously held by Norse, Scottish and English kings and nobles (the English nobles in feudality to the English Crown) until it was revested into the British monarchy in 1765. The title \"Lord\" is today used irrespective of the gender of the person who holds it.  The Channel Islands are part of the territory annexed by the Duchy of Normandy in 933 from the Duchy of Brittany. This territory was added to the grant of land given in settlement by the King of France in 911 to the Viking raiders who had sailed up the Seine almost to the walls of Paris. William the Conqueror, Duke of Normandy, claimed the title King of England in 1066, following the death of Edward the Confessor, and secured the claim through the Norman conquest of England. Subsequent marriages between Kings of England and French nobles meant that Kings of England had title to more French lands than the King of France. When the King of France asserted his feudal right of patronage, the then-King of England, King John, fearing he would be imprisoned should he attend, failed to fulfill his obligation.  In 1204, the title and lands of the Duchy of Normandy and his other French possessions were stripped from King John of England by the King of France. The Channel Islands remained in the possession of the King of England, who ruled them as Duke of Normandy until the Treaty of Paris in 1259. John's son, Henry III, renounced the title of Duke of Normandy by that treaty, and none of his successors ever revived it.  The Channel Islands continued to be governed by the Kings of England as French fiefs, distinct from Normandy, until the Hundred Years' War, during which they were definitively separated from France. At no time did the Channel Islands form part of the Kingdom of England, and they remained legally separate, though under the same monarch, through the subsequent unions of England with Wales (1536), Scotland (1707) and Ireland (1801).  Charles III reigns over the Channel Islands directly, and not by virtue of his role as monarch of the United Kingdom.  No specific title is associated with his role as monarch of the Channel Islands. The monarch has been described, in Jersey, as the \"King in right of Jersey\",[13] and in legislation as the \"Sovereign of the Bailiwick of Jersey\" and \"Sovereign in right of the Bailiwick of Jersey\".[14]  In Jersey, statements in the 21st century of the constitutional position by the Law Officers of the Crown define it as the \"Crown in right of Jersey\",[33] with all Crown land in the Bailiwick of Jersey belonging to the Crown in right of Jersey and not to the Crown Estate of the United Kingdom.[34] In Guernsey, legislation refers to the \"Crown in right of the Bailiwick\",[9] and the Law Officers of the Crown of Guernsey submitted that \"The Crown in this context ordinarily means the Crown in right of the r\u00e9publique of the Bailiwick of Guernsey\"[35] and that this comprises \"the collective governmental and civic institutions, established by and under the authority of the Monarch, for the governance of these Islands, including the States of Guernsey and legislatures in the other Islands, the Royal Court and other courts, the Lieutenant Governor, Parish authorities, and the Crown acting in and through the Privy Council.\"[36] This constitutional concept is also worded as the \"Crown in right of the Bailiwick of Guernsey\".[35]  Crown Dependencies and British Overseas Territories (BOTs) share a similar geopolitical status. They are both categories of self-governing territories which fall under British sovereignty (the Head of State being the King of the United Kingdom) and for which the UK is responsible internationally. Neither Crown Dependencies nor BOTs are part of the UK and neither send representatives to the UK Parliament.[37]  However, Crown Dependencies are distinct from BOTs. Unlike BOTs, which are remnants of the British Empire, the Crown Dependencies have a much older relationship with the UK, springing from their status as 'feudatory kingdoms' subject to the English Crown. The self-governing status of the BOTs evolved through Acts of Parliament and the creation of fairly homogeneous political structures. On the other hand, the political systems of the Crown Dependencies evolved in an ad hoc manner, resulting in particular and unique political structures in each dependency.[37]  The United Kingdom, Crown Dependencies and British Overseas Territories collectively form 'one, undivided realm' under the British monarchy.[38][39] Crown Dependencies have the international status of \"territories for which the United Kingdom is responsible\" rather than sovereign states.[3] The relationship between the governments of the Crown Dependencies and the UK is \"one of mutual respect and support, i.e. a partnership\".[40] There is a significant gap between the official and operational relationship between the UK and the islands.[41]  Until 2001, responsibility for the UK Government's relationships with the Crown dependencies rested with the Home Office, but it was then transferred first to the Lord Chancellor's Department, then to the Department for Constitutional Affairs, and finally to the Ministry of Justice. In 2010, the Ministry of Justice stated that relationships with the Crown Dependencies are the responsibility of the United Kingdom Government as a whole, with the Ministry of Justice holding responsibility for the constitutional relationship and other ministries engaging with their opposite numbers in the Crown Dependencies according to their respective policy areas.[4]  The UK Government is solely responsible for defence and international representation[2] (although, in accordance with 2007 framework agreements,[42] the UK has elected not to act internationally on behalf of the Crown Dependencies without prior consultation). The Crown Dependencies are within the Common Travel Area and apply the same visa policy as the UK, but each Crown dependency has responsibility for its own customs and immigration services.  As in England, but not the United Kingdom as a whole, the Church of England is the established Church in the Isle of Man, Guernsey and Jersey.[43][44]  The constitutional and cultural proximity of the islands to the UK means that there are shared institutions and organisations. The BBC, for example, has local radio stations in the Channel Islands, and also a website run by a team based in the Isle of Man (which is included in BBC North West). Similarly, ITV Channel Television is a franchise in the UK's ITV network, while the Isle of Man falls within the ITV Granada franchise area. While the islands now assume responsibility for their own post and telecommunications, they continue to participate in the UK telephone numbering plan, and they have adopted postcode systems that are compatible with that of the UK.  The growth of offshore finance in all three territories led to a \"conflictual relationship\" with the UK Governments of the 2000s.[41]  The Crown Dependencies, together with the United Kingdom, are collectively known as the British Islands. Since the British Nationality Act 1981 came into effect, they have been treated as part of the United Kingdom for British nationality law purposes.[45] However, each Crown dependency maintains local controls over housing and employment, with special rules applying to British citizens without specified connections to that Crown dependency (as well as to non-British citizens).  On 15 May 2023, the three coats of arms of the Crown Dependencies and the sixteen heraldic shields of the British Overseas Territories, were 'immortalised' in two new stained glass windows unveiled in the Speaker's House at the New Palace of Westminster. The Speaker of the House of Commons, Sir Lindsay Hoyle, said: 'The two windows represent part of our United Kingdom family'.[46]  Before 1950, the islands were considered part of the British metropolitan territory. In 1950, a declaration was agreed such that the three territories would henceforth be each considered distinct from the UK and each other for the purposes of international laws.[26]:\u200a19\u200a  In 2007\u20132008, each Crown Dependency and the UK signed agreements[42][47][48] that established frameworks for the development of the international identity of each Crown Dependency. Among the points clarified in the agreements were that:  While the Parliament of the United Kingdom has the power to legislate for the Crown Dependencies without prior consultation, the United Kingdom is expected to seek permission from the dependencies before doing so.[49][50]  Generally speaking, the British government will only extend international agreements to the Crown Dependencies with their permission. Under international law, the British government is responsible for ensuring the dependencies comply with any treaties that extend to them.[51]  The United Kingdom Parliament has power to legislate for the Islands, but Acts of Parliament do not extend to the Islands automatically, but only by express mention or necessary implication [...] 'it can be said that a constitutional convention has been established whereby Parliament does not legislate for the islands without their consent on domestic matters'. Acts of the UK Parliament do not usually apply to the Channel Islands and the Isle of Man, unless explicitly stated. UK legislation does not ordinarily extend to them without their consent.[4] For a UK Act to extend otherwise than by an Order in Council is now very unusual.[2] The States of Jersey Law 2005[52] and subsequently the 2019 amended version of The Reform (Guernsey) Law, 1948,[53] established that all Acts of Parliament and Orders in Council which have application to either island were to be referred to their respective States assemblies for debate before registration in their Royal Court.  When deemed advisable, Acts of Parliament may be extended to the islands by means of an Order in Council (thus giving the UK Government some responsibility for good governance in the islands). An example of this was the Television Act 1954, which was extended to the Channel Islands, so as to create a local ITV franchise, known as Channel Television. By constitutional convention this is only done at the request of the insular authorities,[54] and has become a rare option (thus giving the insular authorities themselves the responsibility for good governance in the islands); the islands usually prefer nowadays to pass their own versions of laws giving effect to international treaties.  Each dependency retains its own distinct law and legal system. The Channel Islands' law systems are founded in the traditions of Norman law. For all three states, there is a right of judicial appeal to The Crown via the Judicial Committee of the Privy Council, whose judgements are binding once approved and promulgated by The King via an Order-in-Council.[41]  Westminster retains the right to legislate for the islands against their will as a last resort, but this is also rarely exercised, and may, according to legal opinion from the Attorney-General of Jersey, have fallen into desuetude \u2014 although the Department for Constitutional Affairs did not accept this argument. The Marine, &c., Broadcasting (Offences) Act 1967 was one recent piece of legislation extended to the Isle of Man against the wishes of Tynwald.[citation needed]  There are many highly authoritative assertions of Parliament's sovereignty over Jersey, such as the 1861 Civil Commissioners. According to the Kilbrandon Report, the long-standing convention against Parliament intervening in domestic matters did not limit Parliament's authority to legislate for the Crown Dependencies without consent. Baroness Hale further asserted this legal opinion in 2014 (quotation above), though she did not hear arguments from Crown Dependency governments in that case.[55]  Conversely, Jeffrey Jowell argues that Parliament's powers are 'of last resort' and do not therefore constitute paramount power to intervene in the Dependencies' internal affairs. He argues that as the powers have always been used within the limits of their justification, these have become constitutional law. Henry John Stephen argued that, as the Duchy of Normandy conquered England and its territory has never been annexed into England, the level of parliamentary sovereignty exercised elsewhere in the British Empire may not apply to the Channel Islands.[55]  The UK Government has a monopoly on advising how the royal prerogative \u2013 such as giving royal assent to Channel Islands' legislation \u2013 should be exercised in the Crown Dependencies.[55] Gavin St Pier, former Chief Minister of Guernsey, has called in 2023 for the Channel Islands to reconsider their constitutional relationship with the UK, 'making us less susceptible to whimsical breach of conventions should the UK continue to convulse politically'. He called for the Islands to have more power of the exercise of the royal prerogative by their appointment of Privy Counsellors.[56]  While their constitutional status bears some resemblance to that of the Commonwealth realms, the Crown Dependencies are not independent members of the Commonwealth of Nations. They participate in the Commonwealth of Nations by virtue of their relationship with the United Kingdom, and participate in various Commonwealth institutions in their own right. For example, all three participate in the Commonwealth Parliamentary Association and the Commonwealth Games.  All three Crown Dependencies regard the existing situation as unsatisfactory and have lobbied for change. The States of Jersey have called on the British Foreign Secretary to request that the Commonwealth Heads of Government \"consider granting associate membership to Jersey and the other Crown Dependencies as well as any other territories at a similarly advanced stage of autonomy\". Jersey has proposed that it be accorded \"self-representation in all Commonwealth meetings; full participation in debates and procedures, with a right to speak where relevant and the opportunity to enter into discussions with those who are full members; and no right to vote in the Ministerial or Heads of Government meetings, which is reserved for full members\".[57] The States of Guernsey and the Government of the Isle of Man have made calls of a similar nature for a more integrated relationship with the Commonwealth,[58] including more direct representation and enhanced participation in Commonwealth organisations and meetings, including Commonwealth Heads of Government Meetings.[59] The Chief Minister of the Isle of Man has said: \"A closer connection with the Commonwealth itself would be a welcome further development of the Island's international relationships\"[60]  The Crown Dependencies have never been EU member states, including during the period when the UK was. During that time, their relationship with the EU was governed by Protocol 3 of the European Communities Act 1972. The Dependencies were part of the EU customs territory[61] (though only the Isle of Man was in the VAT area)[62] and took part in the free movements of goods, but not the free movement of persons, services or capital.[61] The Common Agricultural Policy of the EU never applied to the Crown Dependencies, and their citizens never took part in elections to the European Parliament. Although they were still European citizens, British citizens who had a connection to the Crown Dependencies only were not entitled to freedom of movement rights.[63][64]  With the Brexit negotiations, the House of Lords produced a report titled \"Brexit: the Crown Dependencies\", which stated that the \"UK Government must continue to fulfil its constitutional obligations to represent the interests of the Crown Dependencies in international relations, even where these differ from those of the UK, both during the Brexit negotiations and beyond.\"[65] In the Great Repeal Bill white paper published on 30 March 2017 the UK government stated, \"The Government is committed to engaging with the Crown Dependencies, Gibraltar and the other Overseas Territories as we leave the EU.\"[66]:\u200ach.5\u200a  The most contentious Brexit issue was an upset to the arrangement of fishing rights of fishermen from France, Jersey, or Guernsey who wished to fish in the territorial waters of a different jurisdiction; proof of historic fishing in the jurisdiction was required in order to obtain a fishing permit, but all communications on the matter had to be routed via national or EU officials in London, Paris, or Brussels, leading to delays. This was resolved after officials in the affected French regions were allowed to communicate directly to counterparts in Guernsey and Jersey.[67]  The UK requirement for EU citizens to present passports to enter the Common Travel Area resulted in a drop of day visitors to Jersey in particular. This issue was resolved in 2022 when Jersey (with UK approval) began to allow French nationals to enter the bailiwick on day trips using just their national ID card.[68] Guernsey followed suit.  All three Crown Dependencies participate in an open borders area, along with the United Kingdom and Ireland. An informal memorandum of understanding exists between the member countries of the Common Travel Area (CTA) whereby the internal borders of each country are expected to have minimal controls, if any, and can normally be crossed by British and Irish citizens with minimal identity documents (with certain exceptions). Under Irish law, Manx people and Channel Islanders\u00a0\u2013 who were not entitled to take advantage of the European Union's freedom of movement provisions\u00a0\u2013 are exempt from immigration control and immune from deportation.[69]  In May 2019, the British and Irish governments signed a Memorandum of Understanding in an effort to secure the rights of British and Irish citizens after Brexit.[70] The document was signed in London, England before a meeting of the British-Irish Intergovernmental Conference, putting the rights of both countries' citizens, that were already in place under an informal agreement, on a more secure footing.  The agreement, which is the culmination of over two years' work of both governments, means the rights of both countries' citizens are protected after Brexit whilst also ensuring that Ireland can continue to meet its obligations under European Union law.  The agreement took effect on 31 January 2020 when the United Kingdom left the European Union. The maintenance of the CTA involves considerable cooperation on immigration matters between the British and Irish authorities.  On 26 November 2018 Jersey, Guernsey and the Isle of Man each signed a customs agreement with the United Kingdom to collectively establish a customs union.[71] "},{"title":"Sport","content":"  Sport is a form of physical activity or game.[1] Often competitive and organized, sports use, maintain, or improve physical ability and skills. They also provide enjoyment to participants and, in some cases, entertainment to spectators.[2] Many sports exist, with different participant numbers, some are done by a single person with others being done by hundreds. Most sports take place either in teams or competing as individuals. Some sports allow a \"tie\" or \"draw\", in which there is no single winner; others provide tie-breaking methods to ensure one winner. A number of contests may be arranged in a tournament format, producing a champion. Many sports leagues make an annual champion by arranging games in a regular sports season, followed in some cases by playoffs.  Sport is generally recognised as system of activities based in physical athleticism or physical dexterity, with major competitions admitting only sports meeting this definition.[3] Some organisations, such as the Council of Europe, preclude activities without any physical element from classification as sports.[2] However, a number of competitive, but non-physical, activities claim recognition as mind sports. The International Olympic Committee who oversee the Olympic Games recognises both chess and bridge as sports. SportAccord, the international sports federation association, recognises five non-physical sports: bridge, chess, draughts, Go and xiangqi.[4][5] However, they limit the number of mind games which can be admitted as sports.[1] Sport is usually governed by a set of rules or customs, which serve to ensure fair competition. Winning can be determined by physical events such as scoring goals or crossing a line first. It can also be determined by judges who are scoring elements of the sporting performance, including objective or subjective measures such as technical performance or artistic impression.  Records of performance are often kept, and for popular sports, this information may be widely announced or reported in sport news. Sport is also a major source of entertainment for non-participants, with spectator sport drawing large crowds to sport venues, and reaching wider audiences through broadcasting. Sport betting is in some cases severely regulated, and in some cases is central to the sport.  According to A.T. Kearney, a consultancy, the global sporting industry is worth up to $620 billion as of 2013.[6] The world's most accessible and practised sport is running, while association football is the most popular spectator sport.[7]  The word \"sport\" comes from the Old French desport meaning \"leisure\", with the oldest definition in English from around 1300 being \"anything humans find amusing or entertaining\".[8]  Other meanings include gambling and events staged for the purpose of gambling; hunting; and games and diversions, including ones that require exercise.[9] Roget's defines the noun sport as an \"activity engaged in for relaxation and amusement\" with synonyms including diversion and recreation.[10]  The singular term \"sport\" is used in most English dialects to describe the overall concept (e.g. \"children taking part in sport\"), with \"sports\" used to describe multiple activities (e.g. \"football and rugby are the most popular sports in England\"). American English uses \"sports\" for both terms.[citation needed]  The precise definition of what differentiates a sport from other leisure activities varies between sources. The closest to an international agreement on a definition is provided by the Global Association of International Sports Federations (GAISF), which is the association for all the largest international sports federations (including association football, athletics, cycling, tennis, equestrian sports, and more), and is therefore the de facto representative of international sport.  GAISF uses the following criteria, determining that a sport should:[1]  They also recognise that sport can be primarily physical (such as rugby or athletics), primarily mind (such as chess or Go), predominantly motorised (such as Formula 1 or powerboating), primarily co-ordination (such as snooker and other cue sports), or primarily animal-supported (such as equestrian sport).[1]  The inclusion of mind sports within sport definitions has not been universally accepted, leading to legal challenges from governing bodies in regards to being denied funding available to sports.[11] Whilst GAISF recognises a small number of mind sports, it is not open to admitting any further mind sports.  There has been an increase in the application of the term \"sport\" to a wider set of non-physical challenges such as video games, also called esports (from \"electronic sports\"), especially due to the large scale of participation and organised competition, but these are not widely recognised by mainstream sports organisations. According to Council of Europe, European Sports Charter, article 2.i, \"'Sport' means all forms of physical activity which, through casual or organised participation, aim at expressing or improving physical fitness and mental well-being, forming social relationships or obtaining results in competition at all levels.\"[12]  There are opposing views on the necessity of competition as a defining element of a sport, with almost all professional sports involving competition, and governing bodies requiring competition as a prerequisite of recognition by the International Olympic Committee (IOC) or GAISF.[1]  Other bodies advocate widening the definition of sport to include all physical activity. For instance, the Council of Europe include all forms of physical exercise, including those competed just for fun.[citation needed]  In order to widen participation, and reduce the impact of losing on less able participants, there has been an introduction of non-competitive physical activity to traditionally competitive events such as school sports days, although moves like this are often controversial.[13][14]  In competitive events, participants are graded or classified based on their \"result\" and often divided into groups of comparable performance, (e.g. gender, weight and age). The measurement of the result may be objective or subjective, and corrected with \"handicaps\" or penalties. In a race, for example, the time to complete the course is an objective measurement. In gymnastics or diving the result is decided by a panel of judges, and therefore subjective. There are many shades of judging between boxing and mixed martial arts, where victory is assigned by judges if neither competitor has lost at the end of the match time.[citation needed]  Artifacts and structures suggest sport in China as early as 2000 BC.[15] Gymnastics appears to have been popular in China's ancient past. Monuments to the Pharaohs indicate that a number of sports, including swimming and fishing, were well-developed and regulated several thousands of years ago in ancient Egypt.[16] Other Egyptian sports included javelin throwing, high jump, and wrestling. Ancient Persian sports such as the traditional Iranian martial art of Zoorkhaneh had a close connection to warfare skills.[17] Among other sports that originated in ancient Persia are polo and jousting. The traditional South Asian sport of kabaddi has been played for thousands of years, potentially as a preparation for hunting.[18]  A wide range of sports were already established by the time of Ancient Greece and the military culture and the development of sport in Greece influenced one another considerably. Sport became such a prominent part of their culture that the Greeks created the Olympic Games, which in ancient times were held every four years in a small village in the Peloponnesus called Olympia.[19]  Sports have been increasingly organised and regulated from the time of the ancient Olympics up to the present century. Industrialisation has brought motorised transportation and increased leisure time, letting people attend and follow spectator sports and participate in athletic activities. These trends continued with the advent of mass media and global communication. Professionalism became prevalent, further adding to the increase in sport's popularity, as sports fans followed the exploits of professional athletes\u00a0\u2013 all while enjoying the exercise and competition associated with amateur participation in sports. Since the turn of the 21st\u00a0century, there has been increasing debate about whether transgender sports people should be able to participate in sport events that conform with their post-transition gender identity.[20]  Sportsmanship is an attitude that strives for fair play, courtesy toward teammates and opponents, ethical behaviour and integrity, and grace in victory or defeat.[21][22][23]  Sportsmanship expresses an aspiration or ethos that the activity will be enjoyed for its own sake. The well-known sentiment by sports journalist Grantland Rice, that it is \"not that you won or lost but how you played the game\", and the modern Olympic creed expressed by its founder Pierre de Coubertin: \"The most important thing... is not winning but taking part\" are typical expressions of this sentiment.[citation needed]  Key principles of sport include that the result should not be predetermined, and that both sides should have equal opportunity to win. Rules are in place to ensure fair play, but participants can break these rules in order to gain advantage.  Participants may cheat in order to unfairly increase their chance of winning, or in order to achieve other advantages such as financial gains. The widespread existence of gambling on the results of sports events creates a motivation for match fixing, where a participant or participants deliberately work to ensure a given outcome rather than simply playing to win.  The competitive nature of sport encourages some participants to attempt to enhance their performance through the use of medicines, or through other means such as increasing the volume of blood in their bodies through artificial means.  All sports recognised by the IOC or SportAccord are required to implement a testing programme, looking for a list of banned drugs, with suspensions or bans being placed on participants who test positive for banned substances.[citation needed]  Violence in sports involves crossing the line between fair competition and intentional aggressive violence. Athletes, coaches, fans, and parents sometimes unleash violent behaviour on people or property, in misguided shows of loyalty, dominance, anger, or celebration. Rioting or hooliganism by fans in particular is a problem at some national and international sporting contests.[citation needed]  Female participation in sports continues to rise alongside the opportunity for involvement and the value of sports for child development and physical fitness. Despite increases in female participation during the last three decades, a gap persists in the enrolment figures between male and female players in sports-related teams. Female players account for 39% of the total participation in US interscholastic athletics.[citation needed]  Certain sports are mixed-gender, allowing (or even requiring) men and women to play on the same team. One example of this is Baseball5, which is the first mixed-gender sport to have been admitted into an Olympic event.[24]  Youth sport presents children with opportunities for fun, socialisation, forming peer relationships, physical fitness, and athletic scholarships. Activists for education and the war on drugs encourage youth sport as a means to increase educational participation and to fight the illegal drug trade. According to the Center for Injury Research and Policy at Nationwide Children's Hospital, the biggest risk for youth sport is death or serious injury including concussion. These risks come from running, basketball, association football, volleyball, gridiron, gymnastics, and ice hockey.[25] Youth sport in the US is a $15 billion industry including equipment up to private coaching.[26]  Disabled or adaptive sports are played by people with a disability, including physical and intellectual disabilities. As many of these are based on existing sports modified to meet the needs of people with a disability, they are sometimes referred to as adapted sports. However, not all disabled sports are adapted; several sports that have been specifically created for people with a disability have no equivalent in able-bodied sports.[citation needed]  The competition element of sport, along with the aesthetic appeal of some sports, result in the popularity of people attending to watch sport being played. This has led to the specific phenomenon of spectator sport.  Both amateur and professional sports attract spectators, both in person at the sport venue, and through broadcast media including radio, television and internet broadcast. Both attendance in person and viewing remotely can incur a sometimes substantial charge, such as an entrance ticket, or pay-per-view television broadcast. Sports league and tournament are two common arrangements to organise sport teams or individual athletes into competing against each other continuously or periodically.[citation needed]  It is common for popular sports to attract large broadcast audiences, leading to rival broadcasters bidding large amounts of money for the rights to show certain events. The football World Cup attracts a global television audience of hundreds of millions; the 2006 final alone attracted an estimated worldwide audience of well over 700\u00a0million and the 2011 Cricket World Cup Final attracted an estimated audience of 135\u00a0million in India alone.[27]  In the United States, the championship game of the NFL, the Super Bowl, has become one of the most watched television broadcasts of the year.[28][29] Super Bowl Sunday is a de facto national holiday in America;[30][31] the viewership being so great that in 2015, advertising space was reported as being sold at $4.5m for a 30-second slot.[28]  Sport can be undertaken on an amateur, professional or semi-professional basis, depending on whether participants are incentivised for participation (usually through payment of a wage or salary). Amateur participation in sport at lower levels is often called \"grassroots sport\".[2][32]  The popularity of spectator sport as a recreation for non-participants has led to sport becoming a major business in its own right, and this has incentivised a high paying professional sport culture, where high performing participants are rewarded with pay far in excess of average wages, which can run into millions of dollars.[33]  Some sports, or individual competitions within a sport, retain a policy of allowing only amateur sport. The Olympic Games started with a principle of amateur competition with those who practised a sport professionally considered to have an unfair advantage over those who practised it merely as a hobby.[34] From 1971, Olympic athletes were allowed to receive compensation and sponsorship,[35] and from 1986, the IOC decided to make all professional athletes eligible for the Olympics,[35][36] with the exceptions of boxing,[37][38] and wrestling.[39][40]  Technology plays an important part in modern sport. It is a necessary part of some sports (such as motorsport), and it is used in others to improve performance. Some sports also use it to allow off-field decision making.  Sports science is a widespread academic discipline, and can be applied to areas including athlete performance, such as the use of video analysis to fine-tune technique, or to equipment, such as improved running shoes or competitive swimwear. Sports engineering emerged as a discipline in 1998 with an increasing focus not just on materials design but also the use of technology in sport, from analytics and big data to wearable technology.[41] In order to control the impact of technology on fair play, governing bodies frequently have specific rules that are set to control the impact of technical advantage between participants. For example, in 2010, full-body, non-textile swimsuits were banned by FINA, as they were enhancing swimmers' performances.[42][43]  The increase in technology has also allowed many decisions in sports matches to be taken, or reviewed, off-field, with another official using instant replays to make decisions. In some sports, players can now challenge decisions made by officials. In Association football, goal-line technology makes decisions on whether a ball has crossed the goal line or not.[44] The technology is not compulsory,[45] but was used in the 2014 FIFA World Cup in Brazil,[46] and the 2015 FIFA Women's World Cup in Canada,[47] as well as in the Premier League from 2013\u201314,[48] and the Bundesliga from 2015\u201316.[49] In the NFL, a referee can ask for a review from the replay booth, or a head coach can issue a challenge to review the play using replays. The final decision rests with the referee.[50] A video referee (commonly known as a Television Match Official or TMO) can also use replays to help decision-making in rugby (both league and union).[51][52] In international cricket, an umpire can ask the Third umpire for a decision, and the third umpire makes the final decision.[53][54] Since 2008, a decision review system for players to review decisions has been introduced and used in ICC-run tournaments, and optionally in other matches.[53][55] Depending on the host broadcaster, a number of different technologies are used during an umpire or player review, including instant replays, Hawk-Eye, Hot Spot and Real Time Snickometer.[56][57] Hawk-Eye is also used in tennis to challenge umpiring decisions.[58][59]  Research suggests that sports have the capacity to connect youth to positive adult role models and provide positive development opportunities, as well as promote the learning and application of life skills.[60][61] In recent years the use of sport to reduce crime, as well as to prevent violent extremism and radicalization, has become more widespread, especially as a tool to improve self-esteem, enhance social bonds and provide participants with a feeling of purpose.[61]  There is no high-quality evidence that shows the effectiveness of interventions to increase sports participation of the community in sports such as mass media campaigns, educational sessions, and policy changes.[62] There is also no high-quality studies that investigate the effect of such interventions in promoting healthy behaviour change in the community.[63] sports is one of the important part of life  Benito Mussolini used the 1934 FIFA World Cup, which was held in Italy, to showcase Fascist Italy.[64][65] Adolf Hitler also used the 1936 Summer Olympics held in Berlin, and the 1936 Winter Olympics held in Garmisch-Partenkirchen, to promote the Nazi ideology of the superiority of the Aryan race, and inferiority of the Jews and other \"undesirables\".[65][66] Germany used the Olympics to give off a peaceful image while secretly preparing for war.[67]  When apartheid was the official policy in South Africa, many sports people, particularly in rugby union, adopted the conscientious approach that they should not appear in competitive sports there. Some feel this was an effective contribution to the eventual demolition of the policy of apartheid, others feel that it may have prolonged and reinforced its worst effects.[68]  In the history of Ireland, Gaelic sports were connected with cultural nationalism. Until the mid-20th\u00a0century a person could have been banned from playing Gaelic football, hurling, or other sports administered by the Gaelic Athletic Association (GAA) if she\/he played or supported Association football, or other games seen to be of British origin. Until recently the GAA continued to ban the playing of football and rugby union at Gaelic venues. This ban, also known as Rule 42,[69] is still enforced, but was modified to allow football and rugby to be played in Croke Park while Lansdowne Road was redeveloped into Aviva Stadium. Until recently, under Rule 21, the GAA also banned members of the British security forces and members of the RUC from playing Gaelic games, but the advent of the Good Friday Agreement in 1998 led to the eventual removal of the ban.[70]  Nationalism is often evident in the pursuit of sport, or in its reporting: people compete in national teams, or commentators and audiences can adopt a partisan view. On occasion, such tensions can lead to violent confrontation among players or spectators within and beyond the sporting venue, as in the Football War. These trends are seen by many as contrary to the fundamental ethos of sport being carried on for its own sake and for the enjoyment of its participants. Sport and politics collided in the 1972 Olympics in Munich. Masked men entered the hotel of the Israeli Olympic team and killed many of their men. This was known as the Munich massacre.[citation needed]  A study of US elections has shown that the result of sports events can affect the results. A study published in the Proceedings of the National Academy of Sciences showed that when the home team wins the game before the election, the incumbent candidates can increase their share of the vote by 1.5\u00a0per cent. A loss had the opposite effect, and the effect is greater for higher-profile teams or unexpected wins and losses.[71] Also, when Washington Redskins win their final game before an election, then the incumbent president is more likely to win, and if the Redskins lose, then the opposition candidate is more likely to win; this has become known as the Redskins Rule.[72][73]  \u00c9tienne de La Bo\u00e9tie, in his essay Discourse on Voluntary Servitude describes athletic spectacles as means for tyrants to control their subjects by distracting them.  Do not imagine that there is any bird more easily caught by decoy, nor any fish sooner fixed on the hook by wormy bait, than are all these poor fools neatly tricked into servitude by the slightest feather passed, so to speak, before their mouths. Truly it is a marvellous thing that they let themselves be caught so quickly at the slightest tickling of their fancy. Plays, farces, spectacles, gladiators, strange beasts, medals, pictures, and other such opiates, these were for ancient peoples the bait toward slavery, the price of their liberty, the instruments of tyranny. By these practices and enticements the ancient dictators so successfully lulled their subjects under the yoke, that the stupefied peoples, fascinated by the pastimes and vain pleasures flashed before their eyes, learned subservience as na\u00efvely, but not so creditably, as little children learn to read by looking at bright picture books.[74]  During the British rule of Bengal, British and European sports began to supplant traditional Bengali sports, resulting in a loss of native culture.[75][76]  Sport was an important form of worship in Ancient Greek religion. The ancient Olympic Games were held in honour of the head deity, Zeus, and featured various forms of religious dedication to him and other gods.[77]  The practice of athletic competitions has been criticised by some Christian thinkers as a form of idolatry, in which \"human beings extol themselves, adore themselves, sacrifice themselves and reward themselves.\"[78] Sports are seen by these critics as a manifestation of \"collective pride\" and \"national self-deification\" in which feats of human power are idolised at the expense of divine worship.[78]  Tertullian condemns the athletic performances of his day, insisting \"the entire apparatus of the shows is based upon idolatry.\"[79] The shows, says Tertullian, excite passions foreign to the calm temperament cultivated by the Christian:  God has enjoined us to deal calmly, gently, quietly, and peacefully with the Holy Spirit, because these things are alone in keeping with the goodness of His nature, with His tenderness and sensitiveness. ... Well, how shall this be made to accord with the shows? For the show always leads to spiritual agitation, since where there is pleasure, there is keenness of feeling giving pleasure its zest; and where there is keenness of feeling, there is rivalry giving in turn its zest to that. Then, too, where you have rivalry, you have rage, bitterness, wrath and grief, with all bad things which flow from them\u00a0\u2013 the whole entirely out of keeping with the religion of Christ.[80]  Christian clerics in the Wesleyan-Holiness movement oppose the viewing of or participation in professional sports, believing that professional sports leagues profane the Sabbath as in the modern era, certain associations hold games on the Lord's Day.[81] They also criticise professional sports for its fostering of a commitment that competes with a Christian's primary commitment to God in opposition to 1 Corinthians 7:35, what they perceive to be a lack of modesty in the players' and cheerleaders' uniforms (which are not in conformity with the Methodistic doctrine of outward holiness), its association with violence in opposition to Hebrews 7:26, what they perceive to be the extensive use of profanity among many players that contravenes Colossians 3:8\u201310, and the frequent presence of gambling, as well as alcohol and other drugs at sporting events, which go against a commitment to teetotalism.[81]  Related topics  \u00a0This article incorporates text from a free content work.  Licensed under CC BY-SA 3.0 IGO. Text taken from Strengthening the rule of law through education: a guide for policymakers\u200b,  UNESCO, UNESCO. UNESCO.   "},{"title":"Parliamentary procedure","content":"Parliamentary procedures are the accepted rules, ethics, and customs governing meetings of an assembly or organization. Their object is to allow orderly deliberation upon questions of interest to the organization and thus to arrive at the sense or the will of the majority of the assembly upon these questions.[1] Self-governing organizations follow parliamentary procedure to debate and reach group decisions, usually by vote, with the least possible friction.  In the United Kingdom, Canada, Ireland, Australia, New Zealand, South Africa, and other English-speaking countries, parliamentary procedure is often called chairmanship, chairing, the law of meetings, procedure at meetings, the conduct of meetings, or the standing orders. In the United States, it is referred to as parliamentary law, parliamentary practice, legislative procedure, rules of order, or Robert's rules of order.[2]  Rules of order consist of rules written by the body itself (often referred to as bylaws), usually supplemented by a published parliamentary authority adopted by the body. Typically, national, state or provincial and other full-scale legislative assemblies have extensive internally written rules of order, whereas non-legislative bodies write and adopt a limited set of specific rules as the need arises.  The term parliamentary procedure gets its name from its use in the parliamentary system of government.[3]  In the 16th and 17th century, the parliaments of England began adopting rules of order.[4] In the 1560s, Sir Thomas Smyth began the process of writing down accepted procedures and published a book about them for the House of Commons in 1583.[4]  Early rules included:  The Westminster parliamentary procedures are followed in several Commonwealth countries, including the United Kingdom, Canada, Australia, New Zealand, India, and South Africa, as well as in the Republic of Ireland.  In Canada, for example, the House of Commons uses House of Commons Procedure and Practice as its primary procedural authority. Others include Arthur Beauchesne's Parliamentary Rules and Forms of the House of Commons of Canada,  Sir John George Bourinot's Parliamentary Procedure and Practice in the Dominion of Canada, and Erskine May's The Law, Privileges, Proceedings and Usage of Parliament from Britain.[6]  The rules of the United States Congress were developed from parliamentary procedures used in Britain.[7] Many nations' legislatures follow American parliamentary procedure,[citation needed] including Indonesia, the Philippines, Mexico and South Korea.  The procedures of the Diet of Japan moved away from the British parliamentary model, when in Occupied Japan, there were efforts to align Japanese parliamentary procedures with American congressional practices.[8] In Japan, informal negotiations are more important than formal procedures.[9]  In Italy, written rules govern the Houses of the Parliament. The Constitutional Court judges the limits beyond which these regulations cannot go, exceeding the parliamentary or political function (judgement n. 120 of 2014)[10] and on their bad application when a law is passed.[11]  Parliamentary procedure is based on the principles of allowing the majority to make decisions effectively and efficiently (majority rule), while ensuring fairness towards the minority and giving each member or delegate the right to voice an opinion.[12] Voting determines the will of the assembly. While each assembly may create their own set of rules, these sets tend to be more alike than different. A common practice is to adopt a standard reference book on parliamentary procedure and modify it through special rules of order that supersede the adopted authority.  A parliamentary structure conducts business through motions, which cause actions. Members bring business before the assembly by introducing main motions. \"Members use subsidiary motions to alter a main motion, or delay or hasten its consideration.\"[13] Parliamentary procedure also allows for rules in regards to nomination, voting, debate, disciplinary action, appeals, and the drafting of organization charters, constitutions, and bylaws.  Robert's Rules of Order Newly Revised[14] aspires to be a comprehensive guide: \"New editions have marked the growth of parliamentary procedure as cases occurring in assemblies have pointed to a need for further rules or additional interpretations to go by.\"[15] Robert's Rules of Order The Modern Edition[16] and The Standard Code of Parliamentary Procedure[17] aspire to be concise. \"This book is a basic reference book but does not claim to be comprehensive. For most organization and for most meetings, it will prove very adequate.\"[18] \"Alice Sturgis believed that confusing or unnecessary motions and terminology should be eliminated. Her goal was to make the process simpler, fairer, and easier to understand, and The Standard Code of Parliamentary Procedure did just that ...\"[19]  A common text in use in the UK, particularly within trade unions, is Walter Citrine's ABC of Chairmanship.  In English-speaking Canada, popular authorities include Kerr & King's Procedures for Meeting and Organizations. The Conservative Party of Canada uses Wainberg's Society meetings including rules of order to run its internal affairs.  In French-speaking Canada, commonly used rules of order for ordinary societies include Victor Morin's Proc\u00e9dures des assembl\u00e9es d\u00e9lib\u00e9rantes (commonly known as the Code Morin)[20] and the Code Conf\u00e9d\u00e9ration des syndicats nationaux.  Legislative assemblies in all countries, because of their nature, tend to have a specialized set of rules that differ from parliamentary procedure used by clubs and organizations.  In the United Kingdom, Thomas Erskine May's Treatise on the Law, Privileges, Proceedings and Usage of Parliament (often referred to simply as Erskine May) is the accepted authority on the powers and procedures of the Westminster parliament. There are also the Standing Orders for each House.[21]  Of the 99 state legislative chambers in the United States (two for each state except Nebraska, which has a unicameral legislature), Mason's Manual of Legislative Procedure governs parliamentary procedures in 70; Jefferson's Manual governs 13, and Robert's Rules of Order governs four.[22] The United States Senate follows the Standing Rules of the United States Senate, while the United States House of Representatives follows Jefferson's Manual.  Mason's Manual, originally written by constitutional scholar and former California Senate staff member Paul Mason in 1935, and since his death revised and published by the National Conference of State Legislatures (NCSL), governs legislative procedures in instances where the state constitution, state statutes, and the chamber's rules are silent.[23][24][25]  According to the NCSL,[24] one of the many reasons that most state legislatures use Mason's Manual instead of Robert's Rules of Order is that Robert's Rules applies best to private organizations and civic groups that do not meet in daily public sessions. Mason's Manual, however, is geared specifically toward state legislative bodies.  In the United States, individuals who are proficient in parliamentary procedure are called parliamentarians (in other English-speaking countries with parliamentary forms of government, \"parliamentarian\" refers to a member of Parliament).  Several organizations offer certification programs for parliamentarians, including the National Association of Parliamentarians and American Institute of Parliamentarians. Agriculture teachers who coach teams in the parliamentary procedure contest of the National FFA Organization (formerly Future Farmers of America) can earn the title Accredited Parliamentarian. Parliamentarians perform an important role in many meetings, including counseling organizations on parliamentary law, holding elections, or writing amendments to the constitution and bylaws of an organization. "},{"title":"Cricket","content":"  First-class cricket  One Day International  Limited overs (domestic)  Twenty20 International  Twenty20 (domestic)  Other forms  Cricket is a bat-and-ball game that is played between two teams of eleven players on a field at the centre of which is a 22-yard (20-metre) pitch with a wicket at each end, each comprising two bails balanced on three stumps. Two players from the batting team (the striker and nonstriker) stand in front of either wicket, with one player from the fielding team (the bowler) bowling the ball towards the striker's wicket from the opposite end of the pitch. The striker's goal is to hit the bowled ball and then switch places with the nonstriker, with the batting team scoring one run for each exchange. Runs are also scored when the ball reaches or crosses the boundary of the field or when the ball is bowled illegally.  The fielding team tries to prevent runs from being scored by dismissing batters (so they are \"out\"). Means of dismissal include being bowled, when the ball hits the striker's wicket and dislodges the bails, and by the fielding side either catching the ball after it is hit by the bat, but before it hits the ground, or hitting a wicket with the ball before a batter can cross the crease in front of the wicket. When ten batters have been dismissed, the innings ends and the teams swap roles. Forms of cricket range from Twenty20 (also known as T20), with each team batting for a single innings of 20 overs (each \"over\" being a set of 6 fair opportunities for the batting team to score) and the game generally lasting three to four hours, to Test matches played over five days.  Traditionally cricketers play in all-white kit, but in limited overs cricket they wear club or team colours. In addition to the basic kit, some players wear protective gear to prevent injury caused by the ball, which is a hard, solid spheroid made of compressed leather with a slightly raised sewn seam enclosing a cork core layered with tightly wound string.  The earliest known definite reference to cricket is to it being played in South East England in the mid-16th century. It spread globally with the expansion of the British Empire, with the first international matches in the second half of the 19th century. The game's governing body is the International Cricket Council (ICC), which has over 100 members, twelve of which are full members who play Test matches. The game's rules, the Laws of Cricket, are maintained by Marylebone Cricket Club (MCC) in London. The sport is followed primarily in South Asia, Australia, New Zealand, the United Kingdom, Southern Africa and the West Indies.[1]  Women's cricket, which is organised and played separately, has also achieved international standard.  The most successful side playing international cricket is Australia, which has won eight One Day International trophies, including six World Cups, more than any other country and has been the top-rated Test side more than any other country.[citation needed]  Cricket is one of many games in the \"club ball\" sphere that basically involve hitting a ball with a hand-held implement; others include baseball (which shares many similarities with cricket, both belonging in the more specific bat-and-ball games category[2]), golf, hockey, tennis, squash, badminton and table tennis.[3] In cricket's case, a key difference is the existence of a solid target structure, the wicket (originally, it is thought, a \"wicket gate\" through which sheep were herded), that the batter must defend.[4] The cricket historian Harry Altham identified three \"groups\" of \"club ball\" games: the \"hockey group\", in which the ball is driven to and from between two targets (the goals); the \"golf group\", in which the ball is driven towards an undefended target (the hole); and the \"cricket group\", in which \"the ball is aimed at a mark (the wicket) and driven away from it\".[5]  It is generally believed that cricket originated as a children's game in the south-eastern counties of England, sometime during the medieval period.[4] Although there are claims for prior dates, the earliest definite reference to cricket being played comes from evidence given at a court case in Guildford in January 1597 (Old Style, equating to January 1598 in the modern calendar). The case concerned ownership of a certain plot of land and the court heard the testimony of a 59-year-old coroner, John Derrick, who gave witness that:[6][7][8]  Being a scholler in the ffree schoole of Guldeford hee and diverse of his fellows did runne and play there at creckett and other plaies. Given Derrick's age, it was about half a century earlier when he was at school and so it is certain that cricket was being played c.\u20091550 by boys in Surrey.[8] The view that it was originally a children's game is reinforced by Randle Cotgrave's 1611 English-French dictionary in which he defined the noun \"crosse\" as \"the crooked staff wherewith boys play at cricket\" and the verb form \"crosser\" as \"to play at cricket\".[9][10]  One possible source for the sport's name is the Old English word \"cryce\" (or \"cricc\") meaning a crutch or staff. In Samuel Johnson's Dictionary, he derived cricket from \"cryce, Saxon, a stick\".[6] In Old French, the word \"criquet\" seems to have meant a kind of club or stick.[11] Given the strong medieval trade connections between south-east England and the County of Flanders when the latter belonged to the Duchy of Burgundy, the name may have been derived from the Middle Dutch (in use in Flanders at the time) \"krick\"(-e), meaning a stick (crook).[11] Another possible source is the Middle Dutch word \"krickstoel\", meaning a long low stool used for kneeling in church and which resembled the long low wicket with two stumps used in early cricket.[12] According to Heiner Gillmeister, a European language expert of Bonn University, \"cricket\" derives from the Middle Dutch phrase for hockey, met de (krik ket)sen (i.e., \"with the stick chase\").[13] Gillmeister has suggested that not only the name but also the sport itself may be of Flemish origin.[13]  Although the main object of the game has always been to score the most runs, the early form of cricket differed from the modern game in certain key technical aspects; the North American variant of cricket known as wicket retained many of these aspects.[14] The ball was bowled underarm by the bowler and along the ground towards a batter armed with a bat that in shape resembled a hockey stick; the batter defended a low, two-stump wicket; and runs were called notches because the scorers recorded them by notching tally sticks.[15][16][17]  In 1611, the year Cotgrave's dictionary was published, ecclesiastical court records at Sidlesham in Sussex state that two parishioners, Bartholomew Wyatt and Richard Latter, failed to attend church on Easter Sunday because they were playing cricket. They were fined 12d each and ordered to do penance.[18] This is the earliest mention of adult participation in cricket and it was around the same time that the earliest known organised inter-parish or village match was played \u2013 at Chevening, Kent.[6][19] In 1624, a player called Jasper Vinall died after he was accidentally struck on the head during a match between two parish teams in Sussex.[20]  Cricket remained a low-key local pursuit for much of the 17th century.[10] It is known, through numerous references found in the records of ecclesiastical court cases, to have been proscribed at times by the Puritans before and during the Commonwealth.[21][22] The problem was nearly always the issue of Sunday play as the Puritans considered cricket to be \"profane\" if played on the Sabbath, especially if large crowds or gambling were involved.[23][24]  According to the social historian Derek Birley, there was a \"great upsurge of sport after the Restoration\" in 1660.[25] Several members of the court of King Charles II took a strong interest in cricket during that era.[26] Gambling on sport became a problem significant enough for Parliament to pass the 1664 Gambling Act, limiting stakes to \u00a3100 which was, in any case, a colossal sum exceeding the annual income of 99% of the population.[25] Along with horse racing, as well as prizefighting and other types of blood sport, cricket was perceived to be a gambling sport.[27] Rich patrons made matches for high stakes, forming teams in which they engaged the first professional players.[28] By the end of the century, cricket had developed into a major sport that was spreading throughout England and was already being taken abroad by English mariners and colonisers \u2013 the earliest reference to cricket overseas is dated 1676.[29] A 1697 newspaper report survives of \"a great cricket match\" played in Sussex \"for fifty guineas apiece\" \u2013 this is the earliest known contest that is generally considered a First Class match.[30][31]  The patrons, and other players from the social class known as the \"gentry\", began to classify themselves as \"amateurs\"[fn 1] to establish a clear distinction from the professionals, who were invariably members of the working class, even to the point of having separate changing and dining facilities.[32] The gentry, including such high-ranking nobles as the Dukes of Richmond, exerted their honour code of noblesse oblige to claim rights of leadership in any sporting contests they took part in, especially as it was necessary for them to play alongside their \"social inferiors\" if they were to win their bets.[33] In time, a perception took hold that the typical amateur who played in first-class cricket, until 1962 when amateurism was abolished, was someone with a public school education who had then gone to one of Cambridge or Oxford University \u2013 society insisted that such people were \"officers and gentlemen\" whose destiny was to provide leadership.[34] In a purely financial sense, the cricketing amateur would theoretically claim expenses for playing while his professional counterpart played under contract and was paid a wage or match fee; in practice, many amateurs claimed more than actual expenditure and the derisive term \"shamateur\" was coined to describe the practice.[35][36]  The game underwent major development in the 18th century to become England's national sport.[37] Its success was underwritten by the twin necessities of patronage and betting.[38] Cricket was prominent in London as early as 1707 and, in the middle years of the century, large crowds flocked to matches on the Artillery Ground in Finsbury.[citation needed] The single wicket form of the sport attracted huge crowds and wagers to match, its popularity peaking in the 1748 season.[39] Bowling underwent an evolution around 1760 when bowlers began to pitch the ball instead of rolling or skimming it towards the batter. This caused a revolution in bat design because, to deal with the bouncing ball, it was necessary to introduce the modern straight bat in place of the old \"hockey stick\" shape.[40][citation needed]  The Hambledon Club was founded in the 1760s and, for the next twenty years until the formation of Marylebone Cricket Club (MCC) and the opening of Lord's Old Ground in 1787, Hambledon was both the game's greatest club and its focal point.[citation needed] MCC quickly became the sport's premier club and the custodian of the Laws of Cricket. New Laws introduced in the latter part of the 18th century included the three stump wicket and leg before wicket (lbw).[41]  The 19th century saw underarm bowling superseded by first roundarm and then overarm bowling. Both developments were controversial.[42] Organisation of the game at county level led to the creation of the county clubs, starting with Sussex in 1839.[43] In December 1889, the eight leading county clubs formed the official County Championship, which began in 1890.[44]  The most famous player of the 19th century was W. G. Grace, who started his long and influential career in 1865. It was especially during the career of Grace that the distinction between amateurs and professionals became blurred by the existence of players like him who were nominally amateur but, in terms of their financial gain, de facto professional. Grace himself was said to have been paid more money for playing cricket than any professional.[citation needed]  The last two decades before the First World War have been called the \"Golden Age of cricket\". It is a nostalgic name prompted by the collective sense of loss resulting from the war, but the period did produce some great players and memorable matches, especially as organised competition at county and Test level developed.[45]  In 1844, the first-ever international match took place between what were essentially club teams, from the United States and Canada, in Toronto; Canada won.[46][47] In 1859, a team of English players went to North America on the first overseas tour.[48] Meanwhile, the British Empire had been instrumental in spreading the game overseas and by the middle of the 19th century it had become well established in Australia, the Caribbean, British India (which includes present-day Pakistan and Bangladesh), New Zealand, North America and South Africa.[49]  In 1862, an English team made the first tour of Australia.[50] The first Australian team to travel overseas consisted of Aboriginal stockmen which toured England in 1868.[51]  In 1876\u201377, an England team took part in what was retrospectively recognized as the first-ever Test match at the Melbourne Cricket Ground against Australia.[52] The rivalry between England and Australia gave birth to The Ashes in 1882, and this has remained Test cricket's most famous contest.[53] Test cricket began to expand in 1888\u201389 when South Africa played England.[54]  The inter-war years were dominated by Australia's Don Bradman, statistically the greatest Test batter of all time. To curb his dominance, England employed Bodyline tactics during the 1932-33 Ashes series, which involved bowling at the body of the batter and setting a field, that resulted in batters having to choose between being hit or risking getting out. This series moved cricket from simply being a game to a matter of national importance with diplomatic cables being passed between the two countries over the incident.[55]  During this time, the number of Test nations continued to grow with the West Indies, New Zealand and India being admitted as full Test members within a four-year period from 1928 to 1932.  An enforced break during the Second World War stopped Test Cricket for a time, although the Partition of India caused Pakistan to gain Test status in 1952. As teams began to travel more, the game quickly grew from 500 tests in 84 years to 1000 within 23.  Cricket entered a new era in 1963 when English counties introduced the limited overs variant.[56] As it was sure to produce a result, limited overs cricket was lucrative and the number of matches increased.[57] The first Limited Overs International was played in 1971 and the governing International Cricket Council (ICC), seeing its potential, staged the first limited overs Cricket World Cup in 1975.[58] In the 21st century, a new limited overs form, Twenty20, made an immediate impact.[citation needed]  Sri Lanka would join the ranks in 1982, although South Africa would be banned by the ICC due to Apartheid from 1970 until 1992. 1992 also brought about the introduction of Zimbabwe.[59]  The 21st century was welcomed in by the introduction of Bangladesh, who made their debut in 2000. The game itself also grew with a new format made up of 20 over innings being created. T20 Cricket took hold and quickly grew to became a highly popular format, putting One Day Cricket at risk. The new shorter format also caused Franchise cricket to be created, with tournaments like the Indian Premier League and the Australian Big Bash League being formed.  Outside factors also took their toll on cricket with the 2008 Mumbai attacks leading India and Pakistan to suspend bilateral series indefinitely, while a 2009 attack on the Sri Lankan team during their tour of Pakistan, led to Pakistan being unable to play at home until 2019.[60][61][62][63]  In 2017, Afghanistan and Ireland became the 11th and 12th Test nations.[64][65]  In cricket, the rules of the game are specified in a code called The Laws of Cricket (hereinafter called \"the Laws\") which has a global remit. There are 42 Laws (always written with a capital \"L\"). The earliest known version of the code was drafted in 1744 and, since 1788, it has been owned and maintained by its custodian, the Marylebone Cricket Club (MCC) in London.[66]  Cricket is a bat-and-ball game played on a cricket field (see image of cricket pitch and creases) between two teams of eleven players each.[67] The field is usually circular or oval in shape and the edge of the playing area is marked by a boundary, which may be a fence, part of the stands, a rope, a painted line or a combination of these; the boundary must if possible be marked along its entire length.[68]  In the approximate centre of the field is a rectangular pitch (see image, below) on which a wooden target called a wicket is sited at each end; the wickets are placed 22 yards (20\u00a0m) apart.[69] The pitch is a flat surface 10 feet (3.0\u00a0m) wide, with very short grass that tends to be worn away as the game progresses (cricket can also be played on artificial surfaces, notably matting). Each wicket is made of three wooden stumps topped by two bails.[70]  As illustrated, the pitch is marked at each end with four white painted lines: a bowling crease, a popping crease and two return creases. The three stumps are aligned centrally on the bowling crease, which is eight feet eight inches long. The popping crease is drawn four feet in front of the bowling crease and parallel to it; although it is drawn as a twelve-foot line (six feet either side of the wicket), it is, in fact, unlimited in length. The return creases are drawn at right angles to the popping crease so that they intersect the ends of the bowling crease; each return crease is drawn as an eight-foot line, so that it extends four feet behind the bowling crease, but is also, in fact, unlimited in length.[71]  Before a match begins, the team captains (who are also players) toss a coin to decide which team will bat first and so take the first innings.[72] Innings is the term used for each phase of play in the match.[72] In each innings, one team bats, attempting to score runs, while the other team bowls and fields the ball, attempting to restrict the scoring and dismiss the batters.[73][74] When the first innings ends, the teams change roles; there can be two to four innings depending upon the type of match. A match with four scheduled innings is played over three to five days; a match with two scheduled innings is usually completed in a single day.[72] During an innings, all eleven members of the fielding team take the field, but usually only two members of the batting team are on the field at any given time. The exception to this is if a batter has any type of illness or injury restricting their ability to run; in this case, the batter is allowed a runner who can run between the wickets when the batter hits a scoring run or runs,[75] though this does not apply in international cricket.[76] The order of batters is usually announced just before the match, but it can be varied.[67]  The main objective of each team is to score more runs than their opponents but, in some forms of cricket, it is also necessary to dismiss all of the opposition batters in their final innings in order to win the match, which would otherwise be drawn.[77] If the team batting last is all out having scored fewer runs than their opponents, they are said to have \"lost by n runs\" (where n is the difference between the aggregate number of runs scored by the teams). If the team that bats last scores enough runs to win, it is said to have \"won by n wickets\", where n is the number of wickets left to fall. For example, a team that passes its opponents' total having lost six wickets (i.e., six of their batters have been dismissed) have won the match \"by four wickets\".[77]  In a two-innings-a-side match, one team's combined first and second innings total may be less than the other side's first innings total. The team with the greater score is then said to have \"won by an innings and n runs\", and does not need to bat again: n is the difference between the two teams' aggregate scores. If the team batting last is all out, and both sides have scored the same number of runs, then the match is a tie; this result is quite rare in matches of two innings a side with only 62 happening in first-class matches from the earliest known instance in 1741 until January 2017. In the traditional form of the game, if the time allotted for the match expires before either side can win, then the game is declared a draw.[77]  If the match has only a single innings per side, then usually a maximum number of overs applies to each innings. Such a match is called a \"limited overs\" or \"one-day\" match, and the side scoring more runs wins regardless of the number of wickets lost, so that a draw cannot occur. In some cases, ties are broken by having each team bat for a one-over innings known as a Super Over; subsequent Super Overs may be played if the first Super Over ends in a tie. If this kind of match is temporarily interrupted by bad weather, then a complex mathematical formula, known as the Duckworth\u2013Lewis\u2013Stern method after its developers, is often used to recalculate a new target score. A one-day match can also be declared a \"no-result\" if fewer than a previously agreed number of overs have been bowled by either team, in circumstances that make normal resumption of play impossible; for example, wet weather.[77]  In all forms of cricket, the umpires can abandon the match if bad light or rain makes it impossible to continue.[78] There have been instances of entire matches, even Test matches scheduled to be played over five days, being lost to bad weather without a ball being bowled: for example, the third Test of the 1970\/71 series in Australia.[79]  The innings (ending with 's' in both singular and plural form) is the term used for each phase of play during a match. Depending on the type of match being played, each team has either one or two innings. Sometimes all eleven members of the batting side take a turn to bat but, for various reasons, an innings can end before they have all done so. The innings terminates if the batting team is \"all out\", a term defined by the Laws: \"at the fall of a wicket or the retirement of a batter, further balls remain to be bowled but no further batter is available to come in\".[72] In this situation, one of the batters has not been dismissed and is termed not out; this is because he has no partners left and there must always be two active batters while the innings is in progress.  An innings may end early while there are still two not out batters:[72]  The Laws state that, throughout an innings, \"the ball shall be bowled from each end alternately in overs of 6 balls\".[80] The name \"over\" came about because the umpire calls \"Over!\" when six balls have been bowled. At this point, another bowler is deployed at the other end, and the fielding side changes ends while the batters do not. A bowler cannot bowl two successive overs, although a bowler can (and usually does) bowl alternate overs, from the same end, for several overs which are termed a \"spell\". The batters do not change ends at the end of the over, and so the one who was non-striker is now the striker and vice versa. The umpires also change positions so that the one who was at \"square leg\" now stands behind the wicket at the non-striker's end and vice versa.[80]  The wicket-keeper (a specialised fielder behind the batter) and the batters wear protective gear because of the hardness of the ball, which can be delivered at speeds of more than 145 kilometres per hour (90\u00a0mph) and presents a major health and safety concern. Protective clothing includes pads (designed to protect the knees and shins), batting gloves or wicket-keeper's gloves for the hands, a safety helmet for the head and a box for male players inside the trousers (to protect the crotch area).[81] Some batters wear additional padding inside their shirts and trousers such as thigh pads, arm pads, rib protectors and shoulder pads. The only fielders allowed to wear protective gear are those in positions very close to the batter (i.e., if they are alongside or in front of him), but they cannot wear gloves or external leg guards.[82]  Subject to certain variations, on-field clothing generally includes a collared shirt with short or long sleeves; long trousers; woolen pullover (if needed); cricket cap (for fielding) or a safety helmet; and spiked shoes or boots to increase traction. The kit is traditionally all white and this remains the case in Test and first-class cricket but, in limited overs cricket, team colours are worn instead.[83]  i) A used white ball. White balls are mainly used in limited overs cricket, especially in matches played at night, under floodlights (left).  The essence of the sport is that a bowler delivers (i.e., bowls) the ball from their end of the pitch towards the batter who, armed with a bat, is \"on strike\" at the other end (see next sub-section: Basic gameplay).  The bat is made of wood, usually Salix alba (white willow) and has the shape of a blade topped by a cylindrical handle. The blade must not be more than 4.25 inches (10.8\u00a0cm) wide and the total length of the bat not more than 38 inches (97\u00a0cm). There is no standard for the weight, which is usually between 2\u00a0lb 7 oz and 3\u00a0lb (1.1 and 1.4\u00a0kg).[84][85]  The ball is a hard leather-seamed spheroid, with a circumference of 9 inches (23\u00a0cm). The ball has a \"seam\": six rows of stitches attaching the leather shell of the ball to the string and cork interior. The seam on a new ball is prominent and helps the bowler propel it in a less predictable manner. During matches, the quality of the ball deteriorates to a point where it is no longer usable; during the course of this deterioration, its behaviour in flight will change and can influence the outcome of the match. Players will, therefore, attempt to modify the ball's behaviour by modifying its physical properties. Polishing the ball and wetting it with sweat or saliva was legal, even when the polishing was deliberately done on one side only to increase the ball's swing through the air. The use of saliva has since been made illegal due to the COVID-19 pandemic.[86] The acts of rubbing other substances into the ball, scratching the surface or picking at the seams constitute illegal ball tampering.[87]  During normal play, thirteen players and two umpires are on the field. Two of the players are batters and the rest are all eleven members of the fielding team. The other nine players in the batting team are off the field in the pavilion. The image with overlay below shows what is happening when a ball is being bowled and which of the personnel are on or close to the pitch.[88]  In the photo, the two batters (3 & 8; wearing yellow) have taken position at each end of the pitch (6). Three members of the fielding team (4, 10 & 11; wearing dark blue) are in shot. One of the two umpires (1; wearing white hat) is stationed behind the wicket (2) at the bowler's (4) end of the pitch. The bowler (4) is bowling the ball (5) from his end of the pitch to the batter (8) at the other end who is called the \"striker\". The other batter (3) at the bowling end is called the \"non-striker\". The wicket-keeper (10), who is a specialist, is positioned behind the striker's wicket (9) and behind him stands one of the fielders in a position called \"first slip\" (11). While the bowler and the first slip are wearing conventional kit only, the two batters and the wicket-keeper are wearing protective gear including safety helmets, padded gloves and leg guards (pads).  While the umpire (1) in shot stands at the bowler's end of the pitch, his colleague stands in the outfield, usually in or near the fielding position called \"square leg\", so that he is in line with the popping crease (7) at the striker's end of the pitch. The bowling crease (not numbered) is the one on which the wicket is located between the return creases (12). The bowler (4) intends to hit the wicket (9) with the ball (5) or, at least, to prevent the striker (8) from scoring runs. The striker (8) intends, by using his bat, to defend his wicket and, if possible, to hit the ball away from the pitch in order to score runs.  Some players are skilled in both batting and bowling, or as either of these as well as wicket-keeping, so are termed all-rounders.  Bowlers are classified according to their style, generally as fast bowlers, seam bowlers or spinners. Batters are classified according to whether they are right-handed or left-handed.  Of the eleven fielders, three are in shot in the image above. The other eight are elsewhere on the field, their positions determined on a tactical basis by the captain or the bowler. Fielders often change position between deliveries, again as directed by the captain or bowler.[82]  If a fielder is injured or becomes ill during a match, a substitute is allowed to field instead of the aforementioned fielder, but the substitute cannot bowl or act as a captain, except in the case of concussion substitutes in international cricket.[76] The substitute leaves the field when the injured player is fit to return.[89] The Laws of Cricket were updated in 2017 to allow substitutes to act as wicket-keepers.[90]  Most bowlers are considered specialists in that they are selected for the team because of their skill as a bowler, although some are all-rounders and even specialist batters bowl occasionally. These specialists bowl multiple overs during an innings, in groups called \"spells\" that are generally 4 to 8 overs long in order not to physically exhaust the bowler, cause muscle strain and stress the skeleton. The rules prevent a single bowler bowling consecutive overs, resulting in at least two bowlers alternating each over. If the captain wants a bowler to \"change ends\", another bowler must temporarily fill in so that the change is not immediate.[80]  A bowler reaches their delivery stride by means of a \"run-up\", and an over is deemed to have begun when the bowler starts their run-up for the first delivery of that over, the ball then being \"in play\".[80] Fast bowlers, needing momentum, take a lengthy run up, while bowlers with a slow delivery take no more than a couple of steps before bowling. The fastest bowlers can deliver the ball at a speed of over 145 kilometres per hour (90\u00a0mph), and they sometimes rely on sheer speed to try to defeat the batter, who is forced to react very quickly.[92] Other fast bowlers rely on a mixture of speed and guile by making the ball seam or swing (i.e. curve) in flight. This type of delivery can deceive a batter into miscuing their shot, for example, so that the ball just touches the edge of the bat and can then be \"caught behind\" by the wicket-keeper or a slip fielder.[92] At the other end of the bowling scale is the spin bowler, who bowls at a relatively slow pace and relies entirely on guile to deceive the batter. A spinner will often \"buy their wicket\" by \"tossing one up\" (in a slower, steeper parabolic path) to lure the batter into making a poor shot. The batter has to be very wary of such deliveries, as the batter is often \"flighted\" or spun so that the ball will not behave quite as the batter expects it to, and the batter could be \"trapped\" into getting themself out. Accidental full toss deliveries can also get wickets as the failure of the ball to bounce can surprise a batsman, or induce a poor stroke in an effort to punish the poor deliver with a boundary hit.[93] In between the pacemen and the spinners are the medium-paced seamers, who rely on persistent accuracy to try to contain the rate of scoring and wear down the batter's concentration.[92]  There are nine ways in which a batter can be dismissed: five relatively common and four extremely rare. The common forms of dismissal are bowled,[94] caught,[95] leg before wicket (lbw),[96] run out[97] and stumped.[98] Rare methods are hit wicket,[99] hit the ball twice,[100] obstructing the field[101] and timed out.[102] The Laws state that the fielding team, usually the bowler in practice, must appeal for a dismissal before the umpire can give their decision. If the batter is out, the umpire raises a forefinger and says \"Out!\"; otherwise, the umpire will shake their head and say \"Not out\".[103] There is, effectively, a tenth method of dismissal, retired out, which is not an on-field dismissal as such but rather a retrospective one for which no fielder is credited.[104]  Batters take turns to bat via a batting order which is decided beforehand by the team captain and presented to the umpires, though the order remains flexible when the captain officially nominates the team.[67] Substitute batters are generally not allowed,[89] except in the case of concussion substitutes in international cricket.[76]  In order to begin batting the batter first adopts a batting stance. Standardly, this involves adopting a slight crouch with the feet pointing across the front of the wicket, looking in the direction of the bowler, and holding the bat so it passes over the feet and so its tip can rest on the ground near to the toes of the back foot.[105]  A skilled batter can use a wide array of \"shots\" or \"strokes\" in both defensive and attacking mode. The idea is to hit the ball to the best effect with the flat surface of the bat's blade. If the ball touches the side of the bat, it is called an \"edge\". The batter does not have to play a shot and can allow the ball to go through to the wicketkeeper. Equally, the batter does not have to attempt a run when hitting the ball with their bat. Batters do not always seek to hit the ball as hard as possible, and a good player can score runs by simply making a deft stroke with a turn of the wrists, or by simply \"blocking\" the ball but directing it away from fielders so that the player has time to take a run. A wide variety of shots are played, the batter's repertoire including strokes named according to the style of swing and the direction aimed: e.g., \"cut\", \"drive\", \"hook\", \"pull\".[106]  The batter on strike (i.e. the \"striker\") must prevent the ball hitting the wicket, and try to score runs by hitting the ball with their bat so that the batter and their partner have time to run from one end of the pitch to the other before the fielding side can return the ball. To register a run, both runners must touch the ground behind the popping crease with either their bats or their bodies (the batters carry their bats as they run). Each completed run increments the score of both the team and the striker.[107]  The decision to attempt a run is ideally made by the batter who has the better view of the ball's progress, and this is communicated by calling: usually \"yes\", \"no\" or \"wait\". More than one run can be scored from a single hit: hits worth one to three runs are common, but the size of the field is such that it is usually difficult to run four or more.[107] To compensate for this, hits that reach the boundary of the field are automatically awarded four runs if the ball touches the ground en route to the boundary or six runs if the ball clears the boundary without touching the ground within the boundary. In these cases the batters do not need to run.[108] Hits for five are unusual and generally rely on the help of \"overthrows\" by a fielder returning the ball.  If an odd number of runs is scored by the striker, the two batters have changed ends, and the one who was non-striker is now the striker. Only the striker can score individual runs, but all runs are added to the team's total.[107]  Additional runs can be gained by the batting team as extras (called \"sundries\" in Australia) due to errors made by the fielding side. This is achieved in four ways: no-ball, a penalty of one extra conceded by the bowler if he breaks the rules;[109] wide, a penalty of one extra conceded by the bowler if they bowl so that the ball is out of the batter's reach;[110] bye, an extra awarded if the batter misses the ball and it goes past the wicket-keeper and gives the batters time to run in the conventional way;[111] leg bye, as for a bye except that the ball has hit the batter's body, though not their bat.[111] If the bowler has conceded a no-ball or a wide, the bowler's team incurs an additional penalty because that ball (i.e., delivery) has to be bowled again and hence the batting side has the opportunity to score more runs from this extra ball.[109][110]  The captain is often the most experienced player in the team, certainly the most tactically astute, and can possess any of the main skillsets as a batter, a bowler or a wicket-keeper. Within the Laws, the captain has certain responsibilities in terms of nominating their players to the umpires before the match and ensuring that the captain's players conduct themselves \"within the spirit and traditions of the game as well as within the Laws\".[67]  The wicket-keeper (sometimes called simply the \"keeper\") is a specialist fielder subject to various rules within the Laws about their equipment and demeanour. The wicket-keeper is the only member of the fielding side who can effect a stumping, and is the only one permitted to wear gloves and external leg guards.[112]  Depending on their primary skills, the other ten players in the team tend to be classified as specialist batters or specialist bowlers. Generally, a team will include five or six specialist batters, and four or five specialist bowlers, plus the wicket-keeper.[113][114]  The game on the field is regulated by the two umpires, one of whom stands behind the wicket at the bowler's end, and the other in a position called \"square leg\" which is about 15\u201320 metres away from the batter on strike and in line with the popping crease on which that umpire is taking guard. The umpires have several responsibilities, including adjudication on whether a ball has been correctly bowled (i.e., not a no-ball or a wide); when a run is scored; whether a batter is out (the fielding side must first appeal to the umpire, usually with the phrase \"How's that?\" or \"Howzat?\"); when intervals start and end; and the suitability of the pitch, field and weather for playing the game. The umpires are authorised to interrupt or even abandon a match due to circumstances likely to endanger the players, such as a damp pitch or deterioration of the light.[78]  Off the field in televised matches, there is usually a third umpire who can make decisions on certain incidents with the aid of video evidence. The third umpire is mandatory under the playing conditions for Test and Limited Overs International matches played between two ICC full member countries. These matches also have a match referee whose job is to ensure that play is within the Laws and the spirit of the game.[78]  The match details, including runs and dismissals, are recorded by two official scorers, one representing each team. The scorers are directed by the hand signals of an umpire (see image, right). For example, the umpire raises a forefinger to signal that the batter is out (has been dismissed); the umpire raises both arms above their head if the batter has hit the ball for six runs. The scorers are required by the Laws to record all runs scored, wickets taken and overs bowled; in practice, they also note significant amounts of additional data relating to the game.[115]  A match's statistics are summarised on a scorecard. Prior to the popularisation of scorecards, most scoring was done by men sitting on vantage points cuttings notches on tally sticks, and runs were originally called notches.[116] According to Rowland Bowen, the earliest known scorecard templates were introduced in 1776 by T. Pratt of Sevenoaks and soon came into general use.[117] It is believed that scorecards were printed and sold at Lord's for the first time in 1846.[118]  Scores are displayed differently depending on location, although it is standard to show how many wickets have been lost and how many runs a team has made in the following formats.  Within Australia, the format is Wickets\/Runs. While in the rest of the world, the format is Runs\/Wickets.  A score of 125 with 4 wickets lost, would be displayed as 4\/125 or 125\/4 respectively.[119]  Besides observing the Laws, cricketers must respect the \"Spirit of Cricket\", a concept encompassing sportsmanship, fair play and mutual respect. This spirit has long been considered an integral part of the sport but is only nebulously defined. Amidst concern that the spirit was weakening, in 2000 a Preamble was added to the Laws instructing all participants to play within the spirit of the game. The Preamble was last updated in 2017, now opening with the line:[120]  \"Cricket owes much of its appeal and enjoyment to the fact that it should be played not only according to the Laws, but also within the Spirit of Cricket\". The Preamble is a short statement intended to emphasise the \"positive behaviours that make cricket an exciting game that encourages leadership, friendship, and teamwork.\"[121] Its second line states that \"the major responsibility for ensuring fair play rests with the captains, but extends to all players, match officials and, especially in junior cricket, teachers, coaches and parents.\"[120]  The umpires are the sole judges of fair and unfair play. They are required under the Laws to intervene in case of dangerous or unfair play or in cases of unacceptable conduct by a player.  Previous versions of the Spirit identified actions that were deemed contrary (for example, appealing knowing that the batter is not out) but all specifics are now covered in the Laws of Cricket, the relevant governing playing regulations and disciplinary codes, or left to the judgement of the umpires, captains, their clubs and governing bodies. The terse expression of the Spirit of Cricket now avoids the diversity of cultural conventions that exist in the detail of sportsmanship \u2013 or its absence.  Women's cricket was first recorded in Surrey in 1745.[122] International development began at the start of the 20th century and the first Test match was played between Australia and England in December 1934.[123] The following year, New Zealand joined them, and in 2007 Netherland became the tenth women's Test nation when they made their debut against South Africa. In 1958, the International Women's Cricket Council was founded (it merged with the ICC in 2005).[123] In 1973, the first Cricket World Cup of any kind took place when a Women's World Cup was held in England.[123]  In 2005, the International Women's Cricket Council was merged with the International Cricket Council (ICC) to form one unified body to help manage and develop cricket. The ICC Women's Rankings were launched on 1 October 2015 covering all three formats of women's cricket. In October 2018 following the ICC's decision to award T20 International status to all members, the Women's rankings were split into separate ODI (for Full Members) and T20I lists.[124]  The International Cricket Council (ICC), which has its headquarters in Dubai, is the global governing body of cricket. It was founded as the Imperial Cricket Conference in 1909 by representatives from England, Australia and South Africa, renamed the International Cricket Conference in 1965 and took up its current name in 1989.[123] The ICC in 2017 has 105 member nations, twelve of which hold full membership and can play Test cricket.[125] The ICC is responsible for the organisation and governance of cricket's major international tournaments, notably the men's and women's versions of the Cricket World Cup. It also appoints the umpires and referees that officiate at all sanctioned Test matches, Limited Overs Internationals and Twenty20 Internationals.  Each member nation has a national cricket board which regulates cricket matches played in its country, selects the national squad, and organises home and away tours for the national team.[126] In the West Indies, which for cricket purposes is a federation of nations, these matters are addressed by Cricket West Indies.[127]  The table below lists the ICC full members and their national cricket boards:[128]  Cricket is a multi-faceted sport with multiple formats that can effectively be divided into first-class cricket, limited overs cricket and, historically, single wicket cricket.  The highest standard is Test cricket (always written with a capital \"T\") which is in effect the international version of first-class cricket and is restricted to teams representing the twelve countries that are full members of the ICC (see above). Although the term \"Test match\" was not coined until much later, Test cricket is deemed to have begun with two matches between Australia and England in the 1876\u201377 Australian season; since 1882, most Test series between England and Australia have been played for a trophy known as The Ashes. The term \"first-class\", in general usage, is applied to top-level domestic cricket. Test matches are played over five days and first-class over three to four days; in all of these matches, the teams are allotted two innings each and the draw is a valid result.[130]  Limited overs cricket is always scheduled for completion in a single day, and the teams are allotted one innings each. There are two main types: List A which normally allows fifty overs per team; and Twenty20 in which the teams have twenty overs each. Both of the limited overs forms are played internationally as Limited Overs Internationals (LOI) and Twenty20 Internationals (T20I). List A was introduced in England in the 1963 season as a knockout cup contested by the first-class county clubs. In 1969, a national league competition was established. The concept was gradually introduced to the other leading cricket countries and the first limited overs international was played in 1971. In 1975, the first Cricket World Cup took place in England. Twenty20 is a new variant of limited overs itself with the purpose being to complete the match within about three to four hours, usually in an evening session. The first Twenty20 World Championship was held in 2007. In addition, a few full-member cricket boards have decided to start leagues that are played in the T10 format,[131][132][133][134] in which games are intended to last approximately 90 minutes.[135][136] Most recently, in 2021, the England and Wales Cricket Board (ECB) introduced a new league featuring a hundred-ball tournament, known as The Hundred.[137] Limited overs matches cannot be drawn, although a tie is possible and an unfinished match is a \"no result\".[138][139]  Single wicket was popular in the 18th and 19th centuries and its matches were generally considered top-class. In this form, although each team may have from one to six players, there is only one batter in at a time, and that batter must face every delivery bowled while their innings lasts. Single wicket has rarely been played since limited overs cricket began. Matches tended to have two innings per team like a full first-class one and they could end in a draw.[140]  Cricket is played at both the international and domestic level. There is one major international championship per format, and top-level domestic competitions mirror the three main international formats. There are now a number of T20 leagues, which have spawned a \"T20 freelancer\" phenomenon.[141]  Most international matches are played as parts of 'tours', when one nation travels to another for a number of weeks or months, and plays a number of matches of various sorts against the host nation. Sometimes a perpetual trophy is awarded to the winner of the Test series, the most famous of which is The Ashes.  The ICC also organises competitions that are for several countries at once, including the Cricket World Cup, ICC T20 World Cup and ICC Champions Trophy. A league competition for Test matches played as part of normal tours, the ICC World Test Championship, had been proposed several times, and its first instance began in 2019. A league competition for ODIs, the ICC Cricket World Cup Super League, began in August 2020 and lasted only for one edition. The ICC maintains Test rankings, ODI rankings and T20 rankings systems for the countries which play these forms of cricket.  Competitions for member nations of the ICC with Associate status include the ICC Intercontinental Cup, for first-class cricket matches, and the World Cricket League for one-day matches, the final matches of which now also serve as the ICC World Cup Qualifier.  The game's only appearance in an Olympic Games was the 1900 Olympics.[142] However, it is scheduled to make a return, with the T20 format of the game, in the 2028 Summer Olympics in Los Angeles.[143][144]  First-class cricket in England is played for the most part by the 18 county clubs which contest the County Championship. The concept of a champion county has existed since the 18th century but the official competition was not established until 1890.[44] The most successful club has been Yorkshire, who had won 32 official titles (plus one shared) as of 2019.[145]  Australia established its national first-class championship in 1892\u201393 when the Sheffield Shield was introduced. In Australia, the first-class teams represent the various states.[146] New South Wales has the highest number of titles.  The other ICC full members have national championship trophies called the Ahmad Shah Abdali 4-day Tournament (Afghanistan); the National Cricket League (Bangladesh); the Ranji Trophy (India); the Inter-Provincial Championship (Ireland); the Plunket Shield (New Zealand); the Quaid-e-Azam Trophy (Pakistan); the Currie Cup (South Africa); the Premier Trophy (Sri Lanka); the Shell Shield (West Indies); and the Logan Cup (Zimbabwe).  The world's earliest known cricket match was a village cricket meeting in Kent which has been deduced from a 1640 court case recording a \"cricketing\" of \"the Weald and the Upland\" versus \"the Chalk Hill\" at Chevening \"about thirty years since\" (i.e., c.\u20091611). Inter-parish contests became popular in the first half of the 17th century and continued to develop through the 18th with the first local leagues being founded in the second half of the 19th.[19]  At the grassroots level, local club cricket is essentially an amateur pastime for those involved but still usually involves teams playing in competitions at weekends or in the evening. Schools cricket, first known in southern England in the 17th century, has a similar scenario and both are widely played in the countries where cricket is popular.[147] Although there can be variations in game format, compared with professional cricket, the Laws are always observed and club\/school matches are therefore formal and competitive events.[148] The sport has numerous informal variants such as French cricket.[149] On the North American side, in 2023, Monroe Township High School, in Monroe Township, Middlesex County, New Jersey, launched the first U.S. high school cricket club.[150][151]  Cricket has had a broad impact on popular culture, both in the Commonwealth of Nations and elsewhere. It has, for example, influenced the lexicon of these nations, especially the English language, with various phrases such as \"that's not cricket\" (that's unfair), \"had a good innings\" (lived a long life) and \"sticky wicket\". \"On a sticky wicket\" (aka \"sticky dog\" or \"glue pot\")[152] is a metaphor[153] used to describe a difficult circumstance. It originated as a term for difficult batting conditions in cricket, caused by a damp and soft pitch.[154]  Cricket is the subject of works by noted English poets, including William Blake and Lord Byron.[155] Beyond a Boundary (1963), written by Trinidadian C. L. R. James, is often named the best book on any sport ever written.[156]  In the visual arts, notable cricket paintings include Albert Chevallier Tayler's Kent vs Lancashire at Canterbury (1907) and Russell Drysdale's The Cricketers (1948), which has been called \"possibly the most famous Australian painting of the 20th century.\"[157] French impressionist Camille Pissarro painted cricket on a visit to England in the 1890s.[155] Francis Bacon, an avid cricket fan, captured a batter in motion.[155] Caribbean artist Wendy Nanan's cricket images[158] are featured in a limited edition first day cover for Royal Mail's \"World of Invention\" stamp issue, which celebrated the London Cricket Conference 1\u20133 March 2007, first international workshop of its kind and part of the celebrations leading up to the 2007 Cricket World Cup.[159]  In music, many calypsos make reference to the Sport of Cricket.  Cricket has close historical ties with Australian rules football and many players have competed at top levels in both sports.[160] In 1858, prominent Australian cricketer Tom Wills called for the formation of a \"foot-ball club\" with \"a code of laws\" to keep cricketers fit during the off-season. The Melbourne Football Club was founded the following year, and Wills and three other members codified the first laws of the game.[161] It is typically played on modified cricket fields.[162]  In England, a number of association football clubs owe their origins to cricketers who sought to play football as a means of keeping fit during the winter months. Derby County was founded as a branch of the Derbyshire County Cricket Club in 1884;[163] Aston Villa (1874) and Everton (1876) were both founded by members of church cricket teams.[164] Sheffield United's Bramall Lane ground was, from 1854, the home of the Sheffield Cricket Club, and then of Yorkshire; it was not used for football until 1862 and was shared by Yorkshire and Sheffield United from 1889 to 1973.[165]  In the late 19th century, a former cricketer, English-born Henry Chadwick of Brooklyn, New York, was credited with devising the baseball box score[166] (which he adapted from the cricket scorecard) for reporting game events. The first box score appeared in an 1859 issue of the Clipper.[167] The statistical record is so central to the game's \"historical essence\" that Chadwick is sometimes referred to as \"the Father of Baseball\" because he facilitated the popularity of the sport in its early days.[168]  Related sports "},{"title":"Performance indicator","content":"A performance indicator or key performance indicator (KPI) is a type of performance measurement.[1] KPIs evaluate the success of an organization or of a particular activity (such as projects, programs, products and other initiatives) in which it engages.[2] KPIs provide a focus for strategic and operational improvement, create an analytical basis for decision making and help focus attention on what matters most.[3]  Often success is simply the repeated, periodic achievement of some levels of operational goal (e.g. zero defects, 10\/10 customer satisfaction), and sometimes success is defined in terms of making progress toward strategic goals.[4] Accordingly, choosing the right KPIs relies upon a good understanding of what is important to the organization.[5] What is deemed important often depends on the department measuring the performance \u2013 e.g. the KPIs useful to finance will differ from the KPIs assigned to sales.  Since there is a need to understand well what is important, various techniques to assess the present state of the business, and its key activities, are associated with the selection of performance indicators. These assessments often lead to the identification of potential improvements, so performance indicators are routinely associated with 'performance improvement' initiatives. A very common way to choose KPIs is to apply a management framework such as the balanced scorecard.  The importance of such performance indicators is evident in the typical decision-making process (e.g. in management of organisations). When a decision-maker considers several options, they must be equipped to properly analyse the status quo to predict the consequences of future actions. Should they make their analysis on the basis of faulty or incomplete information, the predictions will not be reliable and consequently the decision made might yield an unexpected result. Therefore, the proper usage of performance indicators is vital to avoid such mistakes and minimise the risk.[6][7]  KPIs are used not only for business organizations but also for technical aspects such as machine performance. For example, a machine used for production in a factory would output various signals indicating how the current machine status is (e.g., machine sensor signals). Some signals or signals as a result of processing the existing signals may represent the high-level machine performance. These representative signals can be KPI for the machine.  Key performance indicators define a set of values against to which measure. These raw sets of values, which can be fed to systems that aggregate the data, are called indicators. There are two categories of measurements for KPIs.   An 'indicator' can only measure what 'has' happened, in the past tense, so the only type of measurement is descriptive or lagging.  Any KPI that attempts to measure something in a future state as predictive, diagnostic or prescriptive is no longer an 'indicator', it is a 'prognosticator' \u2013 at this point, it is analytics (possibly based on a KPI) but leading KPIs are also used to indicate the amount of front end loading activities.  Performance focuses on measuring a particular element of an activity. An activity can have four elements: input, output, control, and mechanism.[citation needed] At a minimum, activity is required to have at least an input and an output. Something goes into the activity as an input; the activity transforms the input by changing its state, and the activity produces an output. An activity can also enable mechanisms that are typically separated into human and system mechanisms. It can also be constrained in some way by a control. Lastly, its actions can have a temporal construct of time.  Performance indicators differ from business drivers and aims (or goals). A school might consider the failure rate of its students as a key performance indicator which might help the school understand its position in the educational community, whereas a business might consider the percentage of income from returning customers as a potential KPI.  The key stages in identifying KPIs are:  Key performance indicators (KPIs) are ways to periodically assess the performances of organizations, business units, and their division, departments and employees. Accordingly, KPIs are most commonly defined in a way that is understandable, meaningful, and measurable. They are rarely defined in such a way that their fulfillment would be hampered by factors seen as non-controllable by the organizations or individuals responsible. Such KPIs are usually ignored by organizations.[citation needed]  KPIs should follow the SMART criteria. This means the measure has a Specific purpose for the business, it is Measurable to really get a value of the KPI, the defined norms have to be Achievable, the improvement of a KPI has to be Relevant to the success of the organization, and finally it must be Time phased, which means the value or outcomes are shown for a predefined and relevant period.[5]  KPIs should be set at a senior level within an organization and cascaded through all levels of management.[8] In order to be evaluated, KPIs are linked to target values, so that the value of the measure can be assessed as meeting expectations or not.  Key performance indicators are mostly the non-financial measures of a company's performance [8] \u2013 they do not have a monetary value but in a business context they do contribute to the company's profitability.[9]  These are some of the examples:  Many of these customer KPIs are developed and managed with customer relationship management software.  Faster availability of data is a competitive issue for most organizations. For example, businesses that have higher operational\/credit risk (involving for example credit cards or wealth management) may want weekly or even daily availability of KPI analysis, facilitated by appropriate IT systems and tools.  Overall equipment effectiveness (OEE) is a set of broadly accepted nonfinancial metrics that reflect manufacturing success.  Most professional services firms (for example, management consultancies, systems integration firms, or digital marketing agencies) use three key performance indicators to track the health of their businesses. They typically use professional services automation (PSA) software to keep track of and manage these metrics.  Businesses can utilize supply chain KPIs to establish and monitor progress toward a variety of goals, including lean manufacturing objectives, minority business enterprise and diversity spending, environmental \"green\" initiatives, cost avoidance programs and low-cost country sourcing targets. Suppliers can implement KPIs to gain a competitive advantage. Suppliers have instant access to a user-friendly portal for submitting standardized cost savings templates. Suppliers and their customers exchange vital supply chain performance data while gaining visibility to the exact status of cost improvement projects and cost savings documentation.  Any business, regardless of size, can better manage supplier performance and overall supply chain performance,[10] with the help of KPIs' robust capabilities, which include:  Main KPIs for supply chain management will detail the following processes:  In a warehouse, the manager will use KPIs that target best use of the facility, like the receiving and put away KPIs to measure the receiving efficiency and the putaway cost per line. Storage KPIs can also be used to determine the efficiency of the storage space and the carrying cost of the inventory.[11]  The provincial government of Ontario, Canada has been using KPIs since 1998 to measure the performance of higher education institutions in the province. All post-secondary schools collect and report performance data in five areas \u2013 graduate satisfaction, student satisfaction, employer satisfaction, employment rate, and graduation rate.[12] In England, Public Health England uses KPIs to provide a consistent measure of the performance of NHS population screening activities,[13] and publication of up to four main KPIs for the most important contracts outsourced by each UK government department is seen as a measure helping to increase transparency in the delivery of public services.[14]  Human Resource Management  In practice, overseeing key performance indicators can prove expensive or difficult for organizations. Some indicators such as staff morale may be impossible to quantify. As such, dubious KPIs can be adopted that can be used as a rough guide rather than a precise benchmark.[16]  Key performance indicators can also lead to perverse incentives and unintended consequences as a result of employees working to the specific measurements at the expense of the actual quality or value of their work.[17][18]  Sometimes, collecting statistics can become a substitute for a better understanding of the problems, so the use of dubious KPIs can result in progress in aims and measured effectiveness becoming different. For example, during the Vietnam War, US soldiers were shown to be effective in kill ratios and high body counts, but this was misleading when used to measure aims as it did not show the lack of progress towards the US goal of increasing South Vietnamese government control of its territory.[16] Another example would be to measure the productivity of a software development team in terms of lines of source code written. This approach can easily add large amounts of dubious code, thereby inflating the line count but adding little value in terms of systemic improvement. A similar problem arises when a footballer kicks a ball uselessly to build up their statistics. "},{"title":"Oval","content":"An oval (from Latin  ovum\u00a0'egg') is a closed curve in a plane which resembles the outline of an egg. The term is not very specific, but in some areas (projective geometry, technical drawing, etc.) it is given a more precise definition, which may include either one or two axes of symmetry of an ellipse. In common English, the term is used in a broader sense: any shape which reminds one of an egg. The three-dimensional version of an oval is called an ovoid.  The term oval when used to describe curves in geometry is not well-defined, except in the context of projective geometry. Many distinct curves are commonly called ovals or are said to have an \"oval shape\". Generally, to be called an oval, a plane curve should resemble the outline of an egg or an ellipse. In particular, these are common traits of ovals:  Here are examples of ovals described elsewhere:  An ovoid is the surface in 3-dimensional space generated by rotating an oval curve about one of its axes of symmetry. The adjectives ovoidal and ovate mean having the characteristic of being an ovoid, and are often used as synonyms for \"egg-shaped\".  For finite planes (i.e. the set of points is finite) there is a more convenient characterization:[2]  An ovoid in a projective space is a set  \u03a9 of points such that:  In the finite case only for dimension 3 there exist ovoids. A convenient characterization is:  The shape of an egg is approximated by the \"long\" half of a prolate spheroid, joined to a \"short\" half of a roughly spherical ellipsoid, or even a slightly oblate spheroid. These are joined at the equator and share a principal axis of rotational symmetry, as illustrated above.  Although the term egg-shaped usually implies a lack of reflection symmetry across the equatorial plane, it may also refer to true prolate ellipsoids.  It can also be used to describe the 2-dimensional figure that, if revolved around its major axis, produces the 3-dimensional surface.  In technical drawing, an oval is a figure that is constructed from two pairs of arcs, with two different radii (see image on the right). The arcs are joined at a point in which lines tangential to both joining arcs lie on the same line, thus making the joint smooth. Any point of an oval belongs to an arc with a constant radius (shorter or longer), but in an ellipse, the radius is continuously changing.  In common speech, \"oval\" means a shape rather like an egg or an ellipse, which may be two-dimensional or three-dimensional. It also often refers to a figure that resembles two semicircles joined by a rectangle, like a cricket infield, speed skating rink or an athletics track. However, this is most correctly called a stadium.  The term \"ellipse\" is often used interchangeably with oval, despite not being a precise synonym.[4] The term \"oblong\" is often used incorrectly to describe an elongated oval or 'stadium' shape.[5] However, in geometry, an oblong is a rectangle with unequal adjacent sides (i.e., not a square).[6] "},{"title":"Volleyball","content":"    Volleyball is a team sport in which two teams of six players are separated by a net. Each team tries to score points by grounding a ball on the other team's court under organized rules.[1] It has been a part of the official program of the Summer Olympic Games since Tokyo 1964. Beach volleyball was introduced to the programme at the Atlanta 1996 Summer Olympics. The adapted version of volleyball at the Summer Paralympic Games is sitting volleyball.  The complete set of rules is extensive,[2] but play essentially proceeds as follows: a player on one of the teams begins a 'rally' by serving the ball (tossing or releasing it and then hitting it with a hand or arm), from behind the back boundary line of the court, over the net, and into the receiving team's court.[3] The receiving team must not let the ball be grounded within their court. The team may touch the ball up to three times to return the ball to the other side of the court, but individual players may not touch the ball twice consecutively.[3] Typically, the first two touches are used to set up for an attack. An attack is an attempt to direct the ball back over the net in such a way that the team receiving the ball is unable to pass the ball and continue the rally, thus, losing the point. The team that wins the rally is awarded a point and serves the ball to start the next rally. A few of the most common faults include:  The ball is usually played with the hands or arms, but players can legally strike or push (short contact) the ball with any part of the body.[4]  A number of consistent techniques have evolved in volleyball, including spiking and blocking (because these plays are made above the top of the net, the vertical jump is an athletic skill emphasized in the sport) as well as passing, setting, specialized player positions, and offensive and defensive structures.[5]  In December 1895,[6] in Holyoke, Massachusetts (United States), William G. Morgan, a YMCA physical education director, created a new game called Mintonette, a name derived from the game of badminton,[7] as a pastime to preferably be played indoors and by any number of players. The game took some of its characteristics from other sports such as baseball, tennis, and handball.[8] Another indoor sport, basketball, was catching on in the area, having been invented just ten miles (sixteen kilometres) away in the city of Springfield, Massachusetts, only four years before. Mintonette was designed to be an indoor sport, less rough than basketball, for older members of the YMCA, while still requiring a bit of athletic effort.  The first rules, written down by Morgan, called for a net 6\u00a0ft 6\u00a0in (1.98\u00a0m) high, a 25\u00a0ft \u00d7\u00a050\u00a0ft (7.6\u00a0m \u00d7\u00a015.2\u00a0m) court, and any number of players. A match was composed of nine innings with three serves for each team in each inning, and no limit to the number of ball contacts for each team before sending the ball to the opponents' court. In case of a serving error, a second try was allowed. Hitting the ball into the net was considered a foul (with loss of the point or a side-out)\u2014except in the case of the first-try serve.  After an observer, Alfred Halstead, noticed the volleying nature of the game at its first exhibition match in 1896, played at the International YMCA Training School (now called Springfield College), the game quickly became known as volleyball (it was originally spelled as two words: \"volley ball\"). Volleyball rules were slightly modified by the International YMCA Training School and the game spread around the country to various YMCAs.[9][10]  In the early 1900s Spalding, through its publishing company American Sports Publishing Company, produced books with complete instruction and rules for the sport.[11]  The first official ball used in volleyball is disputed; some sources say Spalding created the first official ball in 1896, while others claim it was created in 1900.[12][13][14] The rules evolved over time: in 1916, in the Philippines, the skill and power of the set and spike had been introduced, and four years later a \"three hits\" rule and a rule against hitting from the back row were established. In 1917, the game was changed from requiring 21 points to win to a smaller 15 points to win. In 1919, about 16,000 volleyballs were distributed by the American Expeditionary Forces to their troops and allies, which sparked the growth of volleyball in new countries.[12]  The first country outside the United States to adopt volleyball was Canada in 1900.[12] An international federation, the F\u00e9d\u00e9ration Internationale de Volleyball (FIVB), was founded in 1947, and the first World Championships were held in 1949 for men and 1952 for women.[15] The sport is now popular in Brazil, in Europe, where especially Italy, the Netherlands, and Eastern Europe have been major forces since the late 1980s, in Russia, in other countries, including China and the rest of Asia, and in the United States.[9][10][15]  Beach volleyball, a variation of the game played on sand and with only two players per team, became a FIVB-endorsed variation in 1987 and was added to the Olympic program at the 1996 Summer Olympics.[12][15] Volleyball is also a sport at the Paralympics managed by the World Organization Volleyball for Disabled.  Nudists were early adopters of the game with regular organized play in clubs as early as the late 1920s.[16][17] By the 1960s, a volleyball court had become standard in almost all nudist\/naturist clubs.[18]  A recent issue within the sport is the inclusion of transgender players. With transgender athletes such as Tiffany Abreu joining professional volleyball teams alongside other non-transgender teammates, many professionals, sports analysts, and fans of volleyball are either expressing concerns about the legitimacy and fairness of having transgender players on a team or expressing support for the transgender people's efforts.[19]  Volleyball has been part of the Summer Olympics program for both men and women consistently since 1964.  A volleyball court is 9\u00a0m \u00d7\u00a018\u00a0m (29.5\u00a0ft \u00d7\u00a059.1\u00a0ft), divided into equal square halves by a net with a width of one meter (39.4\u00a0in).[20] The top of the net is 2.43\u00a0m (7\u00a0ft 11+11\u204416\u00a0in) above the center of the court for men's competition, and 2.24\u00a0m (7\u00a0ft 4+3\u204416\u00a0in) for women's competition, varied for veterans and junior competitions.[3]  The minimum height clearance for indoor volleyball courts is 7\u00a0m (23.0\u00a0ft), although a clearance of 8\u00a0m (26.2\u00a0ft) is recommended.[20]  A line 3\u00a0m (9.8\u00a0ft) from and parallel to the net is considered the \"attack line\". This \"3 meter\" (or \"10-foot\") line divides the court into \"back row\" and \"front row\" areas and the back court and front court.[20] These are in turn divided into 3 areas each: these are numbered as follows, starting from area \"1\", which is the position of the serving player:   After a team gains the serve (also known as siding out), its members must rotate in a clockwise direction, with the player previously in area \"2\" moving to area \"1\" and so on, with the player from area \"1\" moving to area \"6\".[3] Each player rotates only one time after the team gains possession of the service; the next time each player rotates will be after the other team wins possession of the ball and loses the point.[20]  The team courts are surrounded by an area called the free zone which is a minimum of 3 meters wide and which the players may enter and play within after the service of the ball.[21] All lines denoting the boundaries of the team court and the attack zone are drawn or painted within the dimensions of the area and are therefore a part of the court or zone. If a ball comes in contact with the line, the ball is considered to be \"in\". An antenna is placed on each side of the net perpendicular to the sideline and is a vertical extension of the side boundary of the court. A ball passing over the net must pass completely between the antennae (or their theoretical extensions to the ceiling) without contacting them.[3]  FIVB regulations state that the ball must be spherical, made of leather or synthetic leather, have a circumference of 65\u201367\u00a0cm (26\u201326\u00a0in), a weight of 260\u2013280\u00a0g (9.2\u20139.9\u00a0oz) and an interior air pressure of 0.30\u20130.325\u00a0kg\/cm2 (4.26 to 4.61 psi; 294.3 to 318.82 mbar or hPa).[22] Other governing bodies have similar regulations.  Each team consists of six players.[20] To get play started, a team is chosen to serve by coin toss. A player from the serving team throws the ball into the air and attempts to hit the ball so it passes over the net on a course such that it will land in the opposing team's court (the serve).[20] The opposing team must use a combination of no more than three contacts with the volleyball to return the ball to the opponent's side of the net.[20] These contacts usually consist first of the bump or pass so that the ball's trajectory is aimed towards the player designated as the setter; second of the set (usually an over-hand pass using wrists to push finger-tips at the ball) by the setter so that the ball's trajectory is aimed towards a spot where one of the players designated as an attacker can hit it, and third by the attacker who spikes (jumping, raising one arm above the head and hitting the ball so it will move quickly down to the ground on the opponent's court) to return the ball over the net.[3] The team with possession of the ball that is trying to attack the ball as described is said to be on offence.  The team on defence attempts to prevent the attacker from directing the ball into their court: players at the net jump and reach above the top (and if possible, across the plane) of the net to block the attacked ball.[3] If the ball is hit around, above, or through the block, the defensive players arranged in the rest of the court attempt to control the ball with a dig (usually a fore-arm pass of a hard-driven ball). After a successful dig, the team transitions to offence.  The game continues in this manner, rallying back and forth until the ball touches the court within the boundaries or until an error is made.[20] The most frequent errors that are made are either to fail to return the ball over the net within the allowed three touches, or to cause the ball to land outside the court.[20] A ball is \"in\" if any part of it touches the inside of a team's court or a sideline or end-line, and a strong spike may compress the ball enough when it lands that a ball which at first appears to be going out may actually be in. Players may travel well outside the court to play a ball that has gone over a sideline or end-line in the air. A standard competitive volleyball match is played in a best-of-five sets format and typically goes on for about 90 minutes.[23]  Other common errors include a player touching the ball twice in succession, a player catching the ball, a player touching the net while attempting to play the ball, or a player penetrating under the net into the opponent's court. There are a large number of other errors specified in the rules, although most of them are infrequent occurrences. These errors include back-row or libero players spiking the ball or blocking (back-row players may spike the ball if they jump from behind the attack line), players not being in the correct position when the ball is served, attacking the serve in the front court and above the height of the net, using another player as a source of support to reach the ball, stepping over the back boundary line when serving, taking more than 8 seconds to serve,[24] or playing the ball when it is above the opponent's court.  A point is scored when the ball contacts the floor within the court boundaries or when an error is made: when the ball strikes one team's side of the court, the other team gains a point; and when an error is made, the team that did not make the error is awarded a point, in either case paying no regard to whether they served the ball or not. If any part of the ball hits the line, the ball is counted as in the court. The team that won the point serves for the next point. If the team that won the point served in the previous point, the same player serves again. If the team that won the point did not serve the previous point, the players of the team acquiring the serve rotate their position on the court in a clockwise manner. The game continues, with the first team to score 25 points by a two-point margin awarded the set. Matches are best-of-five sets and the fifth set, if necessary, is usually played to 15 points. (Scoring differs between leagues, tournaments, and levels; high schools sometimes play best-of-three to 25; in the NCAA matches are played best-of-five to 25 as of the 2008 season.)[25]  Before 1999, points could be scored only when a team had the serve (side-out scoring) and all sets went up to only 15 points. The FIVB changed the rules in 1999 (with the changes being compulsory in 2000) to use the current scoring system (formerly known as rally point system), primarily to make the length of the match more predictable and to make the game more spectator- and television-friendly.  The final year of side-out scoring at the NCAA Division I Women's Volleyball Championship was 2000. Rally point scoring debuted in 2001,[26] and games were played to 30 points through 2007. For the 2008 season, games were renamed \"sets\" and reduced to 25 points to win. Most high schools in the U.S. changed to rally scoring in 2003,[27][28][29] and several states implemented it the previous year on an experimental basis.[30]  The libero player was introduced internationally in 1998,[31] and made its debut for NCAA competition in 2002.[32] The libero is a player specialized in defensive skills: the libero must wear a contrasting jersey color from their teammates and cannot block or attack the ball when it is entirely above net height. When the ball is not in play, the libero can replace any back-row player, without prior notice to the officials. This replacement does not count against the substitution limit each team is allowed per set, although the libero may be replaced only by the player whom he or she replaced. Most U.S. high schools added the libero position from 2003 to 2005.[28][33]  The modern-day libero often takes on the role of a second setter. When the setter digs the ball, the libero is typically responsible for the second ball and sets to the front row attacker. The libero may function as a setter only under certain restrictions. To make an overhand set, the libero must be standing behind (and not stepping on) the 3-meter line; otherwise, the ball cannot be attacked above the net in front of the 3-meter line. An underhand pass is allowed from any part of the court.  The libero is, generally, the most skilled defensive player on the team. There is also a libero tracking sheet, where the referees or officiating team must keep track of whom the libero subs in and out for. Under FIVB (Federation Internationale de Volleyball) rules, two liberos are designated at the beginning of the play, only one of whom can be on the court at any time.  Furthermore, a libero is not allowed to serve, according to international rules. NCAA rules for both men and women differ on this point; a 2004 rule change allows the libero to serve, but only in a specific rotation. That is, the libero can only serve for one person, not for all of the people for whom he or she goes in. That rule change was also applied to high school and junior high play soon after.  In February 2024, the NCAA allowed women's volleyball teams to designate two liberos for each set of a match, effective with the fall 2024 season. Only one libero can be present on the court at a given time, and each libero can serve in one specific rotation.[34]  Other rule changes enacted in 2000 include allowing serves in which the ball touches the net, as long as it goes over the net into the opponents' court. Also, the service area was expanded to allow players to serve from anywhere behind the end line but still within the theoretical extension of the sidelines. Other changes were made to lighten up calls on faults for carries and double-touches, such as allowing multiple contacts by a single player (\"double-hits\") on a team's first contact provided that they are a part of a single play on the ball.  In 2008, the NCAA changed the minimum number of points needed to win any of the first four sets from 30 to 25 for women's volleyball (men's volleyball remained at 30 for another three years, switching to 25 in 2011). If a fifth (deciding) set is reached, the minimum required score remains at 15. In addition, the word \"game\" is now referred to as \"set\".[25]  The Official Volleyball Rules are prepared and updated every few years by the FIVB's Rules of the Game and Refereeing Commission.[35] The latest edition is usually available on the FIVB's website.[2]  Competitive teams master six basic skills: serve, pass, set, attack, block and dig.[3] Each of these skills comprises a number of specific techniques that have been introduced over the years and are now considered standard practice in high-level volleyball.  A player stands behind the inline and serves the ball, in an attempt to drive it into the opponent's court. The main objective is to make it land inside the court; it is also desirable to set the ball's direction, speed and acceleration so that it becomes difficult for the receiver to handle it properly.[3] A serve is called an \"ace\" when the ball either lands directly onto the opponent's court or the first opponent to touch the ball is unable to volley it (hit it upwards enough for a teammate to continue).  In contemporary volleyball, many types of serves are employed:  Also called reception, the pass is the attempt by a team to properly handle the opponent's serve or any form of attack. Proper handling includes not only preventing the ball from touching the court but also making it reach the position where the setter is standing quickly and precisely.[3]  The skill of passing involves fundamentally two specific techniques: underarm pass, or bump, where the ball touches the inside part of the joined forearms or platform, at waistline; and overhand pass, where it is handled with the fingertips, like a set, above the head.[3] Either are acceptable in professional and beach volleyball; however, there are much tighter regulations on the overhand pass in beach volleyball. When a player passes a ball to their setter, it is ideal that the ball does not have a lot of spin to make it easier for the setter.  The set is usually the second contact that a team makes with the ball.[3] The main goal of setting is to put the ball in the air in such a way that it can be driven by an attack into the opponent's court.[3] The setter coordinates the offensive movements of a team, and is the player who ultimately decides which player will actually attack the ball.  As with passing, one may distinguish between an overhand and a bump set. Since the former allows for more control over the speed and direction of the ball, the bump is used only when the ball is so low it cannot be properly handled with fingertips, or in beach volleyball where rules regulating overhand setting are more stringent. In the case of a set, one also speaks of a front or back set, meaning whether the ball is passed in the direction the setter is facing or behind the setter. There is also a jump set that is used when the ball is too close to the net. In this case, the setter usually jumps off their right foot straight up to avoid going into the net. The setter usually stands about \u2154 of the way from the left to the right of the net and faces the left (the larger portion of net that the setter can see).  Sometimes a setter refrains from raising the ball for a teammate to perform an attack and tries to play it directly onto the opponent's court. This movement is called a \"dump\".[38] This can only be performed when the setter is in the front row, otherwise it constitutes an illegal back court attack. The most common dumps are to 'throw' the ball behind the setter or in front of the setter to zones 2 and 4. More experienced setters toss the ball into the deep corners or spike the ball on the second hit.  As with a set or an overhand pass, the setter\/passer must be careful to touch the ball with both hands at the same time.[3] If one hand is noticeably late to touch the ball this could result in a less effective set, as well as the referee calling a 'double hit' and giving the point to the opposing team.  The attack, also known as the spike, is usually the third contact a team makes with the ball.[3] The object of attacking is to handle the ball so that it lands on the opponent's court and cannot be defended.[3] A player makes a series of steps (the \"approach\"), jumps, and swings at the ball.  Ideally, the contact with the ball is made at the apex of the hitter's jump. At the moment of contact, the hitter's arm is fully extended above their head and slightly forward, making the highest possible contact while maintaining the ability to deliver a powerful hit. The hitter uses arm swing, wrist snap, and a rapid forward contraction of the entire body to drive the ball.[3] A 'bounce' is a slang term for a very hard\/loud spike that follows an almost straight trajectory steeply downward into the opponent's court and bounces very high into the air. A \"kill\" is the slang term for an attack that is not returned by the other team thus resulting in a point.  Contemporary volleyball comprises a number of attacking techniques:[39]  Blocking refers to the actions taken by players standing at the net to stop or alter an opponent's attack.[3]  A block that is aimed at completely stopping an attack, thus making the ball remain in the opponent's court, is called offensive. A well-executed offensive block is performed by jumping and reaching to penetrate with one's arms and hands over the net and into the opponent's area.[3] It requires anticipating the direction the ball will go once the attack takes place.[3] It may also require calculating the best footwork to executing the \"perfect\" block.  The jump should be timed so as to intercept the ball's trajectory prior to it crossing over the plane of the net. Palms are held deflected downward roughly 45\u201360 degrees toward the interior of the opponents' court. A \"roof\" is a spectacular offensive block that redirects the power and speed of the attack straight down to the attacker's floor as if the attacker hit the ball into the underside of a peaked house roof.  By contrast, it is called a defensive, or \"soft\" block if the goal is to control and deflect the hard-driven ball up so that it slows down and becomes easier to defend. A well-executed soft-block is performed by jumping and placing one's hands above the net with no penetration into the opponent's court and with the palms up and fingers pointing backwards.  Blocking is also classified according to the number of players involved. Thus, one may speak of single (or solo), double, or triple block.[3]  Successful blocking does not always result in a \"roof\" and many times does not even touch the ball. While it is obvious that a block was a success when the attacker is roofed, a block that consistently forces the attacker away from their 'power' or preferred attack into a more easily controlled shot by the defence is also a highly successful block.  At the same time, the block position influences the positions where other defenders place themselves while opponent hitters are spiking.  Digging is the ability to prevent the ball from touching one's court after a spike or attack, particularly a ball that is nearly touching the ground.[3] In many aspects, this skill is similar to passing, or bumping: overhand dig and bump are also used to distinguish between defensive actions taken with fingertips or with joined arms.[3] It varies from passing, however, in that it is a much more reflex-based skill, especially at the higher levels. It is especially important while digging for players to stay on their toes; several players choose to employ a split step to make sure they're ready to move in any direction.  Some specific techniques are more common in digging than in passing. A player may sometimes perform a \"dive\", i.e., throw their body in the air with a forward movement in an attempt to save the ball, and land on their chest. When the player also slides their hand under a ball that is almost touching the court, this is called a \"pancake\". The pancake is frequently used in indoor volleyball, but rarely if ever in beach volleyball because the uneven and yielding nature of the sand court limits the chances that the ball will make good, clean contact with the hand. When used correctly, it is one of the more spectacular defensive volleyball plays.  Sometimes a player may also be forced to drop their body quickly to the floor to save the ball. In this situation, the player makes use of a specific rolling technique to minimize the chances of injuries.  Volleyball is essentially a game of transition from one of the above skills to the next, with choreographed team movement between plays on the ball. These team movements are determined by the teams chosen serve receive system, offensive system, coverage system, and defensive system.  The serve-receive system is the formation used by the receiving team to attempt to pass the ball to the designated setter. Systems can consist of 5 receivers, 4 receivers, 3 receivers, and in some cases 2 receivers. The most popular formation at higher levels is a 3 receiver formation consisting of two left sides and a libero receiving every rotation. This allows middles and right sides to become more specialized at hitting and blocking.  Offensive systems are the formations used by the offence to attempt to ground the ball into the opposing court (or otherwise score points). Formations often include designated player positions with skill specialization (see Player specialization, below). Popular formations include the 4\u20132, 6\u20132, and 5-1 systems (see Formations, below). There are also several different attacking schemes teams can use to keep the opposing defence off balance.  Coverage systems are the formations used by the offence to protect their court in the case of a blocked attack. Executed by the 5 offensive players not directly attacking the ball, players move to assigned positions around the attacker to dig up any ball that deflects off the block back into their own court. Popular formations include the 2-3 system and the 1-2-2 system. In lieu of a system, some teams just use a random coverage with the players nearest the hitter.  Defensive systems are the formations used by the defence to protect against the ball being grounded into their court by the opposing team. The system will outline which players are responsible for which areas of the court depending on where the opposing team is attacking from. Popular systems include the 6-Up, 6-Back-Deep, and 6-Back-Slide defence. There are also several different blocking schemes teams can employ to disrupt the opposing teams' offence.  When one player is ready to serve, some teams will line up their other five players in a screen to obscure the view of the receiving team. This action is only illegal if the server makes use of the screen, so the call is made at the referee's discretion as to the impact the screen made on the receiving team's ability to pass the ball. The most common style of screening involves a W formation designed to take up as much horizontal space as possible.  There are five positions filled on every volleyball team at the elite level:  setter, outside hitter (left-side hitter), middle hitter (middle blocker), opposite hitter (right-side hitter) and libero \/ defensive specialist. Each of these positions plays a specific, key role in winning a volleyball match.  At some levels where substitutions are unlimited, teams will make use of a defensive specialist in place of or in addition to a libero. This position does not have unique rules like the libero position, instead, these players are used to substitute out a poor back row defender using regular substitution rules. A defensive specialist is often used if you have a particularly poor back court defender in right side or left side, but your team is already using a libero to take out your middles. Most often, the situation involves a team using a right-side player with a big block who must be subbed out in the back row because they are not able to effectively play backcourt defence. Similarly, teams might use a serving specialist to sub out a poor server.  The three standard volleyball formations are known as \"4\u20132\", \"6\u20132\" and \"5\u20131\", which refers to the number of hitters and setters respectively. 4\u20132 is a basic formation used only in beginners' play, while 5\u20131 is by far the most common formation in high-level play.  The 4\u20132 formation has four hitters and two setters. The setters usually set from the middle front or right front position. The team will, therefore, have two front-row attackers at all times. In the international 4\u20132, the setters set from the right front position. The international 4\u20132 translates more easily into other forms of offence.  The setters line up opposite each other in the rotation. The typical lineup has two outside hitters. By aligning like positions opposite themselves in the rotation, there will always be one of each position in the front and back rows. After service, the players in the front row move into their assigned positions, so that the setter is always in the middle front. Alternatively, the setter moves into the right front and has both a middle and an outside attacker; the disadvantage here lies in the lack of an offside hitter, allowing one of the other team's blockers to \"cheat in\" on a middle block.  The clear disadvantage to this offensive formation is that there are only two attackers, leaving a team with fewer offensive weapons.  Another aspect is to see the setter as an attacking force, albeit a weakened force, because when the setter is in the frontcourt they are able to 'tip' or 'dump', so when the ball is close to the net on the second touch, the setter may opt to hit the ball over with one hand. This means that the blocker who would otherwise not have to block the setter is engaged and may allow one of the hitters to have an easier attack.  In the 6\u20132 formation, a player always comes forward from the back row to set. The three front row players are all in attacking positions. Thus, all six players act as hitters at one time or another, while two can act as setters. So the 6\u20132 formation is actually a 4\u20132 system, but the back-row setter penetrates to set.  The 6\u20132 lineup thus requires two setters, who line up opposite to each other in the rotation. In addition to the setters, a typical lineup will have two middle hitters and two outside hitters. By aligning like positions opposite themselves in the rotation, there will always be one of each position in the front and back rows. After service, the players in the front row move into their assigned positions.  The advantage of the 6\u20132 is that there are always three front-row hitters available, maximizing the offensive possibilities. However, not only does the 6\u20132 require a team to possess two people capable of performing the highly specialized role of setter, it also requires both of those players to be effective offensive hitters when not in the setter position. At the international level, only the Cuban National Women's Team employs this kind of formation. It is also used by NCAA teams in Division III men's play and women's play in all divisions, partially due to the variant rules used which allow more substitutions per set than the 6 allowed in the standard rules\u201412 in matches involving two Division III men's teams[42] and 15 for all women's play.[43]  The 5\u20131 formation has only one player who assumes setting responsibilities regardless of their position in the rotation. The team will, therefore, have three front-row attackers when the setter is in the back row and only two when the setter is in the front row, for a total of five possible attackers.  The player opposite the setter in a 5\u20131 rotation is called the opposite hitter. In general, opposite hitters do not pass; they stand behind their teammates when the opponent is serving. The opposite hitter may be used as a third attack option (back-row attack) when the setter is in the front row: this is the normal option used to increase the attack capabilities of modern volleyball teams. Normally the opposite hitter is the most technically skilled hitter of the team. Back-row attacks generally come from the back-right position, known as zone 1, but are increasingly performed from back-centre in high-level play.  The big advantage of this system is that the setter always has 3 hitters to vary sets with. If the setter does this well, the opponent's middle blocker may not have enough time to block with the outside blocker, increasing the chance for the attacking team to make a point.  There is another advantage, the same as that of a 4\u20132 formation: as a front-row player, the setter is allowed to jump and \"dump\" the ball onto the opponent's side. This too can confuse the opponent's blocking players: the setter can jump and dump or can set to one of the hitters. A good setter knows this and thus will not only jump to dump or to set for a quick hit, but when setting outside as well to confuse the opponent.  The 5\u20131 offence is actually a mix of 6\u20132 and 4\u20132: when the setter is in the front row, the offense looks like a 4\u20132; when the setter is in the back row, the offense looks like a 6\u20132.  There are many variations on the basic rules of volleyball. By far the most popular of these is beach volleyball, which is played on sand with two people per team, and rivals the main sport in popularity.  Some games related to volleyball include: "},{"title":"Australian rules football playing field","content":"  An Australian rules football playing field is a venue where Australian rules football is played.  The playing field is typically a large oval-shaped grass surface, usually a modified cricket field, hence often known as an oval.  These fields may vary especially for variations of the game.  However, for official Australian Football League matches, strict requirement specifications must be met for stadiums.  Australian rules football grounds, even at the highest level of the game, have no fixed dimensions. For senior football, the playing field is an oval between 135\u2013185 metres (148\u2013202\u00a0yd) long goal-to-goal and 110\u2013155 metres (120\u2013170\u00a0yd) wide wing-to-wing. Grounds can vary from long and narrow to almost circular, and are not necessarily symmetrical, depending upon how and where the field was constructed. At least 5 metres (5.5\u00a0yd) of space between the boundary line and any fence is required for safety.[1]  Smaller fields are generally used for junior football; some are purpose-built, and some are temporarily marked out within the confines of full-sized oval; as for a senior match, there are no fixed dimensions for a junior-sized field. The Western Australian Football Commission advises that a good rule of thumb is to set the length of the field equivalent to 3+1\u20442 times the length of an average kick of the age group playing.[2]  By definition in the laws of the game, the portion of the field inside the goal line and boundary lines is called the playing surface. The combination of the playing surface and the space between the boundary line and any perimeter fence, as well as any gaps in the perimeter fence, is called the arena.[1]  A top-level Australian rules football ground has the following markings:[2]  Grounds at lower or junior levels will lack many of these markings, or paint them in lower detail.[4]  At each end of the ground there are two goal posts, spaced 6.4\u00a0m (7\u00a0yd) apart, and a further 6.4\u00a0m (7\u00a0yd) on either side of these are behind posts, 5 metres (16\u00a0ft) in height.  The goal posts are conventionally painted white, and in South Australia, the behind posts are customarily painted red.[5] All posts are typically padded with wall padding to minimise injury due to players colliding with them.[2]  Due to possible injuries caused to players moving at high speed by marking, jumping, turning and being tackled without protective padding, the playing field standards imply use of lawn as a surface.  Almost all Australian rules football fields are of a suitable size and shape for cricket; and in the majority of cases, the fields are used for cricket in the summer and Australian rules football in the winter, a seasonal strategy which is part of the history of Australian sport. As a consequence of this, there are very few fields which were purpose-built for and used by Australian rules football to the exclusion of cricket and all other sports.[citation needed] Like the cricket oval, the field is usually referred to and named as an oval.[6][7]  However, there are many grounds \u2013 particularly those built more recently \u2013 which were built with Australian rules football as the primary intended purpose, but upon which other sports, including cricket, have been played.  Variations of the standard field dimensions and layout exist.  For junior levels, smaller fields are often used.  Rectangular fields have also been used in the past in Australia and also overseas, as well as adapted fields from other sports such as association football and American football. "},{"title":"Rectangle","content":"  In Euclidean plane geometry, a rectangle is a quadrilateral with four right angles. It can also be defined as: an equiangular quadrilateral, since equiangular means that all of its angles are equal (360\u00b0\/4 = 90\u00b0); or a parallelogram containing a right angle. A rectangle with four sides of equal length is a square. The term \"oblong\" is used to refer to a non-square rectangle.[1][2][3] A rectangle with vertices ABCD would be denoted as \u00a0ABCD.  The word rectangle comes from the Latin rectangulus, which is a combination of rectus (as an adjective, right, proper) and angulus (angle).  A crossed rectangle is a crossed (self-intersecting) quadrilateral which consists of two opposite sides of a rectangle along with the two diagonals[4] (therefore only two sides are parallel). It is a special case of an antiparallelogram, and its angles are not right angles and not all equal, though opposite angles are equal. Other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.  Rectangles are involved in many tiling problems, such as tiling the plane by rectangles or tiling a rectangle by polygons.  A convex quadrilateral is a rectangle if and only if it is any one of the following:[5][6]  A rectangle is a special case of a parallelogram in which each pair of adjacent sides is perpendicular.  A parallelogram is a special case of a trapezium (known as a trapezoid in North America) in which both pairs of opposite sides are parallel and equal in length.  A trapezium is a convex quadrilateral which has at least one pair of parallel opposite sides.  A convex quadrilateral is  De Villiers defines a rectangle more generally as any quadrilateral with axes of symmetry through each pair of opposite sides.[9]  This definition includes both right-angled rectangles and crossed rectangles. Each has an axis of symmetry parallel to and equidistant from a pair of opposite sides, and another which is the perpendicular bisector of those sides, but, in the case of the crossed rectangle, the first axis is not an axis of symmetry for either side that it bisects.  Quadrilaterals with two axes of symmetry, each through a pair of opposite sides, belong to the larger class of quadrilaterals with at least one axis of symmetry through a pair of opposite sides. These quadrilaterals comprise isosceles trapezia and crossed isosceles trapezia (crossed quadrilaterals with the same vertex arrangement as isosceles trapezia).  A rectangle is cyclic: all corners lie on a single circle.  It is equiangular: all its corner angles are equal (each of 90 degrees).  It is isogonal or vertex-transitive: all corners lie within the same symmetry orbit.  It has two lines of reflectional symmetry and rotational symmetry of order 2 (through 180\u00b0).  The dual polygon of a rectangle is a rhombus, as shown in the table below.[10]  A rectangle is a rectilinear polygon: its sides meet at right angles.  A rectangle in the plane can be defined by five independent degrees of freedom consisting, for example, of three for position (comprising two of translation and one of rotation), one for shape (aspect ratio), and one for overall size (area).  Two rectangles, neither of which will fit inside the other, are said to be incomparable.  If a rectangle has length     \u2113   {\\displaystyle \\ell }   and width     w   {\\displaystyle w}  , then:[11]  The isoperimetric theorem for rectangles states that among all rectangles of a given perimeter, the square has the largest area.  The midpoints of the sides of any quadrilateral with perpendicular diagonals form a rectangle.  A parallelogram with equal diagonals is a rectangle.  The Japanese theorem for cyclic quadrilaterals[12] states that the incentres of the four triangles determined by the vertices of a cyclic quadrilateral taken three at a time form a rectangle.  The British flag theorem states that with vertices denoted A, B, C, and D, for any point P on the same plane of a rectangle:[13]  For every convex body C in the plane, we can inscribe a rectangle r in C such that a homothetic copy R of r is circumscribed about C and the positive homothety ratio is at most 2 and     0.5  \u00a0\u00d7 Area  ( R ) \u2264  Area  ( C ) \u2264 2  \u00a0\u00d7 Area  ( r )   {\\displaystyle 0.5{\\text{ \u00d7 Area}}(R)\\leq {\\text{Area}}(C)\\leq 2{\\text{ \u00d7 Area}}(r)}  .[14]  There exists a unique rectangle with sides     a   {\\displaystyle a}   and     b   {\\displaystyle b}  , where     a   {\\displaystyle a}   is less than     b   {\\displaystyle b}  , with two ways of being folded along a line through its center such that the area of overlap is minimized and each area yields a different shape\u00a0\u2013 a triangle and a pentagon. The unique ratio of side lengths is        a b   = 0.815023701...    {\\displaystyle \\displaystyle {\\frac {a}{b}}=0.815023701...}  .[15]  A crossed quadrilateral (self-intersecting) consists of two opposite sides of a non-self-intersecting quadrilateral along with the two diagonals. Similarly, a crossed rectangle is a crossed quadrilateral which consists of two opposite sides of a rectangle along with the two diagonals. It has the same vertex arrangement as the rectangle. It appears as two identical triangles with a common vertex, but the geometric intersection is not considered a vertex.  A crossed quadrilateral is sometimes likened to a bow tie or butterfly, sometimes called an \"angular eight\". A three-dimensional rectangular wire frame that is twisted can take the shape of a bow tie.  The interior of a crossed rectangle can have a polygon density of \u00b11 in each triangle, dependent upon the winding orientation as clockwise or counterclockwise.  A crossed rectangle may be considered equiangular if right and left turns are allowed. As with any crossed quadrilateral, the sum of its interior angles is 720\u00b0, allowing for internal angles to appear on the outside and exceed 180\u00b0.[16]  A rectangle and a crossed rectangle are quadrilaterals with the following properties in common:    In spherical geometry, a spherical rectangle is a figure whose four edges are great circle arcs which meet at equal angles greater than 90\u00b0. Opposite arcs are equal in length. The surface of a sphere in Euclidean solid geometry is a non-Euclidean surface in the sense of elliptic geometry. Spherical geometry is the simplest form of elliptic geometry.  In elliptic geometry, an elliptic rectangle is a figure in the elliptic plane whose four edges are elliptic arcs which meet at equal angles greater than 90\u00b0. Opposite arcs are equal in length.  In hyperbolic geometry, a hyperbolic rectangle is a figure in the hyperbolic plane whose four edges are hyperbolic arcs which meet at equal angles less than 90\u00b0. Opposite arcs are equal in length.  The rectangle is used in many periodic tessellation patterns, in brickwork, for example, these tilings:  A rectangle tiled by squares, rectangles, or triangles is said to be a \"squared\", \"rectangled\", or \"triangulated\" (or \"triangled\") rectangle respectively. The tiled rectangle is perfect[17][18] if the tiles are similar and finite in number and no two tiles are the same size. If two such tiles are the same size, the tiling is imperfect. In a perfect (or imperfect) triangled rectangle the triangles must be right triangles. A database of all known perfect rectangles, perfect squares and related shapes can be found at squaring.net. The lowest number of squares need for a perfect tiling of a rectangle is 9[19] and the lowest number needed for a perfect tilling a square is 21, found in 1978 by computer search.[20]  A rectangle has commensurable sides if and only if it is tileable by a finite number of unequal squares.[17][21] The same is true if the tiles are unequal isosceles right triangles.  The tilings of rectangles by other tiles which have attracted the most attention are those by congruent non-rectangular polyominoes, allowing all rotations and reflections. There are also tilings by congruent polyaboloes.  The following Unicode code points depict rectangles: "},{"title":"Great Britain","content":"  Great Britain (commonly shortened to Britain) is an island in the North Atlantic Ocean off the north-west coast of continental Europe, consisting of England, Scotland and Wales. With an area of 209,331\u00a0km2 (80,823\u00a0sq\u00a0mi), it is the largest of the British Isles, the largest European island and the ninth-largest island in the world.[6][note 1] It is dominated by a maritime climate with narrow temperature differences between seasons. The island of Ireland, with an area 40 per cent that of Great Britain, is to the west\u2014these islands, along with over 1,000 smaller surrounding islands and named substantial rocks, form the British Isles archipelago.[8]  Connected to mainland Europe until 9,000 years ago by a landbridge now known as Doggerland,[9] Great Britain has been inhabited by modern humans for around 30,000 years. In 2011, it had a population of about 61 million, making it the world's third-most-populous island after Java in Indonesia and Honshu in Japan,[10][11] and the most populated island outside of Asia.  The term \"Great Britain\" can also refer to the political territory of England, Scotland and Wales, which includes their offshore islands.[12] This territory and Northern Ireland constitute the United Kingdom.[13] The single Kingdom of Great Britain resulted from the 1707 Acts of Union between the kingdoms of England (which at the time incorporated Wales) and Scotland.  The archipelago has been referred to by a single name for over 2000 years: the term 'British Isles' derives from terms used by classical geographers to describe this island group. By 50 BC, Greek geographers were using equivalents of Prettanik\u0113 as a collective name for the British Isles.[14] However, with the Roman conquest of Britain, the Latin term Britannia was used for the island of Great Britain, and later Roman-occupied Britain south of Caledonia.[15][16][17]  The earliest known name for Great Britain is Albion (Greek: \u1f08\u03bb\u03b2\u03b9\u03ce\u03bd) or insula Albionum, from either the Latin albus meaning \"white\" (possibly referring to the white cliffs of Dover, the first view of Britain from the continent) or the \"island of the Albiones\".[18] The oldest mention of terms related to Great Britain was by Aristotle (384\u2013322 BC), or possibly by Pseudo-Aristotle, in his text On the Universe, Vol. III. To quote his works, \"There are two very large islands in it, called the British Isles, Albion and Ierne\".[19]  The first known written use of the word Britain was an ancient Greek transliteration of the original Proto-Celtic term in a work on the travels and discoveries of Pytheas that has not survived. The earliest existing records of the word are quotations of the periplus by later authors, such as those within Strabo's Geographica, Pliny's Natural History and Diodorus of Sicily's Bibliotheca historica.[20] Pliny the Elder (AD 23\u201379) in his Natural History records of Great Britain: \"Its former name was Albion; but at a later period, all the islands, of which we shall just now briefly make mention, were included under the name of 'Britanni\u00e6.'\"[21]  The name Britain descends from the Latin name for Britain, Britannia or Britt\u0101nia, the land of the Britons.[22] Old French Bretaigne (whence also Modern French Bretagne) and Middle English Bretayne, Breteyne. The French form replaced the Old English Breoton, Breoten, Bryten, Breten (also Breoton-lond, Breten-lond). Britannia was used by the Romans from the 1st century BC for the British Isles taken together. It is derived from the travel writings of Pytheas around 320 BC, which described various islands in the North Atlantic as far north as Thule (probably Norway).  The peoples of these islands of Prettanike were called the \u03a0\u03c1\u03b5\u03c4\u03c4\u03b1\u03bd\u03bf\u03af, Priteni or Pretani.[18] Priteni is the source of the Welsh language term Prydain, Britain, which has the same source as the Goidelic term Cruithne used to refer to the early Brythonic-speaking inhabitants of Ireland.[23] The latter were later called Picts or Caledonians by the Romans. Greek historians Diodorus of Sicily and Strabo preserved variants of Prettanike from the work of Greek explorer Pytheas of Massalia, who travelled from his home in Hellenistic southern Gaul to Britain in the 4th century BC. The term used by Pytheas may derive from a Celtic word meaning \"the painted ones\" or \"the tattooed folk\" in reference to body decorations.[24] According to Strabo, Pytheas referred to Britain as Bretannik\u0113, which is treated a feminine noun.[25][26][27][28] Marcian of Heraclea, in his Periplus maris exteri, described the island group as \u03b1\u1f31 \u03a0\u03c1\u03b5\u03c4\u03c4\u03b1\u03bd\u03b9\u03ba\u03b1\u1f76 \u03bd\u1fc6\u03c3\u03bf\u03b9 (the Prettanic Isles).[29]  The Greco-Egyptian scientist Ptolemy referred to the larger island as great Britain (\u03bc\u03b5\u03b3\u03ac\u03bb\u03b7 \u0392\u03c1\u03b5\u03c4\u03c4\u03b1\u03bd\u03af\u03b1 megale Brettania) and to Ireland as little Britain (\u03bc\u03b9\u03ba\u03c1\u1f70 \u0392\u03c1\u03b5\u03c4\u03c4\u03b1\u03bd\u03af\u03b1 mikra Brettania) in his work Almagest (147\u2013148 AD).[31] In his later work, Geography (c.\u2009150 AD), he gave the islands the names Alwion, Iwernia, and Mona (the Isle of Man),[32] suggesting these may have been the names of the individual islands not known to him at the time of writing Almagest.[33] The name Albion appears to have fallen out of use sometime after the Roman conquest of Britain, after which Britain became the more commonplace name for the island.[18]  After the Anglo-Saxon period, Britain was used as a historical term only. Geoffrey of Monmouth in his pseudohistorical Historia Regum Britanniae (c.\u20091136) refers to the island of Great Britain as Britannia major (\"Greater Britain\"), to distinguish it from Britannia minor (\"Lesser Britain\"), the continental region which approximates to modern Brittany and had been settled in the fifth and sixth centuries by Celtic Briton migrants from Great Britain.[citation needed]  The term Great Britain was first used officially in 1474, in the instrument drawing up the proposal for a marriage between Cecily, daughter of Edward IV of England, and James, son of James III of Scotland, which described it as \"this Nobill Isle, callit Gret Britanee\". The Scottish philosopher and historian, John Major (Mair), published his 'History of Great Britain, both England and Scotland' (Historia majoris Britanniae, tam Angliae quam Scotiae) in 1521. While promoting a possible royal match in 1548, Lord Protector Somerset said that the English and Scots were, \"like as twoo brethren of one Islande of great Britaynes again.\" In 1604, James VI and I styled himself \"King of Great Brittaine, France and Ireland\".[34]  Great Britain refers geographically to the island of Great Britain. Politically, it may refer to the whole of England, Scotland and Wales, including their smaller offshore islands.[35] It is not technically correct to use the term to refer to the whole of the United Kingdom which includes Northern Ireland, though the Oxford English Dictionary states \"...the term is also used loosely to refer to the United Kingdom.\"[36][37]  Similarly, Britain can refer to either all islands in Great Britain, the largest island, or the political grouping of countries.[38] There is no clear distinction, even in government documents: the UK government yearbooks have used both Britain[39] and United Kingdom.[40]  GB and GBR are used instead of UK in some international codes to refer to the United Kingdom, including the Universal Postal Union, international sports teams, NATO, and the International Organization for Standardization country codes ISO 3166-2 and ISO 3166-1 alpha-3, whilst the aircraft registration prefix is G.  On the Internet, .uk is the country code top-level domain for the United Kingdom. A .gb top-level domain was used to a limited extent, but is now deprecated; although existing registrations still exist (mainly by government organizations and email providers), the domain name registrar will not take new registrations.  In the Olympics, Team GB is used by the British Olympic Association to represent the British Olympic team. The Olympic Federation of Ireland represents the whole island of Ireland, and Northern Irish sportspeople may choose to compete for either team,[41] most choosing to represent Ireland.[42]  Politically, Great Britain refers to the whole of England, Scotland and Wales in combination,[43] but not Northern Ireland; it includes islands, such as the Isle of Wight, Anglesey, the Isles of Scilly, the Hebrides and the island groups of Orkney and Shetland, that are part of England, Wales, or Scotland. It does not include the Isle of Man and the Channel Islands.[43][44]  The political union that joined the kingdoms of England and Scotland happened in 1707 when the Acts of Union ratified the 1706 Treaty of Union and merged the parliaments of the two nations, forming the Kingdom of Great Britain, which covered the entire island. Before this, a personal union had existed between these two countries since the 1603 Union of the Crowns under James VI of Scotland and I of England.[citation needed]  Great Britain was probably first inhabited by those who crossed on the land bridge from the European mainland. Human footprints have been found from over 800,000 years ago in Norfolk[45] and traces of early humans have been found (at Boxgrove Quarry, Sussex) from some 500,000 years ago[46] and modern humans from about 30,000 years ago. Until about 16,000 years ago, it was connected to Ireland by only an ice bridge, prior to 9,000 years ago it retained a land connection to the continent, with an area of mostly low marshland joining it to what are now Denmark and the Netherlands.[47][48]  In Cheddar Gorge, near Bristol, the remains of animal species native to mainland Europe such as antelopes, brown bears, and wild horses have been found alongside a human skeleton, 'Cheddar Man', dated to about 7150 BC.[49] Great Britain became an island at the end of the last glacial period when sea levels rose due to the combination of melting glaciers and the subsequent isostatic rebound of the crust. Great Britain's Iron Age inhabitants are known as Britons; they spoke Celtic languages.  The Romans conquered most of the island (up to Hadrian's Wall in northern England) and this became the Ancient Roman province of Britannia. In the course of the 500 years after the Roman Empire fell, the Britons of the south and east of the island were assimilated or displaced by invading Germanic tribes (Angles, Saxons, and Jutes, often referred to collectively as Anglo-Saxons). At about the same time, Gaelic tribes from Ireland invaded the north-west, absorbing both the Picts and Britons of northern Britain, eventually forming the Kingdom of Scotland in the 9th century. The south-east of Scotland was colonised by the Angles and formed, until 1018, a part of the Kingdom of Northumbria. Ultimately, the population of south-east Britain came to be referred to as the English people, so-named after the Angles.  Germanic speakers referred to Britons as Welsh. This term came to be applied exclusively to the inhabitants of what is now Wales, but it also survives in names such as Wallace and in the second syllable of Cornwall. Cymry, a name the Britons used to describe themselves, is similarly restricted in modern Welsh to people from Wales, but also survives in English in the place name of Cumbria. The Britons living in the areas now known as Wales, Cumbria and Cornwall were not assimilated by the Germanic tribes, a fact reflected in the survival of Celtic languages in these areas into more recent times.[50] At the time of the Germanic invasion of southern Britain, many Britons emigrated to the area now known as Brittany, where Breton, a Celtic language closely related to Welsh and Cornish and descended from the language of the emigrants, is still spoken. In the 9th century, a series of Danish assaults on northern English kingdoms led to them coming under Danish control (an area known as the Danelaw). In the 10th century, however, all the English kingdoms were unified under one ruler as the kingdom of England when the last constituent kingdom, Northumbria, submitted to Edgar in 959. In 1066, England was conquered by the Normans, who introduced a Norman-speaking administration that was eventually assimilated. Wales came under Anglo-Norman control in 1282, and was officially annexed to England in the 16th century.  On 20 October 1604 King James, who had succeeded separately to the two thrones of England and Scotland, proclaimed himself \"King of Great Brittaine, France, and Ireland\".[51] When James died in 1625 and the Privy Council of England was drafting the proclamation of the new king, Charles I, a Scottish peer, Thomas Erskine, 1st Earl of Kellie, succeeded in insisting that it use the phrase \"King of Great Britain\", which James had preferred, rather than King of Scotland and England (or vice versa).[52] While that title was also used by some of James's successors, England and Scotland each remained legally separate countries, each with its own parliament, until 1707, when each parliament passed an Act of Union to ratify the Treaty of Union that had been agreed the previous year. This created a single kingdom with one parliament with effect from 1 May 1707. The Treaty of Union specified the name of the new all-island state as \"Great Britain\", while describing it as \"One Kingdom\" and \"the United Kingdom\". To most historians, therefore, the all-island state that existed between 1707 and 1800 is either \"Great Britain\" or the \"Kingdom of Great Britain\".  Great Britain lies on the European continental shelf, part of the Eurasian Plate and off the north-west coast of continental Europe, separated from this European mainland by the North Sea and by the English Channel, which narrows to 34\u00a0km (18\u00a0nmi; 21\u00a0mi) at the Straits of Dover.[53] It stretches over about ten degrees of latitude on its longer, north\u2013south axis and covers 209,331\u00a0km2 (80,823\u00a0sq\u00a0mi), excluding the much smaller surrounding islands.[54] The North Channel, Irish Sea, St George's Channel and Celtic Sea separate the island from the island of Ireland to its west.[55] The island is since 1993 joined, via one structure, with continental Europe: the Channel Tunnel, the longest undersea rail tunnel in the world. The island is marked by low, rolling countryside in the east and south, while hills and mountains predominate in the western and northern regions. It is surrounded by over 1,000 smaller islands and islets. The greatest distance between two points is 968.0\u00a0km (601+1\u20442\u00a0mi) (between Land's End, Cornwall and John o' Groats, Caithness), 838 miles (1,349\u00a0km) by road.  The English Channel is thought to have been created between 450,000 and 180,000\u00a0years ago by two catastrophic glacial lake outburst floods caused by the breaching of the Weald-Artois Anticline, a ridge that held back a large proglacial lake, now submerged under the North Sea.[56] Around 10,000\u00a0years ago, during the Devensian glaciation with its lower sea level, Great Britain was not an island, but an upland region of continental north-western Europe, lying partially underneath the Eurasian ice sheet. The sea level was about 120 metres (390\u00a0ft) lower than today, and the bed of the North Sea was dry and acted as a land bridge, now known as Doggerland, to the Continent. It is generally thought that as sea levels gradually rose after the end of the last glacial period of the current ice age, Doggerland reflooded cutting off what was the British peninsula from the European mainland by around 6500\u00a0BC.[57]  Great Britain has been subject to a variety of plate tectonic processes over a very extended period of time. Changing latitude and sea levels have been important factors in the nature of sedimentary sequences, whilst successive continental collisions have affected its geological structure with major faulting and folding being a legacy of each orogeny (mountain-building period), often associated with volcanic activity and the metamorphism of existing rock sequences. As a result of this eventful geological history, the island shows a rich variety of landscapes.  The oldest rocks in Great Britain are the Lewisian gneisses, metamorphic rocks found in the far north west of the island and in the Hebrides (with a few small outcrops elsewhere), which date from at least 2,700\u00a0My ago. South of the gneisses are a complex mixture of rocks forming the North West Highlands and Grampian Highlands in Scotland. These are essentially the remains of folded sedimentary rocks that were deposited between 1,000\u00a0My and 670\u00a0My ago over the gneiss on what was then the floor of the Iapetus Ocean.  In the current era the north of the island is rising as a result of the weight of Devensian ice being lifted. Counterbalanced, the south and east is sinking, generally estimated at 1\u00a0mm (1\u204425\u00a0inch) per year, with the London area sinking at double this partly due to the continuing compaction of the recent clay deposits.  Animal diversity is modest, as a result of factors including the island's small land area, the relatively recent age of the habitats developed since the last glacial period and the island's physical separation from continental Europe, and the effects of seasonal variability.[59] Great Britain also experienced early industrialisation and is subject to continuing urbanisation, which have contributed towards the overall loss of species.[60] A DEFRA (Department for Environment, Food and Rural Affairs) study from 2006 suggested that 100 species have become extinct in the UK during the 20th century, about 100 times the background extinction rate. However, some species, such as the brown rat, red fox, and introduced grey squirrel, are well adapted to urban areas.  Rodents make up 40% of the mammal species.[citation needed] These include squirrels, mice, voles, rats and the recently reintroduced European beaver.[60] There is also an abundance of European rabbit, European hare, shrews, European mole and several species of bat.[60] Carnivorous mammals include the red fox, Eurasian badger, Eurasian otter, weasel, stoat and elusive Scottish wildcat.[61] Various species of seal, whale and dolphin are found on or around British shores and coastlines. The largest land-based wild animals today are deer. The red deer is the largest species, with roe deer and fallow deer also prominent; the latter was introduced by the Normans.[61][62] Sika deer and two more species of smaller deer, muntjac and Chinese water deer, have been introduced, muntjac becoming widespread in England and parts of Wales while Chinese water deer are restricted mainly to East Anglia. Habitat loss has affected many species. Extinct large mammals include the brown bear, grey wolf and wild boar; the latter has had a limited reintroduction in recent times.[60]  There is a wealth of birdlife, with 628 species recorded,[63] of which 258 breed on the island or remain during winter.[64] Because of its mild winters for its latitude, Great Britain hosts important numbers of many wintering species, particularly waders, ducks, geese and swans.[65] Other well known bird species include the golden eagle, grey heron, common kingfisher, common wood pigeon, house sparrow, European robin, grey partridge, and various species of crow, finch, gull, auk, grouse, owl and falcon.[66] There are six species of reptile on the island; three snakes and three lizards including the legless slowworm. One snake, the adder, is venomous but rarely deadly.[67] Amphibians present are frogs, toads and newts.[60] There are also several introduced species of reptile and amphibian.[68]  In a similar sense to fauna, and for similar reasons, the flora consists of fewer species compared to much larger continental Europe.[69] The flora comprises 3,354 vascular plant species, of which 2,297 are native and 1,057 have been introduced.[70] The island has a wide variety of trees, including native species of birch, beech, ash, hawthorn, elm, oak, yew, pine, cherry and apple.[71] Other trees have been naturalised, introduced especially from other parts of Europe (particularly Norway) and North America. Introduced trees include several varieties of pine, chestnut, maple, spruce, sycamore and fir, as well as cherry plum and pear trees.[71] The tallest species are the Douglas firs; two specimens have been recorded measuring 65 metres or 212 feet.[72] The Fortingall Yew in Perthshire is the oldest tree in Europe.[73]  There are at least 1,500 different species of wildflower.[74] Some 107 species are particularly rare or vulnerable and are protected by the Wildlife and Countryside Act 1981. It is illegal to uproot any wildflowers without the landowner's permission.[74][75] A vote in 2002 nominated various wildflowers to represent specific counties.[76] These include red poppies, bluebells, daisies, daffodils, rosemary, gorse, iris, ivy, mint, orchids, brambles, thistles, buttercups, primrose, thyme, tulips, violets, cowslip, heather and many more.[77][78][79][80] There is also more than 1000 species of bryophyte including algae and mosses across the island. The currently known species include 767 mosses, 298 liverworts and 4 hornworts.[81]  There are many species of fungi including lichen-forming species, and the mycobiota is less poorly known than in many other parts of the world. The most recent checklist of Basidiomycota (bracket fungi, jelly fungi, mushrooms and toadstools, puffballs, rusts and smuts), published in 2005, accepts over 3600 species.[82] The most recent checklist of Ascomycota (cup fungi and their allies, including most lichen-forming fungi), published in 1985, accepts another 5100 species.[83] These two lists did not include conidial fungi (fungi mostly with affinities in the Ascomycota but known only in their asexual state) or any of the other main fungal groups (Chytridiomycota, Glomeromycota and Zygomycota). The number of fungal species known very probably exceeds 10,000. There is widespread agreement among mycologists that many others are yet to be discovered.  London is the capital of England and the United Kingdom as a whole, and is the seat of the United Kingdom's government. Edinburgh is the capital city of Scotland, and is the seat of the Scottish Government as well as the highest courts in Scotland. The Palace of Holyroodhouse in Edinburgh is the official residence of the British monarch in Scotland. Cardiff is the capital city of Wales, and is the seat of the Welsh Government.   In the Late Bronze Age, Britain was part of a culture called the Atlantic Bronze Age, held together by maritime trading, which also included Ireland, France, Spain and Portugal. In contrast to the generally accepted view[85] that Celtic originated in the context of the Hallstatt culture, since 2009, John T. Koch and others have proposed that the origins of the Celtic languages are to be sought in Bronze Age Western Europe, especially the Iberian Peninsula.[86][87][88][89] Koch et al.'s proposal has failed to find wide acceptance among experts on the Celtic languages.[85]  All the modern Brythonic languages (Breton, Cornish, Welsh) are generally considered to derive from a common ancestral language termed Brittonic, British, Common Brythonic, Old Brythonic or Proto-Brythonic, which is thought to have developed from Proto-Celtic or early Insular Celtic by the 6th century AD.[90] Brythonic languages were probably spoken before the Roman invasion at least in the majority of Great Britain south of the rivers Forth and Clyde, though the Isle of Man later had a Goidelic language, Manx. Northern Scotland mainly spoke Pritennic, which became Pictish, which may have been a Brythonic language. During the period of the Roman occupation of Southern Britain (AD 43 to c.\u2009410), Common Brythonic borrowed a large stock of Latin words. Approximately 800 of these Latin loan-words have survived in the three modern Brythonic languages. Romano-British is the name for the Latinised form of the language used by Roman authors.  British English is spoken in the present day across the island, and developed from the Old English brought to the island by Anglo-Saxon settlers from the mid 5th century. Some 1.5\u00a0million people speak Scots\u2014which was indigenous language of Scotland and has become closer to English over centuries.[91][92] An estimated 700,000 people speak Welsh,[93] an official language in Wales.[94] In parts of north west Scotland, Scottish Gaelic remains widely spoken. There are various regional dialects of English, and numerous languages spoken by some immigrant populations.  Christianity has been the largest religion by number of adherents since the Early Middle Ages: it was introduced under the ancient Romans, developing as Celtic Christianity. According to tradition, Christianity arrived in the 1st or 2nd century. The most popular form is Anglicanism (known as Episcopalism in Scotland). Dating from the 16th-century Reformation, it regards itself as both Catholic and Reformed. The Head of the Church is the monarch of the United Kingdom, as the Supreme Governor. It has the status of established church in England. There are just over 26\u00a0million adherents to Anglicanism in Britain today,[95] although only around one million regularly attend services. The second largest Christian practice is the Latin Church of the Catholic Church, which traces its history to the 6th century with Augustine of Canterbury and the Gregorian mission. It was the main religion for around a thousand years. There are over 5\u00a0million adherents today, 4.5\u00a0million Catholics in England and Wales[96] and 750,000 in Scotland,[97] although fewer than a million Catholics regularly attend mass.[98]  The Church of Scotland, a form of Protestantism with a Presbyterian system of ecclesiastical polity, is the third most numerous on the island with around 2.1\u00a0million members.[99] Introduced in Scotland by clergyman John Knox, it has the status of national church in Scotland. The monarch of the United Kingdom is represented by a Lord High Commissioner. Methodism is the fourth largest and grew out of Anglicanism through John Wesley.[100] It gained popularity in the old mill towns of Lancashire and Yorkshire, also amongst tin miners in Cornwall.[101] The Presbyterian Church of Wales, which follows Calvinistic Methodism, is the largest denomination in Wales. There are other non-conformist minorities, such as Baptists, Quakers, the United Reformed Church (a union of Congregationalists and English Presbyterians), Unitarians.[102] The first patron saint of Great Britain was Saint Alban.[103] He was the first Christian martyr dating from the Romano-British period, condemned to death for his faith and sacrificed to the pagan gods.[104] In more recent times, some have suggested the adoption of St Aidan as another patron saint of Britain.[105] From Ireland, he worked at Iona amongst the D\u00e1l Riata and then Lindisfarne where he restored Christianity to Northumbria.[105]  The three constituent countries of the United Kingdom have patron saints: Saint George and Saint Andrew are represented in the flags of England and Scotland respectively.[106] These two flags combined to form the basis of the Great Britain royal flag of 1604.[106] Saint David is the patron saint of Wales.[107] There are many other British saints. Some of the best known are Cuthbert, Columba, Patrick, Margaret, Edward the Confessor, Mungo, Thomas More, Petroc, Bede, and Thomas Becket.[107]  Numerous other religions are practised.[108] The 2011 census recorded that Islam had around 2.7\u00a0million adherents (excluding Scotland with about 76,000).[109] More than 1.4\u00a0million people (excluding Scotland's about 38,000) believe in Hinduism, Sikhism, or Buddhism\u2014religions that developed in the Indian subcontinent and Southeast Asia.[109] Judaism figured slightly more than Buddhism at the 2011 census, having 263,000 adherents (excluding Scotland's about 6000).[109] Jews have inhabited Britain since 1070. However, those resident and open about their religion were expelled from England in 1290, replicated in some other Catholic countries of the era. Jews were permitted to re-establish settlement as of 1656, in the interregnum which was a peak of anti-Catholicism.[110] Most Jews in Great Britain have ancestors who fled for their lives, particularly from 19th century Lithuania and the territories occupied by Nazi Germany.[111] "},{"title":"Football player","content":"  A football player or footballer is a sportsperson who plays one of the different types of football. The main types of football are association football, American football, Canadian football, Australian rules football, Gaelic football, rugby league, and rugby union.  It has been estimated that there are 250 million association football players in the world,[1] and many play other forms of football.  Jean-Pierre Papin has described football as a \"universal language\".[2] Footballers across the world and at almost any level may regularly attract large crowds of spectators, and players are the focal points of widespread social phenomena such as association football culture.  Footballers generally begin as amateurs and the best players progress to become professional players. Normally they start at a youth team (any local team) and from there, based on skill and talent, scouts offer contracts. Once signed, some learn to play better football and a few advance to the senior or professional teams.  Pay in some top men's leagues is significantly higher than in other jobs. Players in the Premier League earn an average of $3 million per year.[3] In the wealthiest clubs in European football leagues, men earn an average $7.19 million per year.[4] The best players of those clubs can earn up to $260 million per year.[5]  However, only a fraction of men's professional football players are paid at this level. Wages may be somewhat more moderate in other divisions and leagues. For example, the average annual salary for footballers in Major League Soccer (MLS) is $530,262 as of May 2023.[6]  Average salaries in women's leagues are far lower. For example, players in the National Women's Soccer League (NWSL), which started in 2012, earn an average of $54,000 per year as of May 2022.[7] For the first time in 2022, the NWSL guaranteed players a living wage. The minimum salary in 2023 is $36,400 to ensure players do not need second or third jobs to survive.[8]  A minority of retired footballers continue working full-time in football, for instance as football managers. A 1979 study reported that former first-team ballplayers were over-represented as top-ranking executives in their companies and had greater income mobility than second-teamers and reserves.[9] However, some experience chronic health issues, see below.  In association football, there are four traditional types of specialties (positions): goalkeepers (goalies), defenders (full-backs), midfielders (half-backs), and forwards (attackers). Special purpose positions include such performers as sweepers, stoppers, second forwards (under-attackers), wingers, insiders, etc.  The American football teams' positions are categorized by a form of play where each of them has its spectrum of positions. Those are offensive, defensive, and special teams.  Research shows that association football players who take less than 200 milliseconds after the referee blows their whistle to make a penalty kick are significantly less likely to score than those who take over a second.[16][17]  An Irish 2002 study of association and Gaelic football players characterized players as \"lean and muscular with a reasonably high level of capacity in all areas of physical performance\".[18] The opposite is the case for American football, where obesity could be the cause of grave health problems.[19]  A 2000 study documented injuries sustained by Czech [association] football players at all levels:[20]  Trauma was the cause of 81.5% of the injuries, and overuse was the cause of 18.5%. Joint sprains predominated (30%), followed by fractures (16%), muscle strains (15%), ligament ruptures (12%), meniscal tears and contusions (8%), and other injuries. Injuries to the knee were most prevalent (29%), followed by injuries to the ankle (19%) and spine (9%). More injuries occurred during games (59%) than in practice. [21] Patellar tendinitis (knee pain) is considered an injury that comes from overexertion, which also happens to other athletes of virtually every sport. It is a common problem that football players develop and can usually be treated by a quadriceps strengthening program. Jumping activities place particularly high strains on the tendon and with repetitive jumping, tearing and injury of the tendon can occur. The chronic injury and healing response results in inflammation and localized pain.[22]  Although levels of depression and pain in retired football players are on par with the societal average,[23] some players suffer from post-retirement chronic injuries. Head injuries are a particular concern.  Studies have long shown former American football NFL players have a longer life expectancy than the general public or males with a similar age and race distribution, but a higher rate of cardiovascular issues.[24] A study comparing the deaths of former Major League Baseball players found baseball players lived longer still, perhaps suggesting a \"healthy worker\" bias where NFL athletes lived less long than they would otherwise have, despite their longer than average life expectancy.[25]  A 2009 review of the evidence in the American Journal of Medicine concluded the existing evidence \"did not suggest an increased mortality\" but does \"suggest increased cardiovascular risk..., particularly the heavier linemen.\"[26]  In association football, a 2011 German study found that German national team players lived 1.9 years less than the general male population.[27]  Football players participating in international matches for Germany have reduced longevity compared to the general population. This disadvantage was the larger, the earlier the international football player started his international career. This finding is in line with the current knowledge of life expectancy in major athletes, especially those from other team sports A 1983 study of rugby players found that the life expectancy of All Blacks was the same as for the general population.[28]  Australian rules footballers have lower death rates than the general population.[29]  American football players are prone to head injuries such as concussions. In later life, this increases the risk of dementia[30] and Alzheimer's.[31] Professional American football players self-reporting concussions are at greater risk for having depressive episodes later in life compared with those retired players self-reporting no concussions.[32][33]  Probably due to the repeated trauma associated with heading balls, professional association football has been suggested to increase the incidence of amyotrophic lateral sclerosis.[34] In a 1987 study of former Norwegian association football national team players, one third of the players were found to have central cerebral atrophy, i.e. brain damage.[35] A 1999 study connected soccer to chronic traumatic head injury (CTHI):[36]  [P]articipation in amateur association football in general and concussion specifically is associated with impaired performance in memory and planning functions. Due to the worldwide popularity of soccer, these observations may have important public health implications Anterior cruciate ligaments are particularly vulnerable in most types of football due to injuries that can be sustained during tackles.  An increased incidence of osteoarthritis in the hip joint has been found in retired football players.[37]  A 2012 study of association football injuries found that 19% of all injuries were muscle injuries, of which 54% affected the thigh muscles.[38]  In a 2009 study, association football was found to be associated with favourable sleep patterns and psychological functioning in adolescent male football players.[39]  The rate of suicide among NFL vets has been found to be 59% lower than in the general population.[40]  In 2012, FIFA released a paper intended to identify key risk factors for association football players.[41]  In 2015, a systematic review of a sample of fifty-four peer-reviewed publications and three articles on elite athletes\u2019 mortality and longevity, resulted in major longevity outcomes for the elite athletes (baseball, football, soccer, basketball, and cycling) \"compared to age and sex-matched controls from the general population and other athletes.\" The span longevities were influenced by factors like the type of sport, the playing position, the race, and the energy system.[42]  An observational study held from professional footballers -active (during their career) and recently retired (post-career, aged more than 45 years)- in 70 countries between 2007 and 2013, elaborated on data from the World Footballers' Union (FIFPro), recorded 214 deaths of which 25% was caused by accidents, 11% by suicides and 33% by a suspected cardiac pathology (on an overall 55% of deaths caused by some sort of disease).[43]  Clinical evaluation, ECG , and echocardiography are required for the athletes as pre-participation tools in order to prevent sudden cardiac deaths in people aged less than 35. To evaluate the risk of myocardial fibrosis, may use and recommend the additional use of late gadolinium enhancement (LGE) with pre- and post-contrast and extracellular volume fraction (ECV) images.[44] Even encouraged, it wasn't yet made mandatory.  In 2015, 205 deaths among North American professional athletes who were registered as active at the time of their decease were analysed. Data were collected for the four major sports: National Basketball Association (NBA), National Football League (NFL), National Hockey League (NHL), and Major League Baseball (MLB). The NFL and NBA active players had \"a higher likelihood of dying in a car accident\" and a significantly higher likelihood of dying from a cardiac-related illness compared to the NHL and MLB active populations.[45]  In 2013, a study on 3,439 retired athletes of the National Football Leagues with at least five credited playing seasons between 1959 and 1988 did not show a statistical correlation between suicide mortality and professional activity, particularly football-related compared with the general control sample. No stratification was reported between speed and non-speed position players.[46]  Until the 2000s a very limited number of formal studies has been published on mortality from all causes in soccer players, despite the high interest of the public to the matter. An extended study held in Italy between 1975 and 2003 on a total of 5.389 players, aged 14\u201335 years, highlighted that, while the mortality for cancer and cardiovascular diseases among the football players cohort was significantly lower than the general Italian population, the \"mortality rates for amyotrophic lateral sclerosis and car accidents were significantly higher than expected, and for ALS the risk is 18 times than expected.\"[47] "},{"title":"Legislature","content":"  A legislature is a deliberative assembly with the legal authority to make laws for a political entity such as a country, nation or city. They are often contrasted with the executive and judicial powers of government.  Laws enacted by legislatures are usually known as primary legislation. In addition, legislatures may observe and steer governing actions, with authority to amend the budget involved.  The members of a legislature are called legislators. In a democracy, legislators are most commonly popularly elected, although indirect election and appointment by the executive are also used, particularly for bicameral legislatures featuring an upper house.  The name used to refer to a legislative body varies by country.  Common names include:  By names:  By languages:  Though the specific roles for each legislature differ by location, they all aim to serve the same purpose of appointing officials to represent their citizens to determine appropriate legislation for the country.  Among the earliest recognised legislatures was the Athenian Ecclesia.[1] In the Middle Ages, European monarchs would host assemblies of the nobility, which would later develop into predecessors of modern legislatures.[1] These were often named the Estates. The oldest surviving legislature is the Icelandic Althing, founded in 930 CE.  Democratic legislatures have six major functions: representation, deliberation, legislation, authorizing expenditure, making governments, and oversight.[1]  There exist five ways that representation can be achieved in a legislature:[1]  One of the major functions of a legislature is to discuss and debate issues of major importance to society.[1] This activity can take place in two forms. In debating legislatures, such as the Parliament of the United Kingdom, the floor of the legislature frequently sees lively debate.[1] In contrast, in committee-based legislatures like the United States Congress, deliberation takes place in closed committees.[1]  While legislatures have nominally the sole power to create laws, the substantive extent of this power depends on details of the political system. In Westminster-style legislatures the executive (composed of the cabinet) can essentially pass any laws it wants, as it usually has a majority of legislators behind it, kept in check by the party whip, while committee-based legislatures in continental Europe and those in presidential systems of the Americas have more independence in drafting and amending bills.[2]  The origins of the power of the purse which legislatures typically have in passing or denying government budgets goes back to the European assemblies of nobility which the monarchs would have to consult before raising taxes.[3] For this power to be actually effective, the legislature should be able to amend the budget, have an effective committee system, enough time for consideration, as well as access to relevant background information.[3]  There are several ways in which the legislature can hold the government accountable, including questioning, interpellations, and votes of confidence.  In contrast to democratic systems, legislatures under authoritarianism are used to ensure the stability of the power structure by co-opting potential competing interests within the elites, which they achieve by:[4]  Each chamber of the legislature consists of a number of legislators who use some form of parliamentary procedure to debate political issues and vote on proposed legislation. There must be a certain number of legislators present to carry out these activities; this is called a quorum.  Some of the responsibilities of a legislature, such as giving first consideration to newly proposed legislation, are usually delegated to committees made up of a few of the members of the chamber(s).  The members of a legislature usually represent different political parties; the members from each party generally meet as a caucus to organize their internal affairs.  Legislatures vary widely in the amount of political power they wield, compared to other political players such as judiciaries, militaries, and executives. In 2009, political scientists M. Steven Fish and Matthew Kroenig constructed a Parliamentary powers index in an attempt to quantify the different degrees of power among national legislatures. The German Bundestag, the Italian Parliament, and the Mongolian State Great Khural tied for most powerful, while Myanmar's House of Representatives and Somalia's Transitional Federal Assembly (since replaced by the Federal Parliament of Somalia) tied for least powerful.[5]  Some political systems follows the principle of legislative supremacy, which holds that the legislature is the supreme branch of government and cannot be bound by other institutions, such as the judicial branch or a written constitution. Such a system renders the legislature more powerful.  In parliamentary and semi-presidential systems of government, the executive is responsible to the legislature, which may remove it with a vote of no confidence. On the other hand, according to the separation of powers doctrine, the legislature in a presidential system is considered an independent and coequal branch of government along with both the judiciary and the executive.[6] Nevertheless, many presidential systems provide for the impeachment of the executive for criminal or unconstitutional behaviour.  Legislatures will sometimes delegate their legislative power to administrative or executive agencies.[7]  Legislatures are made up of individual members, known as legislators, who vote on proposed laws. A legislature usually contains a fixed number of legislators; because legislatures usually meet in a specific room filled with seats for the legislators, this is often described as the number of \"seats\" it contains. For example, a legislature that has 100 \"seats\" has 100 members. By extension, an electoral district that elects a single legislator can also be described as a \"seat\", as, for example, in the phrases \"safe seat\" and \"marginal seat\".[8]  After election, the members may be protected by parliamentary immunity or parliamentary privilege, either for all actions the duration of their entire term, or for just those related to their legislative duties.  A legislature may debate and vote upon bills as a single unit, or it may be composed of multiple separate assemblies, called by various names including legislative chambers, debate chambers, and houses, which debate and vote separately and have distinct powers. A legislature which operates as a single unit is unicameral, one divided into two chambers is bicameral, and one divided into three chambers is tricameral.  In bicameral legislatures, one chamber is usually considered the upper house, while the other is considered the lower house. The two types are not rigidly different, but members of upper houses tend to be indirectly elected or appointed rather than directly elected, tend to be allocated by administrative divisions rather than by population, and tend to have longer terms than members of the lower house. In some systems, particularly parliamentary systems, the upper house has less power and tends to have a more advisory role, but in others, particularly federal presidential systems, the upper house has equal or even greater power.   In federations, the upper house typically represents the federation's component states. This is also the case with the supranational legislature of the European Union. The upper house may either contain the delegates of state governments\u00a0\u2013 as in the European Union and in Germany and, before 1913, in the United States\u00a0\u2013 or be elected according to a formula that grants equal representation to states with smaller populations, as is the case in Australia and the United States since 1913.  Tricameral legislatures are rare; the Massachusetts Governor's Council still exists, but the most recent national example existed in the waning years of White-minority rule in South Africa. Tetracameral legislatures no longer exist, but they were previously used in Scandinavia. The only legislature with a number of chambers bigger than four was the Federal Assembly of Yugoslavia; initially established as a Pentacameral body in 1963, it was turned into a hexacameral body in 1967.  Legislatures vary widely in their size. Among national legislatures, China's National People's Congress is the largest with 2,980 members,[9] while Vatican City's Pontifical Commission is the smallest with 7.[10] Neither legislature is democratically elected: The Pontifical Commission members are appointed by the Pope and the National People's Congress is indirectly elected within the context of a one-party state.[9][11]  Legislature size is a trade off between efficiency and representation; the smaller the legislature, the more efficiently it can operate, but the larger the legislature, the better it can represent the political diversity of its constituents. Comparative analysis of national legislatures has found that size of a country's lower house tends to be proportional to the cube root of its population; that is, the size of the lower house tends to increase along with population, but much more slowly.[12] "},{"title":"United States soccer league system","content":"  The United States soccer league system is a series of professional and amateur soccer leagues based, in whole or in part, in the United States. Sometimes called the American soccer pyramid, teams and leagues are not linked by the system of promotion and relegation typical in soccer elsewhere. Instead, the United States Soccer Federation (USSF or U.S. Soccer) defines professional leagues in three levels, called divisions, with all other leagues sanctioned by the USSF not having an official designated level or division.  For practical and historical reasons, some teams from Bermuda, Canada, and Puerto Rico (considered a separate country by FIFA) can also compete in these leagues. However, these teams are not eligible for the U.S. Open Cup and cannot represent the United States in the CONCACAF Champions Cup because they are not affiliated with U.S. Soccer.  No professional league in any of the major pro sports leagues in the U.S. or Canada, including the professional soccer leagues, currently uses a system of promotion and relegation.[1] The country's governing body for the sport, the United States Soccer Federation (also known as the USSF or U.S. Soccer), oversees the league system and is responsible for sanctioning professional leagues. The leagues themselves are responsible for admitting and administering individual teams. Amateur soccer in the United States is regulated by the United States Adult Soccer Association (USASA), the only amateur soccer organization sanctioned by the USSF. Automatic promotion and relegation between its leagues, as exists in many other national league systems, was considered by United Soccer League, but was never implemented; although voluntary promotion and relegation has occurred.[2] Some amateur leagues sanctioned by the USASA also use promotion and relegation systems within multiple levels of their leagues. However, there has never been a merit-based promotion system offered to the USASA's \"national\" leagues, the NPSL and League Two.  College soccer in the United States is sanctioned by bodies outside the direct control of the USSF, the most important of which is the National Collegiate Athletic Association (NCAA). See NCAA Division I women's soccer programs, NCAA Division I men's soccer programs, and NCAA Division II men's soccer programs for a list of college soccer programs in the United States.  The standards for Division I, II and III leagues are set by the USSF.[3]  Ownership requirements  Market requirements  Financial viability  Media  Team organization  League operations  In addition to the required positions filled by full-time staff, the league office must have full-time staff performing the functions of a chief operations officer, a chief financial officer and a director of marketing\/public relations on a year-round basis  Ownership requirements  Markets and stadia  Ownership requirements  Markets and stadia  Since 1996, Major League Soccer (MLS) has been the only sanctioned USSF Division I men's outdoor soccer league in the United States. MLS has grown from 10 teams in 1996 to 29 teams as of the 2023 season.  The USL Championship (USLC) is the only sanctioned Division II men's outdoor soccer league as of 2021. Formed in 2010 as a result of the merger of the former USL First Division and USL Second Division, the USL Championship was sanctioned as Division III league from 2011 to 2016 before becoming provisionally sanctioned as a Division II league for 2017,[5] and receiving full Division II sanctioning in 2018.[6]  The USL Championship expanded almost three-fold since its first season in 2011 to include 35 teams in the 2020 season, with the league divided into two conferences, Eastern and Western. After that season, held amid the backdrop of the COVID-19 pandemic, five teams left the league.  The previously Division II North American Soccer League (NASL) was formed in 2009, but did not debut until 2011 following the controversial 2010 season that saw neither the USL First Division nor the NASL receive Division II sanctioning from the USSF, resulting in the temporary USSF Division 2 Pro League. NASL was sanctioned as a Division II league from 2011 to 2016; when it fielded 8 teams for the 2017 season, U.S. Soccer only granted the league provisional sanctioning as it fell under the 12-team requirement.[7] The USSF rejected the NASL's application to maintain provisional Division II status for the 2018 season as the NASL did not present a plan[8] on how it would meet the Division II criteria.[9] In response, the NASL filed \"a federal antitrust suit against the U.S. Soccer Federation\"[10] in an attempt to force USSF to drop all Division designations. Due to the continuing litigation against U.S. Soccer, the NASL then had to postpone its season to August 2018 and lost four more teams in the process.  In March 2017, United Soccer League announced following the sanctioning of the USL Championship as a Division II league it would start a new tier in its professional structure.[11][12] USL League One received sanctioning in December 2018 and conducted its first season in 2019 with 10 teams. The league expanded to include 12 teams for its second season in 2020 and further expansion had been planned prior to the 2021 season, but was delayed until 2022 or later by COVID-19.  A second Division III league, National Independent Soccer Association (NISA) debuted in August 2019 with eight teams. The league initially played a fall-to-spring season spanning two calendar years but switched to the standard U.S. schedule in 2022.  In September 2015, it was reported that the USSF was proposing the addition of eligibility requirements for sanctioned Division I soccer leagues, including that they must have at least 16 teams, stadiums with a capacity of at least 15,000, and at least 75% of the teams must be in cities that have a population of at least 2 million.[13]  In 2018, the National Premier Soccer League (NPSL), a nationwide amateur league announced the intention to set up a professional division, NPSL Pro. As part of the announcement, NPSL initiated a single season competition, the NPSL Founders Cup, involving 11 teams that will form the new professional league in 2020. As of 2022 this has not materialized and NPSL remains an amateur league.[14]  Below is a list of the number of teams[15] sanctioned by the USSF in the so-called \"modern era\" under the division sanctioning scheme described above.  The USSF does not officially recognize distinctions beyond the three professional divisions above. Currently, three other national leagues are sanctioned by the US Soccer Federation and one of those, the National Premier Soccer League (NPSL), is part of USASA which is a national association member of the USSF and the only[16] member of the Adult Council. USL League Two (USL 2) is a national league run by the USL. Both are recognized in practical terms as playing at a higher level and both since 2020 are considered national leagues earning automatic berths to the US Open Cup first round based on their previous season's league results rather than going through local qualifying.[17] The United Premier Soccer League (UPSL) is also recognized by the USSF as a National Affiliate, but does not gain automatic entry to the Open Cup through the National League track, instead going through local qualifiers.  Additionally, clubs in USL2, UPSL and NPSL pay some of their players and are more accurately described as semi-professional leagues.[citation needed]  USL League Two takes place during the summer months, and has age restrictions.[18] Thus, the player pool is drawn mainly from NCAA college soccer players seeking to continue playing high level soccer during their summer break, while still maintaining their college eligibility.[19] The National Premier Soccer League is similar to USL2 and also attracts top amateur talent from around the United States. However, unlike USL2, the NPSL does not have any age limits or restrictions, thus incorporating both college players and former professional players.[citation needed]. The United Premier Soccer League takes place year round with two seasons, one in spring and one in fall. Unlike USL2 and NPSL, the UPSL does not rely on college players and is the national league with the most diverse participation.  The table below shows the current structure of the system. For each division, its official name, sponsorship name, number of clubs and conferences\/divisions are given. The United States Soccer Federation regulates the standards for a league or division to be recognized as professional, while also determining the level of division for each league.[20]  Division   I  Major League Soccer 29 clubs \u2013 2 conferences[m 1]  II  USL Championship 24 clubs \u2013 2 conferences[m 1]  III  MLS Next Pro29 clubs \u2013 2 conferences[m 1]  National IndependentSoccer Association9 clubs  USL League One 12 clubs  The system is only defined as far as Division 3. Some semi-professional leagues refer to themselves as fourth division, however any tier or division numbers are not recognized for these leagues as U.S. Soccer does not designate a division number nor directly sanction anything below Division 3.[21] What follows is a list of additional notable leagues.  Amateur leagues[m 2]  National Premier Soccer League92 clubs \u2013 4 regions with 14 conferences[m 4]  USL League Two 128 clubs \u2013 4 conferences with 18 divisions[m 4]  NISA Nation  21 clubs \u2013 4 regions[m 4]  United Premier Soccer League Premier Division (Tier 1)[m 5] \u2013 4 conferences with 25 divisions[m 4]  USASA Regional Elite Amateur and State Premier Leagues[m 7] Various Multi-State and State Premier Leagues \u2013 4 regions [m 8]  USASA State Leagues Various, many with multiple tiers \u2013 54 state associations  The Women's United Soccer Association started playing in 2001, but suspended operations in 2003. It was replaced in 2009 with Women's Professional Soccer. WPS closed after the 2011 season due to a dispute with owners, and the WPSL Elite League was the de facto top tier of women's soccer in 2012. In November 2012 the National Women's Soccer League, sponsored by the United States Soccer Federation, the Canadian Soccer Association and the Mexican Football Federation was announced.[22] The league started play in April 2013. Mexico withdrew from sponsorship of the NWSL once it established its own women's league in 2017.  For many years, there were two leagues that acted as an unofficial lower division. The United Soccer Leagues ran the W-League from 1995 to 2015.[23][24] The Women's Premier Soccer League (WPSL) was founded in 1998.[25]  Almost immediately following the demise of the W-League, United Women's Soccer was founded with orphan W-League teams and WPSL breakaways.[26] UWS then formed a U23 reserve league, UWS2, in early 2020.[27]  After the 2019 FIFA Women's World Cup, USL began exploring the idea of creating a professional league to directly compete with NWSL.[28] This effort was scaled back to running an amateur revival of the W-League, which would operate beneath the DII Women's Independent Soccer League (WISL) (operated by NISA) and a planned DIII league run by UWS.[29] The amateur USL W League was officially revived in June 2021, called by USL as \"pre-professional\",[30] and three months later, plans for a new USL Super League were announced, initially at Division II status in direct competition to WISL, both of which aimed to launch in 2023.[31][32] USL later announced it would instead pursue Division I sanctioning for the USL Super League, launching with eight teams in 2024 and an additional five teams in 2025.[33]  While there was never official distinction between the national amateur leagues, it was commonly assumed that the W-League was a higher quality than WPSL.[citation needed] Two W-League teams had effectively promoted into the first division \u2013 the Buffalo Flash becoming the Western New York Flash in 2011 and D.C. United Women becoming the Washington Spirit in 2013 \u2013 while no WPSL teams have ever done so. UWS, as W-League's spiritual successor, has strengthened this image of being the higher-quality amateur league by attracting four teams that had been associated with WPSL Elite.  National Women's Soccer League (NWSL) 14 clubs  Women's Independent Soccer League (WISL) (sanctioning pending) 1 club (TBA planned)  Planned UWS Pro League TBA Clubs  Planned WPSL Pro (sanctioning pending) 10 clubs (planned)[34]  United Women's Soccer (UWS) 49 clubs \u2013 6 conferences  Women's Premier Soccer League (WPSL) 129 clubs \u2013 4 regions with 21 conferences  USL W League (USLW) 65 clubs \u2013 10 divisions  UWS League 2 (UWS2) 47 clubs \u2013 9 conferences  United States Adult Soccer Association (USASA) 55 state associations in 4 regions See List of USASA affiliated leagues for complete list Region I Region II Region III Region IV  Indoor soccer in North America is governed by the Confederaci\u00f3n Panamericana de Minifutbol (CPM), a member of the World Minifootball Federation (WMF).  Leagues\/divisions  Major Arena Soccer League (MASL) 13 clubs  Major Arena Soccer League 2 (M2) 13 clubs  Premier Arena Soccer League (PASL) 9 men's clubs  8 women's clubs  Major Arena Soccer League 3 (M3) 9 men's clubs "},{"title":"Ground (cricket)","content":"In cricket, a ground is a location where cricket matches are played, comprising a cricket field, cricket pavilion and any associated buildings and amenities.   A batter's ground is the area behind the popping crease at their end of the pitch. It is one of the two safe zones that batters run between to score runs.  In addition to the cricket field, the ground may include a pavilion, viewing areas or stadium, a car park, shops, bars, floodlights, sight screens, gates, and conference facilities.[1][2][3]  A batter's ground is the area behind the popping crease at his end of the pitch. In general, a ground belongs only to the batter who is closest to it, and stays so until the other batter gets closer to it. [4]  Whether a batter is in or out of his ground is defined by Law 30 of the Laws of Cricket.[5] So long as the batter has his body or his bat (that he is holding) touching the ground, he is in it, and is said to have \"made good his ground\".[6]  Batters can run between the two grounds to score runs. However, if a batter is out of his ground (which can happen when he enters a ground that another batter is already occupying), he may be dismissed (prevented from further scoring) by being run out or stumped if the wicket in his ground is put down by the ball.  This article about cricket terminology is a stub. You can help Wikipedia by expanding it."},{"title":"Cylinder","content":"A cylinder (from Ancient Greek  \u03ba\u03cd\u03bb\u03b9\u03bd\u03b4\u03c1\u03bf\u03c2 (k\u00falindros)\u00a0'roller, tumbler')[1] has traditionally been a three-dimensional solid, one of the most basic of curvilinear geometric shapes. In elementary geometry, it is considered a prism with a circle as its base.  A cylinder may also be defined as an infinite curvilinear surface in various modern branches of geometry and topology. The shift in the basic meaning\u2014solid versus surface (as in ball and sphere)\u2014has created some ambiguity with terminology. The two concepts may be distinguished by referring to solid cylinders and cylindrical surfaces. In the literature the unadorned term cylinder could refer to either of these or to an even more specialized object, the right circular cylinder.  The definitions and results in this section are taken from the 1913 text Plane and Solid Geometry by George A. Wentworth and David Eugene Smith (Wentworth & Smith 1913).  A cylindrical surface is a surface consisting of all the points on all the lines which are parallel to a given line and which pass through a fixed plane curve in a plane not parallel to the given line. Any line in this family of parallel lines is called an element of the cylindrical surface. From a kinematics point of view, given a plane curve, called the directrix, a cylindrical surface is that surface traced out by a line, called the generatrix, not in the plane of the directrix, moving parallel to itself and always passing through the directrix. Any particular position of the generatrix is an element of the cylindrical surface.  A solid bounded by a cylindrical surface and two parallel planes is called a (solid) cylinder. The line segments determined by an element of the cylindrical surface between the two parallel planes is called an element of the cylinder. All the elements of a cylinder have equal lengths. The region bounded by the cylindrical surface in either of the parallel planes is called a base of the cylinder. The two bases of a cylinder are congruent figures. If the elements of the cylinder are perpendicular to the planes containing the bases, the cylinder is a right cylinder, otherwise it is called an oblique cylinder. If the bases are disks (regions whose boundary is a circle) the cylinder is called a circular cylinder. In some elementary treatments, a cylinder always means a circular cylinder.[2]  The height (or altitude) of a cylinder is the perpendicular distance between its bases.  The cylinder obtained by rotating a line segment about a fixed line that it is parallel to is a cylinder of revolution. A cylinder of revolution is a right circular cylinder. The height of a cylinder of revolution is the length of the generating line segment. The line that the segment is revolved about is called the axis of the cylinder and it passes through the centers of the two bases.  The bare term cylinder often refers to a solid cylinder with circular ends perpendicular to the axis, that is, a right circular cylinder, as shown in the figure. The cylindrical surface without the ends is called an open cylinder. The formulae for the surface area and the volume of a right circular cylinder have been known from early antiquity.  A right circular cylinder can also be thought of as the solid of revolution generated by rotating a rectangle about one of its sides. These cylinders are used in an integration technique (the \"disk method\") for obtaining volumes of solids of revolution.[3]  A tall and thin needle cylinder has a height much greater than its diameter, whereas a short and wide disk cylinder has a diameter much greater than its height.  A cylindric section is the intersection of a cylinder's surface with a plane. They are, in general, curves and are special types of plane sections. The cylindric section by a plane that contains two elements of a cylinder is a parallelogram.[4] Such a cylindric section of a right cylinder is a rectangle.[4]  A cylindric section in which the intersecting plane intersects and is perpendicular to all the elements of the cylinder is called a right section.[5] If a right section of a cylinder is a circle then the cylinder is a circular cylinder. In more generality, if a right section of a cylinder is a conic section (parabola, ellipse, hyperbola) then the solid cylinder is said to be parabolic, elliptic and hyperbolic, respectively.    For a right circular cylinder, there are several ways in which planes can meet a cylinder. First, planes that intersect a base in at most one point. A plane is tangent to the cylinder if it meets the cylinder in a single element.  The right sections are circles and all other planes intersect the cylindrical surface in an ellipse.[6] If a plane intersects a base of the cylinder in exactly two points then the line segment joining these points is part of the cylindric section. If such a plane contains two elements, it has a rectangle as a cylindric section, otherwise the sides of the cylindric section are portions of an ellipse. Finally, if a plane contains more than two points of a base, it contains the entire base and the cylindric section is a circle.  In the case of a right circular cylinder with a cylindric section that is an ellipse, the eccentricity e of the cylindric section and semi-major axis a of the cylindric section depend on the radius of the cylinder r and the angle \u03b1 between the secant plane and cylinder axis, in the following way:          e    = cos \u2061 \u03b1 ,     a    =   r  sin \u2061 \u03b1    .       {\\displaystyle {\\begin{aligned}e&=\\cos \\alpha ,\\\\[1ex]a&={\\frac {r}{\\sin \\alpha }}.\\end{aligned}}}    If the base of a circular cylinder has a radius r and the cylinder has height h, then its volume is given by      V = \u03c0  r  2   h   {\\displaystyle V=\\pi r^{2}h}    This formula holds whether or not the cylinder is a right cylinder.[7]  This formula may be established by using Cavalieri's principle.  In more generality, by the same principle, the volume of any cylinder is the product of the area of a base and the height. For example, an elliptic cylinder with a base having semi-major axis a, semi-minor axis b and height h has a volume V = Ah, where A is the area of the base ellipse (= \u03c0ab). This result for right elliptic cylinders can also be obtained by integration, where the axis of the cylinder is taken as the positive x-axis and A(x) = A the area of each elliptic cross-section, thus:      V =  \u222b  0   h   A ( x ) d x =  \u222b  0   h   \u03c0 a b d x = \u03c0 a b  \u222b  0   h   d x = \u03c0 a b h .   {\\displaystyle V=\\int _{0}^{h}A(x)dx=\\int _{0}^{h}\\pi abdx=\\pi ab\\int _{0}^{h}dx=\\pi abh.}    Using cylindrical coordinates, the volume of a right circular cylinder can be calculated by integration          V    =  \u222b  0   h    \u222b  0   2 \u03c0    \u222b  0   r   s   d s  d \u03d5  d z       = \u03c0   r  2    h .       {\\displaystyle {\\begin{aligned}V&=\\int _{0}^{h}\\int _{0}^{2\\pi }\\int _{0}^{r}s\\,\\,ds\\,d\\phi \\,dz\\\\[5mu]&=\\pi \\,r^{2}\\,h.\\end{aligned}}}    Having radius r and altitude (height) h, the surface area of a right circular cylinder, oriented so that its axis is vertical, consists of three parts:  The area of the top and bottom bases is the same, and is called the base area, B. The area of the side is known as the lateral area, L.  An open cylinder does not include either top or bottom elements, and therefore has surface area (lateral area)      L = 2 \u03c0 r h   {\\displaystyle L=2\\pi rh}    The surface area of the solid right circular cylinder is made up the sum of all three components: top, bottom and side. Its surface area is therefore      A = L + 2 B = 2 \u03c0 r h + 2 \u03c0  r  2   = 2 \u03c0 r ( h + r ) = \u03c0 d ( r + h )   {\\displaystyle A=L+2B=2\\pi rh+2\\pi r^{2}=2\\pi r(h+r)=\\pi d(r+h)}    where d = 2r is the diameter of the circular top or bottom.  For a given volume, the right circular cylinder with the smallest surface area has h = 2r. Equivalently, for a given surface area, the right circular cylinder with the largest volume has h = 2r, that is, the cylinder fits snugly in a cube of side length = altitude ( = diameter of base circle).[8]  The lateral area, L, of a circular cylinder, which need not be a right cylinder, is more generally given by      L = e \u00d7 p ,   {\\displaystyle L=e\\times p,}    where e is the length of an element and p is the perimeter of a right section of the cylinder.[9] This produces the previous formula for lateral area when the cylinder is a right circular cylinder.  A right circular hollow cylinder (or cylindrical shell) is a three-dimensional region bounded by two right circular cylinders having the same axis and two parallel annular bases perpendicular to the cylinders' common axis, as in the diagram.  Let the height be h, internal radius r, and external radius R.  The volume is given by      V = \u03c0 (  R  2   \u2212  r  2   ) h = 2 \u03c0  (    R + r  2   )  h ( R \u2212 r ) .   {\\displaystyle V=\\pi (R^{2}-r^{2})h=2\\pi \\left({\\frac {R+r}{2}}\\right)h(R-r).}    Thus, the volume of a cylindrical shell equals 2\u03c0\u2009\u00d7\u2009average radius\u2009\u00d7\u2009altitude\u2009\u00d7\u2009thickness.[10]  The surface area, including the top and bottom, is given by      A = 2 \u03c0 ( R + r ) h + 2 \u03c0 (  R  2   \u2212  r  2   ) .   {\\displaystyle A=2\\pi (R+r)h+2\\pi (R^{2}-r^{2}).}    Cylindrical shells are used in a common integration technique for finding volumes of solids of revolution.[11]  In the treatise by this name, written c.\u2009225 BCE, Archimedes obtained the result of which he was most proud, namely obtaining the formulas for the volume and surface area of a sphere by exploiting the relationship between a sphere and its circumscribed right circular cylinder of the same height and diameter. The sphere has a volume two-thirds that of the circumscribed cylinder and a surface area  two-thirds that of the cylinder (including the bases). Since the values for the cylinder were already known, he obtained, for the first time, the corresponding values for the sphere. The volume of a sphere of radius r is 4\/3\u03c0r3 = 2\/3 (2\u03c0r3). The surface area of this sphere is 4\u03c0r2 = 2\/3 (6\u03c0r2). A sculpted sphere and cylinder were placed on the tomb of Archimedes at his request.   In some areas of geometry and topology the term cylinder refers to what has been called a cylindrical surface. A cylinder is defined as a surface consisting of all the points on all the lines which are parallel to a given line and which pass through a fixed plane curve in a plane not parallel to the given line.[12] Such cylinders have, at times, been referred to as generalized cylinders. Through each point of a generalized cylinder there passes a unique line that is contained in the cylinder.[13] Thus, this definition may be rephrased to say that a cylinder is any ruled surface spanned by a one-parameter family of parallel lines.  A cylinder having a right section that is an ellipse, parabola, or hyperbola  is called an elliptic cylinder, parabolic cylinder and hyperbolic cylinder, respectively. These are degenerate quadric surfaces.[14]  When the principal axes of a quadric are aligned with the reference frame (always possible for a quadric), a general equation of the quadric in three dimensions is given by      f ( x , y , z ) = A  x  2   + B  y  2   + C  z  2   + D x + E y + G z + H = 0 ,   {\\displaystyle f(x,y,z)=Ax^{2}+By^{2}+Cz^{2}+Dx+Ey+Gz+H=0,}    with the coefficients being real numbers and not all of A, B and C being 0. If at least one variable does not appear in the equation, then the quadric is degenerate. If one variable is missing, we may assume by an appropriate rotation of axes that the variable z does not appear and the general equation of this type of degenerate quadric can be written as[15]      A   (  x +   D  2 A     )   2   + B   (  y +   E  2 B     )   2   = \u03c1 ,   {\\displaystyle A\\left(x+{\\frac {D}{2A}}\\right)^{2}+B\\left(y+{\\frac {E}{2B}}\\right)^{2}=\\rho ,}    where       \u03c1 = \u2212 H +    D  2    4 A    +    E  2    4 B    .   {\\displaystyle \\rho =-H+{\\frac {D^{2}}{4A}}+{\\frac {E^{2}}{4B}}.}    If AB > 0 this is the equation of an elliptic cylinder.[15] Further simplification can be obtained by translation of axes and scalar multiplication. If     \u03c1   {\\displaystyle \\rho }   has the same sign as the coefficients A and B, then the equation of an elliptic cylinder may be rewritten in Cartesian coordinates as:        (   x a   )   2   +   (   y b   )   2   = 1.   {\\displaystyle \\left({\\frac {x}{a}}\\right)^{2}+\\left({\\frac {y}{b}}\\right)^{2}=1.}    This equation of an elliptic cylinder is a generalization of the equation of the ordinary, circular cylinder (a = b). Elliptic cylinders are also known as cylindroids, but that name is ambiguous, as it can also refer to the Pl\u00fccker conoid.  If     \u03c1   {\\displaystyle \\rho }   has a different sign than the coefficients, we obtain the imaginary elliptic cylinders:        (   x a   )   2   +   (   y b   )   2   = \u2212 1 ,   {\\displaystyle \\left({\\frac {x}{a}}\\right)^{2}+\\left({\\frac {y}{b}}\\right)^{2}=-1,}    which have no real points on them. (    \u03c1 = 0   {\\displaystyle \\rho =0}   gives a single real point.)  If A and B have different signs and     \u03c1 \u2260 0   {\\displaystyle \\rho \\neq 0}  , we obtain the hyperbolic cylinders, whose equations may be rewritten as:        (   x a   )   2   \u2212   (   y b   )   2   = 1.   {\\displaystyle \\left({\\frac {x}{a}}\\right)^{2}-\\left({\\frac {y}{b}}\\right)^{2}=1.}    Finally, if AB = 0 assume, without loss of generality, that B = 0 and A = 1 to obtain the parabolic cylinders with equations that can be written as:[16]        x   2   + 2 a  y  = 0.   {\\displaystyle {x}^{2}+2a{y}=0.}    In projective geometry, a cylinder is simply a cone whose apex (vertex) lies on the plane at infinity. If the cone is a quadratic cone, the plane at infinity (which passes through the vertex) can intersect the cone at two real lines, a single real line (actually a coincident pair of lines), or only at the vertex. These cases give rise to the hyperbolic, parabolic or elliptic cylinders respectively.[17]  This concept is useful when considering degenerate conics, which may include the cylindrical conics.  A solid circular cylinder can be seen as the limiting case of a n-gonal prism where n approaches infinity. The connection is very strong and many older texts treat prisms and cylinders simultaneously. Formulas for surface area and volume are derived from the corresponding formulas for prisms by using inscribed and circumscribed prisms and then letting the number of sides of the prism increase without bound.[18] One reason for the early emphasis (and sometimes exclusive treatment) on circular cylinders is that a circular base is the only type of geometric figure for which this technique works with the use of only elementary considerations (no appeal to calculus or more advanced mathematics). Terminology about prisms and cylinders is identical. Thus, for example, since a truncated prism is a prism whose bases do not lie in parallel planes, a solid cylinder whose bases do not lie in parallel planes would be called a truncated cylinder.  From a polyhedral viewpoint, a cylinder can also be seen as a dual of a bicone as an infinite-sided bipyramid. "},{"title":"Lacrosse","content":"  Lacrosse is a contact team sport played with a lacrosse stick and a lacrosse ball. It is the oldest organized sport in North America, with its origins with the indigenous people of North America as early as the 12th century.[2][3][4][5] The game was extensively modified by European colonists, reducing the violence, to create its current collegiate and professional form.[6]  Players use the head of the lacrosse stick to carry, pass, catch, and shoot the ball into the goal. The sport has five versions that have different sticks, fields, rules and equipment: field lacrosse, women's lacrosse, box lacrosse, lacrosse sixes and intercrosse. The men's games, field lacrosse (outdoor) and box lacrosse (indoor), are contact sports and all players wear protective gear: helmet, gloves, shoulder pads, and elbow pads.[7] The women's game is played outdoors and does not allow body contact but does allow stick to stick contact.[8] The only protective gear required for women players is eyegear, while goalies wear helmets and protective pads. Lacrosse sixes is played by both men and women on a smaller field, and is the most common version at multi-sport events. Intercrosse is a mixed-gender non-contact sport that uses an all-plastic stick and a softer ball.[9]  The modern sport is governed by World Lacrosse and is the only international sport organization to recognize First Nations bands and Native American tribes as sovereign nations.[10] The organization hosts the World Lacrosse Championship for men, the Women's Lacrosse World Cup, the World Indoor Lacrosse Championship for box lacrosse, and the Under-19 World Lacrosse Championships for both men and women.[11] Each is held every four years.[11] Lacrosse at the Summer Olympics has been contested at two editions of the Summer Olympic Games, 1904 and 1908.[12][13][14] It will be contested at the 2028 Olympic Games in the lacrosse sixes format.[15] It was also held as a demonstration event at the 1928, 1932, and 1948 Summer Olympics.[16][17]  Lacrosse is based on games played by various Native American communities as early as 1100 AD.[18] By the 17th century, a version of lacrosse was well-established and was documented by Jesuit missionary priests in the territory of present-day Canada.[19]  In the traditional aboriginal Canadian version, each team consisted of about 100 to 1,000 men on a field several miles\/kilometers long. These games lasted from sunup to sundown for two to three days straight and were played as part of ceremonial ritual, a kind of symbolic warfare, or to give thanks to the Creator or Master.[20]  Lacrosse played a significant role in the community and religious life of tribes across the continent for many years. Early lacrosse was characterized by deep spiritual involvement, befitting the spirit of combat in which it was undertaken. Those who took part did so in the role of warriors, with the goal of bringing glory and honour to themselves and their tribes.[21] The game was said to be played \"for the Creator\" or was referred to as \"The Creator's Game\",[22] and a version of the game was called \"baggataway\".[23]  The French Jesuit missionary Jean de Br\u00e9beuf saw Huron tribesmen play the game during 1637 in present-day Ontario. He called it la crosse, \"the stick\" in French.[24] The name seems to be originated from the French term for field hockey, le jeu de la crosse.[25]  James Smith described in some detail a game being played in 1757 by Mohawk people \"wherein now they used a wooden ball, about 3 inches (7.6\u00a0cm) in diameter, and the instrument they moved it with was a strong staff about 5 feet (1.5\u00a0m) long, with a hoop net on the end of it, large enough to contain the ball.\"[26]  English-speaking people from Montreal noticed Mohawk people playing the game and started playing themselves in the 1830s.[24] In 1856, William George Beers, a Canadian dentist, founded the Montreal Lacrosse Club.[27] In 1860, Beers codified the game, shortening the length of each game and reducing the number of players to 12 per team. The first game played under Beers's rules was at Upper Canada College in 1867; they lost to the Toronto Cricket Club by a score of 3\u20131.[24]  The new sport proved to be very popular and spread across the English-speaking world; by 1900 there were dozens of men's clubs in Canada, the United States, England, Australia, and New Zealand. The women's game was introduced by Louisa Lumsden in Scotland in 1890. The first women's club in the United States was started by Rosabelle Sinclair at Bryn Mawr School in 1926.[28]  In the United States, lacrosse during the late 1800s and first half of the 1900s was primarily a regional sport centered around the Mid-Atlantic states, especially New York and Maryland. However, in the last half of the 20th century, the sport spread outside this region, and can be currently found in most of the United States. According to a survey conducted by US Lacrosse in 2016, there are over 825,000 lacrosse participants nationwide and lacrosse is the fastest-growing team sport among NFHS member schools.[29]  Field lacrosse is the men's outdoor version of the sport. There are ten players on each team: three attackmen, three midfielders, three defensemen, and one goalie. Each player carries a lacrosse stick. A short stick measures between 40 and 42 inches (100 and 110\u00a0cm) long and is used by attackmen and midfielders. A maximum of four players on the field per team may carry a long stick which is between 52 and 72 inches (130 and 180\u00a0cm) long and is used by the three defensemen and sometimes one defensive midfielder. The goalie uses a stick with a head as wide as 12 inches (30\u00a0cm) that can be between 40 and 72 inches (100 and 180\u00a0cm) long.[30]  The field of play is 110 by 60 yards (101 by 55\u00a0m). The goals are 6 by 6\u00a0ft (1.8 by 1.8\u00a0m) and are 80\u00a0yd (73\u00a0m) apart. Each goal sits inside a circular \"crease\", measuring 18\u00a0ft (5.5\u00a0m) in diameter.[31] The goalie has special privileges within the crease to avoid opponents' stick checks. Offensive players or their sticks may not enter into the crease at any time. The mid-field line separates the field into an offensive and defensive zone for each team. Each team must keep four players in its defensive zone and three players in its offensive zone at all times. It does not matter which positional players satisfy the requirement, although usually the three attackmen stay in the offensive zone, the three defensemen and the goalie stay in the defensive zone, and the three middies play in both zones. A team that violates this rule is offsides and either loses possession of the ball if they have it or incurs a technical foul if they do not.[32]  The regulation playing time of a game is 60 minutes, divided into four periods of 15 minutes each.[32] Play is started at the beginning of each quarter and after each goal with a face-off. During a face-off, two players lay their sticks on the ground parallel to the mid-line, the two heads of their sticks on opposite sides of the ball. At the whistle, the face-off-men scrap for the ball, often by \"clamping\" it under their stick and flicking it out to their teammates. When one of the teams has possession of the ball, they bring it into their offensive zone and try to score a goal. Due to the offsides rule, settled play involves six offensive players versus six defensive players and a goalie.[33]  If the ball goes out of bounds, possession is awarded against the team that touched it last. The exception is when the ball is shot towards the goal. Missed shots that go out of bounds are awarded to the team that has the player who is the closest to the ball when and where the ball goes out. During play, teams may substitute players in and out if they leave and enter the field through the substitution area, sometimes referred to as \"on the fly\". After penalties and goals, players may freely substitute and do not have to go through the substitution area.[34]  Penalties are awarded for rule violations and result in the offending team losing possession (loss of possession) or temporarily losing a player (time serving). During time serving penalties, the penalized team plays with one fewer player for the duration of the penalty. Time serving penalties are either releasable or non-releasable. When serving a releasable penalty, the offending player may re-enter play if a goal is scored by the opposing team during the duration of the penalty. Non-releasable penalties do not allow this and the player must serve the entire duration. In conjunction with the offsides rule, the opponent may play with six attackers versus the penalized team's five defenders and goalie. The team that has taken the penalty is said to be playing man down, while the other team is man up. Teams will use various lacrosse strategies to attack and defend while a player is being penalized.[32]  There are two classes of rule violations that result in penalties: technical fouls and personal fouls. Technical fouls, such as offsides, pushing, and holding, result in either a loss of possession or a 30-second penalty, depending on which team has the ball. Personal fouls, such as cross-checking, illegal body checking, or slashing, concern actions that endanger player safety. Cross-checking is when a player strikes another player with the shaft of the stick between his hands. A slash is when a player strikes another player with the end of the stick anywhere besides the gloves. These fouls draw 1-minute or longer penalties; the offending player must leave the field.[32]  Box lacrosse is played by teams of five runners plus a goalie on an ice hockey rink where the ice has been removed or covered by artificial turf, or in an indoor soccer field. The enclosed playing area is called a box, in contrast to the open playing field of the traditional game.[35] This version of the game was introduced in Canada in the 1930s to promote business for hockey arenas outside of the ice hockey season.[36]:\u200a157\u200a Within several years it had nearly supplanted field lacrosse in Canada.[36]:\u200a120\u200a  The goals in box lacrosse are smaller than field lacrosse, traditionally 4\u00a0ft (1.2\u00a0m) wide and tall. Also, the goaltender wears much more protective padding, including a massive chest protector and armguard combination known as \"uppers\", large shin guards known as leg pads (both of which must follow strict measurement guidelines), and ice hockey-style goalie masks.[35][37]  The style of the game is quick, accelerated by the close confines of the floor and a shot clock. The shot clock requires the attacking team to take a shot on goal within 30 seconds of gaining possession of the ball.[35] Box lacrosse is also a much more physical game. Since cross checking is legal in box lacrosse, players wear rib pads and the shoulder and elbow pads are bigger and stronger than what field lacrosse players wear. Box lacrosse players wear a hockey helmet with a box lacrosse cage. There is no offsides in box lacrosse, the players substitute freely from their bench areas as in hockey. However, most players specialize in offense or defense, so usually all five runners substitute for teammates as their team transitions between offense and defense.[38]  For penalties, the offending player is sent to the penalty box and his team has to play without him, or man-down, for the length of the penalty. Most fouls are minor penalties and last for two minutes, major penalties for serious offenses last five minutes. What separates box lacrosse (and ice hockey) from other sports is that at the top levels of professional and junior lacrosse, participating in a fight does not automatically cause an ejection, but a five-minute major penalty is given.[35]  Box lacrosse is played at the highest level in the National Lacrosse League and by the Senior A divisions of the Canadian Lacrosse Association. The National Lacrosse League (NLL) employs some minor rule changes from the Canadian Lacrosse Association (CLA) rules. Notably, the goals are 4\u00a0feet 9\u00a0inches (1.45\u00a0m) wide instead of 4 feet (1.2\u00a0m) and the games are played during the winter.[35][39] The NLL games consist of four fifteen-minute quarters compared with three periods of twenty minutes each in CLA games. NLL players may only use sticks with hollow shafts, while CLA permits solid wooden sticks.[39][40]  The rules of women's lacrosse differ significantly from men's lacrosse, most notably by equipment and the degree of allowable physical contact.[41] Women's lacrosse rules also differ significantly between the US and all other countries, who play by the Federation of International Lacrosse (FIL) rules. Women's lacrosse does not allow physical contact, the only protective equipment worn is a mouth guard and eye-guard. In the early part of the 21st century, there have been discussions of requiring headgear to prevent concussions. In 2008, Florida was the first state to mandate headgear in women's lacrosse.[42] Stick checking is permitted in the women's game, but only in certain levels of play and within strict rules. Women's lacrosse also does not allow players to have a pocket, or loose net, on the lacrosse stick. Women start the game with a \"draw\" instead of a face-off. The two players stand up and the ball is placed between their stick heads while their sticks are horizontal at waist-height. At the whistle, the players lift their sticks into the air, trying to control where the ball goes.[43]  The first modern women's lacrosse game was held at St Leonards School in Scotland in 1890. It was introduced by the school's headmistress Louisa Lumsden after a visit to Quebec, where she saw it played.[44] The first women's lacrosse team in the United States was established at Bryn Mawr School in Baltimore, Maryland in 1926.[45]  Both the number of players and the lines on the field differ from men's lacrosse. There are 12 players in women's lacrosse and players must abide by certain boundaries that do not exist in men's play. The three specific boundaries are the 8-meter (26\u00a0ft 3\u00a0in) \"fan\" in front of the goal (11\u00a0m\u00a0[36\u00a0ft 1\u00a0in] internationally), the 12-meter (39\u00a0ft 4\u00a0in) (8\u00a0m\u00a0[26\u00a0ft 3\u00a0in] internationally) half circle that surrounds the 8-meter fan, and the draw circle in the center of the field, which is used for draws to start quarters and after goals. The goal circle is also positioned slightly closer to the end line in women's lacrosse compared to men's. In women's lacrosse on either the offensive or defensive end, the players besides the goaltender are not able to step inside the goal circle; this becomes a \"goal-circle violation\". However, at the women's collegiate level, a new rule has been established that allows defenders to pass through the goal circle.[46]  The 8-meter fan that is in front of the goal circle has a few restrictions in it. Defenders cannot stand inside the 8-meter fan longer than 3 seconds without being a stick-length away from the offensive player they are guarding. This is very similar to the three-second rule in basketball. A three seconds violation results in a player from the other team taking a free shot against the goalie. If you are an attacker trying to shoot the ball into the goal, you are not supposed to take a shot while a defender is in \"shooting space\". To make sure that you, the defender, are being safe, you want to lead with your lacrosse stick and once you are a sticks-length away, you can be in front of her.[47]  Lacrosse sixes is a variant of lacrosse played outdoors with six players on each side.[48] The game follows similar rules to traditional field lacrosse, with modifications and a shorter game time.[49] It was created in 2021 by World Lacrosse in a bid to achieve lacrosse's participation in the Olympic Games, and will make its Olympic debut at the 2028 edition in Los Angeles.[50][51]  Lacrosse sixes has similar rules for men and women but preserves some differences, such as the amount of contact allowed.[52][51] The major rule differences as compared to traditional field lacrosse are as follows:[49][53][54]  Intercrosse, or soft stick lacrosse, is a non-contact form of lacrosse with a standardized set of rules using modified lacrosse equipment. An intercrosse stick is different from a normal lacrosse stick, the head is made completely of plastic instead of leather or nylon pockets in traditional lacrosse sticks. The ball is larger, softer and hollow, unlike a lacrosse ball, which is solid rubber.[55]  Intercrosse as a competitive adult sport is popular in Quebec, Canada, as well as in many European countries, particularly in the Czech Republic.[56] Generally, teams consist of five players per side, and the field size is 20\u00a0m (66\u00a0ft) wide and 40\u00a0m (130\u00a0ft) long. Goals for adults are the same size as box lacrosse, 4\u00a0ft or 1.2\u00a0m in height and width. The international governing body, the F\u00e9d\u00e9ration Internationale d'Inter-Crosse, hosts a World Championship bi-annually.[57]  Soft stick lacrosse is a popular way to introduce youth to the sport.[58] It can be played outdoors or indoors and has a developed curriculum for physical education classes.[59]  Lacrosse has historically been played for the most part in Canada and the United States, with small but dedicated lacrosse communities in the United Kingdom and Australia. Recently, however, lacrosse has begun to flourish at the international level, with teams being established around the world, particularly in Europe and East Asia.[60][61]  In August 2008, the men's international governing body, the International Lacrosse Federation, merged with the women's, the International Federation of Women's Lacrosse Associations, to form the Federation of International Lacrosse (FIL). The FIL changed its name to World Lacrosse in May 2019.[62] There are currently 62 member nations of World Lacrosse.[63]  World Lacrosse sponsors five world championship tournaments: the World Lacrosse Championship for men's field, the Women's Lacrosse World Championship for women's, the World Indoor Lacrosse Championship for box lacrosse, as well as the Men's Under-20 World Lacrosse Championships and Women's Under-20 World Lacrosse Championships. Each is held every four years.[11]  The World Lacrosse Championship (WLC) began in 1968 as a four-team invitational tournament sponsored by the International Lacrosse Federation. Until 1990, only the United States, Canada, England, and Australia had entered. With the expansion of the game internationally, the 2014 World Lacrosse Championship was contested by 38 countries.[64] The WLC has been dominated by the United States. Team USA has won 11 of the 14 titles, with Canada winning the other three.[65]  The Women's Lacrosse World Cup (WLWC) began in 1982. The United States has won 9 of the 11 titles, with Australia winning the other two. Canada and England have always finished in the top five. The 2017 tournament was held in England and featured 25 countries.[66]  The first World Indoor Lacrosse Championship (WILC) was held in 2003 and contested by six nations at four sites in Ontario. Canada won the championship by beating the Iroquois Nationals 21\u20134 in the final. The 2007 championship hosted by the Onondaga Nation included 13 teams. Canada has dominated the competition, winning all five gold medals and never losing a game.[67]  The Iroquois Nationals are the men's national team representing the Six Nations of the Iroquois Confederacy in international field lacrosse competition. The team was admitted to the FIL in 1987. It is the only First Nations team sanctioned for international competition in any sport.[68] The Nationals placed fourth in the 1998, 2002 and 2006 World Lacrosse Championships and third in 2014. The indoor team won the silver medal in all four World Indoor Lacrosse Championships. In 2008, the Iroquois women's team was admitted to the FIL as the Haudenosaunee Nationals. They placed 7th at the 2013 Women's Lacrosse World Cup.[69]  Field lacrosse was a medal sport in the 1904 and the 1908 Summer Olympics. In 1904, three teams competed in the games held in St. Louis. Two Canadian teams, the Winnipeg Shamrocks and a team of Mohawk people from the Iroquois Confederacy, plus the local St. Louis Amateur Athletic Association team representing the United States participated. The Winnipeg Shamrocks captured the gold medal.[70][71] The 1908 games held in London, England, featured only two teams, representing Canada and Great Britain. The Canadians again won the gold medal in a single championship match by a score of 14\u201310.[72]  In the 1928, 1932, and the 1948 Summer Olympics, lacrosse was a demonstration sport. The 1928 Olympics in Amsterdam featured three teams: the United States, Canada, and Great Britain.[73] The 1932 games in Los Angeles featured a three-game exhibition between a Canadian all-star team and the United States.[74] The United States was represented by Johns Hopkins in both the 1928 and 1932 Olympics.[75] The 1948 games featured an exhibition by an \"All-England\" team organized by the English Lacrosse Union and the collegiate lacrosse team from Rensselaer Polytechnic Institute representing the United States. This exhibition match ended in a 5\u20135 tie.[76]  Efforts were made to include lacrosse as an exhibition sport at the 1996 Summer Olympics in Atlanta, Georgia, and the 2000 Summer Olympics in Sydney, Australia, but they were not successful.[77]  An obstacle for lacrosse to return to the Olympics has been insufficient international participation. To be considered for the Olympics, a sport had to be played on four continents and by at least 75 countries. Lacrosse is played on all six continents, but as of August 2019 when Ghana joined, there are only 63 countries playing the sport.[78][79] However, nowadays numeric criteria about widely practiced sports have been abolished.[80] The International Olympic Committee granted provisional status to World Lacrosse in 2018.[81] In August 2022, it was announced that nine sports had made the shortlist to be included in the games, among them lacrosse, with presentations expected to be made later that month.[82][83] In October 2023, the LA28 Organizing Committee announced that it had recommended lacrosse as one of five sports that may be added to the program for the 2028 Summer Olympics.[84] On October 16, 2023, lacrosse received approval from the International Olympic Committee for inclusion in the 2028 Summer Olympics in Los Angeles.[85]  The European Lacrosse Federation (ELF) was established in 1995 and held the first European Lacrosse Championships that year.[86] Originally an annual event, it is now held every four years, in between FIL's men's and women's championships. In 2004, 12 men's and 6 women's teams played in the tournament, making it the largest international lacrosse event of the year. The last men's tournament was in 2016, when 24 countries participated. England won its ninth gold medal out of the ten tournaments played. 2015 was the last women's tournament, when 17 teams participated in the Czech Republic. England won its sixth gold medal, with Wales earning silver and Scotland bronze. These three countries from Great Britain have dominated the women's championships, earning all but three medals since the tournament began in 1996. There are currently 29 members of the ELF, they make up the majority of nations in the FIL.[87]  The Asia Pacific Lacrosse Union was founded in 2004 by Australia, Hong Kong, South Korea and Japan.[88] It currently has 12 members and holds the Asia Pacific Championship for both men's and women's teams every two years.[89][90]  Lacrosse was played in the World Games for the first time at the 2017 World Games held in Poland. Only women's teams took part in the competition. The United States won the gold medal defeating Canada in the finals.[91] Australia won the bronze medal match. The Haudenosaunee Nationals women's lacrosse team could not participate.[citation needed]  Both men and women tournaments consisting of the 6v6 version played on smaller fields were held in the 2022 World Games in Birmingham, Alabama, USA.[92]  Collegiate lacrosse in the United States is played at the NCAA, NAIA and club levels. There are currently 71 NCAA Division I men's lacrosse teams, 93 Division II teams, and 236 Division III teams. Thirty-two schools participate at the NAIA level. 184 men's club teams compete in the Men's Collegiate Lacrosse Association, including most universities and colleges outside the northeastern United States. The National College Lacrosse League and Great Lakes Lacrosse League are two other lower-division club leagues. In Canada, 14 teams from Ontario and Quebec play field lacrosse in the fall in the Canadian University Field Lacrosse Association.[93]  The first U. S. intercollegiate men's lacrosse game was played on November 22, 1877 between New York University and Manhattan College.[94] An organizing body for the sport, the U. S. National Lacrosse Association, was founded in 1879 and the first intercollegiate lacrosse tournament was held in 1881, with Harvard beating Princeton 3\u20130 in the championship game.[95] Annual post-season championships were awarded by a variety of early lacrosse associations through the 1930s. From 1936 to 1972, the United States Intercollegiate Lacrosse Association awarded the Wingate Memorial Trophy to the best college lacrosse team each year.[96]  The NCAA began sponsoring a men's lacrosse championship in 1971, when Cornell took the first title over Maryland, 12\u20136. Syracuse has 10 Division I titles, Johns Hopkins 9, and Princeton 6.[97] The NCAA national championship weekend tournament draws over 80,000 fans.[98]  There are currently 112 Division I women's lacrosse teams, 109 Division II teams, and 282 Division III teams. There are 36 NAIA women's lacrosse teams. The NCAA started sponsoring a women's lacrosse championship in 1982. Maryland has traditionally dominated women's intercollegiate play, producing many head coaches and U.S. national team players. The Terrapins won seven consecutive NCAA championships from 1995 through 2001. Princeton's women's teams have made it to the final game seven times since 1993 and have won three NCAA titles, in 1993, 2002, and 2003. In recent years, Northwestern has become a force, winning the national championship from 2005 through 2009. Maryland ended Northwestern's streak by defeating the Wildcats in the 2010 final, however, Northwestern won the next two titles in 2011 and 2012. Maryland again claimed the national championship in 2014, 2015, and 2017.[99]  The Women's Collegiate Lacrosse Associates (WCLA) is a collection of over 260 college club teams that are organized by US Lacrosse. Teams are organized into two divisions and various leagues.[100]  The National Lacrosse League (NLL) is a men's semi-professional box lacrosse league in North America. The NLL currently has fifteen teams, ten in the United States and five in Canada. The 18-game regular season runs from December to April; games are always on the weekends. The champion is awarded the National Lacrosse League Cup in early June.[101]  Games are played in ice rinks with artificial turf covering the ice. Venues range from NHL arenas seating 19,000 to smaller arenas with under 10,000 capacity. In 2017, average attendance ranged from 3,200 per game in Vancouver to over 15,000 in Buffalo. Overall, the league averaged 9,500 people per game.[102]  With an average salary around $20,000 per season, players have regular jobs, mostly non-lacrosse related, and live in different cities, flying into town for games.[103] Canadians and Native Americans make up over 90% of the players.[104]  The NLL started in 1987 as the Eagle Pro Box Lacrosse League. Teams in Philadelphia, New Jersey, Baltimore and Washington, DC, played a 6-game season. The league operated as the Major Indoor Lacrosse League from 1989 to 1997, when there were six teams playing a 10-game schedule. The current NLL name began in the 1998 season, which included the first Canadian team.[105]  The most successful franchises have been the Toronto Rock and the former Philadelphia Wings (now the Albany FireWolves), each has won six championships.[105]  In October 2018, former MLL player Paul Rabil branched away from the MLL and created the Premier Lacrosse League. The PLL focuses on being a traveling lacrosse league that will bring the best players in the world to different cities in the United States.[106]  Each player has a minimum salary of $25,000, equity in the league, and medical benefits. The average salary is $35,000.[107] The most successful team is Whipsnakes Lacrosse Club which has two championships.  Since its inaugural season in 2019, the PLL has expanded to eight teams and merged with the MLL.  Beginning with the 2022 season, the PLL has had a broadcasting deal with ESPN.[108]  Prior to the 2023 season the PLL announced that they would be assigning home-cities to each team for the 2024 season. The touring model would not cease, however, with each team hosting one regular season weekend where they play a doubleheader. There will also be two neutral site weekends.[109][110]  Athletes Unlimited Lacrosse is a women's lacrosse league that had its inaugural season in 2021. Rather than having set teams, at the end of each week, the top four players are determined by a point system and named captains of next week's teams. They then draft their team for the next week. The champion of the league is the player that scores the most points. There are 56 players in the league as of 2023.[111][112]  Major League Lacrosse (MLL) was a semi-professional field lacrosse league started in 2001 with six teams in the Northeastern United States. The leagues final year had six teams, playing a week long round-robin regular season. MLL rules were based on NCAA men's rules with several exceptions, such as a 16-yard 2-point line and a 60-second shot clock.[113]  MLL venues ranged from small stadiums with under 10,000 capacity to an NFL stadium in Denver that seats 76,000. Overall league average attendance is around 4,000 per game, although the leagues Denver Outlaws had averaged around 10,000 per game since their founding in 2006.[114]  The rookie salary was $7,000 per season and most players made between $10,000 and $20,000 per season. Therefore, the players had other jobs, often non-lacrosse related, and travel to games on the weekends.[115]  The Chesapeake Bayhawks, who had played in the Annapolis\u2013Baltimore\u2013Washington, DC area since 2001, were the most successful franchise with six championships.[116]  On December 16, 2020, it was announced that the MLL was merging all operations with the Premier Lacrosse League. The PLL added the Boston Cannons and rebranded them to \"Cannons Lacrosse Club\". No other MLL teams were added into the PLL.  The United Women's Lacrosse League (UWLX), was a four-team women's lacrosse league, was launched in 2016. The teams are the Baltimore Ride, Boston Storm, Long Island Sound and Philadelphia Force. Long Island won the first two championships.[117] The league closed in 2020.  The Women's Professional Lacrosse League was a professional women's lacrosse league with 5 teams that started in 2018.[118] It closed in 2020.  The lacrosse stick has two parts, the head and the shaft. There are three parts to the head: the scoop, sidewall, and pocket. The scoop is the top of the stick that affects picking up ground ball as well as passing and shooting. The sidewall is the side of the head that affects the depth of the head and the stiffness. The pocket is the leather or nylon mesh attached to the sidewall and scoop. A wider pocket allows an easier time catching balls, but will also cause less ball control. A narrower pocket makes catching harder, but allows more ball retention and accuracy.[119]  Shafts are usually made of hollow metal. They are octagonal, instead of round, in order to provide a better grip. Most are made of aluminum, titanium, scandium, or alloys, but some shafts are made from other materials, including wood, plastic, carbon fiber, or fiberglass.  Stick length, both shaft and head together, is governed by NCAA regulations, which require that men's sticks be from 40 to 42 inches (100 to 110\u00a0cm) long for offensive players, and 52 to 72 inches (130 to 180\u00a0cm) long for defensemen, and 40 to 72 inches (100 to 180\u00a0cm) long for goalies.[30]  Women's sticks must be an overall length of 35.5\u201343.25 inches (90.2\u2013109.9\u00a0cm). The head must be seven to nine inches wide and the top of the ball must remain above the side walls when dropped in the pocket. The goalkeeper's stick must be 35.5\u201348 inches (90\u2013122\u00a0cm) long. The head of the goalie's stick can up to 12 inches (30\u00a0cm) wide and the pocket may be mesh.[120]  The ball is made of solid rubber. It is typically white for men's lacrosse, or yellow for women's lacrosse; but is also produced in a wide variety of colors, such as yellow, orange or lime green according to the Men's Lacrosse Rules and Interpretations.  Men's field lacrosse protective equipment contains a pair of gloves, elbow pads, shoulder pads, helmet, mouthguard, and cleats. Pads differ in size and protection from player to player based on position, ability, comfort and preference. For example, many attack players wear larger and more protective elbow pads to protect themselves from checks thrown at them while defenders typically wear smaller and less protective pads due to their smaller possibility of being checked and goalies usually wear no elbow pads due to the very limited opportunities of being checked. A goalkeeper must also wear a large protective chest pad to cover their stomach and chest and a plastic neck guard that connects to the chin of their helmet to protect them from shots hitting their windpipe. In addition, male goalkeepers are required to wear a protective cup.[30]  Men's box players wear more protective gear than field players due to the increased physical contact and more permissive checking rules. Cross-checking in the back is allowed by the rules. Runners wear larger and heavier elbow pads and stronger shoulder pads that extend down the back of the player. Most players wear rib pads as well.[121] Box goalies wear equipment very similar to ice hockey goalies, the leg blockers are somewhat smaller, although the shoulder pads are bigger than ice hockey pads.[122]  Women's field players are not required to wear protective equipment besides eyewear and a mouthguard. Eyegear is a metal cage covering the eyes attached with a strap around the back of the head. In recent years, there has been discussion about allowing or requiring padded headgear to protect against concussions. Women goalies wear a helmet, gloves, and chest protector.[30] "},{"title":"Handball","content":"  Handball (also known as team handball, European handball or Olympic handball)[3] is a team sport in which two teams of seven players each (six outcourt players and a goalkeeper) pass a ball using their hands with the aim of throwing it into the goal of the opposing team. A standard match consists of two periods of 30 minutes, and the team that scores more goals wins.  Modern handball is played on a court of 40 by 20 metres (131 by 66\u00a0ft), with a goal in the middle of each end. The goals are surrounded by a 6-metre (20\u00a0ft) zone where only the defending goalkeeper is allowed; goals must be scored by throwing the ball from outside the zone or while \"diving\" into it. The sport is usually played indoors, but outdoor variants exist in the forms of field handball, Czech handball (which were more common in the past) and beach handball. The game is fast and high-scoring: professional teams now typically score between 20 and 35 goals each, though lower scores were not uncommon until a few decades ago. Body contact is permitted for the defenders trying to stop the attackers from approaching the goal. No protective equipment is mandated, but players may wear soft protective bands, pads and mouth guards.[4]  The modern set of rules was published in 1917 by Karl Schelenz, Max Heiser, and Erich Konigh,[5] on 29 October in Berlin, which is seen as the date of birth of the sport.[1][6] The rules have had several revisions since. The first official handball match was played in 1917 in Germany.[1] Karl Schelenz modified the rules in 1919.[5] The first international games were played (under these rules) with men in 1925 (between Germany and Belgium) and with women in 1930 (between Germany and Austria).[7]  Men's handball was first played at the Olympics in the 1936 Summer Olympics in Berlin outdoors, and the next time at the 1972 Summer Olympics in Munich indoors; handball has been an Olympic sport since then. Women's handball was added at the 1976 Summer Olympics.[8]  The International Handball Federation was formed in 1946 and, as of 2016[update], has 197 member federations.[9] The sport is most popular in Europe, and European countries have won all medals but one in the men's world championships since 1938. In the women's world championships, only two non-European countries have won the title: South Korea and Brazil. The game also enjoys popularity in East Asia, North Africa and parts of South America.  Games similar to handball were played in Ancient Greece and are represented on amphorae and stone carvings. Although detailed textual reference is rare, there are numerous descriptions of ball games being played where players throw the ball to one another; sometimes this is done in order to avoid interception by a player on the opposing team. Such games were played widely and served as both a form of exercise and a social event.[10]  There is evidence of ancient Roman women playing a version of handball called expulsim ludere.[11] There are records of handball-like games in medieval France, and among the Inuit in Greenland, in the Middle Ages. By the 19th century, there existed similar games of h\u00e5ndbold from Denmark, h\u00e1zen\u00e1 in the Czech Republic, handbol in Ukraine, and torball in Germany.[12]  The team handball game of today was codified at the end of the 19th century in northern Europe: primarily in Denmark, Germany, Norway, and Sweden. The first written set of team handball rules was published in 1906 by the Danish gym teacher, lieutenant and Olympic medalist Holger Nielsen from Ordrup grammar school, north of Copenhagen. The modern set of rules was published by Max Heiser, Karl Schelenz, and Erich Konigh in 1917[5] on 29 October in Berlin, Germany; this day is therefore seen as the \"date of birth\" of the sport.[1][6] The first official handball match was played on 2 December 1917 in Berlin.[1] In 1919 the rules were modified by Karl Schelenz.[5] The first international games were played under these rules, between Germany and Austria by men in 1925 and between Germany and Austria by women in 1930.[7]  In 1926, the Congress of World Athletics (then known as the International Amateur Athletic Federation) nominated a committee to draw up international rules for field handball. The International Amateur Handball Federation was formed in 1928 and later the International Handball Federation was formed in 1946.  Men's field handball was played at the 1936 Summer Olympics in Berlin. During the next several decades, indoor handball flourished and evolved in the Scandinavian countries. The sport re-emerged onto the world stage as men's team handball for the 1972 Summer Olympics in Munich. Women's team handball was added at the 1976 Summer Olympics in Montreal.[8][13] Due to its popularity in the region, the Eastern European countries that refined the event became the dominant force in the sport when it was reintroduced.  The International Handball Federation organised the men's world championship in 1938 and every four (sometimes three) years from World War II to 1995. Since the 1995 world championship in Iceland, the competition has been held every two years. The women's world championship has been held since 1957. The IHF also organizes women's and men's junior world championships. By July 2009, the IHF listed 166 member federations \u2013 approximately 795,000 teams and 19 million players.  The rules are laid out in the IHF's set of rules, most recently published in 2015.[14]  Two teams of seven players (six court players plus one goalkeeper) take the court and attempt to score points by putting the game ball into the opposing team's goal. In handling the ball, players are subject to the following restrictions:  Notable scoring opportunities can occur when attacking players jump into the goal area. For example, an attacking player may catch a pass while launching toward the inside the goal area, and then shoot or pass before touching the floor. Doubling occurs when a diving attacking player passes to another diving teammate.  Handball is played on a court 40 by 20 metres (131\u00a0ft 3\u00a0in \u00d7\u00a065\u00a0ft 7\u00a0in), with a goal in the centre of each end. The goals are surrounded by a near-semicircular area, called the zone or the crease, defined by a line six metres from the goal. A dashed near-semicircular line nine metres from the goal marks the free-throw line. Each line on the court is part of the area it encompasses; the centre line belongs to both halves at the same time.  The goals are two metres high and three metres wide. They must be securely bolted either to the floor or the wall behind.  The goal posts and the crossbar must be made out of the same material (e.g., wood or aluminium) and feature a quadratic cross section with sides of 8\u00a0cm (3\u00a0in). The three sides of the beams visible from the playing court must be painted alternatingly in two contrasting colors which both have to contrast against the background. The colors on both goals must be the same.  Each goal must feature a net. This must be fastened in such a way that a ball thrown into the goal does not leave or pass the goal under normal circumstances. If necessary, a second net may be clasped to the back of the net on the inside.  The goals are surrounded by the crease, also called the zone. This area is delineated by two quarter circles with a radius of six metres around the far corners of each goal post and a connecting line parallel to the goal line. Only the defending goalkeeper is allowed inside this zone. However, court players may catch and touch the ball in the air within it as long as the player starts their jump outside the zone and releases the ball before they land (landing inside the perimeter is allowed in this case as long as the ball has been released).  If a player without the ball contacts the ground inside the goal perimeter, or the line surrounding the perimeter, they must take the most direct path out of it. However, should a player cross the zone in an attempt to gain an advantage (e.g., better position) their team cedes the ball. Similarly, violation of the zone by a defending player is penalized only if they do so in order to gain an advantage in defending.  Outside of one long edge of the court to both sides of the middle line are the substitution areas for each team. Team officials, substitutes, and suspended players must wait within this area. A team's area is the same side as the goal the team is defending; during halftime, substitution areas are swapped. Any player entering or leaving the play must cross the substitution line which is part of the side line and extends 4.5 metres (15\u00a0ft) from the middle line to the team's side.   A standard match has two 30-minute halves with a 10- or 15-minute (major Championships\/Olympics) halftime intermission. At half-time, teams switch sides of the court as well as benches. For youths, the length of the halves is reduced\u201425 minutes at ages 12 to 15, and 20 minutes at ages 8 to 11; though national federations of some countries may differ in their implementation from the official guidelines.[15]  If a decision must be reached in a particular match (e.g., in a tournament) and it ends in a draw after regular time, there are at maximum two overtimes, each consisting of two straight 5-minute periods with a one-minute break in between. If these does not decide the game either, then the winning team is determined in a penalty shootout (best-of-five rounds; if still tied, extra rounds are added until one team wins).  The referees may call timeout according to their sole discretion; typical reasons are injuries, suspensions, or court cleaning. Penalty throws should trigger a timeout only for lengthy delays, such as a change of the goalkeeper.  Since 2012, teams can call 3 team timeouts per game (up to two per half), which last one minute each. This right may only be invoked by the team in possession of the ball. Team representatives must show a green card marked with a black T on the timekeeper's desk. The timekeeper then immediately interrupts the game by sounding the buzzer to stop the clock. Before 2012, teams were allowed only one timeout per half. For the purpose of calling timeouts, overtime and shootouts are extensions of the second half.  A handball match is adjudicated by two equal referees. Some national bodies allow games with only a single referee in special cases like illness on short notice. Should the referees disagree on any occasion, a decision is made on mutual agreement during a short timeout; or, in case of punishments, the more severe of the two comes into effect. The referees are obliged to make their decisions \"on the basis of their observations of facts\".[16] Their judgements are final and can be appealed against only if not in compliance with the rules. Officials can look to TV replays, as needed.  The referees position themselves in such a way that the team players are confined between them. They stand diagonally aligned so that each can observe one side line. Depending on their positions, one is called court referee and the other goal referee. These positions automatically switch on ball turnover. They physically exchange their positions approximately every 10 minutes (long exchange), and change sides every five minutes (short exchange).  The IHF defines 18 hand signals for quick visual communication with players and officials. The signal for warning is accompanied by a yellow card.[17] A disqualification for the game is indicated by a red card,[18] followed by a blue card if the disqualification will be accompanied by a report.[19] The referees also use whistle blows to indicate infractions or to restart the play.  The referees are supported by a scorekeeper and a timekeeper who attend to formal things such as keeping track of goals and suspensions, or starting and stopping the clock, respectively. They also keep an eye on the benches and notify the referees on substitution errors. Their desk is located between the two substitution areas.  Each team consists of seven players on court and seven substitute players on the bench. One player on the court must be the designated goalkeeper, differing in his clothing from the rest of the court players. Substitution of players can be done in any number and at any time during game play. An exchange takes place over the substitution line. A prior notification of the referees is not necessary.  Some national bodies, such as the Deutsche Handball Bund (DHB, \"German Handball Federation\"), allow substitution in junior teams only when in ball possession or during timeouts. This restriction is intended to prevent early specialization of players to offence or defence.  Court players are allowed to touch the ball with any part of their bodies above and including the knee. As in several other team sports, a distinction is made between catching and dribbling. A player who is in possession of the ball may stand stationary for only three seconds, and may take only three steps. They must then either shoot, pass, or dribble the ball. Taking more than three steps at any time is considered travelling, and results in a turnover. A player may dribble as many times as they want (though, since passing is faster, it is the preferred method of attack), as long as during each dribble the hand contacts only the top of the ball. Therefore, carrying is completely prohibited, and results in a turnover. After the dribble is picked up, the player has the right to another three seconds or three steps. The ball must then be passed or shot, as further holding or dribbling will result in a double dribble turnover and a free throw for the other team. Other offensive infractions that result in a turnover include charging and setting an illegal screen. Carrying the ball into the six-metre zone results either in ball possession by the goalkeeper (by attacker) or turnover (by defender).  Only the goalkeepers are allowed to move freely within the goal perimeter, although they may not cross the goal perimeter line while carrying or dribbling the ball. Within the zone, they are allowed to touch the ball with all parts of their bodies, including their feet, with a defensive aim (for other actions, they are subject to the same restrictions as the court players). The goalkeepers may participate in the normal play of their teammates. A regular court player may substitute for the goalkeeper if a team elects to use this scheme in order to outnumber the defending players. Prior to 2015, this court player became the designated goalkeeper on the court and had to wear some vest or bib the same color as the goalkeeper's shirt to be identified as such. A rule change meant to make the game more offensive now allows any player to substitute for the goalkeeper without becoming a designated goalkeeper. The new rule resembles the one used in ice hockey. This rule was first used in the women's world championship in December 2015 and has since been used by the men's European championship in January 2016 and by both genders in the Olympic tournament in 2016. This rule change has led to a drastic increase of empty net goals.[citation needed]  If either goalkeeper deflects the ball over the outer goal line, their team stays in possession of the ball, in contrast to other sports like football. The goalkeeper resumes the play with a throw from within the zone (\"goalkeeper throw\"). In a penalty shot or directly taken free throw, throwing the ball against the head of a goalkeeper who is not moving will lead to a direct disqualification (\"red card\"). Hitting a non moving goalkeeper's head out of regular play will lead to a two-minute suspension as long as the player threw without obstruction.  Outside of own D-zone, the goalkeeper is treated as an ordinary court player, and has to follow court players' rules; holding or tackling an opponent player outside the area risks a direct disqualification.[clarification needed] The goalkeeper may not return to the area with the ball. Passing to one's own goalkeeper results in a turnover.  Each team is allowed to have a maximum of four team officials seated on the benches. An official is anybody who is neither player nor substitute. One official must be the designated representative who is usually the team manager. Since 2012, representatives can call up to 3 team timeouts (up to twice per half), and may address the scorekeeper, timekeeper, and referees (before that, it was once per half); overtime and shootouts are considered extensions of the second half. Other officials typically include physicians or managers. No official is allowed to enter the playing court without the permission of the referees.   The ball is spherical and must be made either of leather or a synthetic material. It is not allowed to have a shiny or slippery surface. As the ball is intended to be operated by a single hand, its official sizes vary depending on age and gender of the participating teams.  The referees may award a special throw to a team. This usually happens after certain events such as scored goals, off-court balls, turnovers and timeouts. All of these special throws require the thrower to obtain a certain position, and pose restrictions on the positions of all other players. Sometimes the execution must wait for a whistle blow by the referee.  Penalties are given to players, in progressive format, for fouls that require more punishment than just a free-throw. Actions directed mainly at the opponent and not the ball (such as reaching around, holding, pushing, tripping, and jumping into opponent) as well as contact from the side, from behind a player or impeding the opponent's counterattack are all considered illegal and are subject to penalty. Any infraction that prevents a clear scoring opportunity will result in a seven-metre penalty shot.  Typically the referee will give a warning yellow card for an illegal action; but, if the contact was particularly dangerous, like striking the opponent in the head, neck or throat, the referee can forego the warning for an immediate two-minute suspension. Players are warned once before given a yellow card; they risk being red-carded if they receive three two-minute suspensions.  A red card results in an ejection from the game and a two-minute penalty for the team. A player may receive a red card directly for particularly rough penalties. For instance, any contact from behind during a fast break is now being treated with a red card; as does any deliberate intent to injure opponents. A red-carded player has to leave the playing area completely. A player who is disqualified may be substituted with another player after the two-minute penalty is served. A coach or official can also be penalized progressively. Any coach or official who receives a two-minute suspension will have to pull out one of their players for two minutes; however, the player is not the one punished, and can be substituted in again, as the penalty consists of the team playing with one fewer player than the opposing team.  After referees award the ball to the opponents for whatever reason, the player currently in possession of the ball has to lay it down quickly, or risk a two-minute suspension. Also, gesticulating or verbally questioning the referee's order, as well as arguing with the officials' decisions, will normally risk a yellow card. If the suspended player protests further, does not walk straight off the court to the bench, or if the referee deems the tempo deliberately slow, that player risks a double yellow card. Illegal substitution (outside of the dedicated area, or if the replacement player enters too early) is prohibited; if they do, they risk a yellow card.  Players are typically referred to by the positions they are playing. The positions are always denoted from the view of the respective goalkeeper, so that a defender on the right opposes an attacker on the left. However, not all of the following positions may be occupied depending on the formation or potential suspensions.  Sometimes, the offense uses formations with two pivot players.  There are many variations in defensive formations. Usually, they are described as n:m formations, where n is the number of players defending at the goal line and m the number of players defending more offensive. Exceptions are the 3:2:1 defense and n+m formation (e.g. 5+1), where m players defend some offensive player in man coverage (instead of the usual zone coverage).  Attacks are played with all court players on the side of the defenders. Depending on the speed of the attack, one distinguishes between three attack waves with a decreasing chance of success:  The third wave evolves into the normal offensive play when all defenders not only reach the zone, but gain their accustomed positions. Some teams then substitute specialised offence players. However, this implies that these players must play in the defence should the opposing team be able to switch quickly to offence. The latter is another benefit for fast playing teams.  If the attacking team does not make sufficient progress (eventually releasing a shot on goal), the referees can call passive play (since 1995, the referee gives an advance warning by holding one hand high, signalling that the attacking team should release a shot soon), turning control over to the other team. A shot on goal or an infringement leading to a yellow card or two-minute penalty will mark the start of a new attack, causing the hand to be taken down; but a shot blocked by the defense or a normal free throw will not. This rule prevents an attacking team from stalling the game indefinitely, as it is difficult to intercept a pass without at the same time conceding dangerous openings towards the goal.  The usual formations of the defense are 6\u20130, when all the defense players line up between the 6-metre (20\u00a0ft) and 9-metre (30\u00a0ft) lines to form a wall; the 5\u20131, when one of the players cruises outside the 9-metre (30\u00a0ft) perimeter, usually targeting the center forwards while the other 5 line up on the 6-metre (20\u00a0ft) line; and the less common 4\u20132 when there are two such defenders out front. Very fast teams will also try a 3\u20133 formation which is close to a switching man-to-man style. The formations vary greatly from country to country, and reflect each country's style of play. 6\u20130 is sometimes known as \"flat defense\", and all other formations are usually called \"offensive defense\".  Handball teams are usually organised as clubs. On a national level, the clubs are associated in federations which organize matches in leagues and tournaments.  The International Handball Federation (IHF) is the administrative and controlling body for international handball. Handball is an Olympic sport played during the Summer Olympics.[20]  The IHF organizes world championships, held in odd-numbered years, with separate competitions for men and women.[21] The IHF World Men's Handball Championship 2023 title holders are Denmark.[22] The IHF World Women's Handball Championship 2021 title holder is Norway.[23]  The IHF is composed of five continental federations: Asian Handball Federation, African Handball Confederation, Pan-American Team Handball Federation, European Handball Federation and Oceania Handball Federation. These federations organize continental championships held every other second year. Handball is played during the Pan American Games,[24] All-Africa Games,[25] and Asian Games.[20] It is also played at the Mediterranean Games. In addition to continental competitions between national teams, the federations arrange international tournaments between club teams.[26]  The worldwide attendance record for seven-a-side handball was set on 10 January 2024 in D\u00fcsseldorf, Germany, during the two opening matches of the 2024 European Men's Handball Championship. The two games (France versus North Macedonia and Germany against Switzerland) were played in front of 53,586 spectators.[27]  Handball events have been selected as a main motif in numerous collectors' coins. One of the recent samples is the \u20ac10 Greek Handball commemorative coin, minted in 2003 to commemorate the 2004 Summer Olympics. On the coin, the modern athlete directs the ball in his hands towards his target, while in the background the ancient athlete is just about to throw a ball, in a game known as cheirosphaira, in a representation taken from a black-figure pottery vase of the Archaic period.[28]  The most recent commemorative coin featuring handball is the British 50 pence coin, part of the series of coins commemorating the London 2012 Olympic Games.[29] "},{"title":"Hebrides","content":"  The Hebrides (\/\u02c8h\u025bbr\u026adi\u02d0z\/ HEB-rid-eez; Scottish Gaelic: Innse Gall, pronounced [\u02c8\u0129\u02d0\u0283\u0259 \u02c8kaul\u032a\u02e0]; Old Norse: Su\u00f0reyjar, lit.\u2009'Southern isles') are an archipelago off the west coast of the Scottish mainland. The islands fall into two main groups, based on their proximity to the mainland: the Inner and Outer Hebrides.   These islands have a long history of occupation (dating back to the Mesolithic period), and the culture of the inhabitants has been successively influenced by the cultures of Celtic-speaking, Norse-speaking, and English-speaking peoples. This diversity is reflected in the various names given to the islands, which are derived from the different languages that have been spoken there at various points in their history.  The Hebrides are where much of Scottish Gaelic literature and Gaelic music has historically originated. Today, the economy of the islands is dependent on crofting, fishing, tourism, the oil industry, and renewable energy. The Hebrides have less biodiversity than mainland Scotland, but a significant number of seals and seabirds.  The islands have a combined area of 7,285\u00a0km2 (2,813\u00a0sq\u00a0mi), and, as of 2011[update], a combined population of around 45,000.[1]  The Hebrides have a diverse geology, ranging in age from Precambrian strata that are amongst the oldest rocks in Europe, to Paleogene igneous intrusions.[2][3][Note 1] Raised shore platforms in the Hebrides have been identified as strandflats, possibly formed during the Pliocene period and later modified by the Quaternary glaciations.[4]  The Hebrides can be divided into two main groups, separated from one another by the Minch to the north and the Sea of the Hebrides to the south. The Inner Hebrides lie closer to mainland Scotland and include Islay, Jura, Skye, Mull, Raasay, Staffa and the Small Isles. There are 36 inhabited islands in this group. The Outer Hebrides form a chain of more than 100 islands and small skerries located about 70\u00a0km (45\u00a0mi) west of mainland Scotland. Among them, 15 are inhabited. The main inhabited islands include Lewis and Harris, North Uist, Benbecula, South Uist, and Barra.   A complication is that there are various descriptions of the scope of the Hebrides. The Collins Encyclopedia of Scotland describes the Inner Hebrides as lying \"east of the Minch\". This definition would encompass all offshore islands, including those that lie in the sea lochs, such as Eilean B\u00e0n and Eilean Donan, which might not ordinarily be described as \"Hebridean\". However, no formal definition exists.[5][6]  In the past, the Outer Hebrides were often referred to as the Long Isle (Scottish Gaelic: An t-Eilean Fada). Today, they are also sometimes known as the Western Isles, although this phrase can also be used to refer to the Hebrides in general.[Note 2]  The Hebrides have a cool, temperate climate that is remarkably mild and steady for such a northerly latitude, due to the influence of the Gulf Stream. In the Outer Hebrides, the average temperature is 6\u00a0\u00b0C (44\u00a0\u00b0F) in January and 14\u00a0\u00b0C (57\u00a0\u00b0F) in the summer. The average annual rainfall in Lewis is 1,100\u00a0mm (43\u00a0in), and there are between 1,100 and 1,200 hours of sunshine per annum (13%). The summer days are relatively long, and May through August is the driest period.[8]  The earliest surviving written references to the islands were made circa 77\u00a0AD by Pliny the Elder in his Natural History: He states that there are 30 Hebudes, and makes a separate reference to Dumna, which Watson (1926) concluded refers unequivocally to the Outer Hebrides. About 80 years after Pliny the Elder, in 140\u2013150\u00a0AD, Ptolemy (drawing on accounts of the naval expeditions of Agricola) writes that there are five Ebudes (possibly meaning the Inner Hebrides) and Dumna.[9][10][11] Later texts in classical Latin, by writers such as Solinus, use the forms Hebudes and H\u00e6budes.[12]  The name Ebudes (used by Ptolemy) may be pre-Celtic.[11] Ptolemy calls Islay \u201cEpidion\u201d,[13] and the use of the letter \"p\" suggests a Brythonic or Pictish tribal name, Epidii,[14] because the root is not Gaelic.[15] Woolf (2012) has suggested that Ebudes may be \"an Irish attempt to reproduce the word Epidii phonetically, rather than by translating it\", and that the tribe's name may come from the root epos, meaning \"horse\".[16] Watson (1926) also notes a possible relationship between Ebudes and the ancient Irish Ulaid tribal name Ibdaig, and also the personal name of a king Iubd\u00e1n (recorded in the Silva Gadelica).[11]  The names of other individual islands reflect their complex linguistic history. The majority are Norse or Gaelic, but the roots of several other names for Hebrides islands may have a pre-Celtic origin.[11] Adomn\u00e1n, a 7th-century abbot of Iona, records Colonsay as Colosus and Tiree as Ethica, and both of these may be pre-Celtic names.[17] The etymology of Skye is complex and may also include a pre-Celtic root.[15] Lewis is Ljo\u00f0h\u00fas in Old Norse. Various suggestions have been made as to possible meanings of the name in Norse (for example, \"song house\"),[18] but the name is not of Gaelic origin, and the Norse provenance is questionable.[15]  The earliest comprehensive written list of Hebridean island names was compiled by Donald Monro in 1549. This list also provides the earliest written reference to the names of some of the islands.   The derivations of all the inhabited islands of the Hebrides and some of the larger uninhabited ones are listed below.  Lewis and Harris is the largest island in Scotland and the third largest of the British Isles, after Great Britain and Ireland.[19] It incorporates Lewis in the north and Harris in the south, both of which are frequently referred to as individual islands, although they are joined by a land border. The island does not have a single common name in either English or Gaelic and is referred to as \"Lewis and Harris\", \"Lewis with Harris\", \"Harris with Lewis\" etc. For this reason it is treated as two separate islands below.[20] The derivation of Lewis may be pre-Celtic (see above) and the origin of Harris is no less problematic. In the Ravenna Cosmography, Erimon may refer to Harris[21] (or possibly the Outer Hebrides as a whole). This word may derive from the Ancient Greek: \u1f10\u03c1\u1fc6\u03bc\u03bf\u03c2 (erimos \"desert\".[22] The origin of Uist (Old Norse: \u00cdvist) is similarly unclear.[15]  There are various examples of earlier names for Inner Hebridean islands that were Gaelic, but these names have since been completely replaced. For example, Adomn\u00e1n records Sainea, Elena, Ommon and Oideacha in the Inner Hebrides. These names presumably passed out of usage in the Norse era, and the locations of the islands they refer to are not clear.[34] As an example of the complexity: Rona may originally have had a Celtic name, then later a similar-sounding Norse name, and then still later a name that was essentially Gaelic again, but with a Norse \"\u00f8y\" or \"ey\" ending.[35] (See Rona, below.)  The names of uninhabited islands follow the same general patterns as the inhabited islands. (See the list, below, of the ten largest islands in the Hebrides and their outliers.)  The etymology of the name \u201cSt Kilda\u201d, a small archipelago west of the Outer Hebrides, and the name of its main island, \u201cHirta,\u201d is very complex. No saint is known by the name of Kilda, so various other theories have been proposed for the word's origin, which dates from the late 16th century.[81] Haswell-Smith (2004) notes that the full name \"St Kilda\" first appears on a Dutch map dated 1666, and that it may derive from the Norse phrase sunt kelda (\"sweet wellwater\") or from a mistaken Dutch assumption that the spring Tobar Childa was dedicated to a saint. (Tobar Childa is a tautological placename, consisting of the Gaelic and Norse words for well, i.e., \"well well\").[82] Similarly unclear is the origin of the Gaelic for \"Hirta\", Hiort, Hirt, or Irt[83] a name for the island that long pre-dates the name \"St Kilda\". Watson (1926) suggests that it may derive from the Old Irish word hirt (\"death\"), possibly a reference to the often lethally dangerous surrounding sea.[84] Maclean (1977) notes that an Icelandic saga about an early 13th-century voyage to Ireland refers to \u201cthe islands of Hirtir\u201d, which means \"stags\" in Norse, and suggests that the outline of the island of Hirta resembles the shape of a stag, speculating that therefore the name \u201cHirta\u201d may be a reference to the island's shape.[85]  The etymology of the names of small islands may be no less complex and elusive. In relation to Dubh Artach, Robert Louis Stevenson believed that \"black and dismal\" was one translation of the name, noting that \"as usual, in Gaelic, it is not the only one.\"[86]  The Hebrides were settled during the Mesolithic era around 6500\u00a0BC or earlier, after the climatic conditions improved enough to sustain human settlement. Occupation at a site on R\u00f9m is dated to 8590 \u00b195 uncorrected radiocarbon years BP, which is amongst the oldest evidence of occupation in Scotland.[97][98] There are many examples of structures from the Neolithic period, the finest example being the standing stones at Callanish, dating to the 3rd millennium BC.[99] Cladh Hallan, a Bronze Age settlement on South Uist is the only site in the UK where prehistoric mummies have been found.[100][101]  In 55\u00a0BC, the Greek historian Diodorus Siculus wrote that there was an island called Hyperborea (which means \"beyond the North Wind\"), where a round temple stood from which the moon appeared only a little distance above the earth every 19 years. This may have been a reference to the stone circle at Callanish.[102]  A traveller called Demetrius of Tarsus related to Plutarch the tale of an expedition to the west coast of Scotland in or shortly before 83\u00a0AD. He stated it was a gloomy journey amongst uninhabited islands, but he had visited one which was the retreat of holy men. He mentioned neither the druids nor the name of the island.[103]  The first written records of native life begin in the 6th century AD, when the founding of the kingdom of D\u00e1l Riata took place.[104] This encompassed roughly what is now Argyll and Bute and Lochaber in Scotland and County Antrim in Ireland.[105] The figure of Columba looms large in any history of D\u00e1l Riata, and his founding of a monastery on Iona ensured that the kingdom would be of great importance in the spread of Christianity in northern Britain. However, Iona was far from unique. Lismore in the territory of the Cen\u00e9l Loairn, was sufficiently important for the death of its abbots to be recorded with some frequency and many smaller sites, such as on Eigg, Hinba, and Tiree, are known from the annals.[106]  North of D\u00e1l Riata, the Inner and Outer Hebrides were nominally under Pictish control, although the historical record is sparse. Hunter (2000) states that in relation to King Bridei I of the Picts in the sixth century: \"As for Shetland, Orkney, Skye and the Western Isles, their inhabitants, most of whom appear to have been Pictish in culture and speech at this time, are likely to have regarded Bridei as a fairly distant presence.\u201d[107]  Viking raids began on Scottish shores towards the end of the 8th century, and the Hebrides came under Norse control and settlement during the ensuing decades, especially following the success of Harald Fairhair at the Battle of Hafrsfjord in 872.[108][109] In the Western Isles Ketill Flatnose may have been the dominant figure of the mid 9th century, by which time he had amassed a substantial island realm and made a variety of alliances with other Norse leaders. These princelings nominally owed allegiance to the Norwegian crown, although in practice the latter's control was fairly limited.[110] Norse control of the Hebrides was formalised in 1098 when Edgar of Scotland formally signed the islands over to Magnus III of Norway.[111] The Scottish acceptance of Magnus III as King of the Isles came after the Norwegian king had conquered Orkney, the Hebrides and the Isle of Man in a swift campaign earlier the same year, directed against the local Norwegian leaders of the various island petty kingdoms. By capturing the islands Magnus imposed a more direct royal control, although at a price. His skald Bjorn Cripplehand recorded that in Lewis \"fire played high in the heaven\" as \"flame spouted from the houses\" and that in the Uists \"the king dyed his sword red in blood\".[111][Note 5]  The Hebrides were now part of the Kingdom of the Isles, whose rulers were themselves vassals of the Kings of Norway. This situation lasted until the partitioning of the Western Isles in 1156, at which time the Outer Hebrides remained under Norwegian control while the Inner Hebrides broke out under Somerled, the Norse-Gael kinsman of the Manx royal house.[113]  Following the ill-fated 1263 expedition of Haakon IV of Norway, the Outer Hebrides and the Isle of Man were yielded to the Kingdom of Scotland as a result of the 1266 Treaty of Perth.[114] Although their contribution to the islands can still be found in personal and place names, the archaeological record of the Norse period is very limited. The best known find is the Lewis chessmen, which date from the mid 12th century.[115]  As the Norse era drew to a close, the Norse-speaking princes were gradually replaced by Gaelic-speaking clan chiefs including the MacLeods of Lewis and Harris, Clan Donald and MacNeil of Barra.[116][117][Note 6] This transition did little to relieve the islands of internecine strife although by the early 14th century the MacDonald Lords of the Isles, based on Islay, were in theory these chiefs' feudal superiors and managed to exert some control.[121]  The Lords of the Isles ruled the Inner Hebrides as well as part of the Western Highlands as subjects of the King of Scots until John MacDonald, fourth Lord of the Isles, squandered the family's powerful position. A rebellion by his nephew, Alexander of Lochalsh provoked an exasperated James IV to forfeit the family's lands in 1493.[122]  In 1598, King James VI authorised some \"Gentleman Adventurers\" from Fife to civilise the \"most barbarous Isle of Lewis\".[123] Initially successful, the colonists were driven out by local forces commanded by Murdoch and Neil MacLeod, who based their forces on Bearasaigh in Loch R\u00f2g. The colonists tried again in 1605 with the same result, but a third attempt in 1607 was more successful and in due course Stornoway became a Burgh of Barony.[123][124] By this time, Lewis was held by the Mackenzies of Kintail (later the Earls of Seaforth), who pursued a more enlightened approach, investing in fishing in particular. The Seaforths' royalist inclinations led to Lewis becoming garrisoned during the Wars of the Three Kingdoms by Cromwell's troops, who destroyed the old castle in Stornoway.[125]  With the implementation of the Treaty of Union in 1707, the Hebrides became part of the new Kingdom of Great Britain, but the clans' loyalties to a distant monarch were not strong. A considerable number of islesmen \"came out\" in support of the Jacobite Earl of Mar in the 1715 and again in the 1745 rising including Macleod of Dunvegan and MacLea of Lismore.[127][128] The aftermath of the decisive Battle of Culloden, which effectively ended Jacobite hopes of a Stuart restoration, was widely felt.[129] The British government's strategy was to estrange the clan chiefs from their kinsmen and turn their descendants into English-speaking landlords whose main concern was the revenues their estates brought rather than the welfare of those who lived on them.[130] This may have brought peace to the islands, but in the following century it came at a terrible price. In the wake of the rebellion, the clan system was broken up and islands of the Hebrides became a series of landed estates.[130][131]  The early 19th century was a time of improvement and population growth. Roads and quays were built; the slate industry became a significant employer on Easdale and surrounding islands; and the construction of the Crinan and Caledonian canals and other engineering works such as Clachan Bridge improved transport and access.[132] However, in the mid-19th century, the inhabitants of many parts of the Hebrides were devastated by the Clearances, which destroyed communities throughout the Highlands and Islands as the human populations were evicted and replaced with sheep farms.[133] The position was exacerbated by the failure of the islands' kelp industry that thrived from the 18th century until the end of the Napoleonic Wars in 1815[134][135] and large scale emigration became endemic.[136]  As Iain Mac Fhearchair, a Gaelic poet from South Uist, wrote for his countrymen who were obliged to leave the Hebrides in the late 18th century, emigration was the only alternative to \"sinking into slavery\" as the Gaels had been unfairly dispossessed by rapacious landlords.[137] In the 1880s, the \"Battle of the Braes\" involved a demonstration against unfair land regulation and eviction, stimulating the calling of the Napier Commission. Disturbances continued until the passing of the 1886 Crofters' Act.[138]  The residents of the Hebrides have spoken a variety of different languages during the long period of human occupation.  It is assumed that Pictish must once have predominated in the northern Inner Hebrides and Outer Hebrides.[107][139] The Scottish Gaelic language arrived from Ireland due to the growing influence of the kingdom of D\u00e1l Riata from the 6th century AD onwards, and became the dominant language of the southern Hebrides at that time.[140][141] For a few centuries, the military might of the Gall-Gh\u00e0idheil meant that Old Norse was prevalent in the Hebrides. North of Ardnamurchan, the place names that existed prior to the 9th century have been all but obliterated.[141] The Old Norse name for the Hebrides during the Viking occupation was Su\u00f0reyjar, which means \"Southern Isles\"; in contrast to the Nor\u00f0reyjar, or \"Northern Isles\" of Orkney and Shetland.[142]  South of Ardnamurchan, Gaelic place names are more common,[141] and after the 13th century, Gaelic became the main language of the entire Hebridean archipelago. Due to Scots and English being favoured in government and the educational system, the Hebrides have been in a state of diglossia since at least the 17th century. The Highland Clearances of the 19th century accelerated the language shift away from Scottish Gaelic, as did increased migration and the continuing lower status of Gaelic speakers.[143] Nevertheless, as late as the end of the 19th century, there were significant populations of monolingual Gaelic speakers, and the Hebrides still contain the highest percentages of Gaelic speakers in Scotland. This is especially true of the Outer Hebrides, where a slim majority speak the language.[143][144] The Scottish Gaelic college, Sabhal M\u00f2r Ostaig, is based on Skye and Islay.[145]  Ironically, given the status of the Western Isles as the last Gaelic-speaking stronghold in Scotland, the Gaelic language name for the islands \u2013 Innse Gall \u2013 means \"isles of the foreigners\"; from the time when they were under Norse colonisation.[146]  For those who remained, new economic opportunities emerged through the export of cattle, commercial fishing and tourism.[147] Nonetheless, emigration and military service became the choice of many[148] and the archipelago's populations continued to dwindle throughout the late 19th century and for much of the 20th century.[149][150] Lengthy periods of continuous occupation notwithstanding, many of the smaller islands were abandoned.[151]  There were, however, continuing gradual economic improvements, among the most visible of which was the replacement of the traditional thatched blackhouse with accommodation of a more modern design[152] and with the assistance of Highlands and Islands Enterprise many of the islands' populations have begun to increase after decades of decline.[1] The discovery of substantial deposits of North Sea oil in 1965 and the renewables sector have contributed to a degree of economic stability in recent decades. For example, the Arnish yard has had a chequered history but has been a significant employer in both the oil and renewables industries.[153]  The widespread immigration of mainlanders, particularly non-Gaelic speakers, has been a subject of controversy.[154][155]   Agriculture practised by crofters remained popular in the 21st century in the Hebrides; crofters own a small property but often share a large common grazing area. Various types of funding are available to crofters to help supplement their incomes, including the \"Basic Payment Scheme, the suckler beef support scheme, the upland sheep support scheme and the Less Favoured Area support scheme\". One reliable source discussed the Crofting Agricultural Grant Scheme (CAGS) in March 2020:[156] the scheme \"pays up to \u00a325,000 per claim in any two-year period, covering 80% of investment costs for those who are under 41 and have had their croft less than five years. Older, more established crofters can get 60% grants\". Many contemporary Gaelic musicians have roots in the Hebrides, including vocalist and multi-instrumentalist Julie Fowlis (North Uist),[157] Catherine-Ann MacPhee (Barra), Kathleen MacInnes of the band Capercaillie (South Uist), and Ishbel MacAskill (Lewis). All of these singers have composed their own music in Scottish Gaelic, with much of their repertoire stemming from Hebridean vocal traditions, such as puirt \u00e0 beul (\u201cmouth music\u201d, similar to Irish lilting) and \u00f2rain luaidh (waulking songs). This tradition includes many songs composed by little-known or anonymous poets, well-before the 1800s, such as \"Fear a' bh\u00e0ta\", \"Ailein duinn\", \"H\u00f9g air a\u2019 bhonaid mh\u00f2ir\" and \"Alasdair mhic Cholla Ghasda\". Several of Runrig's songs are inspired by the archipelago; Calum and Ruaraidh D\u00f2mhnallach were raised on North Uist[158] and Donnie Munro on Skye.[159]  The fiddle and violin company Skyinbow is named-after and based in Skye. Their instruments have been played by musicians such as Mairead Nesbitt, Cora Smyth and Eileen Ivers, and have been featured in productions such as Michael Flatley\u2019s Lord of the Dance, Feet of Flames, and Riverdance.  The Gaelic poet Alasdair mac Mhaighstir Alasdair spent much of his life in the Hebrides and often referred to them in his poetry, including in An Airce and Birlinn Chlann Raghnaill.[160] The best known Gaelic poet of her era, M\u00e0iri Mh\u00f2r nan \u00d2ran (Mary MacPherson, 1821\u201398), embodied the spirit of the land agitation of the 1870s and 1880s. This, and her powerful evocation of the Hebrides\u2014she was from Skye\u2014has made her among the most enduring Gaelic poets.[161] Allan MacDonald (1859\u20131905), who spent his adult life on Eriskay and South Uist, composed hymns and verse in honour of the Blessed Virgin, the Christ Child, and the Eucharist. In his secular poetry, MacDonald praised the beauty of Eriskay and its people. In his verse drama, Parlamaid nan Cailleach (The Old Wives' Parliament), he lampooned the gossiping of his female parishioners and local marriage customs.[162]  In the 20th century, Murdo Macfarlane of Lewis wrote C\u00e0nan nan G\u00e0idheal, a well-known poem about the Gaelic revival in the Outer Hebrides.[163] Sorley MacLean, the most respected 20th-century Gaelic writer, was born and raised on Raasay, where he set his best known poem, Hallaig, about the devastating effect of the Highland Clearances.[164] Aonghas Ph\u00e0draig Caimbeul, raised on South Uist and described by MacLean as \"one of the few really significant living poets in Scotland, writing in any language\" (West Highland Free Press, October 1992)[165] wrote the Scottish Gaelic-language novel An Oidhche Mus do She\u00f2l Sinn which was voted in the Top Ten of the 100 Best-Ever Books from Scotland.  Virginia Woolf's To The Lighthouse is set on the Isle of Skye, part of the Inner Hebrides.   In some respects the Hebrides lack biodiversity in comparison to mainland Britain; for example, there are only half as many mammalian species.[180] However, these islands provide breeding grounds for many important seabird species including the world's largest colony of northern gannets.[181] Avian life includes the corncrake, red-throated diver, rock dove, kittiwake, tystie, Atlantic puffin, goldeneye, golden eagle and white-tailed sea eagle.[182][183] The latter was re-introduced to R\u00f9m in 1975 and has successfully spread to various neighbouring islands, including Mull.[184] There is a small population of red-billed chough concentrated on the islands of Islay and Colonsay.[185]  Red deer are common on the hills and the grey seal and common seal are present around the coasts of Scotland. Colonies of seals are found on Oronsay and the Treshnish Isles.[186][187] The rich freshwater streams contain brown trout, Atlantic salmon and water shrew.[188][189] Offshore, minke whales, orcas, basking sharks, porpoises and dolphins are among the sealife that can be seen.[190][191]  Heather moor containing ling, bell heather, cross-leaved heath, bog myrtle and fescues is abundant and there is a diversity of Arctic and alpine plants including Alpine pearlwort and mossy cyphal.[192]  Loch Druidibeg on South Uist is a national nature reserve owned and managed by Scottish Natural Heritage. The reserve covers 1,677 hectares across the whole range of local habitats.[193] Over 200 species of flowering plants have been recorded on the reserve, some of which are nationally scarce.[194] South Uist is considered the best place in the UK for the aquatic plant slender naiad, which is a European Protected Species.[195][196]  Hedgehogs are not native to the Outer Hebrides\u2014they were introduced in the 1970s to reduce garden pests\u2014and their spread poses a threat to the eggs of ground nesting wading birds. In 2003, Scottish Natural Heritage undertook culls of hedgehogs in the area although these were halted in 2007 due to protests. Trapped animals were relocated to the mainland.[197][198]  57\u00b000\u2032N 07\u00b000\u2032W\ufeff \/ \ufeff57.000\u00b0N 7.000\u00b0W\ufeff \/ 57.000; -7.000 "},{"title":"Scots language","content":"  Scots[note 1] is an Anglic language variety in the West Germanic language family, spoken in Scotland and parts of Ulster in the north of Ireland (where the local dialect is known as Ulster Scots).[3] Most commonly spoken in the Scottish Lowlands, Northern Isles, and northern Ulster, it is sometimes called Lowland Scots to distinguish it from Scottish Gaelic, the Goidelic Celtic language that was historically restricted to most of the Scottish Highlands, the Hebrides, and Galloway after the sixteenth century;[4] or Broad Scots to distinguish it from Scottish Standard English. Modern Scots is a sister language of Modern English, as the two diverged independently from the same source: Early Middle English (1100\u20131300).[5][6][7]  Scots is recognised as an indigenous language of Scotland by the Scottish government,[8] a regional or minority language of Europe,[9] and a vulnerable language by UNESCO.[10][11] In the 2011 Scottish Census, over 1.5\u00a0million people in Scotland reported being able to speak Scots.[12]  Given that there are no universally accepted criteria for distinguishing a language from a dialect, scholars and other interested parties often disagree about the linguistic, historical and social status of Scots, particularly its relationship to English.[13] Although a number of paradigms for distinguishing between languages and dialects exist, they often render contradictory results. Broad Scots is at one end of a bipolar linguistic continuum, with Scottish Standard English at the other.[14] Scots is sometimes regarded as a variety of English, though it has its own distinct dialects;[13]:\u200a894\u200a other scholars treat Scots as a distinct Germanic language, in the way that Norwegian is closely linked to but distinct from Danish.[13]:\u200a894\u200a  Native speakers sometimes refer to their vernacular as braid Scots (or \"broad Scots\" in English)[15] or use a dialect name such as the \"Doric\"[16] or the \"Buchan Claik\".[17] The old-fashioned Scotch, an English loan,[13]:\u200a892\u200a occurs occasionally, especially in Ulster.[18][19] The term Lallans, a variant of the Modern Scots word lawlands [\u02c8lo\u031c\u02d0l\u0259n(d)z, \u02c8l\u0251\u02d0l\u0259nz],[20] is also used, though this is more often taken to mean the Lallans literary form.[21] Scots in Ireland is known in official circles as Ulster-Scots (Ulst\u00e8r-Scotch in revivalist Ulster-Scots) or \"Ullans\", a recent neologism merging Ulster and Lallans.[22]  Scots is a contraction of Scottis, the Older Scots[15] and northern version of late Old English: Scottisc (modern English \"Scottish\"), which replaced the earlier i-mutated version Scyttisc.[23] Before the end of the fifteenth century, English speech in Scotland was known as \"English\" (written Ynglis or Inglis at the time), whereas \"Scottish\" (Scottis) referred to Gaelic.[24] By the beginning of the fifteenth century, the English language used in Scotland had arguably become a distinct language, albeit one lacking a name which clearly distinguished it from all the other English variants and dialects spoken in Britain. From 1495, the term Scottis was increasingly used to refer to the Lowland vernacular[13]:\u200a894\u200a and Erse, meaning \"Irish\", was used as a name for Gaelic. For example, towards the end of the fifteenth century, William Dunbar was using Erse to refer to Gaelic and, in the early sixteenth century, Gavin Douglas was using Scottis as a name for the Lowland vernacular.[25][26] The Gaelic of Scotland is now usually called Scottish Gaelic.  Northumbrian Old English had been established in what is now southeastern Scotland as far as the River Forth by the seventh century, as the region was part of the Anglo-Saxon kingdom of Northumbria.[30] Middle Irish was the language of the Scottish court, and the common use of Old English remained largely confined to this area until the thirteenth century. The succeeding variety of Northern Early Middle English spoken in southeastern Scotland is also known as Early Scots. It began to further diverge from the Middle English of Northumbria due to twelfth- and thirteenth-century immigration of Scandinavian-influenced Middle English\u2013speakers from the North and Midlands of England.[30]:\u200axliii\u200a Later influences on the development of Scots came from the Romance languages via ecclesiastical and legal Latin, Norman French,[30]:\u200alxiii\u2013lxv\u200a and later Parisian French, due to the Auld Alliance. Additionally, there were Dutch and Middle Low German influences due to trade with and immigration from the Low Countries.[30]:\u200alxiii\u200a Scots also includes loan words in the legal and administrative fields resulting from contact with Middle Irish, and reflected in early medieval legal documents.[30]:\u200alxi\u200a Contemporary Scottish Gaelic loans are mainly for geographical and cultural features, such as c\u00e8ilidh, loch, whisky, glen and clan. Cumbric and Pictish, the medieval Brittonic languages of Northern England and Scotland, are the suspected source of a small number of Scots words, such as lum (derived from Cumbric) meaning \"chimney\".[31] From the thirteenth century, the Early Scots language spread further into Scotland via the burghs, which were proto-urban institutions first established by King David I. In fourteenth-century Scotland, the growth in prestige of Early Scots and the complementary decline of French made Scots the prestige dialect of most of eastern Scotland. By the sixteenth century, Middle Scots had established orthographic and literary norms largely independent of those developing in England.[32]  From 1610 to the 1690s during the Plantation of Ulster, some 200,000 Scots-speaking Lowlanders settled as colonists in Ulster in Ireland.[33][full citation needed] In the core areas of Scots settlement, Scots outnumbered English settlers by five or six to one.[34][full citation needed]  The name Modern Scots is used to describe the Scots language after 1700.[citation needed]  A seminal study of Scots was undertaken by JAH Murray and published as Dialect of the Southern Counties of Scotland.[35] Murray's results were given further publicity by being included in Alexander John Ellis's book On Early English Pronunciation, Part V alongside results from Orkney and Shetland, as well as the whole of England. Murray and Ellis differed slightly on the border between English and Scots dialects.[36]  Scots was studied alongside English and Scots Gaelic in the Linguistic Survey of Scotland at the University of Edinburgh, which began in 1949 and began to publish results in the 1970s.[37] Also beginning in the 1970s, the Atlas Linguarum Europae studied the Scots language used at 15 sites in Scotland, each with its own dialect.[38]  From the mid-sixteenth century, written Scots was increasingly influenced by the developing Standard English of Southern England due to developments in royal and political interactions with England.[32]:\u200a10\u200a When William Flower, an English herald, spoke with Mary of Guise and her councillors in 1560, they first used the \"Scottyshe toung\". As he found this hard to understand, they switched into her native French.[39] King James VI, who in 1603 became James I of England, observed in his work Some Reulis and Cautelis to Be Observit and Eschewit in Scottis Poesie that \"For albeit sindrie hes written of it in English, quhilk is lykest to our language...\" (For though several have written of (the subject) in English, which is the language most similar to ours...). However, with the increasing influence and availability of books printed in England, most writing in Scotland came to be done in the English fashion.[32]:\u200a11\u200a In his first speech to the English Parliament in March 1603, King James VI and I declared, \"Hath not God first united these two Kingdomes both in Language, Religion, and similitude of maners?\".[40] Following James VI's move to London, the Protestant Church of Scotland adopted the 1611 Authorized King James Version of the Bible; subsequently, the Acts of Union 1707 led to Scotland joining England to form the Kingdom of Great Britain, having a single Parliament of Great Britain based in London. After the Union and the shift of political power to England, the use of Scots was discouraged by many in authority and education, as was the notion of \"Scottishness\" itself.[41] Many leading Scots of the period, such as David Hume, defined themselves as Northern British rather than Scottish.[41]:\u200a2\u200a They attempted to rid themselves of their Scots in a bid to establish standard English as the official language of the newly formed union. Nevertheless, Scots was still spoken across a wide range of domains until the end of the eighteenth century.[32]:\u200a11\u200a Frederick Pottle, the twentieth-century biographer of James Boswell (1740\u20131795), described James's view of the use of Scots by his father Alexander Boswell (1706\u20131782) [when?] in the eighteenth century while serving as a judge of the Supreme Courts of Scotland:  He scorned modern literature, spoke broad Scots from the bench, and even in writing took no pains to avoid the Scotticisms which most of his colleagues were coming to regard as vulgar. However, others did scorn Scots, such as Scottish Enlightenment intellectuals David Hume and Adam Smith, who went to great lengths to get rid of every Scotticism from their writings.[42] Following such examples, many well-off Scots took to learning English through the activities of those such as Thomas Sheridan, who in 1761 gave a series of lectures on English elocution. Charging a guinea at a time (about \u00a3200 in today's money[43]), they were attended by over 300 men, and he was made a freeman of the City of Edinburgh. Following this, some of the city's intellectuals formed the Select Society for Promoting the Reading and Speaking of the English Language in Scotland. These eighteenth-century activities would lead to the creation of Scottish Standard English.[32]:\u200a13\u200a Scots remained the vernacular of many rural communities and the growing number of urban working-class Scots.[32]:\u200a14\u200a  In the eighteenth and nineteenth centuries, the use of Scots as a literary language was revived by several prominent Scotsmen[citation needed] such as Robert Burns. Such writers established a new cross-dialect literary norm.  Scots terms were included in the English Dialect Dictionary, edited by Joseph Wright. Wright had great difficulty in recruiting volunteers from Scotland, as many refused to cooperate with a venture that regarded Scots as a dialect of English, and he obtained enough help only through the assistance from a Professor Shearer in Scotland.[44] Wright himself rejected the argument that Scots was a separate language, saying that this was a \"quite modern mistake\".[44]  During the first half of the twentieth century, knowledge of eighteenth- and nineteenth-century literary norms waned, and as of 2006[update], there is no institutionalised standard literary form.[45] By the 1940s, the Scottish Education Department's language policy was that Scots had no value: \"it is not the language of 'educated' people anywhere, and could not be described as a suitable medium of education or culture\".[46] Students reverted to Scots outside the classroom, but the reversion was not complete. What occurred, and has been occurring ever since, is a process of language attrition, whereby successive generations have adopted more and more features from Standard English. This process has accelerated rapidly since widespread access to mass media in English and increased population mobility became available after the Second World War.[32]:\u200a15\u200a It has recently taken on the nature of wholesale language shift, sometimes also termed language change, convergence or merger. By the end of the twentieth century, Scots was at an advanced stage of language death over much of Lowland Scotland.[47] Residual features of Scots are often regarded as slang.[48] A 2010 Scottish Government study of \"public attitudes towards the Scots language\" found that 64% of respondents (around 1,000 individuals in a representative sample of Scotland's adult population) \"don't really think of Scots as a language\", also finding \"the most frequent speakers are least likely to agree that it is not a language (58%) and those never speaking Scots most likely to do so (72%)\".[49]  Before the Treaty of Union 1707, when Scotland and England joined to form the Kingdom of Great Britain, there is ample evidence that Scots was widely held to be an independent sister language[50] forming a pluricentric diasystem with English.  German linguist Heinz Kloss considered Modern Scots a Halbsprache ('half language') in terms of an abstand and ausbau languages framework,[51] although today in Scotland most people's speech is somewhere on a continuum ranging from traditional broad Scots to Scottish Standard English. Many speakers are diglossic and may be able to code-switch along the continuum depending on the situation. Where on this continuum English-influenced Scots becomes Scots-influenced English is difficult to determine. Because standard English now generally has the role of a Dachsprache ('roofing language'), disputes often arise as to whether the varieties of Scots are dialects of Scottish English or constitute a separate language in their own right.[52][53]  The UK government now accepts Scots as a regional language and has recognised it as such under the European Charter for Regional or Minority Languages.[54]  Notwithstanding the UK government's and the Scottish Executive's obligations under part II of the European Charter for Regional or Minority Languages, the Scottish Executive recognises and respects Scots (in all its forms) as a distinct language, and does not consider the use of Scots to be an indication of poor competence in English. Evidence for its existence as a separate language lies in the extensive body of Scots literature, its independent \u2013 if somewhat fluid \u2013 orthographic conventions, and in its former use as the language of the original Parliament of Scotland.[55] Because Scotland retained distinct political, legal, and religious systems after the Union, many Scots terms passed into Scottish English.  During the 2010s, increased interest was expressed in the language.  The status of the language was raised in Scottish schools,[56] with Scots being included in the new national school curriculum.[57] Previously in Scotland's schools there had been little education taking place through the medium of Scots, although it may have been covered superficially in English lessons, which could entail reading some Scots literature and observing the local dialect. Much of the material used was often Standard English disguised as Scots, which caused upset among proponents of Standard English and proponents of Scots alike.[58] One example of the educational establishment's approach to Scots is, \"Write a poem in Scots. (It is important not to be worried about spelling in this \u2013 write as you hear the sounds in your head.)\",[59] whereas guidelines for English require teaching pupils to be \"writing fluently and legibly with accurate spelling and punctuation\".[60]  A course in Scots language and culture delivered through the medium of Standard English and produced by the Open University (OU) in Scotland, the Open University's School of Languages and Applied Linguistics as well as Education Scotland became available online for the first time in December 2019.[61]  In the 2011 Scottish census, a question on Scots language ability was featured[8] In 2022 a question regarding the Scots language was also featured.[62][63]  The Scottish government set its first Scots Language Policy in 2015, in which it pledged to support its preservation and encourage respect, recognition and use of Scots.[8] The Scottish Parliament website also offers some information on the language in Scots.[64]  Serious use of the language for news, encyclopaedias, documentaries, etc., remains rare and usually reserved for niches where it is deemed acceptable, e.g. comedy, Burns Night, or representations of traditions and times gone by. However, since 2016 The National newspaper has regularly published some news articles in the language.[65] The 2010s also saw an increasing number of English books translated in Scots and becoming widely available, particularly those in popular children's fiction series such as The Gruffalo, Harry Potter, Diary of a Wimpy Kid, and several by Roald Dahl[66] and David Walliams.[67] In 2021, the music streaming service Spotify created a Scots language listing.[68]  In Scotland, Scots is spoken in the Scottish Lowlands, the Northern Isles, Caithness, Arran and Campbeltown. In Ulster, the northern province in Ireland, its area is usually defined through the works of Robert John Gregg to include the counties of Down, Antrim, Londonderry and Donegal (especially in East Donegal and Inishowen).[69] More recently, the Fintona-born linguist Warren Maguire has argued that some of the criteria that Gregg used as distinctive of Ulster-Scots are common in south-west Tyrone and were found in other sites across Northern Ireland investigated by the Linguistic Survey of Scotland.[70] Dialects of Scots include Insular Scots, Northern Scots, Central Scots, Southern Scots and Ulster Scots.  It has been difficult to determine the number of speakers of Scots via census, because many respondents might interpret the question \"Do you speak Scots?\" in different ways. Campaigners for Scots pressed for this question to be included in the 2001 UK National Census. The results from a 1996 trial before the Census, by the General Register Office for Scotland (GRO),[71] suggested that there were around 1.5\u00a0million speakers of Scots, with 30% of Scots responding \"Yes\" to the question \"Can you speak the Scots language?\", but only 17% responding \"Aye\" to the question \"Can you speak Scots?\".[citation needed] It was also found that older, working-class people were more likely to answer in the affirmative. The University of Aberdeen Scots Leid Quorum performed its own research in 1995, cautiously suggesting that there were 2.7\u00a0million speakers, though with clarification as to why these figures required context.[72]  The GRO questions, as freely acknowledged by those who set them, were not as detailed and systematic as the University of Aberdeen ones, and only included reared speakers (people raised speaking Scots), not those who had learned the language. Part of the difference resulted from the central question posed by surveys: \"Do you speak Scots?\". In the Aberdeen University study, the question was augmented with the further clause \"...\u00a0or a dialect of Scots such as Border etc.\", which resulted in greater recognition from respondents. The GRO concluded that there simply was not enough linguistic self-awareness amongst the Scottish populace, with people still thinking of themselves as speaking badly pronounced, grammatically inferior English rather than Scots, for an accurate census to be taken. The GRO research concluded that \"[a] more precise estimate of genuine Scots language ability would require a more in-depth interview survey and may involve asking various questions about the language used in different situations. Such an approach would be inappropriate for a Census.\" Thus, although it was acknowledged that the \"inclusion of such a Census question would undoubtedly raise the profile of Scots\", no question about Scots was, in the end, included in the 2001 Census.[52][73][74] The Scottish Government's Pupils in Scotland Census 2008[75] found that 306 pupils[clarification needed] spoke Scots as their main home language. A Scottish Government study in 2010 found that 85% of around 1000 respondents (being a representative sample of Scotland's adult population) claim to speak Scots to varying degrees.[49]  The 2011 UK census was the first to ask residents of Scotland about Scots. A campaign called Aye Can was set up to help individuals answer the question.[76][77] The specific wording used was \"Which of these can you do? Tick all that apply\" with options for \"Understand\", \"Speak\", \"Read\" and \"Write\" in three columns: English, Scottish Gaelic and Scots.[78] Of approximately 5.1\u00a0million respondents, about 1.2\u00a0million (24%) could speak, read and write Scots, 3.2\u00a0million (62%) had no skills in Scots and the remainder had some degree of skill, such as understanding Scots (0.27\u00a0million, 5.2%) or being able to speak it but not read or write it (0.18\u00a0million, 3.5%).[79] There were also small numbers of Scots speakers recorded in England and Wales on the 2011 Census, with the largest numbers being either in bordering areas (e.g. Carlisle) or in areas that had recruited large numbers of Scottish workers in the past (e.g. Corby or the former mining areas of Kent).[80]  Among the earliest Scots literature is John Barbour's Brus (fourteenth century), Wyntoun's Cronykil and Blind Harry's The Wallace (fifteenth century). From the fifteenth century, much literature based on the Royal Court in Edinburgh and the University of St Andrews was produced by writers such as Robert Henryson, William Dunbar, Gavin Douglas and David Lyndsay. The Complaynt of Scotland was an early printed work in Scots. The Eneados is a Middle Scots translation of Virgil's Aeneid, completed by Gavin Douglas in 1513.  After the seventeenth century, anglicisation increased. At the time, many of the oral ballads from the borders and the North East were written down. Writers of the period were Robert Sempill, Robert Sempill the younger, Francis Sempill, Lady Wardlaw and Lady Grizel Baillie.  In the eighteenth century, writers such as Allan Ramsay, Robert Burns, James Orr, Robert Fergusson and Walter Scott continued to use Scots \u2013 Burns's \"Auld Lang Syne\" is in Scots, for example. Scott introduced vernacular dialogue to his novels. Other well-known authors like Robert Louis Stevenson, William Alexander, George MacDonald, J. M. Barrie and other members of the Kailyard school like Ian Maclaren also wrote in Scots or used it in dialogue.  In the Victorian era popular Scottish newspapers regularly included articles and commentary in the vernacular, often of unprecedented proportions.[81]  In the early twentieth century, a renaissance in the use of Scots occurred, its most vocal figure being Hugh MacDiarmid whose benchmark poem \"A Drunk Man Looks at the Thistle\" (1926) did much to demonstrate the power of Scots as a modern idiom. Other contemporaries were Douglas Young, John Buchan, Sydney Goodsir Smith, Robert Garioch, Edith Anne Robertson and Robert McLellan. The revival extended to verse and other literature.  In 1955, three Ayrshire men \u2013 Sandy MacMillan, an English teacher at Ayr Academy; Thomas Limond, noted town chamberlain of Ayr; and A. L. \"Ross\" Taylor, rector of Cumnock Academy\u00a0\u2013 collaborated to write Bairnsangs (\"Child Songs\"),[82] a collection of children's nursery rhymes and poems in Scots. The book contains a five-page glossary of contemporary Scots words and their pronunciations.  Alexander Gray's translations into Scots constitute the greater part of his work, and are the main basis for his reputation.  In 1983, William Laughton Lorimer's translation of the New Testament from the original Greek was published.  Scots is sometimes used in contemporary fiction, such as the Edinburgh dialect of Scots in Trainspotting by Irvine Welsh (later made into a motion picture of the same name).  But'n'Ben A-Go-Go by Matthew Fitt is a cyberpunk novel written entirely in what Wir Ain Leed[83] (\"Our Own Language\") calls \"General Scots\". Like all cyberpunk work, it contains imaginative neologisms.  The Rubaiyat of Omar Khayyam has been translated into Scots by Rab Wilson (published in 2004). Alexander Hutchison has translated the poetry of Catullus into Scots, and in the 1980s, Liz Lochhead produced a Scots translation of Tartuffe by Moli\u00e8re. J. K. Annand translated poetry and fiction from German and Medieval Latin into Scots.  The strip cartoons Oor Wullie and The Broons in the Sunday Post use some Scots. In 2018, Harry Potter and the Philosopher's Stane, a Scots translation of the first Harry Potter book, Harry Potter and the Philosopher's Stone, was published by Matthew Fitt.  The vowel system of Modern Scots:[84]  Vowel length is usually conditioned by the Scottish vowel length rule.  The orthography of Early Scots had become more or less standardised[87] by the middle to late sixteenth century.[88] After the Union of the Crowns in 1603, the Standard English of England came to have an increasing influence on the spelling of Scots[89] through the increasing influence and availability of books printed in England. After the Acts of Union in 1707 the emerging Scottish form of Standard English replaced Scots for most formal writing in Scotland.[32]:\u200a11\u200a The eighteenth-century Scots revival saw the introduction of a new literary language descended from the old court Scots, but with an orthography that had abandoned some of the more distinctive old Scots spellings[90] and adopted many standard English spellings. Despite the updated spelling, however, the rhymes make it clear that a Scots pronunciation was intended.[91] These writings also introduced what came to be known as the apologetic apostrophe,[91]:\u200axiv\u200a generally occurring where a consonant exists in the Standard English cognate. This Written Scots drew not only on the vernacular, but also on the King James Bible, and was heavily influenced by the norms and conventions of Augustan English poetry.[13]:\u200a168\u200a Consequently, this written Scots looked very similar to contemporary Standard English, suggesting a somewhat modified version of that, rather than a distinct speech form with a phonological system which had been developing independently for many centuries.[92] This modern literary dialect, \"Scots of the book\" or Standard Scots,[93][94] once again gave Scots an orthography of its own, lacking neither \"authority nor author\".[95] This literary language used throughout Lowland Scotland and Ulster,[96] embodied by writers such as Allan Ramsay, Robert Fergusson, Robert Burns, Sir Walter Scott, Charles Murray, David Herbison, James Orr, James Hogg and William Laidlaw among others, is well described in the 1921 Manual of Modern Scots.[97]  Other authors developed dialect writing, preferring to represent their own speech in a more phonological manner rather than following the pan-dialect conventions of modern literary Scots,[91] especially for the northern[98] and insular dialects of Scots.  During the twentieth century, a number of proposals for spelling reform were presented. Commenting on this, John Corbett (2003: 260) writes that \"devising a normative orthography for Scots has been one of the greatest linguistic hobbies of the past century\". Most proposals entailed regularising the use of established eighteenth- and nineteenth-century conventions, in particular, the avoidance of the apologetic apostrophe, which represented letters that were perceived to be missing when compared to the corresponding English cognates but were never actually present in the Scots word.[99][100] For example, in the fourteenth century, Barbour spelt the Scots cognate of \"taken\" as tane. It is argued that, because there has been no k in the word for over 700 years, representing its omission with an apostrophe is of little value. The current spelling is usually taen.  Through the twentieth century, with the decline of spoken Scots and knowledge of the literary tradition, phonetic (often humorous) representations became more common.[citation needed]  Modern Scots follows the subject\u2013verb\u2013object sentence structure like Standard English. However, the word order Gie's it (Give us it) vs. \"Give it to me\" may be preferred.[13]:\u200a897\u200a The indefinite article a may be used before both consonants and vowels. The definite article the is used before the names of seasons, days of the week, many nouns, diseases, trades and occupations, sciences and academic subjects.[97]:\u200a78\u200a It is also often used in place of the indefinite article and instead of a possessive pronoun.[97]:\u200a77\u200a Scots includes some strong plurals such as ee\/een (\"eye\/eyes\"), cauf\/caur (\"calf\/calves\"), horse\/horse (\"horse\/horses\"), cou\/kye (\"cow\/cows\") and shae\/shuin (\"shoe\/shoes\") that survived from Old English into Modern Scots, but have become weak plurals in Standard Modern English \u2013 ox\/oxen and child\/children being exceptions.[97]:\u200a79\u200a[13]:\u200a896\u200a Nouns of measure and quantity remain unchanged in the plural.[13]:\u200a896\u200a[97]:\u200a80\u200a The relative pronoun is that for all persons and numbers, but may be elided.[13]:\u200a896\u200a[97]:\u200a102\u200a Modern Scots also has a third adjective\/adverb this-that-yon\/yonder (thon\/thonder) indicating something at some distance.[13]:\u200a896\u200a Thir and thae are the plurals of this and that respectively. The present tense of verbs adheres to the Northern subject rule whereby verbs end in -s in all persons and numbers except when a single personal pronoun is next to the verb.[13]:\u200a896\u200a[97]:\u200a112\u200a Certain verbs are often used progressively[13]:\u200a896\u200a and verbs of motion may be dropped before an adverb or adverbial phrase of motion.[13]:\u200a897\u200a Many verbs have strong or irregular forms which are distinctive from Standard English.[13]:\u200a896\u200a[97]:\u200a126\u200a The regular past form of the weak or regular verbs is -it, -t or -ed, according to the preceding consonant or vowel.[13]:\u200a896\u200a[97]:\u200a113\u200a The present participle and gerund in are now usually \/\u0259n\/[101] but may still be differentiated \/\u0259n\/ and \/in\/ in Southern Scots,[102] and \/\u0259n\/ and \/\u026an\/ in Northern Scots. The negative particle is na, sometimes spelled nae, e.g. canna (\"can't\"), daurna (\"daren't\"), michtna (\"mightn't\").[97]:\u200a115\u200a  Adverbs usually take the same form as the verb root or adjective, especially after verbs. Examples include Haein a real guid day (\"Having a really good day\") and She's awfu fauchelt (\"She's awfully tired\").  From The Four Gospels in Braid Scots (William Wye Smith):  Noo the nativitie o' Jesus Christ was this gate: whan his mither Mary was mairry't till Joseph, 'or they cam thegither, she was fund wi' bairn o' the Holie Spirit. Than her guidman, Joseph, bein an upricht man, and no desirin her name sud be i' the mooth o' the public, was ettlin to pit her awa' hidlins. But as he had thir things in his mind, see! an Angel o' the Lord appear't to him by a dream, sayin, \"Joseph, son o' Dauvid, binna feared to tak till ye yere wife, Mary; for that whilk is begotten in her is by the Holie Spirit. \"And she sall bring forth a son, and ye sal ca' his name Jesus; for he sal save his folk frae their sins.\" Noo, a' this was dune, that it micht come to pass what was said by the Lord throwe the prophet, \"Tak tent! a maiden sal be wi' bairn, and sal bring forth a son; and they wull ca' his name Emmanuel,\" whilk is translatit, \"God wi' us.\" Sae Joseph, comin oot o' his sleep, did as the Angel had bidden him, and took till him his wife. And leev'd in continence wi' her till she had brocht forth her firstborn son; and ca'd his name Jesus.  From The New Testament in Scots (William Laughton Lorimer, 1885\u20131967)  This is the storie o the birth o Jesus Christ. His mither Mary wis trystit til Joseph, but afore they war mairriet she wis fund tae be wi bairn bi the Halie Sp\u00edrit. Her husband Joseph, honest man, hed nae mind tae affront her afore the warld an wis for brakkin aff their tryst hidlinweys; an sae he wis een ettlin tae dae, whan an angel o the Lord kythed til him in a draim an said til him, \"Joseph, son o Dauvit, be nane feared tae tak Mary your trystit wife intil your hame; the bairn she is cairrein is o the Halie Sp\u00edrit. She will beir a son, an the name ye ar tae g\u00ede him is Jesus, for he will sauf his fowk frae their sins.\" Aa this happent at the wurd spokken bi the Lord throu the Prophet micht be fulfilled: Behaud, the virgin wil bouk an beir a son, an they will caa his name Immanuel \u2013 that is, \"God wi us\". Whan he hed waukit frae his sleep, Joseph did as the angel hed bidden him, an tuik his trystit wife hame wi him. But he bedditna wi her or she buir a son; an he caa'd the bairn Jesus."},{"title":"Cymru","content":"  Cymru ([\u02c8k\u0259m.r\u0268] \u24d8; KUM-ri or COME-ree)[1] is the Welsh language name for Wales, a country of the United Kingdom, on the island of Great Britain.  The modern Welsh name Cymru is the Welsh name for Wales, while the name for the Welsh people is Cymry. These words (both of which are pronounced [\u02c8k\u0259m.r\u0268]) are descended from the Brythonic word combrogi, meaning \"fellow-countrymen\" or a \"compatriot\".[2][3] The use of the word Cymry as a self-designation derives from the location in the post-Roman Era (after the arrival of the Anglo-Saxons) of the Welsh (Brythonic-speaking) people in modern Wales as well as in northern England and southern Scotland (Yr Hen Ogledd) (English: The Old North). It emphasised that the Welsh in modern Wales and in the Hen Ogledd were one people, different from other peoples.[4] In particular, the term was not applied to the Cornish or the Breton peoples, who are of similar heritage, culture, and language to the Welsh. The word came into use as a self-description probably before the 7th century.[5] It is attested in a praise poem to Cadwallon ap Cadfan (Moliant Cadwallon, by Afan Ferddig) c.\u2009633.[6][7] In Welsh literature, the word Cymry was used throughout the Middle Ages to describe the Welsh, though the older, more generic term Brythoniaid continued to be used to describe any of the Britonnic peoples (including the Welsh) and was the more common literary term until c.\u20091200. Thereafter Cymry prevailed as a reference to the Welsh. Until c.\u20091560 the word was spelt Kymry or Cymry, regardless of whether it referred to the people or their homeland,[2] including as Kymry, in the Armes Prydein, in the 10th century.[8]  \"Wales\" on the other hand, is derived from an Anglo-Saxon word meaning \"foreigner\", specifically those who were under Roman rule (specifically a \"Romanised foreigner\").[3][9] Cambria is a medieval Latin name also historically used to refer to Wales, and is a latinisation of Cymru.[10]  In recent history, in particular following Welsh devolution, calls to rename places in Wales to their Welsh names, and prohibiting use of their English names, have been increasing. Including calls for renames into English to be stopped,[11] or for all non-Welsh names to be removed,[12] receiving criticism from London-based Daily Mail and UK Government.[13] The controversial origin of the meaning of \"Wales\", which derives from a term meaning \"foreigner\", and that it is an \"imposed\" non-Welsh name, is used as a reason to stop the use of \"Wales\",[14] or at least prefer Cymru.[15]  Proponents for the change compare it to other countries which changed their name, such as Ceylon to Sri Lanka, Persia to Iran, and in 2022, Turkey to T\u00fcrkiye.[16]  In 2019, during discussions on renaming the then National Assembly for Wales. Senedd Cymru was considered as the body's sole potential name, however, it was rejected by Assembly Members in November 2019.[17] Simply \"Senedd\" was also proposed,[18] but rejected by the first minister Carwyn Jones, fearing it would be not understood.[19][20] The parliament instead chose two names Senedd Cymru and the \"Welsh Parliament\", with \"Senedd\" being a short name used in both English and Welsh.[19] Although the legal preferred name, used in all post-2020 legislation, is just Senedd Cymru in both languages.[21]  In 2022, the Football Association of Wales, considered changing references to the national football team (including women's)[22] to use Cymru rather than \"Wales\". The association already uses the name Cymru in their internal and external communications, and by all their staff.[23][24][25] The consideration was compared to the team's overall shift to become more Welsh nationalist and pro-independence.[26] The association has been increasing its use of Cymru and Welsh words in general since UEFA Euro 2016.[27]  In 2024, a petition called for the prohibition of the name \"Wales\", for the Welsh name Cymru to be the only name. The petition gained 5,400 signatures by 4 January 2024,[28][14] and over 10,000 by 15 January, meeting the threshold for a Senedd debate.[29][30] A counter-petition was launched after.[31]  The petition follows other removals of English names in Wales in 2023, such as the removal of the English names \"Snowdonia\" and \"Snowdon\" for Eryri and Yr Wyddfa, their Welsh names respectively, and removing \"Brecon Beacons\" for Bannau Brycheiniog.[32]  While Cymru is also used by pro-independence organisations such as YesCymru and AUOBCymru, it is also used by various non-political charities and organisations. "},{"title":"List of ball games","content":"This is a list of ball games and ball sports that include a ball as a key element in the activity, usually for scoring points.  Ball sports fall within many sport categories, some sports within multiple categories, including:  Games that are similar and have a common reference are grouped under the primary name such as bowling, football and hockey. "},{"title":"Team sport","content":"  A team sport is a type of sport where the fundamental nature of the game or sport necessitates the participation of multiple individuals working together as a team, and it is inherently impossible or highly impractical to execute the sport as a single-player endeavour. In team sports, the cooperative effort of team members is essential for the sport to function and achieve its objectives. The objective often involves teammates facilitating the movement of a ball or similar object in accordance with a set of rules, in order to score points. Examples are basketball, volleyball, rugby, water polo, handball, lacrosse, cricket, baseball, and the various forms of football, and hockey.  These sports emphasize teamwork, strategy, and coordination among team members, while competing against opposing teams, to achieve a common goal.[2] Team sports do not include individual or individual-to-team events within a sport.[3]  The meaning of a \"team sport\" has been disputed in recent years. Some types of sports have different objectives or rules than \"traditional\" team sports. These types of team sports do not involve teammates facilitating the movement of a ball or similar object in accordance with a set of rules, in order to score points. Overall, the division into team sports and individual sports is not always unproblematic, since there are different combinations in the individual sports.  This includes sports that can only be practiced as a team sport. The number of team members is fixed for the team. In order to compete successfully in championships and tournaments, teams need a roster that is significantly larger than the number of players starting the game. Players may be substituted from a squad in competition matches to replace exhausted or injured players or to make tactical changes. Examples are basketball, volleyball, rugby, water polo, handball, lacrosse, cricket, baseball, and the various forms of football, and hockey.  Teams of two people are sports, such as dancesport or beach volleyball. No substitute players are used here. The two partners are absolutely dependent on each other. The absence of a person here means the loss of competitiveness.[4][5][6]  In addition, there are sports, while mostly played singles, that are also played in different formations together cooperatively, such as badminton, table tennis or tennis in doubles, although this formation is significantly lower in terms of prestige, spectators and prize money.[7] In these formations, common tactics, teamwork and agreements are crucial for success. There are also different rowing formations such as one, two, four and eight or sailing with their different boat classes.[8][9] The most important thing here is smooth movements and common tactics. This also applies approximately to the team time trial in cycling,[10][11] while it is the case with cycling tours and one-day races are different tasks for the team members of a cycling team.[12][13]  In some sports, relay races are held, which can be distinguished from pure team evaluations by a common racing tactic and the observance of change regulations. Relay races are common in running, swimming, cross-country skiing, biathlon or short-track speed skating and are also an integral part in the Olympic Games program[14] with high popularity. [15][16]  There are team ratings in many sports, in which the results of individual athletes or formations are added up. In cycling team members, whilst still in competition with each other, will also work towards assisting one member of the team, usually a specialist, to the highest possible finishing position.[13][12][17]  In some sports where participants are entered by a team, they do not only compete against members of other teams, but also against each other for points towards championship standings, for example in motorsport, particularly Formula One.[18] Team orders can occur in such teams and although previously accepted was banned in Formula One[19] between 2002 and 2010. After a controversy involving team orders at the 2010 German Grand Prix however, the regulation was removed as of the 2011 season.[20]  In summary, team sports are characterized by the impossibility or impracticality of executing the sport as a single-player endeavor, and the entire game or match relies on team dynamics. In contrast, sports with team ratings and formations involve both individual and team aspects, where individual performances contribute to a team's overall success but may not be entirely reliant on team dynamics. Relay races combine individual efforts within a team context, where smooth transitions are essential.  Areas around the Mediterranean had a long tradition of athletic events. Ancient Egyptians and Mesopotamians depicted athletic scenes in tombs of kings and their nobles. They did not, however, hold regular competitions, and those events that occurred were probably the preserve of kings and upper classes. Minoans culture held gymnastics in high esteem, with bull-leaping, tumbling, running, wrestling and boxing shown on their frescoes. The Mycenaeans adopted Minoan games and also raced chariots in religious or funerary ceremonies.[21][22] Homer's heroes participate in athletic competitions to honor the dead. In the Iliad there are chariot races, boxing, wrestling, a foot race, as well as fencing, archery, and spear throwing. The Odyssey adds to these a long jump and discus throw.[23]  It was in Greece that sports were first instituted formally, with the first Olympic Games recorded in 776 BCE in Olympia, where they were celebrated until 393 CE.[24] These ancient Olympic Games consisted of running, long jump, boxing, wrestling, Pankration (combat sport),  discus throw, and javelin throw.[25] In the Bayankhongor Province of Mongolia, Neolithic-era cave paintings dating to 7000 BC depict a wrestling match surrounded by crowds.[26] Prehistoric cave-paintings in Japan show a sport similar to sumo wrestling.[27] In Wadi Sura, near Gilf Kebir in Libya, a Neolithic rock painting in the cave of swimmers shows evidence of swimming and archery being practiced around 6000 BC.[28]  Team sports have a rich and ancient history dating back thousands of years. These activities served as important facets of society, not only for physical fitness but also for social, cultural, and even political purposes. In ancient civilizations, team sports were prevalent and often intertwined with religious and cultural practices. In Mesoamerica, the Aztec ball game, ollamaliztli, was not just a sport but also a ritual with symbolic significance.[29]  The Greeks, who laid the foundations for many contemporary sports, held various team sports as central to their culture. The Olympic Games, first recorded in 776 BCE, featured events like chariot racing and team foot races, fostering unity and friendly competition among city-states.[30] The Spartans, known for their military prowess, engaged in team sports like the episkyros, a type of football.[31]  Rome adopted and adapted many Greek sports, introducing harpastum, a ball game similar to soccer, and ludi circenses, which included team chariot racing. These sports provided a sense of entertainment and unity, while also serving as a means of social control.[32]  In ancient China, cuju was a popular team sport akin to modern soccer, played as early as the Han dynasty (206 BCE \u2013 220 CE). The sport was not only a form of entertainment but also a means of fostering camaraderie among communities.[33]  Throughout history, team sports have reflected the values and priorities of their respective cultures. Whether it was the competitive spirit of the Greeks, the discipline of the Romans, or the communal bonding in China, ancient team sports played an integral role in the social fabric of civilizations. They transcended mere physical activity, serving as a testament to the enduring significance of sports in human history. Today, these ancient traditions continue to influence modern team sports, reminding us of the timeless appeal and cultural importance of collective athletic endeavors.  status after the 2022 Winter Olympics  Summer Olympics (14)  Notes   Winter Olympics (2)  Ice hockey and curling are team sports at the Winter Olympics, with particularity that the men's tournament in Ice hockey was introduced at the 1920 Summer Olympics and was transferred permanently to the Winter Olympic Games program in 1924, in France. Before the monobob event has been introduced as an additional women's class by the IBSF for the 2020\u201321 world cup season and the 2022 Olympic games, bobsleigh was considered as a pure team sport, that can only be practiced as a team with at least two drivers. At the present time the men's events consist of the two-man and four-man class and the women's events are restricted only to the two-woman and women's monobob class.[35]  Bibliography "},{"title":"Score (sport)","content":"In sport, score is a quantitative measure of the relative performance of opponents in a sporting discipline. Score is usually measured in the abstract unit of points, and events in the competition can raise or lower the score of the involved parties. Most games with score use it as a quantitative indicator of success in the game, and in competition, a goal is often made of attaining a better score than one's opponents in order to win.  In team sport, the most common point metric is the \"goal\" or \"score\". Goals are accrued by the respective teams, and the match score represents the total score accrued by each team. For example, in association football and hockey goals are achieved by putting the ball in the opposing team's net. Other team sports like rugby, baseball and cricket have more complicated scoring procedures. The winning team is that which has recorded the best score, usually the team with the higher total score; a draw or tie is a result in which the competing teams record an equal score, sometimes requiring a tiebreaker.  Individual-based sports, such as golf and tennis, have points-based scoring as well. These may be abstract quantities defined for the sport, or more natural measures such as a distance or duration. Each competing athlete accrues points based on the sport's scoring system, and the athlete with the best score is deemed the winner. In some sports, the best score is that of the competitor with the highest score, such as in tennis or high jump. In other sports, the best score is that of the competitor with the lowest score, such as in golf or the 100 metres sprint.  Most sports have time limits, which means point-based victories are usually the result of obtaining more points than one's opponent. In others, the winner must achieve a fixed number of points sooner than the rival. In some sports there is a perfect score that is the highest attainable, such as a 6.0 or 10.0. In boxing and mixed martial arts, a match runs an agreed number of timed rounds, each scored at its conclusion with a mandatory 10 points for winning and 9 or fewer for losing, depending on relative inefficiency. If either player scores a knockout or submission, they immediately win the match regardless of points or time.  Each motor racing series has a points system, and a set of rules and regulations that define how points are accrued. Nearly all series award points according to the finishing position of the competitors in each race. Some series only award points for a certain number of finishing positions. In Formula One, for example, only the top ten finishers get points. Drivers may be forced to finish the race or complete a certain number of the laps in order to score points.  In some series, points are also awarded based on lap leading, lap times, overtaking and qualifying positions (in particular by achieving pole positions and fastest laps). In NASCAR, for example, besides receiving points depending on the final standings, one point is awarded for leading a lap and one point for leading the most laps in the race. In other series, such as for the National Hot Rod Association, points are awarded for attempting the race along with a podium finish in any of the four qualifying rounds, as an incentive to have drivers participate week after week to compete.  Each sport has a system by which scoring is determined and tracked. Sports that use duration include many disciplines in athletics (track events of track and field, road running, cross country running and racewalking), and skiing (alpine skiing and cross-country skiing).  Other disciplines are scored based on a distance or height, including the athletics disciplines of shot put, discus throw, hammer throw, javelin throw, long jump, triple jump, high jump, and pole vault.  Some sports have scoring based on a duration to which is added a penalty time based on the events of the competition. For example, in biathlon an athlete is made to ski a penalty loop for each target missed in the target-shooting portion of the event, causing an increase in the athlete's elapsed time in the competition.  In the equestrian discipline of show jumping, the duration of the performance is complemented with faults which are assessed for exceeding a maximum allowable time for the event (time fault), or if the horse refuses to jump over an obstacle or knocks down a rail of an obstacle.  In most racket sports and net sports a single point is earned when the other team commits a fault or rule infraction. Most such sports apply rally scoring, in which case either team can earn a point regardless of who is serving, but some apply side-out scoring where only the serving team can earn a point. Tennis utilizes rally scoring but has specialized rules for tracking the score. "},{"title":"Constitution","content":"  A constitution is the aggregate of fundamental principles or established precedents that constitute the legal basis of a polity, organization or other type of entity, and commonly determines how that entity is to be governed.[1]  When these principles are written down into a single document or set of legal documents, those documents may be said to embody a written constitution; if they are encompassed in a single comprehensive document, it is said to embody a codified constitution. The Constitution of the United Kingdom is a notable example of an uncodified constitution; it is instead written in numerous fundamental Acts of a legislature, court cases, or treaties.[2]  Constitutions concern different levels of organizations, from sovereign countries to companies and unincorporated associations. A treaty that establishes an international organization is also its constitution, in that it would define how that organization is constituted. Within states, a constitution defines the principles upon which the state is based, the procedure in which laws are made and by whom. Some constitutions, especially codified constitutions, also act as limiters of state power, by establishing lines which a state's rulers cannot cross, such as fundamental rights. Changes to constitutions frequently require consensus or supermajority.[3]  The Constitution of India is the longest written constitution of any country in the world,[4] with 146,385 words[5] in its English-language version,[6] while the Constitution of Monaco is the shortest written constitution with 3,814 words.[7][5] The Constitution of San Marino might be the world's oldest active written constitution, since some of its core documents have been in operation since 1600, while the Constitution of the United States is the oldest active codified constitution. The historical life expectancy of a constitution since 1789 is approximately 19 years.[8]  The term constitution comes through French from the Latin word constitutio, used for regulations and orders, such as the imperial enactments (constitutiones principis: edicta, mandata, decreta, rescripta).[9] Later, the term was widely used in canon law for an important determination, especially a decree issued by the Pope, now referred to as an apostolic constitution.  William Blackstone used the term for significant and egregious violations of public trust, of a nature and extent that the transgression would justify a revolutionary response. The term as used by Blackstone was not for a legal text, nor did he intend to include the later American concept of judicial review: \"for that were to set the judicial power above that of the legislature, which would be subversive of all government\".[10]  Generally, every modern written constitution confers specific powers on an organization or institutional entity, established upon the primary condition that it abides by the constitution's limitations. According to Scott Gordon, a political organization is constitutional to the extent that it \"contain[s] institutionalized mechanisms of power control for the protection of the interests and liberties of the citizenry, including those that may be in the minority\".[11]  Activities of officials within an organization or polity that fall within the constitutional or statutory authority of those officials are termed \"within power\" (or, in Latin, intra vires); if they do not, they are termed \"beyond power\" (or, in Latin, ultra vires). For example, a students' union may be prohibited as an organization from engaging in activities not concerning students; if the union becomes involved in non-student activities, these activities are considered to be ultra vires of the union's charter, and nobody would be compelled by the charter to follow them. An example from the constitutional law of sovereign states would be a provincial parliament in a federal state trying to legislate in an area that the constitution allocates exclusively to the federal parliament, such as ratifying a treaty. Action that appears to be beyond power may be judicially reviewed and, if found to be beyond power, must cease. Legislation that is found to be beyond power will be \"invalid\" and of no force; this applies to primary legislation, requiring constitutional authorization, and secondary legislation, ordinarily requiring statutory authorization. In this context, \"within power\", intra vires, \"authorized\" and \"valid\" have the same meaning; as do \"beyond power\", ultra vires, \"not authorized\" and \"invalid\".  In most but not all modern states the constitution has supremacy over ordinary statutory law (see Uncodified constitution below); in such states when an official act is unconstitutional, i.e. it is not a power granted to the government by the constitution, that act is null and void, and the nullification is ab initio, that is, from inception, not from the date of the finding. It was never \"law\", even though, if it had been a statute or statutory provision, it might have been adopted according to the procedures for adopting legislation. Sometimes the problem is not that a statute is unconstitutional, but that the application of it is, on a particular occasion, and a court may decide that while there are ways it could be applied that are constitutional, that instance was not allowed or legitimate. In such a case, only that application may be ruled unconstitutional. Historically, the remedies for such violations have been petitions for common law writs, such as quo warranto.  Scholars debate whether a constitution must necessarily be autochthonous, resulting from the nations \"spirit\". Hegel said \"A constitution...is the work of centuries; it is the idea, the consciousness of rationality so far as that consciousness is developed in a particular nation.\"[12]  Since 1789, along with the Constitution of the United States of America (U.S. Constitution), which is the oldest and shortest written constitution still in force,[13] close to 800 constitutions have been adopted and subsequently amended around the world by independent states.[14]  In the late 18th century, Thomas Jefferson predicted that a period of 20 years would be the optimal time for any constitution to be still in force, since \"the earth belongs to the living, and not to the dead\".[15] Indeed, according to recent studies,[14] the average life of any new written constitution is around 19 years. However, a great number of constitutions do not last more than 10 years, and around 10% do not last more than one year, as was the case of the French Constitution of 1791.[14] By contrast, some constitutions, notably that of the United States, have remained in force for several centuries, often without major revision for long periods of time.  The most common reasons for these frequent changes are the political desire for an immediate outcome[clarification needed] and the short time devoted to the constitutional drafting process.[16] A study in 2009 showed that the average time taken to draft a constitution is around 16 months,[17] however there were also some extreme cases registered. For example, the Myanmar 2008 Constitution was being secretly drafted for more than 17 years,[17] whereas at the other extreme, during the drafting of Japan's 1946 Constitution, the bureaucrats drafted everything in no more than a week. Japan has the oldest unamended constitution in the world.[18] The record for the shortest overall process of drafting, adoption, and ratification of a national constitution belongs to the Romania's 1938 constitution, which installed a royal dictatorship in less than a month.[19] Studies showed that typically extreme cases where the constitution-making process either takes too long or is extremely short were non-democracies.[20]  In principle, constitutional rights are not a specific characteristic of democratic countries. Autocratic states have constitutions, such as that of North Korea, which officially grants every citizen, among other things, the freedom of expression.[21] However, the extent to which governments abide by their own constitutional provisions varies. In North Korea, for example, the Ten Principles for the Establishment of a Monolithic Ideological System are said to have eclipsed the constitution in importance as a frame of government in practice. Developing a legal and political tradition of strict adherence to constitutional provisions is considered foundational to the rule of law.  Excavations in modern-day Iraq by Ernest de Sarzec in 1877 found evidence of the earliest known code of justice, issued by the Sumerian king Urukagina of Lagash c.\u20092300 BC. Perhaps the earliest prototype for a law of government, this document itself has not yet been discovered; however it is known that it allowed some rights to his citizens. For example, it is known that it relieved tax for widows and orphans, and protected the poor from the usury of the rich.  After that, many governments ruled by special codes of written laws. The oldest such document still known to exist seems to be the Code of Ur-Nammu of Ur (c. 2050 BC). Some of the better-known ancient law codes are the code of Lipit-Ishtar of Isin, the code of Hammurabi of Babylonia, the Hittite code, the Assyrian code, and Mosaic law.  In 621 BC, a scribe named Draco codified the oral laws of the city-state of Athens; this code prescribed the death penalty for many offenses (thus creating the modern term \"draconian\" for very strict rules). In 594 BC, Solon, the ruler of Athens, created the new Solonian Constitution. It eased the burden of the workers, and determined that membership of the ruling class was to be based on wealth (plutocracy), rather than on birth (aristocracy). Cleisthenes again reformed the Athenian constitution and set it on a democratic footing in 508 BC.  Aristotle (c. 350 BC) was the first to make a formal distinction between ordinary law and constitutional law, establishing ideas of constitution and constitutionalism, and attempting to classify different forms of constitutional government. The most basic definition he used to describe a constitution in general terms was \"the arrangement of the offices in a state\". In his works Constitution of Athens, Politics, and Nicomachean Ethics, he explores different constitutions of his day, including those of Athens, Sparta, and Carthage. He classified both what he regarded as good and what he regarded as bad constitutions, and came to the conclusion that the best constitution was a mixed system including monarchic, aristocratic, and democratic elements. He also distinguished between citizens, who had the right to participate in the state, and non-citizens and slaves, who did not.  The Romans initially codified their constitution in 450 BC as the Twelve Tables. They operated under a series of laws that were added from time to time, but Roman law was not reorganized into a single code until the Codex Theodosianus (438 AD); later, in the Eastern Empire, the Codex repetit\u00e6 pr\u00e6lectionis (534) was highly influential throughout Europe. This was followed in the east by the Ecloga of Leo III the Isaurian (740) and the Basilica of Basil I (878).  The Edicts of Ashoka established constitutional principles for the 3rd century BC Maurya king's rule in India. For constitutional principles almost lost to antiquity, see the code of Manu.  Many of the Germanic peoples that filled the power vacuum left by the Western Roman Empire in the Early Middle Ages codified their laws. One of the first of these Germanic law codes to be written was the Visigothic Code of Euric (471 AD). This was followed by the Lex Burgundionum, applying separate codes for Germans and for Romans; the Pactus Alamannorum; and the Salic Law of the Franks, all written soon after 500. In 506, the Breviarum or \"Lex Romana\" of Alaric II, king of the Visigoths, adopted and consolidated the Codex Theodosianus together with assorted earlier Roman laws. Systems that appeared somewhat later include the Edictum Rothari of the Lombards (643), the Lex Visigothorum (654), the Lex Alamannorum (730), and the Lex Frisionum (c. 785). These continental codes were all composed in Latin, while Anglo-Saxon was used for those of England, beginning with the Code of \u00c6thelberht of Kent (602). Around 893, Alfred the Great combined this and two other earlier Saxon codes, with various Mosaic and Christian precepts, to produce the Doom book code of laws for England.  Japan's Seventeen-article constitution written in 604, reportedly by Prince Sh\u014dtoku, is an early example of a constitution in Asian political history. Influenced by Buddhist teachings, the document focuses more on social morality than on institutions of government, and remains a notable early attempt at a government constitution.  The Constitution of Medina (Arabic: \u0635\u062d\u06cc\u0641\u0629 \u0627\u0644\u0645\u062f\u06cc\u0646\u0647, \u1e62a\u1e25\u012bfat al-Mad\u012bna), also known as the Charter of Medina, was drafted by the Islamic prophet Muhammad after his flight (hijra) to Yathrib where he became political leader. It constituted a formal agreement between Muhammad and all of the significant tribes and families of Yathrib (later known as Medina), including Muslims, Jews, and pagans.[22][23] The document was drawn up with the explicit concern of bringing to an end the bitter intertribal fighting between the clans of the Aws (Aus) and Khazraj within Medina. To this effect it instituted a number of rights and responsibilities for the Muslim, Jewish, and pagan communities of Medina bringing them within the fold of one community\u00a0\u2013 the Ummah.[24] The precise dating of the Constitution of Medina remains debated, but generally scholars agree it was written shortly after the Hijra (622).[25]  In Wales, the Cyfraith Hywel (Law of Hywel) was codified by Hywel Dda c. 942\u2013950. It served as the main law code in Wales until it was superseded by the Laws in Wales Acts 1535 and 1542.  The Pravda Yaroslava, originally combined by Yaroslav the Wise the Grand Prince of Kiev, was granted to Great Novgorod around 1017, and in 1054 was incorporated into the Russkaya Pravda; it became the law for all of Kievan Rus'. It survived only in later editions of the 15th century.  In England, Henry I's proclamation of the Charter of Liberties in 1100 bound the king for the first time in his treatment of the clergy and the nobility. This idea was extended and refined by the English barony when they forced King John to sign Magna Carta in 1215. The most important single article of Magna Carta, related to \"habeas corpus\", provided that the king was not permitted to imprison, outlaw, exile or kill anyone at a whim\u00a0\u2013 there must be due process of law first. This article, Article 39, of Magna Carta read:  No free man shall be arrested, or imprisoned, or deprived of his property, or outlawed, or exiled, or in any way destroyed, nor shall we go against him or send against him, unless by legal judgement of his peers, or by the law of the land. This provision became the cornerstone of English liberty after that point. The social contract in the original case was between the king and the nobility, but was gradually extended to all of the people. It led to the system of Constitutional Monarchy, with further reforms shifting the balance of power from the monarchy and nobility to the House of Commons.  The Nomocanon of Saint Sava (Serbian: \u0417\u0430\u043a\u043e\u043d\u043e\u043f\u0440\u0430\u0432\u0438\u043b\u043e\/Zakonopravilo)[26][27][28] was the first Serbian constitution from 1219. St. Sava's Nomocanon was the compilation of civil law, based on Roman Law, and canon law, based on Ecumenical Councils. Its basic purpose was to organize the functioning of the young Serbian kingdom and the Serbian church. Saint Sava began the work on the Serbian Nomocanon in 1208 while he was at Mount Athos, using The Nomocanon in Fourteen Titles, Synopsis of Stefan the Efesian, Nomocanon of John Scholasticus, and Ecumenical Council documents, which he modified with the canonical commentaries of Aristinos and Joannes Zonaras, local church meetings, rules of the Holy Fathers, the law of Moses, the translation of Prohiron, and the Byzantine emperors' Novellae (most were taken from Justinian's Novellae). The Nomocanon was a completely new compilation of civil and canonical regulations, taken from Byzantine sources but completed and reformed by St. Sava to function properly in Serbia. Besides decrees that organized the life of church, there are various norms regarding civil life; most of these were taken from Prohiron. Legal transplants of Roman-Byzantine law became the basis of the Serbian medieval law. The essence of Zakonopravilo was based on Corpus Iuris Civilis.  Stefan Du\u0161an, emperor of Serbs and Greeks, enacted Du\u0161an's Code (Serbian: \u0414\u0443\u0448\u0430\u043d\u043e\u0432 \u0417\u0430\u043a\u043e\u043d\u0438\u043a\/Du\u0161anov Zakonik)[29] in Serbia, in two state congresses: in 1349 in Skopje and in 1354 in Serres. It regulated all social spheres, so it was the second Serbian constitution, after St. Sava's Nomocanon (Zakonopravilo). The Code was based on Roman-Byzantine law. The legal transplanting within articles 171 and 172 of Du\u0161an's Code, which regulated the juridical independence, is notable. They were taken from the Byzantine code Basilika (book VII, 1, 16\u201317).  In 1222, Hungarian King Andrew II issued the Golden Bull of 1222.  Between 1220 and 1230, a Saxon administrator, Eike von Repgow, composed the Sachsenspiegel, which became the supreme law used in parts of Germany as late as 1900.  Around 1240, the Coptic Egyptian Christian writer, 'Abul Fada'il Ibn al-'Assal, wrote the Fetha Negest in Arabic. 'Ibn al-Assal took his laws partly from apostolic writings and Mosaic law and partly from the former Byzantine codes. There are a few historical records claiming that this law code was translated into Ge'ez and entered Ethiopia around 1450 in the reign of Zara Yaqob. Even so, its first recorded use in the function of a constitution (supreme law of the land) is with Sarsa Dengel beginning in 1563. The Fetha Negest remained the supreme law in Ethiopia until 1931, when a modern-style Constitution was first granted by Emperor Haile Selassie I.  In the Principality of Catalonia, the Catalan constitutions were promulgated by the Court from 1283 (or even two centuries before, if Usatges of Barcelona is considered part of the compilation of Constitutions) until 1716, when Philip V of Spain gave the Nueva Planta decrees, finishing with the historical laws of Catalonia. These Constitutions were usually made formally as a royal initiative, but required for its approval or repeal the favorable vote of the Catalan Courts, the medieval antecedent of the modern Parliaments. These laws, like other modern constitutions, had preeminence over other laws, and they could not be contradicted by mere decrees or edicts of the king.  The Kouroukan Founga was a 13th-century charter of the Mali Empire, reconstructed from oral tradition in 1988 by Siriman Kouyat\u00e9.[30]  The Golden Bull of 1356 was a decree issued by a Reichstag in Nuremberg headed by Emperor Charles IV that fixed, for a period of more than four hundred years, an important aspect of the constitutional structure of the Holy Roman Empire.  In China, the Hongwu Emperor created and refined a document he called Ancestral Injunctions (first published in 1375, revised twice more before his death in 1398). These rules served as a constitution for the Ming Dynasty for the next 250 years.  The oldest written document still governing a sovereign nation today is that of San Marino.[31] The Leges Statutae Republicae Sancti Marini was written in Latin and consists of six books. The first book, with 62 articles, establishes councils, courts, various executive officers, and the powers assigned to them. The remaining books cover criminal and civil law and judicial procedures and remedies. Written in 1600, the document was based upon the Statuti Comunali (Town Statute) of 1300, itself influenced by the Codex Justinianus, and it remains in force today.  In 1392 the Carta de Logu was legal code of the Giudicato of Arborea promulgated by the giudicessa Eleanor. It was in force in Sardinia until it was superseded by the code of Charles Felix in April 1827. The Carta was a work of great importance in Sardinian history. It was an organic, coherent, and systematic work of legislation encompassing the civil and penal law.  The Gayanashagowa, the oral constitution of the Haudenosaunee nation also known as the Great Law of Peace, established a system of governance as far back as 1190 AD (though perhaps more recently at 1451) in which the Sachems, or tribal chiefs, of the Iroquois League's member nations made decisions on the basis of universal consensus of all chiefs following discussions that were initiated by a single nation. The position of Sachem descends through families and are allocated by the senior female clan heads, though, prior to the filling of the position, candidacy is ultimately democratically decided by the community itself.[32]  In 1634 the Kingdom of Sweden adopted the 1634 Instrument of Government, drawn up under the Lord High Chancellor of Sweden Axel Oxenstierna after the death of king Gustavus Adolphus. This can be seen as the first written constitution adopted by a modern state.  In 1639, the Colony of Connecticut adopted the Fundamental Orders, which was the first North American constitution. It is the basis for every new Connecticut constitution since, and is also the reason for Connecticut's nickname, \"the Constitution State\".  On 4 January 1649, the Rump Parliament declared \"that the people are, under God, the original of all just power; that the Commons of England, being chosen by and representing the people, have the supreme power in this nation\".[33]  The English Protectorate set up by Oliver Cromwell after the English Civil War promulgated the first detailed written constitution adopted by a modern state;[34] it was called the Instrument of Government. This formed the basis of government for the short-lived republic from 1653 to 1657 by providing a legal rationale for the increasing power of Cromwell after Parliament consistently failed to govern effectively. Most of the concepts and ideas embedded into modern constitutional theory, especially bicameralism, separation of powers, the written constitution, and judicial review, can be traced back to the experiments of that period.[35] Drafted by Major-General John Lambert in 1653, the Instrument of Government included elements incorporated from an earlier document \"Heads of Proposals\",[36][37] which had been agreed to by the Army Council in 1647, as a set of propositions intended to be a basis for a constitutional settlement after King Charles I was defeated in the First English Civil War. Charles had rejected the propositions, but before the start of the Second Civil War, the Grandees of the New Model Army had presented the Heads of Proposals as their alternative to the more radical Agreement of the People presented by the Agitators and their civilian supporters at the Putney Debates. The Instrument of Government was adopted by Parliament on 15 December 1653, and Oliver Cromwell was installed as Lord Protector on the following day. The constitution set up a state council consisting of 21 members while executive authority was vested in the office of \"Lord Protector of the Commonwealth.\" This position was designated as a non-hereditary life appointment. The Instrument also required the calling of triennial Parliaments, with each sitting for at least five months.  The Instrument of Government was replaced in May 1657 by England's second, and last, codified constitution, the Humble Petition and Advice, proposed by Sir Christopher Packe.[38] The Petition offered hereditary monarchy to Oliver Cromwell, asserted Parliament's control over issuing new taxation, provided an independent council to advise the king and safeguarded \"Triennial\" meetings of Parliament. A modified version of the Humble Petition with the clause on kingship removed was ratified on 25 May. This finally met its demise in conjunction with the death of Cromwell and the Restoration of the monarchy.  All of the British colonies in North America that were to become the 13 original United States, adopted their own constitutions in 1776 and 1777, during the American Revolution (and before the later Articles of Confederation and United States Constitution), with the exceptions of Massachusetts, Connecticut and Rhode Island. The Commonwealth of Massachusetts adopted its Constitution in 1780, the oldest still-functioning constitution of any U.S. state; while Connecticut and Rhode Island officially continued to operate under their old colonial charters, until they adopted their first state constitutions in 1818 and 1843, respectively.  What is sometimes called the \"enlightened constitution\" model was developed by philosophers of the Age of Enlightenment such as Thomas Hobbes, Jean-Jacques Rousseau, and John Locke. The model proposed that constitutional governments should be stable, adaptable, accountable, open and should represent the people (i.e., support democracy).[39]  Agreements and Constitutions of Laws and Freedoms of the Zaporizian Host was written in 1710 by Pylyp Orlyk, hetman of the Zaporozhian Host. It was written to establish a free Zaporozhian-Ukrainian Republic, with the support of Charles XII of Sweden. It is notable in that it established a democratic standard for the separation of powers in government between the legislative, executive, and judiciary branches, well before the publication of Montesquieu's Spirit of the Laws. This Constitution also limited the executive authority of the hetman, and established a democratically elected Cossack parliament called the General Council. However, Orlyk's project for an independent Ukrainian State never materialized, and his constitution, written in exile, never went into effect.  Corsican Constitutions of 1755 and 1794 were inspired by Jean-Jacques Rousseau. The latter introduced universal suffrage for property owners.  The Swedish constitution of 1772 was enacted under King Gustavus III and was inspired by the separation of powers by Montesquieu. The king also cherished other enlightenment ideas (as an enlighted despot) and repealed torture, liberated agricultural trade, diminished the use of the death penalty and instituted a form of religious freedom. The constitution was commended by Voltaire.[40][41][42]  The United States Constitution, ratified 21 June 1788, was influenced by the writings of Polybius, Locke, Montesquieu, and others. The document became a benchmark for republicanism and codified constitutions written thereafter.[43]  The Polish\u2013Lithuanian Commonwealth Constitution was passed on 3 May 1791.[44][45][46] Its draft was developed by the leading minds of the Enlightenment in Poland such as King Stanislaw August Poniatowski, Stanis\u0142aw Staszic, Scipione Piattoli, Julian Ursyn Niemcewicz, Ignacy Potocki and Hugo Ko\u0142\u0142\u0105taj.[47] It was adopted by the Great Sejm and is considered the first constitution of its kind in Europe and the world's second oldest one after the American Constitution.[48]  Another landmark document was the French Constitution of 1791.  The 1811 Constitution of Venezuela was the first Constitution of Venezuela and Latin America, promulgated and drafted by Crist\u00f3bal Mendoza[49] and Juan Germ\u00e1n Roscio and in Caracas. It established a federal government but was repealed one year later.[50]  On 19 March 1812, the Spanish Constitution of 1812 was ratified by a parliament gathered in Cadiz, the only Spanish continental city which was safe from French occupation. The Spanish Constitution served as a model for other liberal constitutions of several South European and Latin American nations, for example, the Portuguese Constitution of 1822, constitutions of various Italian states during Carbonari revolts (i.e., in the Kingdom of the Two Sicilies), the Norwegian constitution of 1814, or the Mexican Constitution of 1824.[51]  In Brazil, the Constitution of 1824 expressed the option for the monarchy as political system after Brazilian Independence. The leader of the national emancipation process was the Portuguese prince Pedro I, elder son of the king of Portugal. Pedro was crowned in 1822 as first emperor of Brazil. The country was ruled by Constitutional monarchy until 1889, when it adopted the Republican model.  In Denmark, as a result of the Napoleonic Wars, the absolute monarchy lost its personal possession of Norway to Sweden. Sweden had already enacted its 1809 Instrument of Government, which saw the division of power between the Riksdag, the king and the judiciary.[52] However the Norwegians managed to infuse a radically democratic and liberal constitution in 1814, adopting many facets from the American constitution and the revolutionary French ones, but maintaining a hereditary monarch limited by the constitution, like the Spanish one.  The first Swiss Federal Constitution was put in force in September 1848 (with official revisions in 1878, 1891, 1949, 1971, 1982 and 1999).  The Serbian revolution initially led to a proclamation of a proto-constitution in 1811; the full-fledged Constitution of Serbia followed few decades later, in 1835. The first Serbian constitution (Sretenjski ustav) was adopted at the national assembly in Kragujevac on 15 February 1835.  The Constitution of Canada came into force on 1 July 1867, as the British North America Act, an act of the British Parliament. Over a century later, the BNA Act was patriated to the Canadian Parliament and augmented with the Canadian Charter of Rights and Freedoms.[53] Apart from the Constitution Acts, 1867 to 1982, Canada's constitution also has unwritten elements based in common law and convention.[54][55]  After tribal people first began to live in cities and establish nations, many of these functioned according to unwritten customs, while some developed autocratic, even tyrannical monarchs, who ruled by decree, or mere personal whim. Such rule led some thinkers to take the position that what mattered was not the design of governmental institutions and operations, as much as the character of the rulers. This view can be seen in Plato, who called for rule by \"philosopher-kings\".[56] Later writers, such as Aristotle, Cicero and Plutarch, would examine designs for government from a legal and historical standpoint.  The Renaissance brought a series of political philosophers who wrote implied criticisms of the practices of monarchs and sought to identify principles of constitutional design that would be likely to yield more effective and just governance from their viewpoints. This began with revival of the Roman law of nations concept[57] and its application to the relations among nations, and they sought to establish customary \"laws of war and peace\"[58] to ameliorate wars and make them less likely. This led to considerations of what authority monarchs or other officials have and don't have, from where that authority derives, and the remedies for the abuse of such authority.[59]  A seminal juncture in this line of discourse arose in England from the Civil War, the Cromwellian Protectorate, the writings of Thomas Hobbes, Samuel Rutherford, the Levellers, John Milton, and James Harrington, leading to the debate between Robert Filmer, arguing for the divine right of monarchs, on the one side, and on the other, Henry Neville, James Tyrrell, Algernon Sidney, and John Locke. What arose from the latter was a concept of government being erected on the foundations of first, a state of nature governed by natural laws, then a state of society, established by a social contract or compact, which bring underlying natural or social laws, before governments are formally established on them as foundations.  Along the way several writers examined how the design of government was important, even if the government were headed by a monarch. They also classified various historical examples of governmental designs, typically into democracies, aristocracies, or monarchies, and considered how just and effective each tended to be and why, and how the advantages of each might be obtained by combining elements of each into a more complex design that balanced competing tendencies. Some, such as Montesquieu, also examined how the functions of government, such as legislative, executive, and judicial, might appropriately be separated into branches. The prevailing theme among these writers was that the design of constitutions is not completely arbitrary or a matter of taste. They generally held that there are underlying principles of design that constrain all constitutions for every polity or organization. Each built on the ideas of those before concerning what those principles might be.  The later writings of Orestes Brownson[60] would try to explain what constitutional designers were trying to do. According to Brownson there are, in a sense, three \"constitutions\" involved: The first the constitution of nature that includes all of what was called \"natural law\". The second is the constitution of society, an unwritten and commonly understood set of rules for the society formed by a social contract before it establishes a government, by which it establishes the third, a constitution of government. The second would include such elements as the making of decisions by public conventions called by public notice and conducted by established rules of procedure. Each constitution must be consistent with, and derive its authority from, the ones before it, as well as from a historical act of society formation or constitutional ratification. Brownson argued that a state is a society with effective dominion over a well-defined territory, that consent to a well-designed constitution of government arises from presence on that territory, and that it is possible for provisions of a written constitution of government to be \"unconstitutional\" if they are inconsistent with the constitutions of nature or society. Brownson argued that it is not ratification alone that makes a written constitution of government legitimate, but that it must also be competently designed and applied.  Other writers[61] have argued that such considerations apply not only to all national constitutions of government, but also to the constitutions of private organizations, that it is not an accident that the constitutions that tend to satisfy their members contain certain elements, as a minimum, or that their provisions tend to become very similar as they are amended after experience with their use. Provisions that give rise to certain kinds of questions are seen to need additional provisions for how to resolve those questions, and provisions that offer no course of action may best be omitted and left to policy decisions. Provisions that conflict with what Brownson and others can discern are the underlying \"constitutions\" of nature and society tend to be difficult or impossible to execute, or to lead to unresolvable disputes.  Constitutional design has been treated as a kind of metagame in which play consists of finding the best design and provisions for a written constitution that will be the rules for the game of government, and that will be most likely to optimize a balance of the utilities of justice, liberty, and security. An example is the metagame Nomic.[62]  Political economy theory regards constitutions as coordination devices that help citizens to prevent rulers from abusing power. If the citizenry can coordinate a response to police government officials in the face of a constitutional fault, then the government have the incentives to honor the rights that the constitution guarantees.[63] An alternative view considers that constitutions are not enforced by the citizens at-large, but rather by the administrative powers of the state. Because rulers cannot themselves implement their policies, they need to rely on a set of organizations (armies, courts, police agencies, tax collectors) to implement it. In this position, they can directly sanction the government by refusing to cooperate, disabling the authority of the rulers. Therefore, constitutions could be characterized by a self-enforcing equilibria between the rulers and powerful administrators.[64]  Most commonly, the term constitution refers to a set of rules and principles that define the nature and extent of government. Most constitutions seek to regulate the relationship between institutions of the state, in a basic sense the relationship between the executive, legislature and the judiciary, but also the relationship of institutions within those branches. For example, executive branches can be divided into a head of government, government departments\/ministries, executive agencies and a civil service\/administration. Most constitutions also attempt to define the relationship between individuals and the state, and to establish the broad rights of individual citizens. It is thus the most basic law of a territory from which all the other laws and rules are hierarchically derived; in some territories it is in fact called \"Basic Law\".  A fundamental classification is codification or lack of codification. A codified constitution is one that is contained in a single document, which is the single source of constitutional law in a state. An uncodified constitution is one that is not contained in a single document, consisting of several different sources, which may be written or unwritten; see constitutional convention.  Most states in the world have codified constitutions.  Codified constitutions are often the product of some dramatic political change, such as a revolution. The process by which a country adopts a constitution is closely tied to the historical and political context driving this fundamental change. The legitimacy (and often the longevity) of codified constitutions has often been tied to the process by which they are initially adopted and some scholars have pointed out that high constitutional turnover within a given country may itself be detrimental to separation of powers and the rule of law.  States that have codified constitutions normally give the constitution supremacy over ordinary statute law. That is, if there is any conflict between a legal statute and the codified constitution, all or part of the statute can be declared ultra vires by a court, and struck down as unconstitutional. In addition, exceptional procedures are often required to amend a constitution. These procedures may include: convocation of a special constituent assembly or constitutional convention, requiring a supermajority of legislators' votes, approval in two terms of parliament, the consent of regional legislatures, a referendum process, and\/or other procedures that make amending a constitution more difficult than passing a simple law.  Constitutions may also provide that their most basic principles can never be abolished, even by amendment. In case a formally valid amendment of a constitution infringes these principles protected against any amendment, it may constitute a so-called unconstitutional constitutional law.  Codified constitutions normally consist of a ceremonial preamble, which sets forth the goals of the state and the motivation for the constitution, and several articles containing the substantive provisions. The preamble, which is omitted in some constitutions, may contain a reference to God and\/or to fundamental values of the state such as liberty, democracy or human rights. In ethnic nation-states such as Estonia, the mission of the state can be defined as preserving a specific nation, language and culture.  As of 2017[update] only two sovereign states, New Zealand and the United Kingdom, have wholly uncodified constitutions. The Basic Laws of Israel have since 1950 been intended to be the basis for a constitution, but as of 2017 it had not been drafted. The various Laws are considered to have precedence over other laws, and give the procedure by which they can be amended, typically by a simple majority of members of the Knesset (parliament).[65]  Uncodified constitutions are the product of an \"evolution\" of laws and conventions over centuries (such as in the Westminster System that developed in Britain). By contrast to codified constitutions, uncodified constitutions include both written sources \u2013 e.g. constitutional statutes enacted by the Parliament \u2013 and unwritten sources \u2013 constitutional conventions, observation of precedents, royal prerogatives, customs and traditions, such as holding general elections on Thursdays; together these constitute British constitutional law.  Some constitutions are largely, but not wholly, codified. For example, in the Constitution of Australia, most of its fundamental political principles and regulations concerning the relationship between branches of government, and concerning the government and the individual are codified in a single document, the Constitution of the Commonwealth of Australia. However, the presence of statutes with constitutional significance, namely the Statute of Westminster, as adopted by the Commonwealth in the Statute of Westminster Adoption Act 1942, and the Australia Act 1986 means that Australia's constitution is not contained in a single constitutional document.[citation needed] It means the Constitution of Australia is uncodified,[dubious  \u2013 discuss] it also contains constitutional conventions, thus is partially unwritten.  The Constitution of Canada resulted from the passage of several British North America Acts from 1867 to the Canada Act 1982, the act that formally severed British Parliament's ability to amend the Canadian constitution. The Canadian constitution includes specific legislative acts as mentioned in section 52(2) of the Constitution Act, 1982. However, some documents not explicitly listed in section 52(2) are also considered constitutional documents in Canada, entrenched via reference; such as the Proclamation of 1763. Although Canada's constitution includes a number of different statutes, amendments, and references, some constitutional rules that exist in Canada is derived from unwritten sources and constitutional conventions.  The terms written constitution and codified constitution are often used interchangeably, as are unwritten constitution and uncodified constitution, although this usage is technically inaccurate. A codified constitution is a single document; states that do not have such a document have uncodified, but not entirely unwritten, constitutions, since much of an uncodified constitution is usually written in laws such as the Basic Laws of Israel and the Parliament Acts of the United Kingdom. Uncodified constitutions largely lack protection against amendment by the government of the time. For example, the U.K. Fixed-term Parliaments Act 2011 legislated by simple majority for strictly fixed-term parliaments; until then the ruling party could call a general election at any convenient time up to the maximum term of five years. This change would require a constitutional amendment in most nations.  A constitutional amendment is a modification of the constitution of a polity, organization or other type of entity. Amendments are often interwoven into the relevant sections of an existing constitution, directly altering the text. Conversely, they can be appended to the constitution as supplemental additions (codicils), thus changing the frame of government without altering the existing text of the document.  Most constitutions require that amendments cannot be enacted unless they have passed a special procedure that is more stringent than that required of ordinary legislation.  Some countries are listed under more than one method because alternative procedures may be used.  An entrenched clause or entrenchment clause of a basic law or constitution is a provision that makes certain amendments either more difficult or impossible to pass, making such amendments inadmissible. Overriding an entrenched clause may require a supermajority, a referendum, or the consent of the minority party. For example, the U.S. Constitution has an entrenched clause that prohibits abolishing equal suffrage of the States within the Senate without their consent. The term eternity clause is used in a similar manner in the constitutions of the Czech Republic,[69] Germany, Turkey, Greece,[70] Italy,[71] Morocco,[72] the Islamic Republic of Iran, Brazil and Norway.[71] India's constitution does not contain specific provisions on entrenched clauses but the basic structure doctrine makes it impossible for certain basic features of the Constitution to be altered or destroyed by the Parliament of India through an amendment.[73] The Constitution of Colombia also lacks explicit entrenched clauses, but has a similar substantive limit on amending its fundamental principles through judicial interpretations.[71]  Constitutions include various rights and duties. These include the following:  Constitutions usually explicitly divide power between various branches of government. The standard model, described by the Baron de Montesquieu, involves three branches of government: executive, legislative and judicial. Some constitutions include additional branches, such as an auditory branch. Constitutions vary extensively as to the degree of separation of powers between these branches.  In presidential and semi-presidential systems of government, department secretaries\/ministers are accountable to the president, who has patronage powers to appoint and dismiss ministers. The president is accountable to the people in an election.  In parliamentary systems, Cabinet Ministers are accountable to Parliament, but it is the prime minister who appoints and dismisses them. In the case of the United Kingdom and other countries with a monarchy, it is the monarch who appoints and dismisses ministers, on the advice of the prime minister. In turn the prime minister will resign if the government loses the confidence of the parliament (or a part of it). Confidence can be lost if the government loses a vote of no confidence or, depending on the country,[101] loses a particularly important vote in parliament, such as vote on the budget. When a government loses confidence, it stays in office until a new government is formed; something which normally but not necessarily required the holding of a general election.  Other independent institutions which some constitutions have set out include a central bank,[102] an anti-corruption commission,[103] an electoral commission,[104] a judicial oversight body,[105] a human rights commission,[106] a media commission,[107] an ombudsman,[108] and a truth and reconciliation commission.[109]  Constitutions also establish where sovereignty is located in the state. There are three basic types of distribution of sovereignty according to the degree of centralisation of power: unitary, federal, and confederal. The distinction is not absolute.  In a unitary state, sovereignty resides in the state itself, and the constitution determines this. The territory of the state may be divided into regions, but they are not sovereign and are subordinate to the state. In the UK, the constitutional doctrine of Parliamentary sovereignty dictates that sovereignty is ultimately contained at the centre. Some powers have been devolved to Northern Ireland, Scotland, and Wales (but not England). Some unitary states (Spain is an example) devolve more and more power to sub-national governments until the state functions in practice much like a federal state.  A federal state has a central structure with at most a small amount of territory mainly containing the institutions of the federal government, and several regions (called states, provinces, etc.) which compose the territory of the whole state. Sovereignty is divided between the centre and the constituent regions. The constitutions of Canada and the United States establish federal states, with power divided between the federal government and the provinces or states. Each of the regions may in turn have its own constitution (of unitary nature).  A confederal state comprises again several regions, but the central structure has only limited coordinating power, and sovereignty is located in the regions. Confederal constitutions are rare, and there is often dispute to whether so-called \"confederal\" states are actually federal.  To some extent a group of states which do not constitute a federation as such may by treaties and accords give up parts of their sovereignty to a supranational entity. For example, the countries constituting the European Union have agreed to abide by some Union-wide measures which restrict their absolute sovereignty in some ways, e.g., the use of the metric system of measurement instead of national units previously used.  Many constitutions allow the declaration under exceptional circumstances of some form of state of emergency during which some rights and guarantees are suspended. This provision can be and has been abused to allow a government to suppress dissent without regard for human rights\u00a0\u2013 see the article on state of emergency.  Italian political theorist Giovanni Sartori noted the existence of national constitutions which are a facade for authoritarian sources of power. While such documents may express respect for human rights or establish an independent judiciary, they may be ignored when the government feels threatened, or never put into practice. An extreme example was the Constitution of the Soviet Union that on paper supported freedom of assembly and freedom of speech; however, citizens who transgressed unwritten limits were summarily imprisoned. The example demonstrates that the protections and benefits of a constitution are ultimately provided not through its written terms but through deference by government and society to its principles. A constitution may change from being real to a facade and back again as democratic and autocratic governments succeed each other.  Constitutions are often, but by no means always, protected by a legal body whose job it is to interpret those constitutions and, where applicable, declare void executive and legislative acts which infringe the constitution. In some countries, such as Germany, this function is carried out by a dedicated constitutional court which performs this (and only this) function. In other countries, such as Ireland, the ordinary courts may perform this function in addition to their other responsibilities. While elsewhere, like in the United Kingdom, the concept of declaring an act to be unconstitutional does not exist.  A constitutional violation is an action or legislative act that is judged by a constitutional court to be contrary to the constitution, that is, unconstitutional. An example of constitutional violation by the executive could be a public office holder who acts outside the powers granted to that office by a constitution. An example of constitutional violation by the legislature is an attempt to pass a law that would contradict the constitution, without first going through the proper constitutional amendment process.  Some countries, mainly those with uncodified constitutions, have no such courts at all. For example, the United Kingdom has traditionally operated under the principle of parliamentary sovereignty under which the laws passed by United Kingdom Parliament could not be questioned by the courts.  Judicial philosophies of constitutional interpretation (note: generally specific to United States constitutional law) "},{"title":"Consensus democracy","content":"Consensus democracy[1] is the application of consensus decision-making and supermajority to the process of legislation in a democracy. It is characterized by a decision-making structure that involves and takes into account as broad a range of opinions as possible, as opposed to majoritarian democracy systems where minority opinions can potentially be ignored by vote-winning majorities.[2] Constitutions typically require consensus or supermajority.[3]  A consensus government is a national unity government with representation across the whole political spectrum. A concordance democracy is a type of consensus democracy where majority rule does not play a central role. Optional referendums and popular initiatives correspond to consensus democracy.[4]  Consensus democracy is most closely embodied in certain countries such as Switzerland, Germany, Denmark, Lebanon, Sweden, Iraq, and Belgium, where consensus is an important feature of political culture, particularly with a view to preventing the domination of one linguistic or cultural group in the political process.[5] The term consociational state is used in political science to describe countries with such consensus based political systems. An example of such a system could be the Dutch Poldermodel. Many parties in Lebanon call for applying consensus democracy, especially at times of crisis.  Consensus government chiefly arises in non-partisan democracies and similar systems in which a majority of politicians are independent. Many former British territories with large indigenous populations use consensus government to fuse traditional tribal leadership with the Westminster system. Consensus government in Canada is used in the Northwest Territories and Nunavut, as well as the autonomous Nunatsiavut region, and similar systems have arisen in the Pacific island nations of Fiji, Tuvalu and Vanuatu, as well as the ancient Tynwald of the Isle of Man.[6] "},{"title":"Northern Ireland","content":"  \u2013\u00a0in Europe\u00a0(green &\u00a0dark grey)\u2013\u00a0in the United Kingdom\u00a0(green) Northern Ireland (Irish: Tuaisceart \u00c9ireann [\u02c8t\u032a\u02e0u\u0259\u0283c\u0259\u027e\u02e0t\u032a\u02e0 \u02c8e\u02d0\u027e\u02b2\u0259n\u032a\u02e0] \u24d8;[13] Ulster Scots: Norlin Airlann) is a part of the United Kingdom in the north-east of the island of Ireland that is variously described as a country, province or region.[14][15][16][17][18] Northern Ireland shares an open border to the south and west with the Republic of Ireland. At the 2021 census, its population was 1,903,175,[7] making up around 3% of the UK's population and 27% of the population on the island of Ireland. The Northern Ireland Assembly, established by the Northern Ireland Act 1998, holds responsibility for a range of devolved policy matters, while other areas are reserved for the UK Government. The government of Northern Ireland cooperates with the government of Ireland in several areas under the terms of the Belfast Agreement.[19] The Republic of Ireland also has a consultative role on non-devolved governmental matters through the British\u2013Irish Governmental Conference (BIIG).[20]  Northern Ireland was created in 1921, when Ireland was partitioned by the Government of Ireland Act 1920, creating a devolved government for the six northeastern counties. As was intended by unionists and their supporters in Westminster, Northern Ireland had a unionist majority, who wanted to remain in the United Kingdom;[21] they were generally the Protestant descendants of colonists from Britain. Meanwhile, the majority in Southern Ireland (which became the Irish Free State in 1922), and a significant minority in Northern Ireland, were Irish nationalists (generally Catholics) who wanted a united independent Ireland.[22] Today, the former generally see themselves as British and the latter generally see themselves as Irish, while a Northern Irish or Ulster identity is claimed by a significant minority from all backgrounds.[23]  The creation of Northern Ireland was accompanied by violence both in defence of and against partition. During the conflict of 1920\u201322, the capital Belfast saw major communal violence, mainly between Protestant unionist and Catholic nationalist civilians.[24] More than 500 were killed[25] and more than 10,000 became refugees, mostly Catholics.[26] For the next fifty years, Northern Ireland had an unbroken series of Unionist Party governments.[27] There was informal mutual segregation by both communities,[28] and the Unionist governments were accused of discrimination against the Irish nationalist and Catholic minority.[29] In the late 1960s, a campaign to end discrimination against Catholics and nationalists was opposed by loyalists, who saw it as a republican front.[30] This unrest sparked the Troubles, a thirty-year conflict involving republican and loyalist paramilitaries and state forces, which claimed over 3,500 lives and injured 50,000 others.[31][32] The 1998 Good Friday Agreement was a major step in the peace process, including paramilitary disarmament and security normalisation, although sectarianism and segregation remain major social problems, and sporadic violence has continued.[33]  The economy of Northern Ireland was the most industrialised in Ireland at the time of partition, but soon began to decline, exacerbated by the political and social turmoil of the Troubles.[34] Its economy has grown significantly since the late 1990s. Unemployment in Northern Ireland peaked at 17.2% in 1986, but dropped back down to below 10% in the 2010s,[35] similar to the rate of the rest of the UK.[36] Cultural links between Northern Ireland, the rest of Ireland, and the rest of the UK are complex, with Northern Ireland sharing both the culture of Ireland and the culture of the United Kingdom. In many sports, there is an All-Ireland governing body or team for the whole island; the most notable exception is association football. Northern Ireland competes separately at the Commonwealth Games, and people from Northern Ireland may compete for either Great Britain or Ireland at the Olympic Games.  The region that is now Northern Ireland was long inhabited by native Gaels who were Irish-speaking and predominantly Catholic.[37] It was made up of several Gaelic kingdoms and territories and was part of the province of Ulster. In 1169, Ireland was invaded by a coalition of forces under the command of the English crown that quickly overran and occupied most of the island, beginning 800 years of foreign central authority. Attempts at resistance were swiftly crushed everywhere outside of Ulster. Unlike in the rest of the country, where Gaelic authority continued only in scattered, remote pockets, the major kingdoms of Ulster would mostly remain intact with English authority in the province contained to areas on the eastern coast closest to Great Britain. English power gradually eroded in the face of stubborn Irish resistance in the centuries that followed; eventually being reduced to only the city of Dublin and its suburbs. When Henry VIII launched the 16th century Tudor re-conquest of Ireland, Ulster once again resisted most effectively. In the Nine Years' War (1594\u20131603), an alliance of Gaelic chieftains led by the two most powerful Ulster lords, Hugh Roe O'Donnell and the Earl of Tyrone fought against the English government in Ireland. The Ulster-dominated alliance represented the first Irish united front; prior resistance had always been geographically localized. Despite being able to cement an alliance with Spain and major victories early on, defeat was virtually inevitable following England's victory at the siege of Kinsale. In 1607, the rebellion's leaders fled to mainland Europe alongside much of Ulster's Gaelic nobility. Their lands were confiscated by the Crown and colonized with English-speaking Protestant settlers from Britain, in the Plantation of Ulster. This led to the founding of many of Ulster's towns and created a lasting Ulster Protestant community with ties to Britain. The Irish Rebellion of 1641 began in Ulster. The rebels wanted an end to anti-Catholic discrimination, greater Irish self-governance, and to roll back the Plantation. It developed into an ethnic conflict between Irish Catholics and British Protestant settlers and became part of the wider Wars of the Three Kingdoms (1639\u201353), which ended with the English Parliamentarian conquest. Further Protestant victories in the Williamite-Jacobite War (1688\u201391) solidified Anglican Protestant rule in the Kingdom of Ireland. The Williamite victories of the siege of Derry (1689) and Battle of the Boyne (1690) are still celebrated by some Protestants in Northern Ireland.[38] Many more Scots Protestants migrated to Ulster during the Scottish famine of the 1690s.  Following the Williamite victory, and contrary to the Treaty of Limerick (1691), a series of Penal Laws were passed by the Anglican Protestant ruling class in Ireland. The intention was to disadvantage Catholics and, to a lesser extent, Presbyterians. Some 250,000 Ulster Presbyterians emigrated to the British North American colonies between 1717 and 1775.[39] It is estimated that there are more than 27\u00a0million Scotch-Irish Americans now living in the United States,[40] along with many Scotch-Irish Canadians in Canada. In the context of institutional discrimination, the 18th century saw secret, militant societies develop in Ulster and act on sectarian tensions in violent attacks. This escalated at the end of the century, especially during the County Armagh disturbances, where the Protestant Peep o' Day Boys fought the Catholic Defenders. This led to the founding of the Protestant Orange Order. The Irish Rebellion of 1798 was led by the United Irishmen; a cross-community Irish republican group founded by Belfast Presbyterians, which sought Irish independence. Following this, the government of the Kingdom of Great Britain pushed for the two kingdoms to be merged, in an attempt to quell violent sectarianism, remove discriminatory laws, and prevent the spread of French-style republicanism. The United Kingdom of Great Britain and Ireland was formed in 1801 and governed from London. During the 19th century, legal reforms known as the Catholic emancipation continued to remove discrimination against Catholics, and progressive programs enabled tenant farmers to buy land from landlords.  By the late 19th century, a large and disciplined cohort of Irish Nationalist MPs at Westminster committed the Liberal Party to \"Irish Home Rule\"\u2014self-government for Ireland, within the United Kingdom. This was bitterly opposed by Irish Unionists, most of whom were Protestants, who feared an Irish devolved government dominated by Irish nationalists and Catholics. The Government of Ireland Bill 1886 and Government of Ireland Bill 1893 were defeated. However, Home Rule became a near-certainty in 1912 after the Government of Ireland Act 1914 was first introduced. The Liberal government was dependent on Nationalist support, and the Parliament Act 1911 prevented the House of Lords from blocking the bill indefinitely.[41]  In response, unionists vowed to prevent Irish Home Rule, from Conservative and Unionist Party leaders such as Bonar Law and Dublin-based barrister Edward Carson to militant working class unionists in Ireland. This sparked the Home Rule Crisis. In September 1912, more than 500,000 unionists signed the Ulster Covenant, pledging to oppose Home Rule by any means and to defy any Irish government.[42] In 1914, unionists smuggled thousands of rifles and rounds of ammunition from Imperial Germany for use by the Ulster Volunteers (UVF), a paramilitary organisation formed to oppose Home Rule. Irish nationalists had also formed a paramilitary organisation, the Irish Volunteers. It sought to ensure Home Rule was implemented, and it smuggled its own weapons into Ireland a few months after the Ulster Volunteers.[43] Ireland seemed to be on the brink of civil war.[44]  Unionists were in a minority in Ireland as a whole, but a majority in the province of Ulster, especially the counties Antrim, Down, Armagh and Londonderry.[45] Unionists argued that if Home Rule could not be stopped then all or part of Ulster should be excluded from it.[46] In May 1914, the UK Government introduced an Amending Bill to allow for 'Ulster' to be excluded from Home Rule. There was then debate over how much of Ulster should be excluded and for how long. Some Ulster unionists were willing to tolerate the 'loss' of some mainly-Catholic areas of the province.[47] The crisis was interrupted by the outbreak of the First World War in August 1914, and Ireland's involvement in it. The UK government abandoned the Amending Bill, and instead rushed through a new bill, the Suspensory Act 1914, suspending Home Rule for the duration of the war,[48] with the exclusion of Ulster still to be decided.[49]  By the end of the war (during which the 1916 Easter Rising had taken place), most Irish nationalists now wanted full independence rather than home rule. In September 1919, British Prime Minister David Lloyd George tasked a committee with planning another home rule bill. Headed by English unionist politician Walter Long, it was known as the 'Long Committee'. It decided that two devolved governments should be established\u2014one for the nine counties of Ulster and one for the rest of Ireland\u2014together with a Council of Ireland for the \"encouragement of Irish unity\".[50] Most Ulster unionists wanted the territory of the Ulster government to be reduced to six counties so that it would have a larger Protestant unionist majority, which they believed would guarantee its longevity. The six counties of Antrim, Down, Armagh, Londonderry, Tyrone and Fermanagh comprised the maximum area unionists believed they could dominate,[51] The area that was to become Northern Ireland included counties Fermanagh and Tyrone, even though they had nationalist majorities in the 1918 Irish general election.[52]  Events overtook the government. In the 1918 Irish general election, the pro-independence Sinn F\u00e9in party won the overwhelming majority of Irish seats. Sinn F\u00e9in's elected members boycotted the British parliament and founded a separate Irish parliament (D\u00e1il \u00c9ireann), declaring an independent Irish Republic covering the whole island. Many Irish republicans blamed the British establishment for the sectarian divisions in Ireland, and believed that Ulster unionism would fade once British rule was ended.[53] The British authorities outlawed the D\u00e1il in September 1919,[54] and a guerrilla conflict developed as the Irish Republican Army (IRA) began attacking British forces. This became known as the Irish War of Independence.[55]  Meanwhile, the Government of Ireland Act 1920 passed through the British parliament in 1920. It would divide Ireland into two self-governing UK territories: the six northeastern counties (Northern Ireland) being ruled from Belfast, and the other twenty-six counties (Southern Ireland) being ruled from Dublin. Both would have a shared Lord Lieutenant of Ireland, who would appoint both governments and a Council of Ireland, which the UK government intended to evolve into an all-Ireland parliament.[56] The Act received royal assent that December, becoming the Government of Ireland Act 1920. It came into force on 3 May 1921,[57][58] partitioning Ireland and creating Northern Ireland. the 1921 Irish elections were held on 24 May, in which unionists won most seats in the Northern Ireland parliament. It first met on 7 June and formed its first devolved government, headed by Ulster Unionist Party leader James Craig. Irish nationalist members refused to attend. King George V addressed the ceremonial opening of the Northern parliament on 22 June.[57]  During 1920\u201322, in what became Northern Ireland, partition was accompanied by violence \"in defence or opposition to the new settlement\"[24] during The Troubles (1920\u20131922). The IRA carried out attacks on British forces in the north-east but was less active than in the rest of Ireland. Protestant loyalists attacked Catholics in reprisal for IRA actions. In the summer of 1920, sectarian violence erupted in Belfast and Derry, and there were mass burnings of Catholic property in Lisburn and Banbridge.[59] Conflict continued intermittently for two years, mostly in Belfast, which saw \"savage and unprecedented\" communal violence between Protestants and Catholics, including rioting, gun battles, and bombings. Homes, businesses, and churches were attacked and people were expelled from workplaces and mixed neighbourhoods.[24] More than 500 were killed[25] and more than 10,000 became refugees, most of them Catholics.[60] The British Army was deployed and the Ulster Special Constabulary (USC) was formed to help the regular police. The USC was almost wholly Protestant. Members of the USC and regular police were involved in reprisal attacks on Catholic civilians.[61] A truce between British forces and the IRA was established on 11 July 1921, ending the fighting in most of Ireland. However, communal violence continued in Belfast, and in 1922 the IRA launched a guerrilla offensive along the new Irish border.[62]  The Anglo-Irish Treaty was signed between representatives of the governments of the UK and the Irish Republic on 6 December 1921, creating the Irish Free State. Under the terms of the treaty, Northern Ireland would become part of the Free State unless its government opted out by presenting an address to the king, although in practice partition remained in place.[63]   As expected, the Parliament of Northern Ireland resolved on 7 December 1922 (the day after the establishment of the Irish Free State) to exercise its right to opt out of the Free State by making an address to King George V.[64] The text of the address was:  Most Gracious Sovereign, We, your Majesty's most dutiful and loyal subjects, the Senators and Commons of Northern Ireland in Parliament assembled, having learnt of the passing of the Irish Free State Constitution Act 1922, being the Act of Parliament for the ratification of the Articles of Agreement for a Treaty between Great Britain and Ireland, do, by this humble Address, pray your Majesty that the powers of the Parliament and Government of the Irish Free State shall no longer extend to Northern Ireland.[65]  Shortly afterwards, the Irish Boundary Commission was established to decide on the border between the Irish Free State and Northern Ireland. Owing to the outbreak of the Irish Civil War, the work of the commission was delayed until 1925. The Free State government and Irish nationalists hoped for a large transfer of territory to the Free State, as many border areas had nationalist majorities. Many believed this would leave the remaining Northern Ireland territory too small to be viable.[66] However, the commission's final report recommended only small transfers of territory, and in both directions. The Free State, Northern Ireland, and UK governments agreed to suppress the report and accept the status quo, while the UK government agreed that the Free State would no longer have to pay a share of the UK national debt.[67]  Northern Ireland's border was drawn to give it \"a decisive Protestant majority\". At the time of its creation, Northern Ireland's population was two-thirds Protestant and one-third Catholic.[21] Most Protestants were unionists\/loyalists who sought to maintain Northern Ireland as a part of the United Kingdom, while most Catholics were Irish nationalists\/republicans who sought an independent United Ireland. There was mutual self-imposed segregation in Northern Ireland between Protestants and Catholics such as in education, housing, and often employment.[68]  For its first fifty years, Northern Ireland had an unbroken series of Ulster Unionist Party governments.[69] Every prime minister and almost every minister of these governments were members of the Orange Order, as were all but 11 of the 149 Ulster Unionist Party (UUP) MPs elected during this time.[70] Almost all judges and magistrates were Protestant, many of them closely associated with the UUP. Northern Ireland's new police force was the Royal Ulster Constabulary (RUC), which succeeded the Royal Irish Constabulary (RIC). It too was almost wholly Protestant and lacked operational independence, responding to directions from government ministers. The RUC and the reserve Ulster Special Constabulary (USC) were militarized police forces due to the perceived threat of militant republicanism. In 1936 the British advocacy group - the National Council for Civil Liberties characterised the USC as \"nothing but the organised army of the Unionist party\".[71] They \"had at their disposal the Special Powers Act, a sweeping piece of legislation which allowed arrests without warrant, internment without trial, unlimited search powers, and bans on meetings and publications\".[72] This 1922 Act was made permanent in 1933 and was not repealed until 1973.[73]  The Nationalist Party was the main political party in opposition to the UUP governments. However, its elected members often protested by abstaining from the Northern Ireland parliament, and many nationalists did not vote in parliamentary elections.[68] Other early nationalist groups which campaigned against partition included the National League of the North (formed in 1928), the Northern Council for Unity (formed in 1937) and the Irish Anti-Partition League (formed in 1945).[74]  The Local Government Act (Northern Ireland) of 1922 allowed for the altering of municipal and rural boundaries. This Act led to the gerrymandering of election boundaries in the Nationalists majority cities of Derry City, Enniskillen, Omagh, Armagh and many other towns and rural districts. That action ensured Unionist control over local councils in areas where they were a minority.[75] The UUP governments, and some UUP-dominated local authorities, discriminated against the Catholic and Irish nationalist minority; especially by the gerrymandering of electoral boundaries, the allocation of public housing, public sector employment, and policing, showing \"a consistent and irrefutable pattern of deliberate discrimination against Catholics\".[76] Many Catholics\/Nationalists saw the gerrymandered electoral boundaries and the abolishing of proportional representation as proof of government-sponsored discrimination. Until 1969 a system was in place called plural voting which was a practice whereby one person might be able to vote multiple times in an election. Property and business owners could vote both in the constituency where their property lay and that in which they lived, if the two were different. This system often resulted in one person being able to cast multiple votes.[77] Decades later, UUP First Minister of Northern Ireland, David Trimble, said that Northern Ireland under the UUP had been a \"cold house\" for Catholics.[78]  During World War II, recruitment to the British military was noticeably lower than the high levels reached during World War I. In June 1940, to encourage the neutral Irish state to join with the Allies, British Prime Minister Winston Churchill indicated to Taoiseach \u00c9amon de Valera that the British government would encourage Irish unity, but believing that Churchill could not deliver, de Valera declined the offer.[79] The British did not inform the government of Northern Ireland that they had made the offer to the Dublin government, and de Valera's rejection was not publicised until 1970. Belfast was a key industrial city in the UK's war effort, producing ships, tanks, aircraft, and munitions. The unemployment that had been so persistent in the 1930s disappeared, and labour shortages appeared, prompting migration from the Free State. The city was thinly defended, and had only 24 anti-aircraft guns. Richard Dawson Bates, the Minister for Home Affairs, had prepared too late, assuming that Belfast was far enough away to be safe. The city's fire brigade was inadequate, and as the Northern Ireland government had been reluctant to spend money on air raid shelters, it only started to build them after the Blitz in London during the autumn of 1940. There were no searchlights in the city, which made shooting down enemy bombers more difficult. In April\u2013May 1941, the Belfast Blitz began when the Luftwaffe launched a series of raids that were the most deadly seen outside London. Working-class areas in the north and east of the city were particularly hard hit, and over 1,000 people were killed and hundreds were seriously injured. Tens of thousands of people fled the city in fear of future attacks. In the final raid, Luftwaffe bombs inflicted extensive damage to the docks and the Harland & Wolff shipyard, closing it for six months. Half of the city's houses had been destroyed, highlighting the terrible slum conditions in Belfast, and about \u00a320 million worth of damage was caused. The Northern Ireland government was criticised heavily for its lack of preparation, and Northern Ireland Prime Minister J. M. Andrews resigned. There was a major munitions strike in 1944.[80]  The Ireland Act 1949 gave the first legal guarantee that the region would not cease to be part of the United Kingdom without the consent of the Parliament of Northern Ireland.  From 1956 to 1962, the Irish Republican Army (IRA) carried out a limited guerrilla campaign in border areas of Northern Ireland, called the Border Campaign. It aimed to destabilize Northern Ireland and bring about an end to partition but failed.[81]  In 1965, Northern Ireland's Prime Minister Terence O'Neill met the Taoiseach, Se\u00e1n Lemass. It was the first meeting between the two heads of government since partition.[82]  The Troubles, which started in the late 1960s, consisted of about 30 years of recurring acts of intense violence during which 3,254 people were killed[83] with over 50,000 casualties.[84] From 1969 to 2003 there were over 36,900 shooting incidents and over 16,200 bombings or attempted bombings associated with The Troubles.[32] The conflict was caused by escalating tensions between the Irish nationalist minority and the dominant unionist majority; Irish nationalists object to Northern Ireland staying within the United Kingdom.[85] From 1967 to 1972 the Northern Ireland Civil Rights Association (NICRA), which modelled itself on the US civil rights movement, led a campaign of civil resistance to anti-Catholic discrimination in housing, employment, policing, and electoral procedures. The franchise for local government elections included only rate-payers and their spouses, and so excluded over a quarter of the electorate. While the majority of disenfranchised electors were Protestant, Catholics were over-represented since they were poorer and had more adults still living in the family home.[86]  NICRA's campaign, seen by many unionists as an Irish republican front, and the violent reaction to it proved to be a precursor to a more violent period.[87] As early as 1969, armed campaigns of paramilitary groups began, including the Provisional IRA campaign of 1969\u20131997 which was aimed at the end of British rule in Northern Ireland and the creation of a United Ireland, and the Ulster Volunteer Force, formed in 1966 in response to the perceived erosion of both the British character and unionist domination of Northern Ireland. The state security forces \u2013 the British Army and the police (the Royal Ulster Constabulary) \u2013 were also involved in the violence. The UK Government's position is that its forces were neutral in the conflict, trying to uphold law and order in Northern Ireland and the right of the people of Northern Ireland to democratic self-determination. Republicans regarded the state forces as combatants in the conflict, pointing to the collusion between the state forces and the loyalist paramilitaries as proof of this. The \"Ballast\" investigation by the Police Ombudsman for Northern Ireland has confirmed that British forces, and in particular the RUC, did collude with loyalist paramilitaries, were involved in murder, and did obstruct the course of justice when such claims had been investigated,[88] although the extent to which such collusion occurred is still disputed.  As a consequence of the worsening security situation, the autonomous regional government for Northern Ireland was suspended in 1972. Alongside the violence, there was a political deadlock between the major political parties in Northern Ireland, including those who condemned the violence, over the future status of Northern Ireland and the form of government there should be within Northern Ireland. In 1973, Northern Ireland held a referendum to determine if it should remain in the United Kingdom, or be part of a united Ireland. The vote went heavily in favour (98.9%) of maintaining the status quo. Approximately 57.5% of the total electorate voted in support, but only 1% of Catholics voted following a boycott organised by the Social Democratic and Labour Party (SDLP).[89]  The Troubles were brought to an uneasy end by a peace process that included the declaration of ceasefires by most paramilitary organisations and the complete decommissioning of their weapons, the reform of the police, and the corresponding withdrawal of army troops from the streets and sensitive border areas such as South Armagh and Fermanagh, as agreed by the signatories to the Belfast Agreement (commonly known as the \"Good Friday Agreement\"). This reiterated the long-held British position, which had never before been fully acknowledged by successive Irish governments, that Northern Ireland will remain within the United Kingdom until a majority of voters in Northern Ireland decides otherwise. The Constitution of Ireland was amended in 1999 to remove a claim of the \"Irish nation\" to sovereignty over the entire island (in Article 2).[90]  The new Articles 2 and 3, added to the Constitution to replace the earlier articles, implicitly acknowledge that the status of Northern Ireland, and its relationships within the rest of the United Kingdom and with the Republic of Ireland, would only be changed with the agreement of a majority of voters in each jurisdiction. This aspect was also central to the Belfast Agreement which was signed in 1998 and ratified by referendums held simultaneously in both Northern Ireland and the Republic. At the same time, the UK Government recognised for the first time, as part of the prospective, the so-called \"Irish dimension\": the principle that the people of the island of Ireland as a whole have the right, without any outside interference, to solve the issues between North and South by mutual consent.[91] The latter statement was key to winning support for the agreement from nationalists. It established a devolved power-sharing government, the Northern Ireland Assembly, located on the Stormont Estate, which must consist of both unionist and nationalist parties. These institutions were suspended by the UK Government in 2002 after Police Service of Northern Ireland (PSNI) allegations of spying by people working for Sinn F\u00e9in at the Assembly (Stormontgate). The resulting case against the accused Sinn F\u00e9in member collapsed.[92]  On 28 July 2005, the Provisional IRA declared an end to its campaign and has since decommissioned what is thought to be all of its arsenal. This final act of decommissioning was performed under the watch of the Independent International Commission on Decommissioning (IICD) and two external church witnesses. Many unionists, however, remained sceptical. The IICD later confirmed that the main loyalist paramilitary groups, the Ulster Defence Association, UVF, and the Red Hand Commando, had decommissioned what is thought to be all of their arsenals, witnessed by former archbishop Robin Eames and a former top civil servant.[93]  Politicians elected to the Assembly at the 2003 Assembly election were called together on 15 May 2006 under the Northern Ireland Act 2006[94] to elect a First Minister and deputy First Minister of Northern Ireland and choose the members of an Executive (before 25 November 2006) as a preliminary step to the restoration of devolved government.  Following the election on 7 March 2007, the devolved government returned on 8 May 2007 with Democratic Unionist Party (DUP) leader Ian Paisley and Sinn F\u00e9in deputy leader Martin McGuinness taking office as First Minister and deputy First Minister, respectively.[95] In its white paper on Brexit the United Kingdom government reiterated its commitment to the Belfast Agreement. Concerning Northern Ireland's status, it said that the UK Government's \"clearly-stated preference is to retain Northern Ireland's current constitutional position: as part of the UK, but with strong links to Ireland\".[96]  On 3 February 2022, Paul Givan resigned as first minister, which automatically resigned Michelle O'Neill as deputy first minister and collapsed the executive of Northern Ireland.[97] On 30 January 2024, leader of the DUP Jeffrey Donaldson announced that the DUP would restore an executive government on the condition that new legislation was passed by the UK House of Commons.[98]  The main political divide in Northern Ireland is between unionists, who wish to see Northern Ireland continue as part of the United Kingdom, and nationalists, who wish to see Northern Ireland unified with the Republic of Ireland, independent from the United Kingdom. These two opposing views are linked to deeper cultural divisions. Unionists are predominantly Ulster Protestant, descendants of mainly Scottish, English, and Huguenot settlers as well as Gaels who converted to one of the Protestant denominations. Nationalists are overwhelmingly Catholic and descend from the population predating the settlement, with a minority from the Scottish Highlands as well as some converts from Protestantism. Discrimination against nationalists under the Stormont government (1921\u20131972) gave rise to the civil rights movement in the 1960s.[99]  While some unionists argue that discrimination was not just due to religious or political bigotry, but also the result of more complex socio-economic, socio-political and geographical factors,[100] its existence, and the manner in which nationalist anger at it was handled, were a major contributing factor to the Troubles. The political unrest went through its most violent phase between 1968 and 1994.[101]  In 2007, 36% of the population defined themselves as unionist, 24% as nationalist, and 40% defined themselves as neither.[102] According to a 2015 opinion poll, 70% express a long-term preference of the maintenance of Northern Ireland's membership of the United Kingdom (either directly ruled or with devolved government), while 14% express a preference for membership of a united Ireland.[103] This discrepancy can be explained by the overwhelming preference among Protestants to remain a part of the UK (93%), while Catholic preferences are spread across several solutions to the constitutional question including remaining a part of the UK (47%), a united Ireland (32%), Northern Ireland becoming an independent state (4%), and those who \"don't know\" (16%).[104]  Official voting figures, which reflect views on the \"national question\" along with issues of the candidate, geography, personal loyalty, and historic voting patterns, show 54% of Northern Ireland voters vote for unionist parties, 42% vote for nationalist parties, and 4% vote \"other\". Opinion polls consistently show that the election results are not necessarily an indication of the electorate's stance regarding the constitutional status of Northern Ireland. Most of the population of Northern Ireland is at least nominally Christian, mostly Roman Catholic and Protestant denominations. Many voters (regardless of religious affiliation) are attracted to unionism's conservative policies, while other voters are instead attracted to the traditionally leftist Sinn F\u00e9in and SDLP and their respective party platforms for democratic socialism and social democracy.[105]  For the most part, Protestants feel a strong connection with Great Britain and wish for Northern Ireland to remain part of the United Kingdom. Many Catholics however, generally aspire to a United Ireland or are less certain about how to solve the constitutional question. Catholics have a slight majority in Northern Ireland, according to the latest Northern Ireland census. The make-up of the Northern Ireland Assembly reflects the appeals of the various parties within the population. Of the 90\u00a0Members of the Legislative Assembly (MLAs), 37 are unionists and 35 are nationalists (the remaining 18 are classified as \"other\").[106]  The 1998 Good Friday Agreement acts as a de facto constitution for Northern Ireland. Local government in Northern Ireland since 2015 has been divided between 11 councils with limited responsibilities.[107] The First Minister and deputy First Minister of Northern Ireland are the joint heads of government of Northern Ireland.[108][109]  Since 1998, Northern Ireland has had devolved government within the United Kingdom, presided over by the Northern Ireland Assembly and a cross-community government (the Northern Ireland Executive). The UK Government and UK Parliament are responsible for reserved and excepted matters. Reserved matters comprise listed policy areas (such as civil aviation, units of measurement, and human genetics) that Parliament may devolve to the Assembly some time in the future. Excepted matters (such as international relations, taxation and elections) are never expected to be considered for devolution. On all other governmental matters, the Executive together with the 90-member Assembly may legislate for and govern Northern Ireland. Devolution in Northern Ireland is dependent upon participation by members of the Northern Ireland executive in the North\/South Ministerial Council, which coordinates areas of cooperation (such as agriculture, education, and health) between Northern Ireland and the Republic of Ireland. Additionally, \"in recognition of the Irish Government's special interest in Northern Ireland\", the Government of Ireland and Government of the United Kingdom co-operate closely on non-devolved matters through the British\u2013Irish Intergovernmental Conference.  Elections to the Northern Ireland Assembly are by single transferable vote with five Members of the Legislative Assembly (MLAs) elected from each of 18 parliamentary constituencies. In addition, eighteen representatives (Members of Parliament, MPs) are elected to the lower house of the UK parliament from the same constituencies using the first-past-the-post system. However, not all of those elected take their seats. Sinn F\u00e9in MPs, currently seven, refuse to take the oath to serve the King that is required before MPs are allowed to take their seats. In addition, the upper house of the UK parliament, the House of Lords, currently has some 25 appointed members from Northern Ireland.  The Northern Ireland Office represents the UK Government in Northern Ireland on reserved matters and represents Northern Ireland's interests within the UK Government. Additionally, the Republic's government also has the right to \"put forward views and proposals\" on non-devolved matters about Northern Ireland. The Northern Ireland Office is led by the Secretary of State for Northern Ireland, who sits in the Cabinet of the United Kingdom.  Northern Ireland is a distinct legal jurisdiction, separate from the two other jurisdictions in the United Kingdom (England and Wales, and Scotland). Northern Ireland law developed from Irish law that existed before the partition of Ireland in 1921. Northern Ireland is a common law jurisdiction and its common law is similar to that in England and Wales. However, there are important differences in law and procedure between Northern Ireland and England and Wales. The body of statute law affecting Northern Ireland reflects the history of Northern Ireland, including Acts of the Parliament of the United Kingdom, the Northern Ireland Assembly, the former Parliament of Northern Ireland and the Parliament of Ireland, along with some Acts of the Parliament of England and of the Parliament of Great Britain that were extended to Ireland under Poynings' Law between 1494 and 1782.  There is no generally accepted term to describe what Northern Ireland is: province, region, country or something else. The choice of term can be controversial and can reveal the writer's political preferences.[17] This has been noted as a problem by several writers on Northern Ireland, with no generally recommended solution.[16][17][18]  ISO 3166-2:GB defines Northern Ireland as a province.[15] The UK's submission to the 2007 United Nations Conference on the Standardization of Geographical Names defines the UK as being made up of two countries (England and Scotland), one principality (Wales) and one province (Northern Ireland).[110] However, this term can be controversial, particularly for nationalists for whom the title province is properly reserved for the traditional province of Ulster, of which Northern Ireland comprises six out of nine counties.[111][17][112] Some authors have described the meaning of this term as being equivocal: referring to Northern Ireland as being a province both of the United Kingdom and the traditional country of Ireland.[113]  The UK Office for National Statistics and the website of the Office of the Prime Minister of the United Kingdom describe the United Kingdom as being made up of four countries, one of these being Northern Ireland.[14][114] Some newspaper style guides also consider country as an acceptable term for Northern Ireland.[111] However, some authors reject the term.[112][16][18][113]  \"Region\" has also been used by UK government agencies[115] and newspapers.[111] Some authors choose this word but note that it is \"unsatisfactory\".[17][18] Northern Ireland can also be simply described as \"part of the UK\", including by the UK government offices.[114]  Many people inside and outside Northern Ireland use other names for Northern Ireland, depending on their point of view. Disagreement on names, and the reading of political symbolism into the use or non-use of a word, also attaches itself to some urban centres. The most notable example is whether Northern Ireland's second-largest city should be called \"Derry\" or \"Londonderry\".  Choice of language and nomenclature in Northern Ireland often reveals the cultural, ethnic, and religious identity of the speaker. Those who do not belong to any group but lean towards one side often tend to use the language of that group. Supporters of unionism in the British media (notably The Daily Telegraph and the Daily Express) regularly call Northern Ireland \"Ulster\".[116] Many media outlets in the Republic use \"North of Ireland\" (or simply \"the North\"),[117][118][119][120][121] as well as the \"Six Counties\".[122] The New York Times has also used \"the North\".[123]  Government and cultural organisations in Northern Ireland often use the word \"Ulster\" in their title; for example, the University of Ulster, the Ulster Museum, the Ulster Orchestra, and BBC Radio Ulster.  Although some news bulletins since the 1990s have opted to avoid all contentious terms and use the official name, Northern Ireland, the term \"the North\" remains commonly used by broadcast media in the Republic.[117][118][119]  The volcanic activity which created the Antrim Plateau also formed the geometric pillars of the Giant's Causeway on the north Antrim coast. Also in north Antrim are the Carrick-a-Rede Rope Bridge, Mussenden Temple and the Glens of Antrim. Northern Ireland was covered by an ice sheet for most of the last ice age and on numerous previous occasions, the legacy of which can be seen in the extensive coverage of drumlins in Counties Fermanagh, Armagh, Antrim and particularly Down.  The centrepiece of Northern Ireland's geography is Lough Neagh, at 151 square miles (391\u00a0km2) the largest freshwater lake both on the island of Ireland and in the British Isles. A second extensive lake system is centred on Lower and Upper Lough Erne in Fermanagh. The largest island of Northern Ireland is Rathlin, off the north Antrim coast. Strangford Lough is the largest inlet in the British Isles, covering 150\u00a0km2 (58\u00a0sq\u00a0mi).  There are substantial uplands in the Sperrin Mountains (an extension of the Caledonian mountain belt) with extensive gold deposits, the granite Mourne Mountains and the basalt Antrim Plateau, as well as smaller ranges in South Armagh and along the Fermanagh\u2013Tyrone border. None of the hills are especially high, with Slieve Donard in the dramatic Mournes reaching 850 metres (2,789\u00a0ft), Northern Ireland's highest point. Belfast's most prominent peak is Cavehill.  The Lower and Upper River Bann, River Foyle and River Blackwater form extensive fertile lowlands, with excellent arable land also found in North and East Down, although much of the hill country is marginal and suitable largely for animal husbandry. The valley of the River Lagan is dominated by Belfast, whose metropolitan area includes over a third of the population of Northern Ireland, with heavy urbanisation and industrialisation along the Lagan Valley and both shores of Belfast Lough.  The vast majority of Northern Ireland has a temperate maritime climate, (Cfb in the K\u00f6ppen climate classification) rather wetter in the west than the east, although cloud cover is very common across the region. The weather is unpredictable at all times of the year, and although the seasons are distinct, they are considerably less pronounced than in interior Europe or the eastern seaboard of North America. Average daytime maximums in Belfast are 6.5\u00a0\u00b0C (43.7\u00a0\u00b0F) in January and 17.5\u00a0\u00b0C (63.5\u00a0\u00b0F) in July. The highest maximum temperature recorded was 31.4\u00a0\u00b0C (88.5\u00a0\u00b0F), registered in July 2021 at Armagh Observatory's weather station.[134] The lowest minimum temperature recorded was \u221218.7\u00a0\u00b0C (\u22121.7\u00a0\u00b0F) at Castlederg, County Tyrone on 23 December 2010.[135]  Until the end of the Middle Ages, the land was heavily forested. Native species include deciduous trees such as oak, ash, hazel, birch, alder, willow, aspen, elm, rowan and hawthorn, as well as evergreen trees such Scots pine, yew and holly.[136] Today, only 8% of Northern Ireland is woodland, and most of this is non-native conifer plantations.[137]  As of the 21st century, Northern Ireland is the least forested part of the United Kingdom and Ireland, and one of the least forested countries in Europe.[138]  The only native reptile in Northern Ireland is the viviparous lizard, or common lizard, which is widely distributed, particularly in heaths, bogs and sand dunes. The common frog is a very widespread species.\u00a0Some lakes support internationally important bird populations, Lough Neagh and Lough Beg hold up to 80,000 wintering waterfowl of some 20 species, including ducks, geese, swans and gulls. The otter is the fourth largest land mammal in Northern Ireland. It can be found along the river systems, although it is seldom seen and will avoid contact with humans.[139] 356 species of marine algae have been recorded in the northeast of Ireland; 77 species are considered rare.[140]  Northern Ireland consists of six historic counties: County Antrim, County Armagh, County Down, County Fermanagh, County Londonderry,[e] and County Tyrone.  These counties are no longer used for local government purposes; instead, there are eleven districts of Northern Ireland which have different geographical extents. These were created in 2015, replacing the twenty-six districts which previously existed.[141]  Although counties are no longer used for local governmental purposes, they remain a popular means of describing where places are. They are officially used while applying for an Irish passport, which requires one to state one's county of birth. The name of that county then appears in both Irish and English on the passport's information page, as opposed to the town or city of birth on the United Kingdom passport. The Gaelic Athletic Association still uses the counties as its primary means of organisation and fields representative teams of each GAA county. The original system of car registration numbers largely based on counties remains in use. In 2000, the telephone numbering system was restructured into an 8-digit scheme with (except for Belfast) the first digit approximately reflecting the county.  The county boundaries still appear on Ordnance Survey of Northern Ireland Maps and the Philip's Street Atlases, among others. With their decline in official use, there is often confusion surrounding towns and cities which lie near county boundaries, such as Belfast and Lisburn, which are split between counties Down and Antrim (the majorities of both cities, however, are in Antrim).  In March 2018, The Sunday Times published its list of Best Places to Live in Britain, including the following places in Northern Ireland: Ballyhackamore near Belfast (overall best for Northern Ireland), Holywood, County Down, Newcastle, County Down, Portrush, County Antrim, Strangford, County Down.[142]  The population of Northern Ireland has risen yearly since 1978. The population at the time of the 2021 census was 1.9\u00a0million, having grown 5% over the previous decade.[145] The population in 2011 was 1.8\u00a0million, a rise of 7.5% over the previous decade.[146] The current population makes up 2.8% of the UK's population (67\u00a0million) and 27% of the island of Ireland's population (7.03\u00a0million). The population density is 135 inhabitants \/ km2.  As of the 2021 census, the population of Northern Ireland is almost entirely white (96.6%).[147] In 2021, 86.5% of the population were born in Northern Ireland, with 4.8% born in Great Britain, 2.1% born in the Republic of Ireland, and 6.5% born elsewhere (more than half of them in another European country).[148] In 2021 the largest non-white ethnic groups were black (0.6%), Indian (0.5%), and Chinese (0.5%).[147] In 2011, 88.8% of the population were born in Northern Ireland, 4.5% in Great Britain, and 2.9% in the Republic of Ireland. 4.3% were born elsewhere; triple the amount there were in 2001.[149]  In Northern Ireland censuses, respondents can choose more than one national identity. In 2021:[153]  The main national identities given in recent censuses were:  As of the 2021 census, regarding national identity, four of the six traditional counties had an Irish plurality and two had a British plurality.[155][156][157][158]  At the 2021 census, 42.3% of the population identified as Roman Catholic, 37.3% as Protestant\/other Christian, 1.3% as other religions, while 17.4% identified with no religion or did not state one.[159] The biggest of the Protestant\/other Christian denominations were the Presbyterian Church (16.6%), the Church of Ireland (11.5%) and the Methodist Church (2.3%).[159] At the 2011 census, 41.5% of the population identified as Protestant\/other Christian, 41% as Roman Catholic, 0.8% as other religions, while 17% identified with no religion or did not state one.[160] In terms of background (i.e. religion or religion brought up in), at the 2021 census 45.7% of the population came from a Catholic background, 43.5% from a Protestant background, 1.5% from other religious backgrounds, and 5.6% from non-religious backgrounds.[159] This was the first time since Northern Ireland's creation that there were more people from a Catholic background than Protestant.[161] At the 2011 census, 48% came from a Protestant background, 45% from a Catholic background, 0.9% from other religious backgrounds, and 5.6% from non-religious backgrounds.[160]  In recent censuses, respondents gave their religious identity or religious upbringing as follows:[162][154][159]  As of the 2021 census, regarding religious background, four of the six traditional counties had a Catholic majority, one had a Protestant plurality, and one had a Protestant majority.[163]  Several studies and surveys carried out between 1971 and 2006 have indicated that, in general, most Protestants in Northern Ireland see themselves primarily as British, whereas most Catholics see themselves primarily as Irish.[164][165][166][167][168][169][170][171] This does not, however, account for the complex identities within Northern Ireland, given that many of the population regard themselves as \"Ulster\" or \"Northern Irish\", either as a primary or secondary identity.  A 2008 survey found that 57% of Protestants described themselves as British, while 32% identified as Northern Irish, 6% as Ulster, and 4% as Irish. Compared to a similar survey in 1998, this shows a fall in the percentage of Protestants identifying as British and Ulster and a rise in those identifying as Northern Irish. The 2008 survey found that 61% of Catholics described themselves as Irish, with 25% identifying as Northern Irish, 8% as British, and 1% as Ulster. These figures were largely unchanged from the 1998 results.[172][173]  People born in Northern Ireland are, with some exceptions, deemed by UK law to be citizens of the United Kingdom. They are also, with similar exceptions, entitled to be citizens of Ireland. This entitlement was reaffirmed in the 1998 Good Friday Agreement between the British and Irish governments, which provides that:  ...it is the birthright of all the people of Northern Ireland to identify themselves and be accepted as Irish or British, or both, as they may so choose, and accordingly [the two governments] confirm that their right to hold both British and Irish citizenship is accepted by both Governments and would not be affected by any future change in the status of Northern Ireland. As a result of the Agreement, the Constitution of the Republic of Ireland was amended. The current wording provides that people born in Northern Ireland are entitled to be Irish citizens on the same basis as people from any other part of the island.[174]  Neither government, however, extends its citizenship to all persons born in Northern Ireland. Both governments exclude some people born in Northern Ireland, in particular persons born without one parent who is a British or Irish citizen. The Irish restriction was given effect by the twenty-seventh amendment to the Irish Constitution in 2004. The position in UK nationality law is that most of those born in Northern Ireland are UK nationals, whether or not they so choose. Renunciation of British citizenship requires the payment of a fee, currently \u00a3372.[175]  In recent censuses, residents said they held the following passports:[154][176]  Irish is an official language of Northern Ireland as of 6 December 2022 when the Irish Language Act (Identity and Language (Northern Ireland) Act 2022) became law. The Irish Language Act officially repealed legislation from 1737 that banned the use of Irish in courts.[1] English is a de facto official language.[citation needed] English is also spoken as a first language by 95.4% of the Northern Ireland population.[177]  Under the Good Friday Agreement, Irish and Ulster Scots (an Ulster dialect of the Scots language, sometimes known as Ullans), are recognised as \"part of the cultural wealth of Northern Ireland\".[178] The Irish Language Act of 2022 also legislated commissioners for both Irish and Ulster Scots.[1]  Two all-island bodies for the promotion of these were created under the Agreement: Foras na Gaeilge, which promotes the Irish language, and the Ulster Scots Agency, which promotes the Ulster-Scots dialect and culture. These operate separately under the aegis of the North\/South Language Body, which reports to the North\/South Ministerial Council.  The UK Government in 2001 ratified the European Charter for Regional or Minority Languages. Irish (in Northern Ireland) was specified under Part III of the Charter, with a range of specific undertakings about education, translation of statutes, interaction with public authorities, the use of placenames, media access, support for cultural activities, and other matters. A lower level of recognition was accorded to Ulster-Scots, under Part II of the Charter.[179]  According to the 2021 census, in 94.74% of households, all people aged 16 and above spoke English as their main language.[180] The dialect of English spoken in Northern Ireland shows influence from the lowland Scots language.[181] There are supposedly some minute differences in pronunciation between Protestants and Catholics, for instance; the name of the letter h, which Protestants tend to pronounce as \"aitch\", as in British English, and Catholics tend to pronounce as \"haitch\", as in Hiberno-English.[182] However, geography is a much more important determinant of dialect than religious background.  The Irish language (Irish: an Ghaeilge), or Gaelic, is the second most spoken language in Northern Ireland and is a native language of Ireland.[183] It was spoken predominantly throughout what is now Northern Ireland before the Ulster Plantations in the 17th century and most place names in Northern Ireland are anglicised versions of a Gaelic name. Today, the language is often associated with Irish nationalism (and thus with Catholics). However, in the 19th century, the language was seen as a common heritage, with Ulster Protestants playing a leading role in the Gaelic revival.[184]  In the 2021 census, 12.4% (compared with 10.7% in 2011) of the population of Northern Ireland claimed \"some knowledge of Irish\" and 3.9% (compared with 3.7% in 2011) reported being able to \"speak, read, write and understand\" Irish.[146][177] In another survey, from 1999, 1% of respondents said they spoke it as their main language at home.[185]  The dialect spoken in Northern Ireland, Ulster Irish, has two main types, East Ulster Irish and Donegal Irish (or West Ulster Irish),[186] is the one closest to Scottish Gaelic (which developed into a separate language from Irish Gaelic in the 17th century). Some words and phrases are shared with Scots Gaelic, and the dialects of east Ulster \u2013 those of Rathlin Island and the Glens of Antrim \u2013 were very similar to the dialect of Argyll, the part of Scotland nearest to Ireland. The dialects of Armagh and Down were also very similar to the dialects of Galloway.  The use of the Irish language in Northern Ireland today is politically sensitive. The erection by some district councils of bilingual street names in both English and Irish,[187] invariably in predominantly nationalist districts, is resisted by unionists who claim that it creates a \"chill factor\" and thus harms community relationships. Efforts by members of the Northern Ireland Assembly to legislate for some official uses of the language have failed to achieve the required cross-community support. In May 2022, the UK Government proposed a bill in the House of Lords to make Irish an official language (and support Ulster Scots) in Northern Ireland and to create an Irish Language Commissioner.[188][189] The bill has since been passed, and received royal assent in December 2022.[190] There has recently been an increase in interest in the language among unionists in East Belfast.[191]  Ulster Scots comprises varieties of the Scots language spoken in Northern Ireland. For a native English speaker, \"[Ulster Scots] is comparatively accessible, and even at its most intense can be understood fairly easily with the help of a glossary.\"[192]  Along with the Irish language, the Good Friday Agreement recognised the dialect as part of Northern Ireland's unique culture and the St Andrews Agreement recognised the need to \"enhance and develop the Ulster Scots language, heritage and culture\".[193]  At the time of the 2021 census, approximately 1.1% (compared to 0.9% in 2011) of the population claimed to be able to speak, read, write and understand Ulster-Scots, while 10.4% (compared to 8.1% in 2011) professed to have \"some ability\".[146][177][185]  The most common sign language in Northern Ireland is Northern Ireland Sign Language (NISL). However, because in the past Catholic families tended to send their deaf children to schools in Dublin[citation needed] where Irish Sign Language (ISL) is commonly used, ISL is still common among many older deaf people from Catholic families.  Irish Sign Language (ISL) has some influence from the French family of sign language, which includes American Sign Language (ASL). NISL takes a large component from the British family of sign language (which also includes Auslan) with many borrowings from ASL. It is described as being related to Irish Sign Language at the syntactic level while much of the lexicon is based on British Sign Language (BSL).[194]  As of March\u00a02004[update] the UK Government recognises only British Sign Language and Irish Sign Language as the official sign languages used in Northern Ireland.[195][196]  Unlike most areas of the United Kingdom, in the last year of primary school, many children sit entrance examinations for grammar schools. Integrated schools, which attempt to ensure a balance in enrolment between pupils of Protestant, Roman Catholic, and other faiths (or none), are becoming increasingly popular, although Northern Ireland still has a primarily de facto religiously segregated education system. In the primary school sector, 40 schools (8.9% of the total number) are integrated schools and 32 (7.2% of the total number) are Gaelscoileanna (Irish language-medium schools).  As with the island of Ireland as a whole, Northern Ireland has one of the youngest populations in Europe and, among the four UK nations, it has the highest proportion of children aged under 16 years (21% in mid-2019).[197]  In the most recent full academic year (2021\u20132022), the region's school education system comprised 1,124 schools (of all types) and around 346,000 pupils, including:  Enrolments in further and higher education were as follows (in 2019\u20132020) before disruption to enrolments and classes caused by the COVID-19 pandemic:  Statistics on education in Northern Ireland are published by the Department of Education and the Department for the Economy.  The main universities in Northern Ireland are Queen's University Belfast and Ulster University, and the distance learning Open University which has a regional office in Belfast.  Since 1948 Northern Ireland has a health care system similar to England, Scotland and Wales, though it provides not only health care, but also social care. Health care performance has been decreasing since the mid-2010s and reached crisis levels since 2022.[202]  Northern Ireland traditionally had an industrial economy, most notably featuring shipbuilding, rope manufacture, and textiles. In 2019, 53% of GVA was generated by services, 22% by the public sector, 15% by production, 8% by construction and 2% by agriculture.[203]  Belfast is the United Kingdom's second largest tech hub outside of London with more than 25% of their jobs being technology related. Many established multinational tech companies such as Fujitsu, SAP, IBM and Microsoft have a presence here. It is regarded an appealing place to live for tech professionals and has a low cost of living compared to other cities.[204][205]  In 2019 Northern Ireland welcomed 5.3m visitors, who spent over \u00a31billion. A total of 167 cruise ships docked at Northern Ireland ports in 2019.[206] Tourism in recent years has been a major growth area with key attractions including the Giants Causeway and the many castles in the region with the historic towns and cities of Belfast, Derry, Armagh and Enniskillen being popular with tourists. Entertainment venues include the SSE Arena, Waterfront Hall, the Grand Opera House and Custom House Square. Tourists use various means of transport around Northern Ireland such as vehicle hire, guided tours, taxi tours, electric bikes, electric cars and public transport.[207]  Belfast currently has an 81-acre shipyard which was purposely developed to be able to take some of the world's largest vessels. It has the largest dry dock for ships in Europe measuring 556m x 93m and has 106m high cranes, it is ideally situated between the Atlantic Ocean and the North Sea.[208] The shipyard can build ships and complete maintenance contracts such as the contracts awarded by P&O and Cunard cruise ships in 2022.[209]  Northern Ireland feeds around 10 million people when their population is only 1.8 million.[210] The predominant activity on Northern Ireland farms in 2022 was cattle and sheep. 79 per cent of farms in Northern Ireland have some cattle, 38 per cent have some sheep. Over three-quarters of farms in Northern Ireland are very small, in 2022 there were 26,089 farms in Northern Ireland with approximately one million hectares of land farmed.[211]  Northern Ireland is in a unique position where it can sell goods to the rest of the United Kingdom and the European Union tariff-free, free from customs declarations, rules of origin certificates and non-tariff barriers on the sale of goods to both regions.[212][213]  Below is a comparison of the goods being sold and purchased between Northern Ireland and the United Kingdom, compared with the goods being exported and imported between Northern Ireland and the Republic of Ireland:  Northern Ireland has underdeveloped transport infrastructure, with most infrastructure concentrated around Greater Belfast, Greater Derry, and Craigavon. Northern Ireland is served by three airports\u2014Belfast International near Antrim, George Best Belfast City integrated into the railway network at Sydenham in East Belfast, and City of Derry in County Londonderry. There are upgrade plans to transform the railway network in Northern Ireland including new lines from Derry to Portadown and Belfast to Newry, though it will take the best part of 25 years to deliver.[215] There are major seaports at Larne and Belfast which carry passengers and freight between Great Britain and Northern Ireland.  Passenger railways are operated by Northern Ireland Railways. With Iarnr\u00f3d \u00c9ireann (Irish Rail), Northern Ireland Railways co-operates in providing the joint Enterprise service between Dublin Connolly and Lanyon Place. The whole of Ireland has a mainline railway network with a gauge of 5\u00a0ft 3\u00a0in (1,600\u00a0mm), which is unique in Europe and has resulted in distinct rolling stock designs. The only preserved line of this gauge on the island is the Downpatrick and County Down Railway, which operates heritage steam and diesel locomotives. Main railway lines linking to and from Belfast Great Victoria Street railway station and Lanyon Place railway station are:  The Derry line is the busiest single-track railway line in the United Kingdom, carrying 3 million passengers per annum, the Derry-Londonderry Line has also been described by Michael Palin as \"one of the most beautiful rail journeys in the world\".[216]  Main motorways are:  Additional short motorway spurs include:  The cross-border road connecting the ports of Larne in Northern Ireland and Rosslare Harbour in the Republic of Ireland is being upgraded as part of an EU-funded scheme. European route E01 runs from Larne through the island of Ireland, Spain, and Portugal to Seville.  Northern Ireland shares both the culture of Ulster and the culture of the United Kingdom.  Northern Ireland has witnessed rising numbers of tourists. Attractions include concert venues, cultural festivals, musical and artistic traditions, countryside and geographical sites of interest, public houses, welcoming hospitality, and sports (especially golf and fishing).[217] Since 1987 public houses have been allowed to open on Sundays, despite some opposition.  Parades are a prominent feature of Northern Ireland society,[218] more so than in the rest of Ireland or the United Kingdom. Most are held by Protestant fraternities such as the Orange Order, and Ulster loyalist marching bands. Each summer, during the \"marching season\", these groups have hundreds of parades, deck streets with British flags, bunting and specially-made arches, and light large towering bonfires in the \"Eleventh Night\" celebrations.[219] The biggest parades are held on 12 July (The Twelfth). There is often tension when these activities take place near Catholic neighbourhoods, which sometimes leads to violence.[220]  The Ulster Cycle is a large body of prose and verse centring on the traditional heroes of the Ulaid in what is now eastern Ulster. This is one of the four major cycles of Irish mythology. The cycle centres on the reign of Conchobar mac Nessa, who is said to have been the king of Ulster around the 1st century. He ruled from Emain Macha (now Navan Fort near Armagh), and had a fierce rivalry with queen Medb and king Ailill of Connacht and their ally, Fergus mac R\u00f3ich, former king of Ulster. The foremost hero of the cycle is Conchobar's nephew C\u00fachulainn, who features in the epic prose\/poem An T\u00e1in B\u00f3 C\u00faailnge (The Cattle Raid of Cooley, a casus belli between Ulster and Connaught).  Northern Ireland comprises a patchwork of communities whose national loyalties are represented in some areas by flags flown from flagpoles or lamp posts. The Union Jack and the former Northern Ireland flag are flown in many loyalist areas, and the Tricolour, adopted by republicans as the flag of Ireland in 1916,[222] is flown in some republican areas. Even kerbstones in some areas are painted red-white-blue or green-white-orange, depending on whether local people express unionist\/loyalist or nationalist\/republican sympathies.[223]  The official flag is that of the state having sovereignty over the territory, i.e. the Union Flag.[224] The former Northern Ireland flag, also known as the \"Ulster Banner\" or \"Red Hand Flag\", is a banner derived from the coat of arms of the Government of Northern Ireland until 1972. Since 1972, it has had no official status. The Union Flag and the Ulster Banner are used exclusively by unionists. The UK flags policy states that in Northern Ireland, \"The Ulster flag and the Cross of St Patrick have no official status and, under the Flags Regulations, are not permitted to be flown from Government Buildings.\"[225][226]  The Irish Rugby Football Union and the Church of Ireland have used the Saint Patrick's Saltire or \"Cross of St\u00a0Patrick\". This red saltire on a white field was used to represent Ireland in the flag of the United Kingdom. It is still used by some British Army regiments. Foreign flags are also found, such as the Palestinian flags in some nationalist areas and Israeli flags in some unionist areas.[227]  The United Kingdom national anthem of \"God Save the King\" is often played at state events in Northern Ireland. At the Commonwealth Games and some other sporting events, the Northern Ireland team uses the Ulster Banner as its flag\u2014notwithstanding its lack of official status\u2014and the Londonderry Air (usually set to lyrics as Danny Boy), which also has no official status, as its national anthem.[228][229] The Northern Ireland national football team also uses the Ulster Banner as its flag but uses \"God Save The King\" as its anthem.[230] Major Gaelic Athletic Association matches are opened by the national anthem of the Republic of Ireland, \"Amhr\u00e1n na bhFiann (The Soldier's Song)\", which is also used by most other all-Ireland sporting organisations.[231] Since 1995, the Ireland rugby union team has used a specially commissioned song, \"Ireland's Call\" as the team's anthem. The Irish national anthem is also played at Dublin home matches, being the anthem of the host country.[232]  Northern Irish murals have become well-known features of Northern Ireland, depicting past and present events and documenting peace and cultural diversity. Almost 2,000 murals have been documented in Northern Ireland since the 1970s.  The BBC has a division called BBC Northern Ireland with headquarters in Belfast and operates BBC One Northern Ireland and BBC Two Northern Ireland. As well as broadcasting standard UK-wide programmes, BBC NI produces local content, including a news break-out called BBC Newsline. The ITV franchise in Northern Ireland is UTV. The state-owned Channel 4 and the privately owned Channel 5 also broadcast in Northern Ireland. Access is also available to satellite and cable services.[233] All Northern Ireland viewers must obtain a UK TV licence to watch live television transmissions or use BBC iPlayer.  RT\u00c9, the national broadcaster of the Republic of Ireland, is available over the air to most parts of Northern Ireland via reception overspill of the Republic's Saorview service,[234] or via satellite and cable. Since the digital TV switchover, RT\u00c9 One, RT\u00c92 and the Irish-language channel TG4, are now available over the air on the UK's Freeview system from transmitters within Northern Ireland.[235] Although they are transmitted in standard definition, a Freeview HD box or television is required for reception.  As well as the standard UK-wide radio stations from the BBC, Northern Ireland is home to many local radio stations, such as Cool FM, Q Radio, Downtown Radio and U105. The BBC has two regional radio stations which broadcast in Northern Ireland, BBC Radio Ulster and BBC Radio Foyle.  Besides the UK and Irish national newspapers, there are three main regional newspapers published in Northern Ireland. These are the Belfast Telegraph, The Irish News and The News Letter.[236] According to the Audit Bureau of Circulations (UK) the average daily circulation for these three titles in 2018 was:  Northern Ireland uses the same telecommunications and postal services as the rest of the United Kingdom at standard domestic rates and there are no mobile roaming charges between Great Britain and Northern Ireland.[239][240] People in Northern Ireland who live close to the border with the Republic of Ireland may inadvertently switch over to the Irish mobile networks, causing international roaming fees to be applied.[241] Calls from landlines in Northern Ireland to numbers in the Republic of Ireland are charged at the same rate as those to numbers in Great Britain, while landline numbers in Northern Ireland can similarly be called from the Republic of Ireland at domestic rates, using the 048 prefix.[242]  Many sports are organised on an all-Ireland basis, with a single governing body or team for the whole island.[243] The most notable exception is association football (soccer), which has a separate governing body, league and national team for Northern Ireland.[243][244]  The Irish Football Association (IFA) serves as the organising body for men's domestic and national association football in Northern Ireland, it is a member of the International Football Association Board which sets the rules for association football.[245]  The NIWFA are responsible for women's domestic and national association football in Northern Ireland.  The NIFL Premiership is a professional men's football league which operates at the highest division of the Northern Ireland Football League, the current format has been organised with 12 clubs. The winners will enter the first qualifying round of the Champions League, if they do not progress they will enter the Europa League or Europa Conference League depending on performance. The two runners-up progress to the Europa Conference League with play-offs for another Europa Conference League position.[246]  The NLFL Women's Premiership is a professional women's football league which operates at the highest division in Northern Ireland with 10 clubs. The winner qualifies for a spot in the UEFA Women's Champions League. The men's Northern Ireland national football team qualified for the 1958 FIFA World Cup, 1982 FIFA World Cup and 1986 FIFA World Cup, making it to the quarter-finals in 1958 and 1982 and made it the first knockout round in the European Championships in 2016.  The IRFU is the governing body for the sport of Rugby Union on the island of Ireland (Northern Ireland and the Republic of Ireland).[247] Rugby in Northern Ireland is run within the historic province of Ulster which includes Northern Ireland plus 3 counties from the Republic of Ireland - Donegal, Cavan and Monaghan.  The Ireland national rugby league team has participated in the Emerging Nations Tournament (1995), the Super League World Nines (1996), the World Cup (2000, 2008, 2013, 2017, 2021), European Nations Cup (since 2003) and Victory Cup (2004). The Ireland A rugby league team competes annually in the Amateur Four Nations competition (since 2002) and the St Patrick's Day Challenge (since 1995).  The Ireland cricket team represents both Northern Ireland and the Republic of Ireland. It is a full member of the International Cricket Council, having been granted Test status and full membership by the ICC in June 2017. The side competes in Test cricket, the highest level of competitive cricket in the international arena, and is one of the 12 full-member countries of the ICC. Ireland men's side has played in the Cricket World Cup and T20 World Cup and has won the ICC Intercontinental Cup four times. The women's side has played in the Women's World Cup. One of the men's side's regular international venues is Stormont in Belfast.  The governing body for golf on the island of Ireland is Golf Ireland, it is the successor to the Golfing Union of Ireland, governing body for men's and boy's amateur golf, and the oldest golfing union in the world, which was founded in Belfast in 1891, and the Irish Ladies Golf Union. Northern Ireland's golf courses include the Royal Belfast Golf Club (the earliest, formed in 1881), Royal Portrush Golf Club, which is the only course outside Great Britain to have hosted The Open Championship, and Royal County Down Golf Club (Golf Digest magazine's top-rated course outside the United States).[248][249] Northern Ireland had three major champions in the space of just 14 months from the U.S. Open in 2010 to The Open Championship in 2011. Notable golfers include Fred Daly (winner of The Open in 1947), Ryder Cup players Ronan Rafferty and David Feherty, leading European Tour professionals David Jones, Michael Hoey (a five-time winner on the tour) and Gareth Maybin, as well as three recent major winners Graeme McDowell (winner of the U.S. Open in 2010, the first European to do so since 1970), Rory McIlroy (winner of four majors) and Darren Clarke (winner of The Open in 2011).[250][251] Northern Ireland has also contributed several players to the Great Britain and Ireland Walker Cup team, including Alan Dunbar and Paul Cutler who played on the victorious 2011 team in Scotland. Dunbar also won The Amateur Championship in 2012, at Royal Troon.  Both the national flag and the national anthem of present-day Ireland drive origins directly from the Rising. At first, it still appeared as if the revolutionaries would take over the old symbols because on the roof of their headquarters, the Dublin General Post Office, a green flag with the harp was hoisted next to the republican tricolour although with the inscription 'Irish Republic'. Even 'Got save Ireland' was sung by the revolutionaries during Easter week. But after the failure of the Rising and the subsequent executions of the leading revolutionaries the tricolour and 'The Soldier's Song' became more and more popular as symbols of the rebellion. 54\u00b037\u2032N 6\u00b037\u2032W\ufeff \/ \ufeff54.61\u00b0N 6.62\u00b0W\ufeff \/ 54.61; -6.62 "},{"title":"The Football Association","content":"  The Football Association (known by its abbreviation The FA) is the governing body of association football in England and the Crown Dependencies of Jersey, Guernsey and the Isle of Man. Formed in 1863, it is the oldest football association in the world and is responsible for overseeing all aspects of the amateur and professional game in its territory.  The FA facilitates all competitive football matches within its remit at national level, and indirectly at local level through the county football associations. It runs numerous competitions, the most famous of which is the FA Cup. It is also responsible for appointing the management of the men's, women's, and youth national football teams.  The FA is a member of both UEFA and FIFA and holds a permanent seat on the International Football Association Board (IFAB) which is responsible for the Laws of the Game. As the first football association, it does not use the national name \"English\" in its title. The FA is based at Wembley Stadium, London. The FA is a member of the British Olympic Association, meaning that the FA has control over the men's and women's Great Britain Olympic football team.[1]  All of England's professional football teams are members of the Football Association. Although it does not run the day-to-day operations of the Premier League, it has veto power over the appointment of the league chairman and chief executive and over any changes to league rules.[2] The English Football League, made up of the three fully professional divisions below the Premier League, is self-governing, subject to the FA's sanctions.  For centuries before the first meeting of the Football Association in the Freemasons' Tavern on Great Queen Street, London on 26 October 1863, there were no universally accepted rules for playing football.[3][4] Ebenezer Cobb Morley, as captain of Barnes, in 1862 wrote to Bell's Life newspaper proposing a governing body for the sport \"with the object of establishing a definite code of rules for the regulation of the game\"; the letter led to the first meeting at The Freemasons' Tavern that created the FA in 1863. Morley was a founding member.[4] Six meetings near London's Covent Garden, at 81\u201382 Long Acre,[5] ended in a split between the Association football and Rugby football.[6] Both of them had their own uniforms, rituals, gestures and highly formalised rules.[7]  In each public school the game was formalised according to local conditions; but when the schoolboys reached university, chaos ensued when the players used different rules, so members of the University of Cambridge devised and published a set of Cambridge Rules in 1848 which was widely adopted.[3] Another set of rules, the Sheffield Rules, was used by a number of clubs in the North of England from the 1850s.[citation needed]  Eleven London football clubs and schools representatives met on 26 October 1863 to agree on common rules.[3][4] The founding clubs present at the first meeting were:  Charterhouse sent their captain, B.F. Hartshorne, but declined the offer to join.[10] Many of these clubs are now defunct or still play rugby. Civil Service FC, who now plays in the Southern Amateur League, is the only one of the original eleven football clubs still in existence, with an unbroken history, and playing association football,[4] although Forest School has been a member since the fifth meeting in December 1863. Both Barnes and Wanderers have been refounded as football clubs in the modern era.  Ebenezer Cobb Morley was the FA's first secretary (1863\u201366) and its second president (1867\u201374) and drafted the Laws of the Game generally called the \"London Rules\" at his home in Barnes, London.[4] He played in the first-ever match in 1863.  The first version of the rules for the modern game was drawn up over a series of six meetings held in The Freemasons' Tavern from October till December.[4] Of the clubs at the first meeting, Crusaders, Surbiton and Charterhouse did not attend the subsequent meetings, replaced instead by the Royal Navy School, Wimbledon School and Forest School.[11]  At the final meeting, F. M. Campbell, the first FA treasurer and the Blackheath representative, withdrew his club from the FA over the removal of two draft rules at the previous meeting, the first which allowed for the running with the ball in hand and the second, obstructing such a run by hacking (kicking an opponent in the shins), tripping and holding. Other English rugby clubs followed this lead and did not join the FA but instead in 1871 formed the Rugby Football Union.[3] The term \"soccer\" dates back to this split to refer to football played under the \"association\" rules. After six clubs had withdrawn as they supported the opposing Rugby Rules, the Football Association had just nine members in January 1864: Barnes, Kilburn, Crystal Palace, War Office (Civil Service), Forest Club, Forest School, Sheffield, Uppingham and Royal Engineers (Chatham).[12]  An inaugural game using the new FA rules was initially scheduled for Battersea Park on 2 January 1864, but enthusiastic members of the FA could not wait for the new year: the first game under F. A. rules was played at Mortlake on 19 December 1863 between Morley's Barnes team and their neighbours Richmond (who were not members of the FA), ending in a goalless draw. The Richmond side were obviously unimpressed by the new rules in practice because they subsequently helped form the Rugby Football Union in 1871. The Battersea Park game was the first exhibition game using FA rules, and was played there on Saturday 9 January 1864.[13]  The members of the opposing teams for this game were chosen by the President of the FA (A. Pember) and the Secretary (E. C. Morley) and included many well-known footballers of the day.[14] After the first match according to the new FA rules a toast was given \"Success to football, irrespective of class or creed\".[15]  Another notable match was London v Sheffield, in which a representative team from the FA played Sheffield FC under Association rules in March 1866; Charles Alcock described this game as \"first [match] of any importance under the auspices of the Football Association\".[16]  Alcock (of Harrow School) of the Wanderers was elected to the committee of the FA in 1866, becoming its first full-time secretary and treasurer in 1870. He masterminded the creation of the Football Association Cup[17]\u2014the longest-running association football competition in the world\u2014in 1871. Fifteen participating clubs subscribed to purchase a trophy. The first Cup Final was held at The Oval on 16 March 1872, fought between the Wanderers and the Royal Engineers (RE), watched by 2,000 spectators.[4] In 1874 Francis Marindin became the third president of the Football Association.  After many years of wrangling between the London-based Football Association and the Sheffield Football Association, the FA Cup brought the acceptance that one undisputed set of laws was required. The two associations had played 16 inter-association matches under differing rules; the Sheffield Rules, the London Rules and Mixed Rules. In April 1877, those laws were set with a number of Sheffield Rules being incorporated. In 1890 Arthur Kinnaird replaced Major Francis Marindin, becoming the fourth president of the Football Association. Kinnaird had at that time been a FA committeeman since the age of 21, in 1868. Kinnaird remained president for the next 33 years, until his death in 1923.  The FA Cup was initially contested by mostly southern, amateur teams, but more professionally organised northern clubs began to dominate the competition during the early 1880s; \"The turning point, north replacing south, working class defeating upper and professionals impinging upon the amateurs' territory, came in 1883.\"[18] Hitherto, public school sides had played a dribbling game punctuated by violent tackles, but a new passing style developed in Scotland was successfully adopted by some Lancashire teams, along with a more organised approach to training. Blackburn Olympic reached the final in March 1883 and defeated Old Etonians.[19] Near-neighbours Blackburn Rovers started to pay players, and the following season won the first of three consecutive FA Cups.[19][18] The FA initially tried to outlaw professionalism but, in the face of a threatened breakaway body (the British Football Association), by 1885 was forced to permit payments to players.[20] Three years later, in 1888, the first Football League was established, formed by six professional clubs from northwest England and six from the midlands.[18]  In 1992, the Football Association took control of the newly created Premier League which consisted of 22 clubs who had broken away from the First Division of the Football League. The Premier League reduced to 20 clubs in 1995 and is one of the richest football leagues in the world.[21]  The Football Association has updated their logo several times. They celebrated their 150th year with a special 2013\u20132014 season logo. The shield design (taken from the coat of arms of the Football Association) is the same, but the three lions, rosettes and border are in gold instead of black and red, with the usual white background. The title strip above reads \"The FA\" in white on gold, and there is a scroll below reading \"150 years\" in white on gold, between \"1863\" and \"2013\".[22][23]  By 1921 women's football had become increasingly popular through the charitable games played by women's teams during and after the First World War. In a move that was widely seen as caused by jealousy of the crowds' interest in women's games which frequently exceeded that of the top men's teams, in 1921 the Football Association banned all women's teams from playing on grounds affiliated to the FA because they thought football damaged women's bodies.[24][25] For several decades, this meant that women's football virtually ceased to exist.  The decision to exclude women was only reversed from 1969 when, after the increased interest in football caused by England's 1966 World Cup triumph, the Women's Football Association was founded,[26] although it would take a further two years \u2013 and an order from UEFA \u2013 to force the (men's) Football Association to remove its restrictions on the playing rights of women's teams.[27] It was not until 1983 that the WFA was able to affiliate to the FA as a \"County Association\" and only in 1993 did the FA found the \"Women's Football Committee\" to run women's football in England.[28] The \"Women's Football Conference\", as it is now known, has representation on the FA Council equivalent to a County Football Association.[29]  In December 2016, five former FA executives \u2013 David Bernstein, David Davies, Greg Dyke, Alex Horne and David Triesman \u2013 called on Parliament's Culture, Media and Sport Committee to propose legislation to reform the FA, saying it was outdated, held back by \"elderly white men\", and unable to counter the power of the Premier League or \"to reform and modernise in a fast-changing world\".[30]  In April 2017, it was announced that some reforms, including reducing the size of the FA's board and increasing the number of women, would be submitted for approval to the FA's annual general meeting on 18 May. However, the proposed changes were criticised by some for not going far enough, particularly to improve minority representation.[31] The proposals were approved at the AGM and include:[32]  However, pressure for FA reform continued fuelled by allegations of racism and bullying in relation to the Mark Sampson and Eniola Aluko cases, and the historical sexual abuse scandal.[33] In October 2017, FA chairman Greg Clarke announced a \"fundamental\" review of the FA after admitting it had \"lost the trust of the public\" following the Sampson controversy.[34] In the same month, Clarke was criticised by sexual abuse victim Andy Woodward and the Professional Footballers' Association's chief executive Gordon Taylor for remarks Clarke made to a Digital, Culture, Media and Sport Committee (DCMS) hearing.[35][36][37]  In November 2020, Clarke resigned as FA chairman over his use of the term \"coloured\" when referring to black players in comments to the DCMS committee via video link.[38] The FA subsequently announced they would seek a new chairman, with hopes there would be an announcement as to the successor by March 2021.[39]  In mid-November 2016, allegations of widespread historical sexual abuse at football clubs dating back to the 1970s began to emerge. On 21 November, the Football Association said it would set up a helpline;[40] this was established with the NSPCC and opened on 24 November,[41] reportedly receiving over 50 calls within the first two hours,[42] over 100 by 27 November,[43] and 860 (\"more than three times as many referrals as in the first three days of the Jimmy Savile scandal\") by 1 December[44] with 350 individuals alleging abuse.[45] The FA and NSPCC also collaborated to produce a film about how to keep children safe in the sport, featuring the captains of England's men's, women's and cerebral palsy football teams (Wayne Rooney, Steph Houghton and Jack Rutter).[46]  On 27 November, the FA announced it was to set up an internal review, led by independent counsel Kate Gallafent QC, into what Crewe and Manchester City knew about convicted child sex offender Barry Bennell and allegations of child sexual abuse in football, and investigate what information it was aware of at the time of the alleged offences.[47]  The FA was criticised by Conservative MP Damian Collins, chairman of the House of Commons' Culture, Media and Sport Committee, for being too slow in reacting and not instigating a wider review.[48] Former sport minister Gerry Sutcliffe talked of previous concern about how the FA dealt with governance of the sport and with youth development (in the 1990s, the FA was said to have reacted \"dismissively\" to worries about sexual abuse in the game, and too slow to implement criminal record checks;[49] in 2003, the FA had scrapped a project meant to ensure children were being protected from sexual abuse;[50] and FA officials had been uncooperative with the review project, with ten of 14 FA staff not replying to interview requests and a report by the researchers of others being \"prevented\/bullied\" from talking).[51] Sutcliffe said an independent body, such as the Department for Culture, Media and Sport should look at the issue rather than the FA investigating itself: \"What I've seen in football over the years is that they're very narrow, very insular, and may not do a proper job even though with the right intentions.\"[52]  On 6 December 2016, the FA announced that, due to \"the increased scope of the review since it was announced\"[53] and Gallafent's other professional commitments, the review would be conducted by Clive Sheldon QC.[54] On 11 January 2017, the Sheldon review had made its first call for evidence, writing to all football clubs in England and Wales, amateur and professional, asking for information by 15 March about allegations of child sexual abuse between 1970 and 2005.[55] In March 2018, it was reported that the scale of evidence provided, plus the \"chaotic nature of the archiving\", had delayed the inquiry team's sift through the FA's legal files; around 500,000 pages of material from 6,000 files were uploaded to a digital platform, and 353 documents were identified as highly relevant. Sheldon expected to start writing his final report in August 2018.[56]  In July 2018, it was reported that the FA's independent inquiry had found no evidence of an institutional cover-up or of a paedophile ring operating within football. Sheldon's report, likely to be highly critical of several clubs, was initially expected to be delivered to the FA in September 2018,[57] but its publication was delayed, potentially by up to a year, pending the retrial of Bob Higgins and possible further charges against Barry Bennell.[58]  The 700-page report was eventually published on 17 March 2021. It identified failures to act adequately on complaints or rumours of sexual abuse at eight professional clubs: Aston Villa, Chelsea, Crewe Alexandra, Manchester City, Newcastle United, Peterborough, Southampton and Stoke City.[59] The report also made 13 recommendations for further improvements, including clubs employing qualified safeguarding officers, an FA board member to be the designated \"children's safeguarding champion\", spot checks of amateur clubs, a \"national day of safeguarding in football\" and an annual safeguarding report. However, the measures were criticised for being too late and lacking ambition. The FA issued a \"heartfelt apology\" to survivors and said it would be implementing all of Sheldon's recommendations.[59]  The football associations within the Crown Dependencies of Jersey (Jersey Football Association), Guernsey (Guernsey Football Association) and the Isle of Man (Isle of Man Football Association) are affiliated to the FA despite having a separate identity from that of the United Kingdom and by extension England.[60] They are considered county football associations by the FA. Matt Le Tissier and Graeme Le Saux have represented the FA's full national representative team and were born in Guernsey and Jersey respectively.[61]  The Guernsey Football Association, Isle of Man Football Association and Jersey Football Association have been affiliated with the FA since 1903, 1908 and 1905 respectively.[62][63][64]  A loophole was closed in May 2008 by FIFA which allowed players born in the Channel Islands to choose which home nation within the United Kingdom they will represent at international level. During the 1990s, Trevor Wood (Jersey) and Chris Tardif (Guernsey) represented Northern Ireland.  The British overseas territory of Gibraltar's Gibraltar Football Association was affiliated to the FA from 1911 until it opted to become a fully recognised member of UEFA, a feat achieved after a 14-year legal battle.[when?] Joseph Nunez, the Gibraltar FA President claimed they were \"unilaterally thrown out\" of the FA following an intervention from Geoff Thompson.[62]  On the other hand, the Hong Kong Football Association (HKFA), established in 1914, is one of the oldest football associations in Asia. They joined FIFA in 1954, and were also one of twelve founding members of the Asian Football Confederation (AFC). HK played an important role in the early development of Asian football and hosted the first Asian Cup competition in 1956. The dependent territory was relinquished by the UK in 1997 and handed over to the People's Republic of China.  Some of the other British overseas territories have local football associations or leagues (including the Anguilla Football Association, the Ascension Island Football League, the Bermuda Football Association, the British Virgin Islands Football Association, the Cayman Islands Football Association, the Falkland Islands Football League, the Montserrat Football Association, the Turks and Caicos Islands Football Association), but these are not considered subsidiary to the Football Association.  Although the British overseas territories are too small to support professional teams,[citation needed] they have produced players such as Clyde Best who have gone on to play professionally in the Football Association, and referees such as Carlyle Crockwell, who have refereed FIFA matches.  The Football Association first joined FIFA in 1905. The British Associations (England, Ireland, Scotland and Wales) opted to leave FIFA after World War I when FIFA chose not to exclude those who were part of the Central Powers from the organisation. The British Associations' stance had changed by 1922 and in 1924 they had rejoined FIFA.[b]  The British Olympic Association had fought against 'broken time' \u2013 monetary compensation for athletes' earnings when competing in the Olympic games. At the 1925 Olympic Congress in Prague, the British had made an amendment that concluded governing federations should define amateur status for their sports but only in accordance with the definition of amateurism accepted by the Olympic Congress. In 1928, Switzerland proposed to FIFA that in certain circumstances, 'broken time' payments should be allowed and FIFA accepted. The FA resigned from FIFA in protest against the proposal. As a result of the FA's resignation, England did not participate in the 1930, 1934 or 1938 FIFA World Cup.  At the 1930 Olympic Congress in Berlin, Belgian delegates proposed that for each sport the definition of amateur status be left to its international federation. The BOA argued for a common definition of amateurism and argued that 'broken time' payments were against the Olympic ideal.  The FA rejoined FIFA in 1946 and participated in their first World Cup in 1950. One of the first actions of the Football Association was to request the expulsion of the German and Japanese national football associations for their countries' role in World War II. Germany and Japan were prevented from qualifying for the 1950 FIFA World Cup as a consequence. They were re-acquainted with FIFA in 1950 following a second request from Switzerland who had had a previous request rejected in 1948.  The FA runs several competitions:  The FA's main commercial asset is its ownership of the rights to England internationals and the FA Cup. Broadcasting income remains the FA's largest revenue stream with both domestic and international broadcasting rights for England fixtures and the FA Cup tied up until at least 2021.  For the four seasons from 2008 to 2012, the FA secured \u00a3425\u00a0million from ITV and Setanta for England and FA Cup games domestic television rights, a 42% increase over the previous contract, and \u00a3145\u00a0million for overseas television rights, up 272% on the \u00a339\u00a0million received for the previous four-year period.[66] However, during 2008\u201309 Setanta UK went into administration, which weakened the FA's cashflow position.  Turnover for the year ending 31 July 2016 was \u00a3370\u00a0million on which it made a profit after tax of \u00a37\u00a0million. It has also made an investment of \u00a3125\u00a0million back into every level of Football in 2016. In July 2015 the FA announced plans to carry out a significant organisational restructure, in order to deliver considerable cost savings to invest in elite England teams, facilities and grassroots coaching.[67]  The FA's income does not include the turnover of English football clubs, which are independent businesses. As well as running its own operations the FA chooses five charities each year to which it gives financial support.[68][69]  In three years up to 2014, the FA received \u00a3350,000 in fines from players over comments made on Twitter. The highest fine imposed was a \u00a390,000 fine to Ashley Cole in 2012 after calling the FA \"a bunch of twats.\" The FA became stricter on comments made by players on Twitter, disciplining 121 players in three years.[70]  The FA has a figurehead President, who since 1939 has always been a member of the British royal family. The Chairman of the FA has overall responsibility for policy. Traditionally this person rose through the ranks of the FA's committee structure (e.g. by holding posts such as the chairmanship of a county football association). In 2008 politician David Triesman was appointed as the FA's first \"independent chairman\", the first from outside the football hierarchy. The day-to-day head of the FA was known as the Secretary until 1989, when the job title was changed to Chief Executive.[71][72][73]  Taken from The FA's website on 9 January 2022[74]  National Game representatives:  Professional Game representatives:   Independent Non-Executive directors:  Board observers: "},{"title":"Juggling","content":"Juggling is a physical skill, performed by a juggler, involving the manipulation of objects for recreation, entertainment, art or sport. The most recognizable form of juggling is toss juggling. Juggling can be the manipulation of one object or many objects at the same time, most often using one or two hands but other body parts as well, like feet or head. Jugglers often refer to the objects they juggle as props. The most common props are balls, clubs, or rings. Some jugglers use more dramatic objects such as knives, fire torches or chainsaws. The term juggling can also commonly refer to other prop-based manipulation skills, such as diabolo, plate spinning, devil sticks, poi, cigar boxes, contact juggling, hooping, yo-yo, hat manipulation and kick-ups.  The words juggling and juggler derive from the Middle English jogelen (\"to entertain by performing tricks\"), which in turn is from the Old French jangler. There is also the Late Latin form joculare of Latin joculari, meaning \"to jest\".[1] Although the etymology of the terms juggler and juggling in the sense of manipulating objects for entertainment originates as far back as the 11th century, the current sense of to juggle, meaning \"to continually toss objects in the air and catch them\", originates from the late 19th century.[2][3]  From the 12th to the 17th century, juggling and juggler were the terms most consistently used to describe acts of magic, though some have called the term juggling a lexicographical nightmare, stating that it is one of the least understood relating to magic. In the 21st century, the term juggling usually refers to toss juggling, where objects are continuously thrown into the air and caught again, repeating in a rhythmical pattern.[2][4][5]  According to James Ernest in his book Contact Juggling, most people will describe juggling as \"throwing and catching things\"; however, a juggler might describe the act as \"a visually complex or physically challenging feat using one or more objects\".[6] David Levinson and Karen Christensen describe juggling as \"the sport of tossing and catching or manipulating objects [...] keeping them in constant motion\".[7] \"Juggling, like music, combines abstract patterns and mind-body coordination in a pleasing way.\"[8]  The earliest record of juggling is suggested in a panel from the 15th (1994 to 1781 B.C.) Beni Hasan tomb of an unknown Egyptian prince, showing female dancers and acrobats throwing balls.[10] Juggling has been recorded in many early cultures including Egyptian, Nabataean, Chinese, Indian, Greek, Roman, Norse, Aztec (Mexico) and Polynesian civilizations.[11][12][13]  Juggling in ancient China was an art performed by some warriors. One such warrior was Xiong Yiliao, whose juggling of nine balls in front of troops on a battlefield reportedly caused the opposing troops to flee without fighting, resulting in a complete victory.[14]  In Europe, juggling was an acceptable diversion until the decline of the Roman Empire, after which the activity fell into disgrace. Throughout the Middle Ages, most histories were written by religious clerics who frowned upon the type of performers who juggled, called gleemen, accusing them of base morals or even practicing witchcraft. Jugglers in this era would only perform in marketplaces, streets, fairs, or drinking houses. They would perform short, humorous and bawdy acts and pass a hat or bag among the audience for tips. Some kings' and noblemen\u2019s bards, fools, or jesters would have been able to juggle or perform acrobatics, though their main skills would have been oral (poetry, music, comedy and storytelling).  In 1768, Philip Astley opened the first modern circus. A few years later, he employed jugglers to perform acts along with the horse and clown acts. Since then, jugglers have been associated with circuses.  In the early 19th century,[15] troupes from Asia, such as the famous \"Indian Jugglers\"[16] referred to by William Hazlitt,[17] arrived to tour Britain, Europe and parts of America.[18]  In the 19th century, variety and music hall theatres became more popular, and jugglers were in demand to fill time between music acts, performing in front of the curtain while sets were changed. Performers started specializing in juggling, separating it from other kinds of performance such as sword swallowing and magic. The Gentleman Juggler style was established by German jugglers such as Salerno and Kara. Rubber processing developed, and jugglers started using rubber balls. Previously, juggling balls were made from balls of twine, stuffed leather bags, wooden spheres, or various metals. Solid or inflatable rubber balls meant that bounce juggling was possible. Inflated rubber balls made ball spinning easier and more readily accessible. Soon in North America, vaudeville theatres employed jugglers, often hiring European performers.  In the early to mid-20th century, variety and vaudeville shows decreased in popularity due to competition from motion picture theatres, radio and television, and juggling suffered as a result. Music and comedy transferred very easily to radio, but juggling could not. In the early years of TV, when variety-style programming was popular, jugglers were often featured; but developing a new act for each new show, week after week, was more difficult for jugglers than other types of entertainers; comedians and musicians can pay others to write their material, but jugglers cannot get other people to learn new skills on their behalf.  The International Jugglers' Association, founded in 1947, began as an association for professional vaudeville jugglers, but restrictions for membership were eventually changed, and non-performers were permitted to join and attend the annual conventions. The IJA continues to hold an annual convention each summer and runs a number of other programs dedicated to advance the art of juggling worldwide.  World Juggling Day was created as an annual day of recognition for the hobby, with the intent to teach people how to juggle, to promote juggling and to get jugglers together and celebrate. It is held on the Saturday in June closest to the 17th, the founding date of the International Jugglers' Association.[19]  Most cities and large towns now have juggling clubs. These are often based within, or connected to, universities and colleges. There are also community circus groups that teach young people and put on shows. The Juggling Edge[20] maintains a searchable database of most juggling clubs.  Since the 1980s, a juggling culture has developed. The scene revolves around local clubs and organizations, special events, shows, magazines, web sites, internet forums and, possibly most importantly, juggling conventions. In recent years, there has also been a growing focus on juggling competitions. Juggling today has evolved and branched out to the point where it is synonymous with all prop manipulation. The wide variety of the juggling scene can be seen at any juggling convention.  Juggling conventions or festivals form the backbone of the juggling scene. The focus of most of these conventions is the main space used for open juggling. There will also be more formal workshops in which expert jugglers will work with small groups on specific skills and techniques. Most juggling conventions also include a main show (open to the general public), competitions, and juggling games.  Juggling can be categorised by various criteria:  There is no organisation that tracks all juggling world records.  Toss juggling and club passing world records used to be tracked by the Juggling Information Service Committee on Numbers Juggling (JISCON) (now defunct).[23] Some records are tracked by Guinness World Records.  The most footballs (soccer balls) juggled simultaneously is five and was achieved by Victor Rubilar (Argentina) at the Gallerian Shopping Centre in Stockholm, Sweden, on 4 November 2006. This was equaled by Marko Vermeer (Netherlands) in Amstelveen, Netherlands, on 11 August 2014 and Isidro Silveira (Spain), in Adeje, Tenerife, Spain, on 4 November 2015.[24]  Professional jugglers perform in a number of different styles, which are not mutually exclusive. These juggling styles have developed or been introduced over time with some becoming more popular at some times than others.  Traditional circus-style juggling emphasises high levels of skill and sometimes large-scale props to enable the act to \"fill\" the circus ring. The juggling act may involve some comedy or other circus skills such as acrobatics, but the principal focus is the technical skill of the jugglers. Costumes are usually colourful with sequins. Variations within this style include the traditions from Chinese and Russian circus.  Comedy juggling acts vary greatly in their skill level, prop use and costuming. However, they all share the fact that the focus of the performance is comedic rather than a demonstration of technical juggling skill. Comedy juggling acts are most commonly seen in street performance, festivals and fairs.  Gentleman juggling was popular in variety theatres and usually involves juggling some of the elements of a gentleman's attire, namely hats, canes, gloves, cigars, and other everyday items[25] such as plates and wine bottles.[26] The style is often sophisticated and visual rather than comedic, though it has been interpreted in many different styles.  French juggler Gaston Palmer, for example, gained a kind of notoriety for his comedic execution of gentleman juggling tricks.[27]  Jugglers perform themed acts, sometimes with specifically themed props and usually in themed costumes. Examples include jesters, pirates, sports, Victorians and chefs.  Jugglers commonly feature in circuses, with many performers having enjoyed a star billing. Circus jugglers come from many countries and include those from Russia and other Eastern European countries, China, Latin America and other European countries. Some of the greatest jugglers from the past 50 years are from Eastern Europe, including Sergej Ignatov, Andrii Kolesnikov, Evgenij Biljauer, and Gregory Popovich.  Variety theatres have a long history of including juggling acts on their billing. Vaudeville in the USA and Music halls in the UK regularly featured jugglers during the heyday of variety theatre in the first half of 20th century. Variety theatre has declined in popularity but is still present in many European countries, particularly Germany. Television talent shows have introduced juggling acts to a wider audience with the newest examples being Britain's Got Talent and America's Got Talent.  In North America jugglers have often performed in casinos, in places like Las Vegas. Germany and the United States have produced some of the greatest jugglers from the past 50 years, most notably Francis Brunn from Germany and Anthony Gatto from the United States.  There is a wide variety of festivals and fairs where juggling acts are sometimes booked to perform. Music, food and arts festivals have all booked professional performers. The festivals can range from very large scale events such as Glastonbury Festival to small town or village fairs. The acts may differ from year to year or a one-act may become a regular feature at these yearly events.  Renaissance fairs in North America and medieval fairs in Europe often book professional jugglers. Other historically themed events such as Victorian, maritime, and large-scale festivals of history such as the one organised by English Heritage regularly employ juggling acts as part of the event.  In many countries such as the UK, USA, Australia, Spain, France jugglers perform on the street (busking). Street juggling acts usually perform what is known as a circle show and collect money at the end of the performance in a hat or bottle. Most street jugglers perform comedy juggling acts. Well known locations for this kind of street performance include Covent Garden in London, Faneuil Hall in Boston, Outside the Pump Rooms in Bath, Prince's Street in Edinburgh, outside the Pompidou Centre in Paris, Circular Quay in Sydney, and Pearl Street in Boulder.  Juggling has been performed in space despite the fact that the micro-gravity environment of orbit deprives the juggled objects of the essential ability to fall. This was accomplished initially by Don Williams, as part of a Houston scientist's \"Toys In Space\" project, with apples and oranges.[28]  Two person juggling passing multiple objects between them was first accomplished in space by Greg Chamitoff and Richard Garriott[29] while Garriott was visiting the International Space Station as a Spaceflight Participant in October 2008. Their juggling of objects while in orbit was featured in Apogee of Fear, the first science fiction movie made in space by Garriott and 'Zero-G Magic', a magic show also recorded in space by Chamitoff and Garriott at that time.  According to an Oxford University study, juggling improves cerebral connectivity performance.[30][31]  Mathematics has been used to understand juggling as juggling has been used to test mathematics. The number of possible patterns n digits long using b or fewer balls is bn and the average of the numbers in a siteswap pattern equal the number of balls required for the pattern.[10] For example, the number of three digit three ball patterns is 33 = 27, and the box, (4,2x)(2x,4), requires (4+2+4+2)\/4 = 3 balls.  \"The time that a ball spends in flight is proportional to the square root of the height of the throw,\" meaning that the number of balls used greatly increases the amount of speed or height required, which increases the need for accuracy between the direction and synchronization of throws.[10]  Coupled oscillation and synchronization (\"the tendency of two limbs to move at the same frequency\"[10]) appear to be easier in all patterns and also required by certain patterns. For example, \"the fountain pattern...can be stably performed in two ways...one can perform the fountain with different frequencies for the two hands, but that coordination is difficult because of the tendency of the limbs to synchronize,\" while \"in the cascade...the crossing of the balls between the hands demands that one hand catches at the same rate that the other hand throws.\"[10]  Claude Shannon, builder of the first juggling robot, developed a juggling theorem, relating the time balls spend in the air and in the hands: (F+D)H=(V+D)N, where F = time a ball spends in the air, D = time a ball spends in a hand\/time a hand is full, V = time a hand is vacant, N = number of balls, and H = number of hands.[10] For example, a hand's and a ball's perspectives in the two-hand (H) three-ball (N) cascade pattern:  Juggling tricks and patterns can become very complex, and hence can be difficult to communicate to others. Therefore, notation systems have been developed for specifying patterns, as well as for discovering new patterns.[34]  Diagram-based notations are the clearest way to show juggling patterns on paper, but as they are based on images, their use is limited in text-based communication. Ladder diagrams track the path of all the props through time, where the less complicated causal diagrams only track the props that are in the air, and assumes that a juggler has a prop in each hand. Numeric notation systems are more popular and standardized than diagram-based notations. They are used extensively in both a written form and in normal conversations among jugglers.  Siteswap is by far the most common juggling notation. Various heights of throw, considered to take specific \"beats\" of time to complete, are assigned a relative number. From those, a pattern is conveyed as a sequence of numbers, such as \"3\", \"744\", or \"97531\". Those examples are for two hands making alternating or \"asynchronous\" throws, and often called vanilla siteswap. For showing patterns in which both hands throw at the same time, there are other notating conventions for synchronous siteswap. There is also multiplex siteswap for patterns where one hand holds or throws two or more balls on the same beat. Other extensions to siteswap have been developed, including passing siteswap, Multi-Hand Notation (MHN), and General Siteswap (GS).  Organizations  Resources  Other "},{"title":"Ulster Scots dialect","content":"  Ulster Scots or Ulster-Scots  (Ulst\u00e8r-Scotch, Irish: Albainis Uladh),[6][7] also known as Ulster Scotch and Ullans, is the dialect of Scots spoken in parts of Ulster in Northern Ireland and the Republic of Ireland.[5][8][9] It is generally considered a dialect or group of dialects of Scots, although groups such as the Ulster-Scots Language Society[10] and Ulster-Scots Academy[11] consider it a language in its own right, and the Ulster-Scots Agency[12] and former Department of Culture, Arts and Leisure[13] have used the term Ulster-Scots language.  Some definitions of Ulster Scots may also include Standard English spoken with an Ulster Scots accent.[14][15] This is a situation like that of Lowland Scots and Scottish Standard English[16] with words pronounced using the Ulster Scots phonemes closest to those of Standard English.[16] Ulster Scots has been influenced by Hiberno-English, particularly Ulster English, and by Ulster Irish. As a result of the competing influences of English and Scots, varieties of Ulster Scots can be described as \"more English\" or \"more Scots\".[15]  While once referred to as Scotch-Irish by several researchers, that has now been superseded by the term Ulster Scots.[17] Speakers usually refer to their vernacular as 'Braid Scots',[1] 'Scotch'[3][18] or 'the hamely tongue'.[19] Since the 1980s Ullans, a neologism popularized by the physician, amateur historian and politician Ian Adamson,[20] merging Ulster and Lallans, the Scots for Lowlands,[21] but also an acronym for \"Ulster-Scots language in literature and native speech\"[22] and Ulst\u00e8r-Scotch,[6][7] the preferred revivalist parlance, have also been used. Occasionally, the term Hiberno-Scots appears,[23] whether for the vernacular or the ethnic group.[24]  During the middle of the 20th century, the linguist Robert John Gregg established the geographical boundaries of Ulster's Scots-speaking areas based on information gathered from native speakers.[25] By his definition, Ulster Scots is spoken in mid and east Antrim, north Down, north-east County Londonderry, and in the fishing villages of the Mourne coast. It is also spoken in the Laggan district and parts of the Finn Valley in east Donegal and in the south of Inishowen in north Donegal.[26] Writing in 2020, the Fintona-born linguist Warren Maguire argued that some of the criteria that Gregg used as distinctive of Ulster Scots are common in south-west Tyrone and were found in other sites across Northern Ireland investigated by the Linguistic Survey of Scotland.[27]  The 1999 Northern Ireland Life and Times Survey found that 2% of Northern Ireland residents claimed to speak Ulster Scots, which would mean a total speech community of approximately 30,000 in the territory.[28] Other estimates range from 35,000 in Northern Ireland,[29] to an \"optimistic\" total of 100,000 including the Republic of Ireland (mainly the east of County Donegal).[30] Speaking at a seminar on 9 September 2004, Ian Sloan of the Northern Ireland Department of Culture, Arts and Leisure (DCAL) accepted that the 1999 Northern Ireland Life and Times Survey \"did not significantly indicate that unionists or nationalists were relatively any more or less likely to speak Ulster Scots, although in absolute terms there were more unionists who spoke Ulster Scots than nationalists\".[citation needed]  In the 2021 census of Northern Ireland, 20,930 people (1.14% of the population) stated that they can speak, read, write and understand Ulster Scots, 26,570 people (1.45% of the population) stated they can speak but cannot read or write Ulster Scots, and 190,613 people (10.38% of the population) reported having some knowledge of it.[31]  The majority of linguists treat Ulster Scots as a variety of the Scots language; Caroline Macafee, for example, writes that \"Ulster Scots is [...] clearly a dialect of Central Scots.\"[8]  The Northern Ireland Department of Culture, Arts and Leisure considers Ulster Scots to be \"the local variety of the Scots language.\"[29] Some linguists, such as Raymond Hickey,[32] treat Ulster Scots (and other forms of Scots) as a dialect of English. It has been said that its \"status varies between dialect and language\".[33]  Enthusiasts such as Philip Robinson (author of Ulster-Scots: a Grammar of the Traditional Written and Spoken Language[34]), the Ulster-Scots Language Society[35] and supporters of an Ulster-Scots Academy[36] are of the opinion that Ulster Scots is a language in its own right. That position has been criticised by the Ulster-Scots Agency, a BBC report stating: \"[The Agency] accused the academy of wrongly promoting Ulster-Scots as a language distinct from Scots.\"[37] This position is reflected in many of the Academic responses[clarification needed] to the \"Public Consultation on Proposals for an Ulster-Scots Academy\"[38]  Ulster Scots is defined in an Agreement between the Government of the United Kingdom of Great Britain and Northern Ireland and the Government of Ireland establishing implementation bodies done at Dublin on the 8th day of March 1999 in the following terms:  \"Ullans\" is to be understood as the variety of the Scots language traditionally found in parts of Northern Ireland and Donegal. The North\/South Co-operation (Implementation Bodies) Northern Ireland Order 1999,[39] which gave effect to the implementation bodies incorporated the text of the agreement in its Schedule 1.  The declaration made by the British Government regarding the European Charter for Regional or Minority Languages reads as follows:[40]  The United Kingdom declares, in accordance with Article 2, paragraph 1 of the Charter that it recognises that Scots and Ulster Scots meet the Charter's definition of a regional or minority language for the purposes of Part II of the Charter. This recognition differed significantly from the commitments entered into under the Charter in relation to Irish, for which specific provisions under Part III were invoked for the protection and promotion of that language. The definition of Ullans from the North\/South Co-operation (Implementation Bodies) Northern Ireland Order 1999 above was used on 1 July 2005 Second Periodical Report by the United Kingdom to the Secretary General of the Council of Europe outlining how the UK met its obligations under the Charter.[41]  The Good Friday Agreement (which does not refer to Ulster Scots as a \"language\") recognises Ulster Scots as \"part of the cultural wealth of the island of Ireland\", and the Implementation Agreement established the cross-border Ulster-Scots Agency (Tha Boord o Ulst\u00e8r-Scotch).  The legislative remit laid down for the agency by the North\/South Co-operation (Implementation Bodies) Northern Ireland Order 1999 is: \"the promotion of greater awareness and the use of Ullans and of Ulster-Scots cultural issues, both within Northern Ireland and throughout the island\".  The agency has adopted a mission statement: to promote the study, conservation, development and use of Ulster Scots as a living language; to encourage and develop the full range of its attendant culture; and to promote an understanding of the history of the Ulster-Scots people.[6] Despite the Agency's reference to Ulster Scots as \"a language\", this eliding of the distinction between Ulster Scots as a linguistic form, and \"Ulster Scots culture\" broadly referring to cultural forms associated with the Scottish-descended population, continued thereafter.  The Northern Ireland (St Andrews Agreement) Act 2006[42] amended the Northern Ireland Act 1998 to insert a section (28D) entitled Strategies relating to Irish language and Ulster Scots language etc. which inter alia laid on the Executive Committee a duty to \"adopt a strategy setting out how it proposes to enhance and develop the Ulster Scots language, heritage and culture.\" This reflects the wording used in the St Andrews Agreement to refer to the enhancement and development of \"the Ulster Scots language, heritage and culture\".[43] There is still controversy on the status of Ulster Scots.[44]  Scots, mainly Gaelic-speaking, had been settling in Ulster since the 15th century, but large numbers of Scots-speaking Lowlanders, some 200,000, arrived during the 17th century following the 1610 Plantation, with the peak reached during the 1690s.[45] In the core areas of Scots settlement, Scots outnumbered English settlers by five or six to one.[46]  Literature from shortly before the end of the unselfconscious tradition at the turn of the 19th and 20th centuries is almost identical with contemporary writing from Scotland.[47] W. G. Lyttle, writing in Paddy McQuillan's Trip Tae Glesco, uses the typically Scots forms kent and begood, now replaced in Ulster by the more mainstream Anglic forms knew, knowed or knawed and begun. Many of the modest contemporary differences between Scots as spoken in Scotland and Ulster may be due to dialect levelling and influence from Mid Ulster English brought about through relatively recent demographic change rather than direct contact with Irish, retention of older features or separate development.[citation needed]  The earliest identified writing in Scots in Ulster dates from 1571: a letter from Agnes Campbell of County Tyrone to Queen Elizabeth on behalf of Turlough O'Neil, her husband. Although documents dating from the Plantation period show conservative Scots features, English forms started to predominate from the 1620s as Scots declined as a written medium.[48]  In Ulster Scots-speaking areas there was traditionally a considerable demand for the work of Scottish poets, often in locally printed editions. These include Alexander Montgomerie's The Cherrie and the Slae in 1700; shortly over a decade later an edition of poems by Sir David Lindsay; nine printings of Allan Ramsay's The Gentle shepherd between 1743 and 1793; and an edition of Robert Burns' poetry in 1787, the same year as the Edinburgh edition, followed by reprints in 1789, 1793 and 1800. Among other Scottish poets published in Ulster were James Hogg and Robert Tannahill.  That was complemented by a poetry revival and nascent prose genre in Ulster, which started around 1720.[49] The most prominent of these was the rhyming weaver poetry, of which, some 60 to 70 volumes were published between 1750 and 1850, the peak being in the decades 1810 to 1840,[clarification needed] although the first printed poetry (in the Habbie stanza form) by an Ulster Scots writer was published in a broadsheet in Strabane in 1735.[50] These weaver poets looked to Scotland for their cultural and literary models and were not simple imitators but clearly inheritors of the same literary tradition following the same poetic and orthographic practices; it is not always immediately possible to distinguish traditional Scots writing from Scotland and Ulster. Among the rhyming weavers were James Campbell (1758\u20131818), James Orr (1770\u20131816), Thomas Beggs (1749\u20131847), David Herbison (1800\u20131880), Hugh Porter (1780\u20131839) and Andrew McKenzie (1780\u20131839).  Scots was also used in the narrative by Ulster novelists such as W. G. Lyttle (1844\u20131896) and Archibald McIlroy (1860\u20131915). By the middle of the 19th century the Kailyard school of prose had become the dominant literary genre, overtaking poetry. This was a tradition shared with Scotland which continued into the early 20th century.[49] Scots also frequently appeared in Ulster newspaper columns, especially in Antrim and Down, in the form of pseudonymous social commentary employing a folksy first-person style.[48] The pseudonymous Bab M'Keen (probably successive members of the Weir family: John Weir, William Weir, and Jack Weir) provided comic commentaries in the Ballymena Observer and County Antrim Advertiser for over a hundred years from the 1880s.[51]  A somewhat diminished tradition of vernacular poetry survived into the 20th century in the work of poets such as Adam Lynn, author of the 1911 collection Random Rhymes frae Cullybackey, John Stevenson (died 1932), writing as \"Pat M'Carty\", and John Clifford (1900\u20131983) from East Antrim.[52] In the late 20th century the poetic tradition was revived, albeit often replacing the traditional Modern Scots orthographic practice with a series of contradictory idiolects.[53] Among the significant writers is James Fenton, mostly using a blank verse form, but also occasionally the Habbie stanza.[49] He employs an orthography that presents the reader with the difficult combination of eye dialect, dense Scots, and a greater variety of verse forms than employed hitherto.[53] The poet Michael Longley (born 1939) has experimented with Ulster Scots for the translation of Classical verse, as in his 1995 collection The Ghost Orchid.[51] The writing of Philip Robinson (born 1946) has been described as verging on \"post-modern kailyard\".[51] He has produced a trilogy of novels Wake the Tribe o Dan (1998), The Back Streets o the Claw (2000) and The Man frae the Ministry (2005), as well as story books for children Esther, Quaen o tha Ulidian Pechts and Fergus an tha Stane o Destinie, and two volumes of poetry Alang the Shore (2005) and Oul Licht, New Licht (2009).[54]  A team in Belfast has begun translating portions of the Bible into Ulster Scots. The Gospel of Luke was published in 2009 by the Ullans Press. It is available in the YouVersion Bible Project.[55]  In 1992 the Ulster-Scots Language Society was formed for the protection and promotion of Ulster Scots, which some of its members viewed as a language in its own right, encouraging use in speech, writing and in all areas of life.  Within the terms of the European Charter for Regional or Minority Languages the British Government is obliged, among other things, to:  The Ulster-Scots Agency, funded by DCAL in conjunction with the Department of Culture, Heritage and the Gaeltacht, is responsible for promotion of greater awareness and use of Ullans and of Ulster-Scots cultural issues, both within Northern Ireland and throughout the island. The agency was established as a result of the Belfast Agreement of 1998. Its headquarters are on Great Victoria Street in central Belfast, while the agency has a major office in Raphoe, County Donegal.  In 2001 the Institute of Ulster Scots Studies was established at the University of Ulster.[57]  An Ulster Scots Academy has been planned with the aim of conserving, developing, and teaching the language of Ulster-Scots in association with native speakers to the highest academic standards.[36]  The 2010 documentary The Hamely Tongue by filmmaker Deagl\u00e1n O Moch\u00e1in traces back the origins of this culture and language, and relates its manifestations in today's Ireland.   By the early 20th century the literary tradition was almost extinct,[59] though some 'dialect' poetry continued to be written.[60] Much revivalist Ulster Scots has appeared, for example as \"official translations\", since the 1990s. However, it has little in common with traditional Scots orthography as described in Grant and Dixon's Manual of Modern Scots (1921). Aod\u00e1n Mac P\u00f3ilin, an Irish language activist, has described these revivalist orthographies as an attempt to make Ulster Scots an independent written language and to achieve official status. They seek \"to be as different to English (and occasionally Scots) as possible\".[61] He described it as a hotchpotch of obsolete words, neologisms (example: stour-sucker[62] for vacuum cleaner), redundant spellings (example: qoho[63] for who) and \"erratic spelling\".[61] This spelling \"sometimes reflects everyday Ulster Scots speech rather than the conventions of either modern or historic Scots, and sometimes does not\".[61] The result, Mac P\u00f3ilin writes, is \"often incomprehensible to the native speaker\".[61] In 2000, John Kirk described the \"net effect\" of that \"amalgam of traditional, surviving, revived, changed, and invented features\" as an \"artificial dialect\". He added, It is certainly not a written version of the vestigial spoken dialect of rural County Antrim, as its activists frequently urge, perpetrating the fallacy that it's wor ain leid. (Besides, the dialect revivalists claim not to be native speakers of the dialect themselves!) The colloquialness of this new dialect is deceptive, for it is neither spoken nor innate. Traditional dialect speakers find it counter-intuitive and false...[64] In 2005, Gavin Falconer questioned officialdom's complicity, writing: \"The readiness of Northern Ireland officialdom to consign taxpayers' money to a black hole of translations incomprehensible to ordinary users is worrying\".[65] Recently produced teaching materials, have, on the other hand, been evaluated more positively.[66]  The three text excerpts below illustrate how the traditional written form of Ulster Scots from the 18th to early 20th century was virtually indistinguishable from contemporary written Scots from Scotland.[67]  The Muse Dismissed (Hugh Porter 1780\u20131839)  To M.H. (Barney Maglone[68] 1820?\u20131875)  From The Lammas Fair (Robert Huddleston 1814\u20131889)  The examples below illustrate how 21st century Ulster Scots texts seldom adhere to the previous literary tradition, Yer guide tae the cheenge-ower, perhaps being a rare exception. Instead there has been an increase in the use of somewhat creative phonetic spellings based on the perceived sound-to-letter correspondences of Standard English, i.e. dialect writing, as exemplified in Alice's Carr\u00e0nts in Wunnerlan or the adoption of a more esoteric \"amalgam of traditional, surviving, revived, changed, and invented features\"[64] as exemplified in Hannlin Rede.  From Yer guide tae the cheenge-ower (digitaluk 2012)[69]  From Alice's Carr\u00e0nts in Wunnerlan (Anne Morrison-Smyth, 2013)[70]  From Hannlin Rede [annual report] 2012\u20132013 (M\u00e4nnyst\u00e8r o Fairms an Kintra Ford\u00e8rin, 2012)[71] "},{"title":"Ancient Rome","content":"  In modern historiography, ancient Rome encompasses the founding of the Italian city of Rome in the 8th century BC, the Roman Kingdom (753\u2013509 BC), Roman Republic (509\u201327 BC), Roman Empire (27 BC\u2013 395 AD), and the collapse of the Western Roman Empire in the 5th century AD.[1][a]  Ancient Rome began as an Italic settlement, traditionally dated to 753 BC, beside the River Tiber in the Italian Peninsula. The settlement grew into the city and polity of Rome, and came to control its neighbours through a combination of treaties and military strength. It eventually controlled the Italian Peninsula, assimilating the Greek culture of southern Italy (Magna Grecia) and the Etruscan culture, and then became the dominant power in the Mediterranean region and parts of Europe. At its height it controlled the North African coast, Egypt, Southern Europe, and most of Western Europe, the Balkans, Crimea, and much of the Middle East, including Anatolia, Levant, and parts of Mesopotamia and Arabia. That empire was among the largest empires in the ancient world, covering around 5\u00a0million square kilometres (1.9\u00a0million square miles) in AD 117,[2] with an estimated 50 to 90\u00a0million inhabitants, roughly 20% of the world's population at the time.[b] The Roman state evolved from an elective monarchy to a classical republic and then to an increasingly autocratic military dictatorship during the Empire.  Ancient Rome is often grouped into classical antiquity together with ancient Greece, and their similar cultures and societies are known as the Greco-Roman world. Ancient Roman civilisation has contributed to modern language, religion, society, technology, law, politics, government, warfare, art, literature, architecture, and engineering. Rome professionalised and expanded its military and created a system of government called res publica, the inspiration for modern republics such as the United States and France.[3] It achieved impressive technological and architectural feats, such as the empire-wide construction of aqueducts and roads, as well as more grandiose monuments and facilities.  Archaeological evidence of settlement around Rome starts to emerge c.\u20091000\u00a0BC.[4] Large-scale organisation appears only c.\u2009800\u00a0BC, with the first graves in the Esquiline Hill's necropolis, along with a clay and timber wall on the bottom of the Palatine Hill dating to the middle of the 8th century\u00a0BC. Starting from c.\u2009650\u00a0BC, the Romans started to drain the valley between the Capitoline and Palatine Hills, where today sits the Roman Forum.[5] By the sixth century BC, the Romans were constructing the Temple of Jupiter Optimus Maximus on the Capitoline and expanding to the Forum Boarium located between the Capitoline and Aventine Hills.[6]  The Romans themselves had a founding myth, attributing their city to Romulus and Remus, offspring of Mars and a princess of the mythical city of Alba Longa.[7] The sons, sentenced to death, were rescued by a wolf and returned to restore the Alban king and found a city. After a dispute, Romulus killed Remus and became the city's sole founder. The area of his initial settlement on the Palatine Hill was later known as Roma Quadrata (\"Square Rome\"). The story dates at least to the third century, and the later Roman antiquarian Marcus Terentius Varro placed the city's foundation to 753\u00a0BC.[8] Another legend, recorded by Greek historian Dionysius of Halicarnassus, says that Prince Aeneas led a group of Trojans on a sea voyage to found a new Troy after the Trojan War. They landed on the banks of the Tiber River and a woman travelling with them, Roma, torched their ships to prevent them leaving again. They named the settlement after her.[9] The Roman poet Virgil recounted this legend in his classical epic poem the Aeneid, where the Trojan prince Aeneas is destined to found a new Troy.  Literary and archaeological evidence is clear on there having been kings in Rome, attested in fragmentary 6th century BC texts.[10] Long after the abolition of the Roman monarchy, a vestigial rex sacrorum was retained to exercise the monarch's former priestly functions. The Romans believed that their monarchy was elective, with seven legendary kings who were largely unrelated by blood.[11]  Evidence of Roman expansion is clear in the sixth century\u00a0BC; by its end, Rome controlled a territory of some 780 square kilometres (300 square miles) with a population perhaps as high as 35,000.[11] A palace, the Regia, was constructed c.\u2009625\u00a0BC;[11] the Romans attributed the creation of their first popular organisations and the Senate to the regal period as well.[12] Rome also started to extend its control over its Latin neighbours. While later Roman stories like the Aeneid asserted that all Latins descended from the titular character Aeneas,[13] a common culture is attested to archaeologically.[14] Attested to reciprocal rights of marriage and citizenship between Latin cities\u2014the Jus Latii\u2014along with shared religious festivals, further indicate a shared culture. By the end of the 6th century, most of this area had become dominated by the Romans.[15]  By the end of the sixth century, Rome and many of its Italian neighbours entered a period of turbulence. Archaeological evidence implies some degree of large-scale warfare.[16] According to tradition and later writers such as Livy, the Roman Republic was established c.\u2009509\u00a0BC, [17] when the last of the seven kings of Rome, Tarquin the Proud, was deposed and a system based on annually elected magistrates and various representative assemblies was established.[18] A constitution set a series of checks and balances, and a separation of powers. The most important magistrates were the two consuls, who together exercised executive authority such as imperium, or military command.[19] The consuls had to work with the Senate, which was initially an advisory council of the ranking nobility, or patricians, but grew in size and power.[20]  Other magistrates of the Republic include tribunes, quaestors, aediles, praetors and censors.[21] The magistracies were originally restricted to patricians, but were later opened to common people, or plebeians.[22] Republican voting assemblies included the comitia centuriata (centuriate assembly), which voted on matters of war and peace and elected men to the most important offices, and the comitia tributa (tribal assembly), which elected less important offices.[23]  In the 4th century BC, Rome had come under attack by the Gauls, who now extended their power in the Italian peninsula beyond the Po Valley and through Etruria. On 16 July 390\u00a0BC, a Gallic army under the leadership of tribal chieftain Brennus, defeated the Romans at the Battle of the Allia and marched to Rome. The Gauls looted and burned the city, then laid siege to the Capitoline Hill, where some Romans had barricaded themselves, for seven months. The Gauls then agreed to give the Romans peace in exchange for 1000 pounds of gold.[24] According to later legend, the Roman supervising the weighing noticed that the Gauls were using false scales. The Romans then took up arms and defeated the Gauls. Their victorious general Camillus remarked \"With iron, not with gold, Rome buys her freedom.\"[25]  The Romans gradually subdued the other peoples on the Italian peninsula, including the Etruscans.[26] The last threat to Roman hegemony in Italy came when Tarentum, a major Greek colony, enlisted the aid of Pyrrhus of Epirus in 281\u00a0BC, but this effort failed as well.[27][26] The Romans secured their conquests by founding Roman colonies in strategic areas, thereby establishing stable control over the region.[26]  In the 3rd century BC Rome faced a new and formidable opponent: Carthage, the other major power in the Western Mediterranean.[29][30] The First Punic War began in 264\u00a0BC, when the city of Messana asked for Carthage's help in their conflicts with Hiero II of Syracuse. After the Carthaginian intercession, Messana asked Rome to expel the Carthaginians. Rome entered this war because Syracuse and Messana were too close to the newly conquered Greek cities of Southern Italy and Carthage was now able to make an offensive through Roman territory; along with this, Rome could extend its domain over Sicily.[31]  Carthage was a maritime power, and the Roman lack of ships and naval experience made the path to the victory a long and difficult one for the Roman Republic. Despite this, after more than 20 years of war, Rome defeated Carthage and a peace treaty was signed. Among the reasons for the Second Punic War[32] was the subsequent war reparations Carthage acquiesced to at the end of the First Punic War.[33] The war began with the audacious invasion of Hispania by Hannibal, who marched through Hispania to the Italian Alps, causing panic among Rome's Italian allies. The best way found to defeat Hannibal's purpose of causing the Italians to abandon Rome was to delay the Carthaginians with a guerrilla war of attrition, a strategy propounded by Quintus Fabius Maximus Verrucosus. Hannibal's invasion lasted over 16 years, ravaging Italy, but ultimately Carthage was defeated in the decisive Battle of Zama in October 202\u00a0BC.  More than a half century after these events, Carthage was humiliated and the Republic's focus now was only to the Hellenistic kingdoms of Greece and revolts in Hispania. However, Carthage, having paid the war indemnity, felt that its commitments and submission to Rome had ceased, a vision not shared by the Roman Senate. The Third Punic War began when Rome declared war against Carthage in 149\u00a0BC. Carthage resisted well at the first strike but could not withstand the attack of Scipio Aemilianus, who entirely destroyed the city, enslaved all the citizens and gained control of that region, which became the province of Africa. All these wars resulted in Rome's first overseas conquests (Sicily, Hispania and Africa) and the rise of Rome as a significant imperial power.[34][35]  After defeating the Macedonian and Seleucid Empires in the 2nd century BC, the Romans became the dominant people of the Mediterranean Sea.[36] The conquest of the Hellenistic kingdoms brought the Roman and Greek cultures in closer contact and the Roman elite, once rural, became cosmopolitan. At this time Rome was a consolidated empire\u2014in the military view\u2014and had no major enemies.  Foreign dominance led to internal strife. Senators became rich at the provinces' expense; soldiers, who were mostly small-scale farmers, were away from home longer and could not maintain their land; and the increased reliance on foreign slaves and the growth of latifundia reduced the availability of paid work.[37] Income from war booty, mercantilism in the new provinces, and tax farming created new economic opportunities for the wealthy, forming a new class of merchants, called the equestrians.[38] The lex Claudia forbade members of the Senate from engaging in commerce, so while the equestrians could theoretically join the Senate, they were severely restricted in political power.[38][39] The Senate squabbled perpetually, repeatedly blocked important land reforms and refused to give the equestrian class a larger say in the government.  Violent gangs of the urban unemployed, controlled by rival Senators, intimidated the electorate through violence. The situation came to a head in the late 2nd century BC under the Gracchi brothers, a pair of tribunes who attempted to pass land reform legislation that would redistribute the major patrician landholdings among the plebeians. Both brothers were killed and the Senate passed reforms reversing the Gracchi brother's actions.[40] This led to the growing divide of the plebeian groups (populares) and equestrian classes (optimates).  Gaius Marius soon become a leader of the Republic, holding the first of his seven consulships (an unprecedented number) in 107\u00a0BC by arguing that his former patron Quintus Caecilius Metellus Numidicus was not able to defeat and capture the Numidian king Jugurtha. Marius then started his military reform: in his recruitment to fight Jugurtha, he levied the very poor (an innovation), and many landless men entered the army. Marius was elected for five consecutive consulships from 104 to 100\u00a0BC, as Rome needed a military leader to defeat the Cimbri and the Teutones, who were threatening Rome. After Marius's retirement, Rome had a brief peace, during which the Italian socii (\"allies\" in Latin) requested Roman citizenship and voting rights. The reformist Marcus Livius Drusus supported their legal process but was assassinated, and the socii revolted against the Romans in the Social War. At one point both consuls were killed; Marius was appointed to command the army together with Lucius Julius Caesar and Lucius Cornelius Sulla.[41]  By the end of the Social War, Marius and Sulla were the premier military men in Rome and their partisans were in conflict, both sides jostling for power. In 88\u00a0BC, Sulla was elected for his first consulship and his first assignment was to defeat Mithridates VI of Pontus, whose intentions were to conquer the Eastern part of the Roman territories. However, Marius's partisans managed his installation to the military command, defying Sulla and the Senate. To consolidate his own power, Sulla conducted a surprising and illegal action: he marched to Rome with his legions, killing all those who showed support to Marius's cause. In the following year, 87\u00a0BC, Marius, who had fled at Sulla's march, returned to Rome while Sulla was campaigning in Greece. He seized power along with the consul Lucius Cornelius Cinna and killed the other consul, Gnaeus Octavius, achieving his seventh consulship. Marius and Cinna revenged their partisans by conducting a massacre.[41][42]  Marius died in 86\u00a0BC, due to age and poor health, just a few months after seizing power. Cinna exercised absolute power until his death in 84\u00a0BC. After returning from his Eastern campaigns, Sulla had a free path to reestablish his own power. In 83\u00a0BC he made his second march in Rome and began a time of terror: thousands of nobles, knights and senators were executed. Sulla held two dictatorships and one more consulship, which began the crisis and decline of Roman Republic.[41]  In the mid-1st century BC, Roman politics were restless. Political divisions in Rome split into one of two groups, populares (who hoped for the support of the people) and optimates (the \"best\", who wanted to maintain exclusive aristocratic control). Sulla overthrew all populist leaders and his constitutional reforms removed powers (such as those of the tribune of the plebs) that had supported populist approaches. Meanwhile, social and economic stresses continued to build; Rome had become a metropolis with a super-rich aristocracy, debt-ridden aspirants, and a large proletariat often of impoverished farmers. The latter groups supported the Catilinarian conspiracy\u2014a resounding failure since the consul Marcus Tullius Cicero quickly arrested and executed the main leaders.  Gaius Julius Caesar reconciled the two most powerful men in Rome: Marcus Licinius Crassus, who had financed much of his earlier career, and Crassus' rival, Gnaeus Pompeius Magnus (anglicised as Pompey), to whom he married his daughter. He formed them into a new informal alliance including himself, the First Triumvirate (\"three men\"). Caesar's daughter died in childbirth in 54 BC, and in 53\u00a0BC, Crassus invaded Parthia and was killed in the Battle of Carrhae; the Triumvirate disintegrated. Caesar conquered Gaul, obtained immense wealth, respect in Rome and the loyalty of battle-hardened legions. He became a threat to Pompey and was loathed by many optimates. Confident that Caesar could be stopped by legal means, Pompey's party tried to strip Caesar of his legions, a prelude to Caesar's trial, impoverishment, and exile.  To avoid this fate, Caesar crossed the Rubicon River and invaded Rome in 49\u00a0BC. The Battle of Pharsalus was a brilliant victory for Caesar and in this and other campaigns, he destroyed all of the optimates leaders: Metellus Scipio, Cato the Younger, and Pompey's son, Gnaeus Pompeius. Pompey was murdered in Egypt in 48\u00a0BC. Caesar was now pre-eminent over Rome: in five years he held four consulships, two ordinary dictatorships, and two special dictatorships, one for perpetuity. He was murdered in 44\u00a0BC, on the Ides of March by the Liberatores.[43]  Caesar's assassination caused political and social turmoil in Rome; the city was ruled by his friend and colleague, Marcus Antonius. Soon afterward, Octavius, whom Caesar adopted through his will, arrived in Rome. Octavian (historians regard Octavius as Octavian due to the Roman naming conventions) tried to align himself with the Caesarian faction. In 43\u00a0BC, along with Antony and Marcus Aemilius Lepidus, Caesar's best friend,[44] he legally established the Second Triumvirate. Upon its formation, 130\u2013300 senators were executed, and their property was confiscated, due to their supposed support for the Liberatores.[45]  In 42\u00a0BC, the Senate deified Caesar as Divus Iulius; Octavian thus became Divi filius,[46] the son of the deified. In the same year, Octavian and Antony defeated both Caesar's assassins and the leaders of the Liberatores, Marcus Junius Brutus and Gaius Cassius Longinus, in the Battle of Philippi. The Second Triumvirate was marked by the proscriptions of many senators and equites: after a revolt led by Antony's brother Lucius Antonius, more than 300 senators and equites involved were executed, although Lucius was spared.[47]  The Triumvirate divided the Empire among the triumvirs: Lepidus was given charge of Africa, Antony, the eastern provinces, and Octavian remained in Italia and controlled Hispania and Gaul. The Second Triumvirate expired in 38\u00a0BC but was renewed for five more years. However, the relationship between Octavian and Antony had deteriorated, and Lepidus was forced to retire in 36\u00a0BC after betraying Octavian in Sicily. By the end of the Triumvirate, Antony was living in Ptolemaic Egypt, ruled by his lover, Cleopatra VII. Antony's affair with Cleopatra was seen as an act of treason, since she was queen of another country. Additionally, Antony adopted a lifestyle considered too extravagant and Hellenistic for a Roman statesman.[48] Following Antony's Donations of Alexandria, which gave to Cleopatra the title of \"Queen of Kings\", and to Antony's and Cleopatra's children the regal titles to the newly conquered Eastern territories, war between Octavian and Antony broke out. Octavian annihilated Egyptian forces in the Battle of Actium in 31\u00a0BC. Antony and Cleopatra committed suicide. Now Egypt was conquered by the Roman Empire.  In 27\u00a0BC and at the age of 36, Octavian was the sole Roman leader. In that year, he took the name Augustus. That event is usually taken by historians as the beginning of Roman Empire. Officially, the government was republican, but Augustus assumed absolute powers.[49][50] His reform of the government brought about a two-century period colloquially referred to by Romans as the Pax Romana.  The Julio-Claudian dynasty was established by Augustus. The emperors of this dynasty were Augustus, Tiberius, Caligula, Claudius and Nero. The Julio-Claudians started the destruction of republican values, but on the other hand, they boosted Rome's status as the central power in the Mediterranean region.[51] While Caligula and Nero are usually remembered in popular culture as dysfunctional emperors, Augustus and Claudius are remembered as successful in politics and the military. This dynasty instituted imperial tradition in Rome[52] and frustrated any attempt to reestablish a Republic.[53]  Augustus (r.\u200927 BC\u00a0\u2013\u00a0AD 14) gathered almost all the republican powers under his official title, princeps, and diminished the political influence of the senatorial class by boosting the equestrian class. The senators lost their right to rule certain provinces, like Egypt, since the governor of that province was directly nominated by the emperor. The creation of the Praetorian Guard and his reforms in the military, creating a standing army with a fixed size of 28 legions, ensured his total control over the army.[54] Compared with the Second Triumvirate's epoch, Augustus' reign as princeps was very peaceful, which led the people and the nobles of Rome to support Augustus, increasing his strength in political affairs.[55] His generals were responsible for the field command; gaining such commanders as Marcus Vipsanius Agrippa, Nero Claudius Drusus and Germanicus much respect from the populace and the legions. Augustus intended to extend the Roman Empire to the whole known world, and in his reign, Rome conquered Cantabria, Aquitania, Raetia, Dalmatia, Illyricum and Pannonia.[56] Under Augustus' reign, Roman literature grew steadily in what is known as the Golden Age of Latin Literature. Poets like Virgil, Horace, Ovid and Rufus developed a rich literature, and were close friends of Augustus. Along with Maecenas, he sponsored patriotic poems, as Virgil's epic Aeneid and historiographical works, like those of Livy. Augustus continued the changes to the calendar promoted by Caesar, and the month of August is named after him.[57] Augustus brought a peaceful and thriving era to Rome, known as Pax Augusta or Pax Romana. Augustus died in 14\u00a0AD, but the empire's glory continued after his era.  The Julio-Claudians continued to rule Rome after Augustus' death and remained in power until the death of Nero in 68\u00a0AD.[58] Influenced by his wife, Livia Drusilla, Augustus appointed her son from another marriage, Tiberius, as his heir.[59] The Senate agreed with the succession, and granted to Tiberius the same titles and honours once granted to Augustus: the title of princeps and Pater patriae, and the Civic Crown. However, Tiberius was not an enthusiast for political affairs: after agreement with the Senate, he retired to Capri in 26\u00a0AD,[60] and left control of the city of Rome in the hands of the praetorian prefect Sejanus (until 31\u00a0AD) and Macro (from 31 to 37\u00a0AD).  Tiberius died (or was killed)[61] in 37\u00a0AD. The male line of the Julio-Claudians was limited to Tiberius' nephew Claudius, his grandson Tiberius Gemellus and his grand-nephew Caligula. As Gemellus was still a child, Caligula was chosen to rule the empire. He was a popular leader in the first half of his reign, but became a crude and insane tyrant in his years controlling government.[62] The Praetorian Guard murdered Caligula four years after the death of Tiberius,[63] and, with belated support from the senators, proclaimed his uncle Claudius as the new emperor.[64] Claudius was not as authoritarian as Tiberius and Caligula. Claudius conquered Lycia and Thrace; his most important deed was the beginning of the conquest of Britannia.[65] Claudius was poisoned by his wife, Agrippina the Younger in 54\u00a0AD.[66] His heir was Nero, son of Agrippina and her former husband, since Claudius' son Britannicus had not reached manhood upon his father's death.  Nero sent his general, Suetonius Paulinus, to invade modern-day Wales, where he encountered stiff resistance. The Celts there were independent, tough and resistant to tax collectors and fought Paulinus, as he battled his way across from east to west. It took him a long time to reach the north west coast, and in 60 AD he finally crossed the Menai Strait to the sacred island of Mona (Anglesey), the last stronghold of the druids.[67] His soldiers attacked the island and massacred the druids: men, women and children,[68] destroyed the shrine and the sacred groves and threw many of the sacred standing stones into the sea. While Paulinus and his troops were massacring druids in Mona, the tribes of modern-day East Anglia staged a revolt led by queen Boadicea of the Iceni.[69] The rebels sacked and burned Camulodunum, Londinium and Verulamium (modern-day Colchester, London and St Albans respectively) before they were crushed by Paulinus.[70] Boadicea, like Cleopatra before her, committed suicide to avoid the disgrace of being paraded in triumph in Rome.[71] Nero is widely known as the first persecutor of Christians and for the Great Fire of Rome, rumoured to have been started by the emperor himself.[72] A conspiracy against Nero in 65 AD under Calpurnius Piso failed, but in 68 AD the armies under Julius Vindex in Gaul and Servius Sulpicius Galba in modern-day Spain revolted. Deserted by the Praetorian Guards and condemned to death by the senate, Nero killed himself.[73]  The Flavians were the second dynasty to rule Rome.[74] By 68\u00a0AD, the year of Nero's death, there was no chance of a return to the Roman Republic, and so a new emperor had to arise. After the turmoil in the Year of the Four Emperors, Titus Flavius Vespasianus (anglicised as Vespasian) took control of the empire and established a new dynasty. Under the Flavians, Rome continued its expansion, and the state remained secure.[75] Under Trajan, the Roman Empire reached the peak of its territorial expansion.[76] Rome's dominion now spanned 5.0\u00a0million square kilometres (1.9\u00a0million square miles).[2]  The most significant military campaign undertaken during the Flavian period was the siege and destruction of Jerusalem in 70 AD by Titus. The destruction of the city was the culmination of the Roman campaign in Judea following the Jewish uprising of 66 AD. The Second Temple was completely demolished, after which Titus' soldiers proclaimed him imperator in honour of the victory. Jerusalem was sacked and much of the population killed or dispersed. Josephus claims that 1,100,000 people were killed during the siege, of whom a majority were Jewish.[77] 97,000 were captured and enslaved, including Simon bar Giora and John of Giscala. Many fled to areas around the Mediterranean.  Vespasian was a general under Claudius and Nero and fought as a commander in the First Jewish-Roman War. Following the turmoil of the Year of the Four Emperors, in 69\u00a0AD, four emperors were enthroned in turn: Galba, Otho, Vitellius, and, lastly, Vespasian, who crushed Vitellius' forces and became emperor.[78] He reconstructed many buildings which were uncompleted, like a statue of Apollo and the temple of Divus Claudius (\"the deified Claudius\"), both initiated by Nero. Buildings destroyed by the Great Fire of Rome were rebuilt, and he revitalised the Capitol. Vespasian started the construction of the Flavian Amphitheater, commonly known as the Colosseum.[78] The historians Josephus and Pliny the Elder wrote their works during Vespasian's reign. Vespasian was Josephus' sponsor and Pliny dedicated his Naturalis Historia to Titus, son of Vespasian. Vespasian sent legions to defend the eastern frontier in Cappadocia, extended the occupation in Britannia (modern-day England, Wales and southern Scotland) and reformed the tax system. He died in 79\u00a0AD.  Titus became emperor in 79. He finished the Flavian Amphitheater, using war spoils from the First Jewish-Roman War, and hosted victory games that lasted for a hundred days. These games included gladiatorial combats, horse races and a sensational mock naval battle on the flooded grounds of the Colosseum.[79] Titus died of fever in 81\u00a0AD, and was succeeded by his brother Domitian. As emperor, Domitian showed the characteristics of a tyrant.[80] He ruled for fifteen years, during which time he acquired a reputation for self-promotion as a living god. He constructed at least two temples in honour of Jupiter, the supreme deity in Roman religion.[81] He was murdered following a plot within his own household.  Following Domitian's murder, the Senate rapidly appointed Nerva as Emperor. Nerva had noble ancestry, and he had served as an advisor to Nero and the Flavians. His rule restored many of the traditional liberties of Rome's upper classes, which Domitian had over-ridden.[82][83] The Nerva\u2013Antonine dynasty from 96 AD to 192 AD included the \"five good emperors\" Nerva, Trajan, Hadrian, Antoninus Pius and Marcus Aurelius; and ended with Commodus.  Nerva abdicated and died in 98\u00a0AD, and was succeeded by the general Trajan. Trajan is credited with the restoration of traditional privileges and rights of commoner and senatorial classes, which later Roman historians claim to have been eroded during Domitian's autocracy.[84] Trajan fought three Dacian wars, winning territories roughly equivalent to modern-day Romania and Moldova. He undertook an ambitious public building program in Rome, including Trajan's Forum, Trajan's Market and Trajan's Column, with the architect Apollodorus of Damascus. He remodelled the Pantheon and extended the Circus Maximus.[85] When Parthia appointed a king for Armenia without consulting Rome, Trajan declared war on Parthia and deposed the king of Armenia. In 115 he took the Northern Mesopotamian cities of Nisibis and Batnae, organised a province of Mesopotamia (116), and issued coins that claimed Armenia and Mesopotamia were under the authority of the Roman people.[86] In that same year, he captured Seleucia and the Parthian capital Ctesiphon (near modern Baghdad).[87] After defeating a Parthian revolt and a Jewish revolt, he withdrew due to health issues, and in 117, he died of edema.  Many Romans emigrated to Hispania (modern-day Spain and Portugal) and stayed for generations, in some cases intermarrying with Iberians; one of these families produced the emperor Hadrian.[88] Hadrian withdrew all the troops stationed in Parthia, Armenia and Mesopotamia (modern-day Iraq), abandoning Trajan's conquests. Hadrian's army crushed a revolt in Mauretania and the Bar Kokhba revolt in Judea. This was the last large-scale Jewish revolt against the Romans, and was suppressed with massive repercussions in Judea. Hundreds of thousands of Jews were killed. Hadrian renamed the province of Judea \"Provincia Syria Palaestina\", after one of Judea's most hated enemies.[89] He constructed fortifications and walls, like the celebrated Hadrian's Wall which separated Roman Britannia and the tribes of modern-day Scotland. Hadrian promoted culture, especially the Greek. He forbade torture and humanised the laws. His many building projects included aqueducts, baths, libraries and theatres; additionally, he travelled nearly every province in the Empire to review military and infrastructural conditions.[90] Following Hadrian's death in 138 AD, his successor Antoninus Pius built temples, theatres, and mausoleums, promoted the arts and sciences, and bestowed honours and financial rewards upon the teachers of rhetoric and philosophy. On becoming emperor, Antoninus made few initial changes, leaving intact as far as possible the arrangements instituted by his predecessor. Antoninus expanded Roman Britannia by invading what is now southern Scotland and building the Antonine Wall.[91] He also continued Hadrian's policy of humanising the laws. He died in 161\u00a0AD.  Marcus Aurelius, known as the Philosopher, was the last of the Five Good Emperors. He was a stoic philosopher and wrote the Meditations. He defeated barbarian tribes in the Marcomannic Wars as well as the Parthian Empire.[92] His co-emperor, Lucius Verus, died in 169\u00a0AD, probably from the Antonine Plague, a pandemic that killed nearly five million people through the Empire in 165\u2013180\u00a0AD.[93]  From Nerva to Marcus Aurelius, the empire achieved an unprecedented status. The powerful influence of laws and manners had gradually cemented the union of the provinces. All the citizens enjoyed and abused the advantages of wealth. The image of a free constitution was preserved with decent reverence. The Roman senate appeared to possess the sovereign authority, and devolved on the emperors all the executive powers of government. Gibbon declared the rule of these \"Five Good Emperors\" the golden era of the Empire.[94] During this time, Rome reached its greatest territorial extent.[95]  Commodus, son of Marcus Aurelius, became emperor after his father's death. He is not counted as one of the Five Good Emperors, due to his direct kinship with the latter emperor; in addition, he was militarily passive. Cassius Dio identifies his reign as the beginning of Roman decadence: \"(Rome has transformed) from a kingdom of gold to one of iron and rust.\"[92]  Commodus was killed by a conspiracy involving Quintus Aemilius Laetus and his wife Marcia in late 192\u00a0AD. The following year is known as the Year of the Five Emperors, during which Helvius Pertinax, Didius Julianus, Pescennius Niger, Clodius Albinus and Septimius Severus held the imperial dignity. Pertinax, a member of the senate who had been one of Marcus Aurelius's right-hand men, was the choice of Laetus, and he ruled vigorously and judiciously. Laetus soon became jealous and instigated Pertinax's murder by the Praetorian Guard, who then auctioned the empire to the highest bidder, Didius Julianus, for 25,000 sesterces per man.[96] The people of Rome were appalled and appealed to the frontier legions to save them. The legions of three frontier provinces\u2014Britannia, Pannonia Superior, and Syria\u2014resented being excluded from the \"donative\" and replied by declaring their individual generals to be emperor. Lucius Septimius Severus Geta, the Pannonian commander, bribed the opposing forces, pardoned the Praetorian Guards and installed himself as emperor. He and his successors governed with the legions' support. The changes on coinage and military expenditures were the root of the financial crisis that marked the Crisis of the Third Century.  Severus was enthroned after invading Rome and having Didius Julianus killed. Severus attempted to revive totalitarianism and, addressing the Roman people and Senate, praised the severity and cruelty of Marius and Sulla, which worried the senators.[97] When Parthia invaded Roman territory, Severus successfully waged war against that country. Notwithstanding this military success, Severus failed in invading Hatra, a rich Arabian city. Severus killed his legate, who was gaining respect from the legions; and his soldiers fell victim to famine. After this disastrous campaign, he withdrew.[98] Severus also intended to vanquish the whole of Britannia. To achieve this, he waged war against the Caledonians. After many casualties in the army due to the terrain and the barbarians' ambushes, Severus himself went to the field. However, he became ill and died in 211\u00a0AD, at the age of 65.  Upon the death of Severus, his sons Caracalla and Geta were made emperors. Caracalla had his brother, a youth, assassinated in his mother's arms, and may have murdered 20,000 of Geta's followers. Like his father, Caracalla was warlike. He continued Severus' policy and gained respect from the legions. Knowing that the citizens of Alexandria disliked him and were denigrating his character, Caracalla served a banquet for its notable citizens, after which his soldiers killed all the guests. From the security of the temple of Sarapis, he then directed an indiscriminate slaughter of Alexandria's people.[99] In 212, he issued the Edict of Caracalla, giving full Roman citizenship to all free men living in the Empire, with the exception of the dediticii, people who had become subject to Rome through surrender in war, and freed slaves.[100]  Mary Beard points to the edict as a fundamental turning point, after which Rome was \"effectively a new state masquerading under an old name\".[101]  Macrinus conspired to have Caracalla assassinated by one of his soldiers during a pilgrimage to the Temple of the Moon in Carrhae, in 217\u00a0AD. Macrinus assumed power, but soon removed himself from Rome to the east and Antioch. His brief reign ended in 218, when the youngster Bassianus, high priest of the temple of the Sun at Emesa, and supposedly illegitimate son of Caracalla, was declared Emperor by the disaffected soldiers of Macrinus. He adopted the name of Antoninus but history has named him after his Sun god Elagabalus, represented on Earth in the form of a large black stone. An incompetent and lascivious ruler,[34] Elagabalus offended all but his favourites. Cassius Dio, Herodian and the Historia Augusta give many accounts of his notorious extravagance. Elagabalus adopted his cousin Severus Alexander, as Caesar, but subsequently grew jealous and attempted to assassinate him. However, the Praetorian guard preferred Alexander, murdered Elagabalus, dragged his mutilated corpse through the streets of Rome, and threw it into the Tiber. Severus Alexander then succeeded him. Alexander waged war against many foes, including the revitalised Persia and also the Germanic peoples, who invaded Gaul. His losses generated dissatisfaction among his soldiers, and some of them murdered him during his Germanic campaign in 235\u00a0AD.[102]  A disastrous scenario emerged after the death of Alexander Severus: the Roman state was plagued by civil wars, external invasions, political chaos, pandemics and economic depression.[103][34] The old Roman values had fallen, and Mithraism and Christianity had begun to spread through the populace. Emperors were no longer men linked with nobility; they usually were born in lower-classes of distant parts of the Empire. These men rose to prominence through military ranks, and became emperors through civil wars.  There were 26 emperors in a 49-year period, a signal of political instability. Maximinus Thrax was the first ruler of that time, governing for just three years. Others ruled just for a few months, like Gordian I, Gordian II, Balbinus and Hostilian. The population and the frontiers were abandoned, since the emperors were mostly concerned with defeating rivals and establishing their power. The economy also suffered: massive military expenditures from the Severi caused a devaluation of Roman coins. Hyperinflation came at this time as well. The Plague of Cyprian broke out in 250 and killed a huge portion of the population.[104] In 260\u00a0AD, the provinces of Syria Palaestina, Asia Minor and Egypt separated from the rest of the Roman state to form the Palmyrene Empire, ruled by Queen Zenobia and centered on Palmyra. In that same year the Gallic Empire was created by Postumus, retaining Britannia and Gaul.[105] These countries separated from Rome after the capture of emperor Valerian by the Sassanids of Persia, the first Roman ruler to be captured by his enemies; it was a humiliating fact for the Romans.[104] The crisis began to recede during the reigns of Claudius Gothicus (268\u2013270), who defeated the Gothic invaders, and Aurelian (271\u2013275), who reconquered both the Gallic and Palmyrene Empires.[106] The crisis was overcome during the reign of Diocletian.  In 284\u00a0AD, Diocletian was hailed as Imperator by the eastern army. Diocletian healed the empire from the crisis, by political and economic shifts. A new form of government was established: the Tetrarchy. The Empire was divided among four emperors, two in the West and two in the East. The first tetrarchs were Diocletian (in the East), Maximian (in the West), and two junior emperors, Galerius (in the East) and Flavius Constantius (in the West). To adjust the economy, Diocletian made several tax reforms.[107]  Diocletian expelled the Persians who plundered Syria and conquered some barbarian tribes with Maximian. He adopted many behaviours of Eastern monarchs. Anyone in the presence of the emperor had now to prostrate himself\u2014a common act in the East, but never practised in Rome before.[108] Diocletian did not use a disguised form of Republic, as the other emperors since Augustus had done.[109] Between 290 and 330, half a dozen new capitals had been established by the members of the Tetrarchy, officially or not: Antioch, Nicomedia, Thessalonike, Sirmium, Milan, and Trier.[110] Diocletian was also responsible for a significant Christian persecution. In 303 he and Galerius started the persecution and ordered the destruction of all the Christian churches and scripts and forbade Christian worship.[111] Diocletian abdicated in 305\u00a0AD together with Maximian, thus, he was the first Roman emperor to resign. His reign ended the traditional form of imperial rule, the Principate (from princeps) and started the Tetrarchy.  Constantine assumed the empire as a tetrarch in 306. He conducted many wars against the other tetrarchs. Firstly he defeated Maxentius in 312. In 313, he issued the Edict of Milan, which granted liberty for Christians to profess their religion.[112] Constantine was converted to Christianity, enforcing the Christian faith. He began the Christianization of the Empire and of Europe\u2014a process concluded by the Catholic Church in the Middle Ages. He was defeated by the Franks and the Alamanni during 306\u2013308. In 324 he defeated another tetrarch, Licinius, and controlled all the empire, as it was before Diocletian. To celebrate his victories and Christianity's relevance, he rebuilt Byzantium and renamed it Nova Roma (\"New Rome\"); but the city soon gained the informal name of Constantinople (\"City of Constantine\").[113]  The reign of Julian, who under the influence of his adviser Mardonius attempted to restore Classical Roman and Hellenistic religion, only briefly interrupted the succession of Christian emperors. Constantinople served as a new capital for the Empire. In fact, Rome had lost its central importance since the Crisis of the Third Century\u2014Mediolanum was the western capital from 286 to 330, until the reign of Honorius, when Ravenna was made capital, in the 5th century.[114] Constantine's administrative and monetary reforms, that reunited the Empire under one emperor, and rebuilt the city of Byzantium, as Constantinopolis Nova Roma, changed the high period of the ancient world.  In the late 4th and 5th centuries the Western Empire entered a critical stage which terminated with the fall of the Western Roman Empire.[115] Under the last emperors of the Constantinian dynasty and the Valentinianic dynasty, Rome lost decisive battles against the Sasanian Empire and Germanic barbarians: in 363, emperor Julian the Apostate was killed in the Battle of Samarra, against the Persians and the Battle of Adrianople cost the life of emperor Valens (364\u2013378); the victorious Goths were never expelled from the Empire nor assimilated.[116] The next emperor, Theodosius I (379\u2013395), gave even more force to the Christian faith, and after his death, the Empire was divided into the Eastern Roman Empire, ruled by Arcadius and the Western Roman Empire, commanded by Honorius, both of which were Theodosius' sons.[117]  The situation became more critical in 408, after the death of Stilicho, a general who tried to reunite the Empire and repel barbarian invasion in the early years of the 5th century. The professional field army collapsed. In 410, the Theodosian dynasty saw the Visigoths sack Rome.[118] During the 5th century, the Western Empire experienced a significant reduction of its territory. The Vandals conquered North Africa, the Visigoths claimed the southern part of Gaul, Gallaecia was taken by the Suebi, Britannia was abandoned by the central government, and the Empire suffered further from the invasions of Attila, chief of the Huns.[119] General Orestes refused to meet the demands of the barbarian \"allies\" who now formed the army, and tried to expel them from Italy. Unhappy with this, their chieftain Odoacer defeated and killed Orestes, invaded Ravenna and dethroned Romulus Augustus, son of Orestes. This event of 476, usually marks the end of Classical antiquity and beginning of the Middle Ages.[120] The Roman noble and former emperor Julius Nepos continued to rule as emperor from Dalmatia even after the deposition of Romulus Augustus until his death in 480. Some historians consider him to be the last emperor of the Western Empire instead of Romulus Augustus.[121]  After 1200 years of independence and nearly 700 years as a great power, the rule of Rome in the West ended.[122] Various reasons for Rome's fall have been proposed ever since, including loss of Republicanism, moral decay, military tyranny, class war, slavery, economic stagnation, environmental change, disease, the decline of the Roman race, as well as the inevitable ebb and flow that all civilisations experience. The Eastern Empire survived for almost 1000 years after the fall of its Western counterpart and became the most stable Christian realm during the Middle Ages. During the 6th century, Justinian reconquered the Italian peninsula from the Ostrogoths, North Africa from the Vandals, and southern Hispania from the Visigoths. But within a few years of Justinian's death, Eastern Roman (Byzantine) possessions in Italy were greatly reduced by the Lombards who settled in the peninsula.[123] In the east, partially due to the weakening effect of the Plague of Justinian, the Byzantine Romans were threatened by the rise of Islam. Its followers rapidly brought about the conquest of the Levant, the conquest of Armenia and the conquest of Egypt during the Arab\u2013Byzantine wars, and soon presented a direct threat to Constantinople.[124][125] In the following century, the Arabs captured southern Italy and Sicily.[126] In the west, Slavic populations penetrated deep into the Balkans.  The Byzantine Romans, however, managed to stop further Islamic expansion into their lands during the 8th century and, beginning in the 9th century, reclaimed parts of the conquered lands.[124][127] In 1000\u00a0AD, the Eastern Empire was at its height: Basil II reconquered Bulgaria and Armenia, and culture and trade flourished.[128] However, soon after, this expansion was abruptly stopped in 1071 with the Byzantine defeat in the Battle of Manzikert. The aftermath of this battle sent the empire into a protracted period of decline. Two decades of internal strife and Turkic invasions ultimately led Emperor Alexios I Komnenos to send a call for help to the Western European kingdoms in 1095.[124] The West responded with the Crusades, eventually resulting in the Sack of Constantinople by participants of the Fourth Crusade. The conquest of Constantinople in 1204 fragmented what remained of the Empire into successor states; the ultimate victor was the Empire of Nicaea.[129] After the recapture of Constantinople by Imperial forces, the Empire was little more than a Greek state confined to the Aegean coast. The Eastern Roman (Byzantine) Empire collapsed when Mehmed the Conqueror conquered Constantinople on 29 May\u00a01453.[130]  The imperial city of Rome was the largest urban center in the empire, with a population variously estimated from 450,000 to close to one million.[131] Around 20 per cent of the population under jurisdiction of ancient Rome (25\u201340%, depending on the standards used, in Roman Italy)[132] lived in innumerable urban centers, with population of 10,000 and more and several military settlements, a very high rate of urbanisation by pre-industrial standards. Most of those centers had a forum, temples, and other buildings similar to Rome's. The average life expectancy in the Middle Empire was about 26\u201328 years.[133][134]  The roots of the legal principles and practices of the ancient Romans may be traced to the Law of the Twelve Tables promulgated in 449\u00a0BC and to the codification of law issued by order of Emperor Justinian I around 530\u00a0AD (see Corpus Juris Civilis). Roman law as preserved in Justinian's codes continued into the Byzantine Roman Empire, and formed the basis of similar codifications in continental Western Europe. Roman law continued, in a broader sense, to be applied throughout most of Europe until the end of the 17th century.  The major divisions of the law of ancient Rome, as contained within the Justinian and Theodosian law codes, consisted of Jus civile, Jus gentium, and Jus naturale. The Jus civile (\"Citizen Law\") was the body of common laws that applied to Roman citizens.[135] The praetores urbani (sg. Praetor Urbanus) were the people who had jurisdiction over cases involving citizens. The Jus gentium (\"Law of nations\") was the body of common laws that applied to foreigners, and their dealings with Roman citizens.[136] The praetores peregrini (sg. Praetor Peregrinus) were the people who had jurisdiction over cases involving citizens and foreigners. Jus naturale encompassed natural law, the body of laws that were considered common to all beings.  Roman society is largely viewed as hierarchical, with slaves (servi) at the bottom, freedmen (liberti) above them, and free-born citizens (cives) at the top. Free citizens were subdivided by class. The broadest, and earliest, division was between the patricians, who could trace their ancestry to one of the 100 patriarchs at the founding of the city, and the plebeians, who could not. This became less important in the later Republic, as some plebeian families became wealthy and entered politics, and some patrician families fell economically. Anyone, patrician or plebeian, who could count a consul as his ancestor was a noble (nobilis); a man who was the first of his family to hold the consulship, such as Marius or Cicero, was known as a novus homo (\"new man\") and ennobled his descendants. Patrician ancestry, however, still conferred considerable prestige, and many religious offices remained restricted to patricians.  A class division originally based on military service became more important. Membership of these classes was determined periodically by the censors, according to property. The wealthiest were the Senatorial class, who dominated politics and command of the army. Next came the equestrians (equites, sometimes translated \"knights\"), originally those who could afford a warhorse, and who formed a powerful mercantile class. Several further classes, originally based on the military equipment their members could afford, followed, with the proletarii, citizens who had no property other than their children, at the bottom. Before the reforms of Marius they were ineligible for military service and are often described as being just above freed slaves in wealth and prestige.  Voting power in the Republic depended on class. Citizens were enrolled in voting \"tribes\", but the tribes of the richer classes had fewer members than the poorer ones, all the proletarii being enrolled in a single tribe. Voting was done in class order, from top down, and stopped as soon as most of the tribes had been reached, so the poorer classes were often unable to cast their votes.  Women in ancient Rome shared some basic rights with their male counterparts, but were not fully regarded as citizens and were thus not allowed to vote or take part in politics. At the same time the limited rights of women were gradually expanded (due to emancipation) and women reached freedom from pater familias, gained property rights and even had more juridical rights than their husbands, but still no voting rights, and were absent from politics.[137]  Allied foreign cities were often given the Latin Rights, an intermediary level between full citizens and foreigners (peregrini), which gave their citizens rights under Roman law and allowed their leading magistrates to become full Roman citizens. While there were varying degrees of Latin rights, the main division was between those cum suffragio (\"with vote\"; enrolled in a Roman tribe and able to take part in the comitia tributa) and sine suffragio (\"without vote\"; could not take part in Roman politics). Most of Rome's Italian allies were given full citizenship after the Social War of 91\u201388\u00a0BC, and full Roman citizenship was extended to all free-born men in the Empire by Caracalla in 212, with the exception of the dediticii, people who had become subject to Rome through surrender in war, and freed slaves.[100]  In the early Republic, there were no public schools, so boys were taught to read and write by their parents, or by educated slaves, called paedagogi, usually of Greek origin.[138][139][140] The primary aim of education during this period was to train young men in agriculture, warfare, Roman traditions, and public affairs.[138] Young boys learned much about civic life by accompanying their fathers to religious and political functions, including the Senate for the sons of nobles.[139] The sons of nobles were apprenticed to a prominent political figure at the age of 16, and campaigned with the army from the age of 17.[139] Educational practices were modified after the conquest of the Hellenistic kingdoms in the 3rd century BC and the resulting Greek influence, although Roman educational practices were still much different from Greek ones.[139][141] If their parents could afford it, boys and some girls at the age of 7 were sent to a private school outside the home called a ludus, where a teacher (called a litterator or a magister ludi, and often of Greek origin) taught them basic reading, writing, arithmetic, and sometimes Greek, until the age of 11.[139][140][142]  Beginning at age 12, students went to secondary schools, where the teacher (now called a grammaticus) taught them about Greek and Roman literature.[139][142] At the age of 16, some students went on to rhetoric school (where the teacher, usually Greek, was called a rhetor).[139][142] Education at this level prepared students for legal careers, and required that the students memorise the laws of Rome.[139]  Initially, Rome was ruled by kings, who were elected from each of Rome's major tribes in turn.[143] The exact nature of the king's power is uncertain. He may have held near-absolute power, or may have merely been the chief executive of the Senate and the people. In military matters, the king's authority (Imperium) was likely absolute. He was also the head of the state religion. In addition to the authority of the King, there were three administrative assemblies: the Senate, which acted as an advisory body for the King; the Comitia Curiata, which could endorse and ratify laws suggested by the King; and the Comitia Calata, which was an assembly of the priestly college that could assemble the people to bear witness to certain acts, hear proclamations, and declare the feast and holiday schedule for the next month.  The class struggles of the Roman Republic resulted in an unusual mixture of democracy and oligarchy. The word republic comes from the Latin res publica, which literally translates to \"public business\". Roman laws traditionally could only be passed by a vote of the Popular assembly (Comitia Tributa). Likewise, candidates for public positions had to run for election by the people. However, the Roman Senate represented an oligarchic institution, which acted as an advisory body.  In the Republic, the Senate held actual authority (auctoritas), but no real legislative power; it was technically only an advisory council. However, as the Senators were individually very influential, it was difficult to accomplish anything against the collective will of the Senate. New senators were chosen from among the most accomplished patricians by censors (Censura), who could also remove a senator from his office if he was found \"morally corrupt\"; a charge that could include bribery or, as under Cato the Elder, embracing one's wife in public. Later, under the reforms of the dictator Sulla, quaestors were made automatic members of the Senate, though most of his reforms did not survive.  The Republic had no fixed bureaucracy, and collected taxes through the practice of tax farming. Government positions such as quaestor, aedile, or praefect were funded by the office-holder. To prevent any citizen from gaining too much power, new magistrates were elected annually and had to share power with a colleague. For example, under normal conditions, the highest authority was held by two consuls. In an emergency, a temporary dictator could be appointed. Throughout the Republic, the administrative system was revised several times to comply with new demands. In the end, it proved inefficient for controlling the ever-expanding dominion of Rome, contributing to the establishment of the Roman Empire.  In the early Empire, the pretense of a republican form of government was maintained. The Roman Emperor was portrayed as only a princeps, or \"first citizen\", and the Senate gained legislative power and all legal authority previously held by the popular assemblies. However, the rule of the Emperors became increasingly autocratic, and the Senate was reduced to an advisory body appointed by the Emperor. The Empire did not inherit a set bureaucracy from the Republic, since the Republic did not have any permanent governmental structures apart from the Senate. The Emperor appointed assistants and advisers, but the state lacked many institutions, such as a centrally planned budget. Some historians have cited this as a significant reason for the decline of the Roman Empire.  The early Roman army (c.\u2009500\u00a0BC) was, like those of other contemporary city-states influenced by Greek civilisation, a citizen militia that practised hoplite tactics. It was small and organised in five classes (in parallel to the comitia centuriata, the body of citizens organised politically), with three providing hoplites and two providing light infantry. The early Roman army was tactically limited and its stance during this period was essentially defensive.[144][145][146]  By the 3rd century BC, the Romans abandoned the hoplite formation in favour of a more flexible system in which smaller groups of 120 (or sometimes 60) men called maniples could manoeuvre more independently on the battlefield. Thirty maniples arranged in three lines with supporting troops constituted a legion, totalling between 4,000 and 5,000 men.[144][145] The early Republican legion consisted of five sections: the three lines of manipular heavy infantry (hastati, principes and triarii), a force of light infantry (velites), and the cavalry (equites). With the new organisation came a new orientation toward the offensive and a much more aggressive posture toward adjoining city-states.[144][145] At nominal full strength, an early Republican legion included 3,600 to 4,800 heavy infantry, several hundred light infantry, and several hundred cavalrymen.[144][147][148]  Until the late Republican period, the typical legionary was a property-owning citizen farmer from a rural area (an adsiduus) who served for particular (often annual) campaigns,[c] and who supplied his own equipment. After 200\u00a0BC, economic conditions in rural areas deteriorated as manpower needs increased, so that the property qualifications for compulsory service were gradually reduced. Beginning in the 3rd century BC, legionaries were paid a stipend (stipendium). By the time of Augustus, the ideal of the citizen-soldier had been abandoned and the legions had become fully professional. At the end of the Civil War, Augustus reorganised Roman military forces, discharging soldiers and disbanding legions. He retained 28 legions, distributed through the provinces of the Empire.[150]  During the Principate, the tactical organisation of the Army continued to evolve. The auxilia remained independent cohorts, and legionary troops often operated as groups of cohorts rather than as full legions. A new and versatile type of unit, the cohortes equitatae, combined cavalry and legionaries in a single formation. They could be stationed at garrisons or outposts and could fight on their own as balanced small forces or combine with similar units as a larger, legion-sized force. This increase in organizational flexibility helped ensure the long-term success of Roman military forces.[151] The Emperor Gallienus (253\u2013268\u00a0AD) began a reorganisation that created the last military structure of the late Empire. Withdrawing some legionaries from the fixed bases on the border, Gallienus created mobile forces (the comitatenses or field armies) and stationed them behind and at some distance from the borders as a strategic reserve. The border troops (limitanei) stationed at fixed bases continued to be the first line of defence. The basic units of the field army were regimental; legiones or auxilia for infantry and vexillationes for cavalry. Nominal strengths may have been 1,200 men for infantry regiments and 600 for cavalry, but actual troop levels could have been much lower\u2014800 infantry and 400 cavalry.[152] Many infantry and cavalry regiments operated in pairs under the command of a comes. Field armies included regiments recruited from allied tribes and known as foederati. By 400\u00a0AD, foederati regiments had become permanently established units of the Roman army, paid and equipped by the Empire, led by a Roman tribune and used just as Roman units were used. The Empire also used groups of barbarians to fight along with the legions as allies without integration into the field armies, under overall command of a Roman general, but led by their own officers.[152]  Military leadership evolved over the course of the history of Rome. Under the monarchy, the hoplite armies were led by the kings. During the early and middle Roman Republic, military forces were under the command of one of the two elected consuls for the year. During the later Republic, members of the Roman Senatorial elite, as part of the normal sequence of elected public offices known as the cursus honorum, would have served first as quaestor (often posted as deputies to field commanders), then as praetor.[153][154] Following the end of a term as praetor or consul, a Senator might be appointed by the Senate as a propraetor or proconsul (depending on the highest office held before) to govern a foreign province. Under Augustus, whose most important political priority was to place the military under a permanent and unitary command, the Emperor was the legal commander of each legion but exercised that command through a legatus (legate) he appointed from the Senatorial elite. In a province with a single legion, the legate commanded the legion (legatus legionis) and served as provincial governor, while in a province with more than one legion, each legion was commanded by a legate and the legates were commanded by the provincial governor (also a legate but of higher rank).[155]  During the later stages of the Imperial period (beginning perhaps with Diocletian), the Augustan model was abandoned. Provincial governors were stripped of military authority, and command of the armies in a group of provinces was given to generals (duces) appointed by the Emperor. These were no longer members of the Roman elite but men who came up through the ranks and had seen much practical soldiering. With increasing frequency, these men attempted (sometimes successfully) to usurp the positions of the Emperors. Decreased resources, increasing political chaos and civil war eventually left the Western Empire vulnerable to attack and takeover by neighbouring barbarian peoples.[156]  Less is known about the Roman navy than the Roman army. Prior to the middle of the 3rd century BC, officials known as duumviri navales commanded a fleet of twenty ships used mainly to control piracy. This fleet was given up in 278\u00a0AD and replaced by allied forces. The First Punic War required that Rome build large fleets, and it did so largely with the assistance of and financing from allies. This reliance on allies continued to the end of the Roman Republic. The quinquereme was the main warship on both sides of the Punic Wars and remained the mainstay of Roman naval forces until replaced by the time of Caesar Augustus by lighter and more manoeuvrable vessels.[159]  As compared with a trireme, the quinquereme permitted the use of a mix of experienced and inexperienced crewmen (an advantage for a primarily land-based power), and its lesser manoeuvrability permitted the Romans to adopt and perfect boarding tactics using a troop of about 40 marines in lieu of the ram. Ships were commanded by a navarch, a rank equal to a centurion, who was usually not a citizen. Potter suggests that because the fleet was dominated by non-Romans, the navy was considered non-Roman and allowed to atrophy in times of peace.[159]  Information suggests that by the time of the late Empire (350\u00a0AD), the Roman navy comprised several fleets including warships and merchant vessels for transportation and supply. Warships were oared sailing galleys with three to five banks of oarsmen. Fleet bases included such ports as Ravenna, Arles, Aquilea, Misenum and the mouth of the Somme River in the West and Alexandria and Rhodes in the East. Flotillas of small river craft (classes) were part of the limitanei (border troops) during this period, based at fortified river harbours along the Rhine and the Danube. That prominent generals commanded both armies and fleets suggests that naval forces were treated as auxiliaries to the army and not as an independent service. The details of command structure and fleet strengths during this period are not well known, although fleets were commanded by prefects.[160]  Ancient Rome commanded a vast area of land, with tremendous natural and human resources. As such, Rome's economy remained focused on farming and trade. Agricultural free trade changed the Italian landscape, and by the 1st century BC, vast grape and olive estates had supplanted the yeoman farmers, who were unable to match the imported grain price. The annexation of Egypt, Sicily and Tunisia in North Africa provided a continuous supply of grains. In turn, olive oil and wine were Italy's main exports. Two-tier crop rotation was practised, but farm productivity was low, around 1 ton per hectare.  Industrial and manufacturing activities were small. The largest such activities were the mining and quarrying of stones, which provided basic construction materials for the buildings of that period. In manufacturing, production was on a relatively small scale, and generally consisted of workshops and small factories that employed at most dozens of workers. However, some brick factories employed hundreds of workers.  The economy of the early Republic was largely based on smallholding and paid labour. However, foreign wars and conquests made slaves increasingly cheap and plentiful, and by the late Republic, the economy was largely dependent on slave labour for both skilled and unskilled work. Slaves are estimated to have constituted around 20% of the Roman Empire's population at this time and 40% in the city of Rome. Only in the Roman Empire, when the conquests stopped and the prices of slaves increased, did hired labour become more economical than slave ownership.  Although barter was used in ancient Rome, and often used in tax collection, Rome had a very developed coinage system, with brass, bronze, and precious metal coins in circulation throughout the Empire and beyond\u2014some have even been discovered in India. Before the 3rd century BC, copper was traded by weight, measured in unmarked lumps, across central Italy. The original copper coins (as) had a face value of one Roman pound of copper, but weighed less. Thus, Roman money's utility as a unit of exchange consistently exceeded its intrinsic value as metal. After Nero began debasing the silver denarius, its legal value was an estimated one-third greater than its intrinsic value.  Horses were expensive and other pack animals were slower. Mass trade on the Roman roads connected military posts, where Roman markets were centered.[161] These roads were designed for wheels.[162] As a result, there was transport of commodities between Roman regions, but increased with the rise of Roman maritime trade in the 2nd century BC. During that period, a trading vessel took less than a month to complete a trip from Gades to Alexandria via Ostia, spanning the entire length of the Mediterranean.[76] Transport by sea was around 60 times cheaper than by land, so the volume for such trips was much larger.  Some economists consider the Roman Empire a market economy, similar in its degree of capitalistic practices to 17th century Netherlands and 18th century England.[163]  The basic units of Roman society were households and families.[136] Groups of households connected through the male line formed a family (gens), based on blood ties, a common ancestry or adoption. During the Roman Republic, some powerful families, or Gentes Maiores, came to dominate political life. Families were headed by their oldest male citizen, the pater familias (father of the family), who held lawful authority (patria potestas, \"father's power\") over wives, sons, daughters, and slaves of the household, and the family's wealth.[136]  The extreme expressions of this power\u2014the selling or killing of family members for moral or civil offences, including simple disobedience\u2014were very rarely exercised, and were forbidden in the Imperial era. A pater familias had moral and legal duties towards all family members. Even the most despotic pater familias was expected to consult senior members of his household and gens over matters that affected the family's well-being and reputation. Traditionally, such matters were regarded as outside the purview of the state and its magistrates; under the emperors, they were increasingly subject to state interference and legislation.[165]  Once accepted into their birth family by their fathers, children were potential heirs. They could not be lawfully given away, or sold into slavery. If parents were unable to care for their child, or if its paternity was in doubt, they could resort to infant exposure (Boswell translates this as being \"offered\" up to care by the gods or strangers). If a deformed or sickly newborn was patently \"unfit to live\", killing it was a duty of the pater familias. A citizen father who exposed a healthy freeborn child was not punished, but automatically lost his potestas over that child. Abandoned children were sometimes adopted; some would have been sold into slavery.[166] Slavery was near-ubiquitous and almost universally accepted. In the early Republic, citizens in debt were allowed to sell their labour, and perhaps their sons, to their debtor in a limited form of slavery called nexum, but this was abolished in the middle Republic. Freedom was considered a natural and proper state for citizens; slaves could be lawfully freed, with consent and support of their owners, and still serve their owners' family and financial interests, as freedmen or freed women. This was the basis of the client-patron relationship, one of the most important features of Rome's economy and society.[167]  In law, a pater familias held potestas over his adult sons with their own households. This could give rise to legal anomalies, such as adult sons also having the status of minors. No man could be considered a pater familias, nor could he truly hold property under law, while his own father lived.[168][169] During Rome's early history, married daughters came under the control (manus) of their husbands' pater familias. By the late Republic, most married women retained lawful connection to their birth family, though any children from the marriage belonged to her husband's family.[170] The mother or an elderly relative often raised both boys and girls.[171] Roman moralists held that marriage and child-raising fulfilled a basic duty to family, gens, and the state. Multiple remarriages were not uncommon. Fathers usually began seeking husbands for their daughters when these reached an age between twelve and fourteen, but most commoner-class women stayed single until their twenties, and in general seem to have been far more independent than wives of the elite. Divorce required the consent of one party, along with the return of any dowry. Both parents had power over their children during their minority and adulthood, but husbands had much less control over their wives.[172]  Roman citizen women held a restricted form of citizenship; they could not vote but were protected by law. They ran families, could own and run businesses, own and cultivate land, write their own wills, and plead in court on their own behalf, or on behalf of others, all under dispensation of the courts and the nominal supervision of a senior male relative. Throughout the late Republican and Imperial eras, a declining birthrate among the elite, and a corresponding increase among commoners was cause of concern for many gentes; Augustus tried to address this through state intervention, offering rewards to any woman who gave birth to three or more children, and penalising the childless. The latter was much resented, and the former had seemingly negligible results. Aristocratic women seem to have been increasingly disinclined to childbearing; it carried a high risk of mortality to mothers, and a deal of inconvenience thereafter.[173]  Roman hours were counted ordinally from dawn to dawn. Thus, if sunrise was at 6 am, then 6 to 7 am was called the \"first hour\". Midday was called meridies and it is from this word that the terms am (ante meridiem) and pm (post meridiem) stem. The English word \"noon\" comes from nona (\"ninth (hour)\"), which referred to 3 pm in Ancient Rome.[d] The Romans had clocks (horologia), which included giant public sundials (solaria) and water clocks (clepsydrae).  The ancient Roman week originally had eight days, which were identified by letters A to H, with the eighth day being the nundinum or market day, a kind of weekend when farmers sold their produce on the streets. The seven-day week, first introduced from the East during the early Empire, was officially adopted during the reign of Constantine. Romans named week days after celestial bodies from at least the 1st century AD. Roman months had three important days: the calends (first day of each month, always in plural), the ides (13th or 15th of the month), and the nones (ninth day before the ides, inclusive, i.e. 5th or 7th of the month). Other days were counted backwards from the next one of these days.  The Roman year originally had ten months from Martius (March) to December, with the winter period not included in the calendar. The first four months were named after gods (Martius, Aprilis, Maius, Junius) and the others were numbered (Quintilis, Sextilis, September, October, November, and December). Numa Pompilius, the second king of Rome (716\u2013673 BC), is said to have introduced the months of January and February, both also named after gods, beginning the 12-month calendar still in use today. In 44 BC, the month Quintilis was renamed to Julius (July) after Julius Caesar and in 8 BC, Sextilis was renamed to Augustus (August) after Augustus Caesar.  The Romans had several ways of tracking years. One widespread way was the consular dating, which identified years by the two consuls who ruled each year. Another way, introduced in the late 3rd century AD, was counting years from the indictio, a 15-year period based on the announcement of the delivery of food and other goods to the government. Another way, less popular but more similar to present day, was ab urbe condita, which counted years from the mythical foundation of Rome in 753 BC.  Life in ancient Rome revolved around the city of Rome, located on seven hills. The city had a vast number of monumental structures like the Colosseum, the Trajan's Forum and the Pantheon. It had theatres, gymnasiums, marketplaces, functional sewers, bath complexes complete with libraries and shops, and fountains with fresh drinking water supplied by hundreds of miles of aqueducts. Throughout the territory under the control of ancient Rome, residential architecture ranged from modest houses to country villas.  In the capital city of Rome, there were imperial residences on the elegant Palatine Hill, from which the word palace derives. The low plebeian and middle equestrian classes lived in the city center, packed into apartments, or insulae, which were almost like modern ghettos. These areas, often built by upper class property owners to rent, were often centred upon collegia or taberna. These people, provided with a free supply of grain, and entertained by gladiatorial games, were enrolled as clients of patrons among the upper class patricians, whose assistance they sought and whose interests they upheld.  The native language of the Romans was Latin, an Italic language the grammar of which relies little on word order, conveying meaning through a system of affixes attached to word stems.[174] Its alphabet was based on the Etruscan alphabet, which was in turn based on the Greek alphabet.[175] Although surviving Latin literature consists almost entirely of Classical Latin, an artificial and highly stylised and polished literary language from the 1st century BC, the spoken language of the Roman Empire was Vulgar Latin, which significantly differed from Classical Latin in grammar and vocabulary, and eventually in pronunciation.[176] Speakers of Latin could understand both until the 7th century when spoken Latin began to diverge so much that 'Classical' or 'Good Latin' had to be learned as a second language.[177]  While Latin remained the main written language of the Roman Empire, Greek came to be the language spoken by the well-educated elite, as most of the literature studied by Romans was written in Greek. Most of the emperors were bilingual but had a preference for Latin in the public sphere for political reasons, a practice that first started during the punic wars.[178] In the eastern part of the Roman Empire (and later the Eastern Roman Empire), Latin was never able to replace Greek, a legacy of the Hellenistic period.[179] Justinian would be the last emperor to use Latin in government and marks when Greek officially took over.[180] The expansion of the Roman Empire spread Latin throughout Europe, and Vulgar Latin evolved into many distinct Romance languages.  Archaic Roman religion, at least concerning the gods, was made up not of written narratives, but rather of complex interrelations between gods and humans.[181] Unlike in Greek mythology, the gods were not personified, but were vaguely defined sacred spirits called numina. Romans also believed that every person, place or thing had its own genius, or divine soul. During the Roman Republic, Roman religion was organised under a strict system of priestly offices, which were held by men of senatorial rank. The College of Pontifices was uppermost body in this hierarchy, and its chief priest, the Pontifex Maximus, was the head of the state religion. Flamens took care of the cults of various gods, while augurs were trusted with taking the auspices. The sacred king took on the religious responsibilities of the deposed kings. In the Roman Empire, deceased emperors who had ruled well were deified by their successors and the Senate.[182] and the formalised imperial cult became increasingly prominent.  As contact with the Greeks increased, the old Roman gods became increasingly associated with Greek gods.[183] Under the Empire, the Romans absorbed the mythologies of their conquered subjects, often leading to situations in which the temples and priests of traditional Italian deities existed side by side with those of foreign gods.[184]  Beginning with Emperor Nero in the 1st century AD, Roman official policy towards Christianity was negative, and at some point, being a Christian could be punishable by death. Under Emperor Diocletian, the persecution of Christians reached its peak. However, it became an officially supported religion in the Roman state under Diocletian's successor, Constantine I, with the signing of the Edict of Milan in 313, and quickly became dominant. All religions except Christianity were prohibited in 391\u00a0AD by an edict of Emperor Theodosius I.[185]  Like many ancient cultures, concepts of ethics and morality, while sharing some commonalities with modern society, differed greatly in several important ways. Because ancient civilisations like Rome were under constant threat of attack from marauding tribes, their culture was necessarily militaristic with martial skills being a prized attribute.[186] Whereas modern societies consider compassion a virtue, Roman society considered compassion a vice, a moral defect. Indeed, one of the primary purposes of the gladiatorial games was to inoculate Roman citizens from this weakness.[187][186][188] Romans instead prized virtues such as courage and conviction (virtus), a sense of duty to one's people, moderation and avoiding excess (moderatio), forgiveness and understanding (clementia), fairness (severitas), and loyalty (pietas).[189]  Roman society had well-established and restrictive norms related to sexuality, though as with many societies, the lion's share of the responsibilities fell on women. Women were generally expected to be monogamous having only a single husband during their life (univira), though this was much less regarded by the elite, especially under the empire. Women were expected to be modest in public avoiding any provocative appearance and to demonstrate absolute fidelity to their husbands (pudicitia). Indeed, wearing a veil was a common expectation to preserve modesty. Sex outside of marriage was generally frowned upon for men and women and indeed was made illegal during the imperial period.[190] Nevertheless, prostitution was an accepted and regulated practice.[191]  Public demonstrations of death, violence, and brutality were used as a source of entertainment in Roman communities; however it was also a way to maintain social order, demonstrate power, and signify communal unity.  Roman painting styles show Greek influences, and surviving examples are primarily frescoes used to adorn the walls and ceilings of country villas, though Roman literature includes mentions of paintings on wood, ivory, and other materials.[192][193] Several examples of Roman painting have been found at Pompeii, and from these art historians divide the history of Roman painting into four periods.  The first style of Roman painting was practised from the early 2nd century BC to the early- or mid-1st century BC. It was mainly composed of imitations of marble and masonry, though sometimes including depictions of mythological characters. The second style began during the early 1st century BC and attempted to depict realistically three-dimensional architectural features and landscapes. The third style occurred during the reign of Augustus (27\u00a0BC\u00a0\u2013 14\u00a0AD), and rejected the realism of the second style in favour of simple ornamentation. A small architectural scene, landscape, or abstract design was placed in the center with a monochrome background. The fourth style, which began in the 1st century AD, depicted scenes from mythology, while retaining architectural details and abstract patterns.  Portrait sculpture used youthful and classical proportions, evolving later into a mixture of realism and idealism. During the Antonine and Severan periods, ornate hair and bearding, with deep cutting and drilling, became popular. Advancements were also made in relief sculptures, usually depicting Roman victories.  Roman music was largely based on Greek music, and played an important part in many aspects of Roman life.[194] In the Roman military, musical instruments such as the tuba (a long trumpet) or the cornu were used to give various commands, while the buccina (possibly a trumpet or horn) and the lituus (probably an elongated J-shaped instrument), were used in ceremonial capacities.[195] Music was used in the Roman amphitheatres between fights and in the odea, and in these settings is known to have featured the cornu and the hydraulis (a type of water organ).[196] Most religious rituals featured musical performances.[197] Some music historians believe that music was used at almost all public ceremonies.[194]  The graffiti, brothels, paintings, and sculptures found in Pompeii and Herculaneum suggest that the Romans had a sex-saturated culture.[198]  Latin literature was, from its start, influenced heavily by Greek authors. Some of the earliest extant works are of historical epics telling the early military history of Rome. As the Republic expanded, authors began to produce poetry, comedy, history, and tragedy.  Ancient Rome's literary contributions are still recognized today and the works by ancient Roman authors were available in bookshops as well as in public and private libraries. Many scholars and statesmen of Ancient Rome cultivated private libraries that were used both as demonstrations of knowledge and displays of wealth and power.[199] Private libraries were so commonly encountered that Vitruvius wrote about where libraries should be situated within a villa.[200] In addition to numerous private libraries, the Roman Empire saw the establishment of early public libraries.  Although Julius Caesar had intended to establish public libraries to further establish Rome as a great cultural center like Athens and Alexandria, he died before this was accomplished. Caesar's former lieutenant, Gaius Asinius Pollio, took up the project and opened the first public library in Rome in the Atrium Libertatis.[201] Emperors Augustus, Tiberius, Vespasian, Domitian, and Trajan also founded or expanded public libraries in Rome during their reigns.[202][203][204] These included the Ulpian Library in Trajan's Forum and libraries in the Temple of Apollo Palatinus, the Temple of Peace in the Roman Forum, the Temple of Divus Augustus, which was dedicated to Minerva when it was \u00a0rebuilt under Emperor Domitian's orders.[205] Some of these, including the library at the Temple of Divus Augustus also served as archives.[205] By the fall of the Western Roman Empire, the city of Rome had more than two dozen public libraries.[206] Rome was not the only city to benefit from such institutions. As the Roman Empire spread, public libraries were established in other major cities and cultural centers including Ephesos, Athens, and Timgad.[207][208]  Most public libraries of this time were not built expressly for that purpose, instead sharing space in temples, baths, and other community buildings. In addition to serving as repositories for books, public libraries hosted orations by authors.[199] These recitations served as social gatherings and allowed those who may not be literate to be entertained by poetry, epics, philosophical treatises, and other works.  Ancient Roman cuisine changed over the long duration of this ancient civilisation. Dietary habits were affected by the influence of Greek culture, the political changes from Kingdom to Republic to Empire, and the Empire's enormous expansion, which exposed Romans to many new, provincial culinary habits and cooking techniques. In the beginning the differences between social classes were relatively small, but disparities evolved with the Empire's growth. Men and women drank wine with their meals.[210]  The ancient Roman diet included many items that are staples of modern Italian cooking. Pliny the Elder discussed more than 30 varieties of olive, 40 kinds of pear, figs (native and imported from Africa and the eastern provinces), and a wide variety of vegetables, including carrots (of different colours, but not orange[211]) as well as celery, garlic, some flower bulbs, cabbage and other brassicas (such as kale and broccoli), lettuce, endive, onion, leek, asparagus, radishes, turnips, parsnips, beets, green peas, chard, cardoons, olives, and cucumber.[212]  However, some foods now considered characteristic of modern Italian cuisine were not used.[213] In particular, spinach and eggplant (aubergine) were introduced later from the Arab world, and tomatoes, potatoes, capsicum peppers, and maize (the modern source of polenta)[212] only appeared in Europe following the discovery of the New World and the Columbian Exchange.[213] The Romans knew of rice, but it was very rarely available to them. There were also few citrus fruits.[213]  Butcher's meat such as beef was an uncommon luxury. The most popular meat was pork, especially sausages.[214] Fish was more common than meat, with a sophisticated aquaculture and large-scale industries devoted to oyster farming. The Romans also engaged in snail farming and oak grub farming. Some fish were greatly esteemed and fetched high prices, such as mullet raised in the fishery at Cosa, and \"elaborate means were invented to assure its freshness\".[215]  Traditionally, a breakfast called ientaculum[216] was served at dawn. At mid-day to early afternoon, Romans ate cena,[216] the main meal of the day, and at nightfall a light supper called vesperna.[217] With the increased importation of foreign foods, the cena grew larger in size and included a wider range of foods. Thus, it gradually shifted to the evening, while the vesperna[217] was abandoned completely over the course of the years. The mid-day meal prandium became a light meal to hold one over until cena.[216]  The toga, a common garment during the era of Julius Caesar, was gradually abandoned by all social classes of the Empire. At the early 4th century, the toga had become just a garment worn by senators in Senate and ceremonial events. At the 4th century, the toga was replaced by the paenula (a garment similar to a poncho) as the everyday garment of the Romans, from the lower classes to the upper classes. Another garment that was popular among the Romans in the later years of the Western Roman Empire was the pallium, which was mostly worn by philosophers and scholars in general. Due to external influences, mainly from the Germanic peoples, the Romans adopted tunics very similar to those used by the Germanic peoples with whom they interacted in the final years of the Western Empire, also adopted trousers and hats like the pileus pannonicus. At the Late Empire the paludamentum (a type of military clothing) was used only by the Emperor of Rome (since the reign of Augustus, the first emperor) while the dalmatic (also used by the Christian clergy) began to spread throughout the empire.[218]  The youth of Rome had several forms of athletic play and exercise. Play for boys was supposed to prepare them for active military service, such as jumping, wrestling, boxing, and racing.[219] In the countryside, pastimes for the wealthy also included fishing and hunting.[220] The Romans also had several forms of ball playing, including one resembling handball.[219] Dice games, board games, and gamble games were popular pastimes.[219] For the wealthy, dinner parties presented an opportunity for entertainment, sometimes featuring music, dancing, and poetry readings.[192] The majority, less well-off, sometimes enjoyed similar parties through clubs or associations, but for most Romans, recreational dining usually meant patronising taverns.[192]Children entertained themselves with toys and such games as leapfrog.[220][192]  Public games and spectacles were sponsored by leading Romans who wished to advertise their generosity and court popular approval; in Rome or its provinces, this usually meant the emperor or his governors. Venues in Rome and the provinces were developed specifically for public games. Rome's Colisseum was built in 70 AD under the Roman emperor Vespasian and opened in 80 AD to host other events and gladiatorial combats. Gladiators had an exotic and inventive variety of arms and armour. They sometimes fought to the death, but more often to an adjudicated victory, usually in keeping with the mood of the watching crowd. Shows of exotic animals were popular in their own right; but sometimes animals were pitted against human beings, either armed professionals or unarmed criminals who had been condemned to public death.  Chariot racing was extremely popular among all classes. In Rome, these races were usually held at the Circus Maximus, which had been purpose-built for chariot and horse-racing and, as Rome's largest public place, was also used for festivals and animal shows.[221] It could seat around 150,000 people;[222] The charioteers raced in teams, identified by their colours; some aficionados were members of extremely, even violently partisan circus factions.  Ancient Rome boasted impressive technological feats, using many advancements that were lost in the Middle Ages and not rivalled again until the 19th and 20th centuries. An example of this is insulated glazing, which was not invented again until the 1930s. Many practical Roman innovations were adopted from earlier Greek designs. Advancements were often divided and based on craft. Artisans guarded technologies as trade secrets.[223]  Roman civil engineering and military engineering constituted a large part of Rome's technological superiority and legacy, and contributed to the construction of hundreds of roads, bridges, aqueducts, public baths, theatres and arenas. Many monuments, such as the Colosseum, Pont du Gard, and Pantheon, remain as testaments to Roman engineering and culture.  The Romans were renowned for their architecture, which is grouped with Greek traditions into \"Classical architecture\". Although there were many differences from Greek architecture, Rome borrowed heavily from Greece in adhering to strict, formulaic building designs and proportions. Aside from two new orders of columns, composite and Tuscan, and from the dome, which was derived from the Etruscan arch, Rome had relatively few architectural innovations until the end of the Republic.  In the 1st century BC, Romans started to use Roman concrete widely. Concrete was invented in the late 3rd century BC. It was a powerful cement derived from pozzolana, and soon supplanted marble as the chief Roman building material and allowed many daring architectural forms.[224] Also in the 1st century BC, Vitruvius wrote De architectura, possibly the first complete treatise on architecture in history. In the late 1st century BC, Rome also began to use glassblowing soon after its invention in Syria about 50\u00a0BC. Mosaics took the Empire by storm after samples were retrieved during Lucius Cornelius Sulla's campaigns in Greece.  The Romans also largely built using timber, causing a rapid decline of the woodlands surrounding Rome and in much of the Apennine Mountains due to the demand for wood for construction, shipbuilding and fire. The first evidence of long-distance wood trading come from the discovery of wood planks, felled between AD 40 and 60, coming from the Jura mountains in northeastern France and ending up more than 1,055 miles (1,700\u00a0km) away, in the foundations of a lavish portico that was part of a vast wealthy patrician villa, in Central Rome. It is suggested that timber, around 4 metres (13\u00a0ft) long, came up to Rome via the Tiber River on ships travelling across the Mediterranean Sea from the confluence of the Sa\u00f4ne and Rh\u00f4ne rivers in what is now the city of Lyon in present-day France.[225]  With solid foundations and good drainage,[226] Roman roads were known for their durability and many segments of the Roman road system were still in use a thousand years after the fall of Rome. The construction of a vast and efficient travel network throughout the Empire dramatically increased Rome's power and influence. They allowed Roman legions to be deployed rapidly, with predictable marching times between key points of the empire, no matter the season.[227] These highways also had enormous economic significance, solidifying Rome's role as a trading crossroads\u2014the origin of the saying \"all roads lead to Rome\". The Roman government maintained a system of way stations, known as the cursus publicus, and established a system of horse relays allowing a dispatch to travel up to 80\u00a0km (50\u00a0mi) a day.  The Romans constructed numerous aqueducts to supply water to cities and industrial sites and to aid in their agriculture. By the third century, the city of Rome was supplied by 11 aqueducts with a combined length of 450\u00a0km (280\u00a0mi). The Romans also made major advancements in sanitation. Romans were particularly famous for their public baths, called thermae, which were used for both hygienic and social purposes. Many Roman houses had flush toilets and indoor plumbing, and a complex sewer system, the Cloaca Maxima, was used to drain the local marshes and carry waste into the Tiber. Some historians have speculated that lead pipes in the sewer and plumbing systems led to widespread lead poisoning, which contributed to fall of Rome; however, lead content would have been minimised.[228][229]  Ancient Rome is the progenitor of Western civilisation.[230] The customs, religion, law, technology, architecture, political system, military, literature, languages, alphabet, government and many factors and aspects of western civilisation are all inherited from Roman advancements. The rediscovery of Roman culture revitalised Western civilisation, playing a role in the Renaissance and the Age of Enlightenment.[231]  The two longest ancient accounts of the Roman history, the histories of Livy and Dionysius of Halicarnassus, were composed 500 years later than the date for the founding of the republic and 200 years from the defeat of Hannibal.[232] Although there has been a diversity of works on ancient Roman history, many of them are lost. As a result of this loss, there are gaps in Roman history, which are filled by unreliable works, such as the Historia Augusta and other books from obscure authors. Historians used their works for the lauding of Roman culture and customs, and to flatter their patrons.[233] Caesar wrote his own accounts of his military campaigns in Gaul and during the Civil War in part to impress his contemporaries.[234]  In the Empire, the biographies of famous men and early emperors flourished, examples being The Twelve Caesars of Suetonius, and Plutarch's Parallel Lives. Other major works of Imperial times were that of Livy and Tacitus.  Interest in studying, and idealising, ancient Rome became prevalent during the Italian Renaissance. Edward Gibbon's The History of the Decline and Fall of the Roman Empire \"began the modern study of Roman history in the English-speaking world\".[235] Barthold Georg Niebuhr was a founder of the examination of ancient Roman history and wrote The Roman History, tracing the period until the First Punic war. During the Napoleonic, The History of Romans by Victor Duruy highlighted the Caesarean period popular at the time. History of Rome, Roman constitutional law and Corpus Inscriptionum Latinarum, all by Theodor Mommsen,[236] became milestones.  Footnotes  Citations "},{"title":"Hockey stick","content":"A hockey stick is a piece of sports equipment used by the players in all the forms of hockey to move the ball or puck (as appropriate to the type of hockey) either to push, pull, hit, strike, flick, steer, launch or stop the ball\/puck during play with the objective being to move the ball\/puck around the playing area using the stick, and then trying to score.  The word \"stick\" is a very generic term for the equipment since the different disciplines of hockey require significant differences in both the form and the size of the stick used for it to be effective in the different sports. Field\/ice\/roller hockey all have a visually similar form of stick with a long shaft or handle which can be held with two hands, and a curved and flattened end; the end and curvature of these sticks are generally the most visible differences between the sticks for these sports. A modern underwater hockey stick bears little resemblance to any field\/ice\/roller hockey stick, since it is much smaller to enable it to be used exclusively in one hand, and it also has to be produced in one of two colours in order to identify which of the competing teams a player is playing for.  Field hockey sticks have an end that varies in shape, often depending on the player's position. In general, there are four main variations on the head:  The 'short' is mainly used by players wishing control over the ball, and increase their manoeuvrability. This specific head is most associated with the mid-field position. (or centre for Ice Hockey)  The 'Midi' is used by players who will be hitting the ball often and need to be strong on their 'reverse side'. This specific head is most associated with the striker or 'up-front' position.  The 'Maxi' is similar to the 'Midi' as it has an increased surface area which is useful for hitting. However, its strength allows it to be used much more effectively for stopping the ball. This head is used by 'defenders' and 'attackers'.  The 'J Hook' again has a large surface area. However does not have the effectiveness of the 'Midi' for striking the ball, it has an increased thickness making it ideal for stopping the ball. This head is most commonly used by 'defenders'. Field hockey sticks vary widely in length and price, ranging from 26\u00a0in (660\u00a0mm) to 38.5\u00a0in (980\u00a0mm). The main brands of sticks include TK, Grays, Slazenger, Byte, Kookaburra, Malik, Dita, Voodoo, Adidas, Gryphon, uber hockey, Woodworm, Brabo, Mercian, Mazon, Zoppo, Tempest, Matador, King Karachi, NedStar, The Indian Maharaja, Stag, Wasa, No Fear, BHP, Taurus, Wasp, Princess, IHSAN, Mohinder, Chryso, Piranha, Rage, Sachin and Edge.  The size of the stick that is most effective for a specific player is judged by that player's height. A 28\u00a0in (710\u00a0mm) stick would be used by a player under 4' most commonly, whereas a 38\u00a0in (970\u00a0mm) stick would be used mainly by players over 5\u00a0ft 10\u00a0in (1.78\u00a0m). However 'defenders' often like to have a longer stick than 'attackers' as this can be used for a greater reach when stopping a moving ball. The 'attackers' prefer a shorter stick as it allows greater control of the ball.  Ice hockey sticks have traditionally been made from wood, but in recent years, sticks made of more expensive materials such as aluminum, aramid (brands Kevlar, Nomex, Twaron, etc.), fibreglass, carbon fibre, and other composite materials have become common. In addition to weighing less, composite sticks can be manufactured with more consistent flexibility properties than their wooden counterparts. They also do not have the natural variations that wooden sticks possess therefore a batch of the same sticks will all perform roughly the same. There were a few die-hard NHL professionals who still liked the feel of wood sticks as late as 2010, such as Paul Stastny, son of Hall-of-Famer Peter \u0160\u0165astn\u00fd.[citation needed] Some of these sticks have replaceable wood or composite blades, while others are one-piece sticks without a replaceable blade. Composite sticks, despite their greater expense, are now commonplace at nearly all competitive levels of the sport, including youth ice hockey. Some of the top brands of composite sticks include Bauer, True, Reebok\/CCM, and Warrior. These new sticks are lighter and provide a quicker release of the puck, resulting in a harder, more accurate shot.  Although the new materials do enable harder shots, the improved durability and lighter materials can make the transition from wooden to composite stick more difficult for less experienced players. A shortcut used by numerous players is to use a weighted system, such as kwik hands,[1] to quickly adjust to the new sticks. More expensive ice hockey sticks (such as the Bauer Vapor 1X, Bauer Supreme 1S, Bauer Nexus 1N, CCM Ribcor Trigger PMT2, CCM RBZ FT1, CCM Super Tacks 2.0,  Easton Stealth CX, Easton Synergy GX, Warrior Covert QRL, Warrior Alpha QX, Warrior Dynasty HD1) usually are the lightest sticks on the market (390-470 grams in a senior stick). In addition to the increased torque that these composite sticks possess, the sticks do not warp or absorb moisture like their wooden counterparts.  When the player is standing on his skates with the stick upright, on the toe, perpendicular to the ice, the top of the shaft should stop just below or above the chin, depending on personal preference. Defensemen tend to use longer sticks which provide greater reach when poke-checking.  Ice hockey sticks are also used in rinkball.  In the event of roller inline hockey, one-piece sticks are usually the same as ice hockey sticks.  But when graphite shafts are used with replacement blades, it's quite common for the replacement blades to be made of mainly fibreglass with a narrow wood core.  Fibreglass shaves down over time on concrete, sport court and blacktop surfaces where traditional wooden ice hockey replacement blades are more likely to splinter, split and\/or crack on those surfaces.  The stick (also referred to as a pusher) for underwater hockey is relatively short compared to that for field\/ice\/roller hockey, and should be coloured either white or black in its entirety to indicate the player's team. The shape of the stick can affect playing style and is often a very personal choice.   A wide variety of stick designs are allowed within the constraints of the rules of the game, the principal rule being that the stick must fit into a box of 100\u00a0mm \u00d7\u00a050\u00a0mm \u00d7\u00a0350\u00a0mm (3.9\u00a0in \u00d7\u00a02.0\u00a0in \u00d7\u00a013.8\u00a0in) and that the stick must not be capable of surrounding the puck by any more than 50% of the puck's circumference, nor any part of the hand. A rule concerning the radiuses of projections and edges tries to address the risk that the stick might unintentionally become more of a weapon than a playing tool.  Construction materials may be of wood or plastics and current rules now supersede those that previously required sticks to be homogeneous, although they almost always are anyway.  Many players of UWH manufacture their own sticks of wood to their preferred shape and style, although there are increasingly more mass-produced designs that suit the majority (such as Bentfish, Britbat, CanAm, Dorsal, Stingray etc.) which in most cases are made of a moulded nylon or PTFE, and many styles can be obtained to suit either handedness.  The rules allow for a symmetrical double-ended stick to be used, i.e. one that may be held in either the left or the right hand, and this can give ambidextrous players the opportunity to swap hands during play, although the rules are also very clear that the stick may be held in only one hand at a time.  Modern-day Underwater Hockey (UWH) was invented as a sport originally known as Octopush in Southsea, England in 1954 and has always used short sticks or pushers similar to those described above, but a very similar game also called underwater hockey evolved some years after this in South Africa. This game used a 'long stick' that had a very similar form to an ice hockey stick, although it was considerably smaller at around 50\u00a0cm (20\u00a0in) long and required two hands to hold and use it. The 'long stick' version of the game that was played largely in the southern hemisphere eventually gave way to the more widely played 'short stick' version and since about 1980, the year of the first UWH World Championship, the original 'short stick' game has been played universally around the world.  In the cha-cha and rhumba dancing, the \"hockey stick\" is a figure in which the dancer moves along a straight line, with an angled turn at the end.[2][3]  On aircraft liveries, a Hockey stick is a cheatline \u2013 a line that extends along the side of an aircraft \u2013 which turns up at the end and goes up the tailfin. "},{"title":"FA Cup","content":"  The Football Association Challenge Cup, more commonly known as the FA Cup, is an annual knockout football competition in men's domestic English football. First played during the 1871\u201372 season, it is the oldest national football competition in the world.[1] It is organised by and named after The Football Association (The FA). Since 2015, it has been known as Emirates FA Cup after its headline sponsor Emirates. A concurrent Women's FA Cup has been held since 1970.  The competition is open to all eligible clubs down to Level 9 of the English football league system with Level 10 clubs acting as stand-ins in the event of non-entries from above.[2] A record 763 clubs competed in 2011\u201312. The tournament consists of 12 randomly drawn rounds followed by the semi-finals and the final. Entrants are not seeded, although a system of byes based on league level ensures higher ranked teams enter in later rounds \u2013 the minimum number of games needed to win, depending on which round a team enters the competition, ranges from six to fourteen.  The first six rounds are the Qualifying Competition, and are contested by clubs in the National League System, levels 5 to 10 of the English football system, more commonly called non-League. 32 of these teams progress to the first round of the Competition Proper, meeting the first of the 48 professional teams from Leagues One and Two. The last entrants are the 20 Premier League and 24 Championship clubs, into the draw for the third round proper.[2] In the modern era, only one non-League team has ever reached the quarter-finals, and teams below Level 2 have never reached the final.[note 1] As a result, significant focus is given to the smaller teams who progress furthest, especially if they achieve an unlikely \"giant-killing\" victory.  Winners receive the FA Cup trophy, of which there have been two designs and five actual cups; the latest is a 2014 replica of the second design, introduced in 1911. Winners also qualify for the UEFA Europa League and a place in the upcoming FA Community Shield. Arsenal are the most successful club with fourteen titles, most recently in 2020, and their former manager Ars\u00e8ne Wenger is the competition's most successful, having won seven finals with the team. Manchester City are the current holders, having defeated local rivals Manchester United in the 2023 final.  In 1863, the newly founded Football Association (the FA) published the Laws of the Game of Association Football, unifying the various different rules in use before then. On 20 July 1871, in the offices of The Sportsman newspaper, the FA Secretary C. W. Alcock proposed to the FA committee that \"it is desirable that a Challenge Cup should be established in connection with the Association for which all clubs belonging to the Association should be invited to compete\". The inaugural FA Cup tournament kicked off in November 1871. After thirteen games in all, Wanderers were crowned the winners in the final, on 16 March 1872. Wanderers retained the trophy the following year. The modern cup was beginning to be established by the 1888\u201389 season, when qualifying rounds were introduced.[3]  Following the 1914\u201315 edition, the competition was suspended due to the First World War, and did not resume until 1919\u201320. The 1923 FA Cup Final, commonly known as the \"White Horse Final\", was the first final to be played in the newly opened Wembley Stadium (known at the time as the Empire Stadium). The 1927 final saw \"Abide with Me\" being sung for the first time at the Cup final, which has become a pre-match tradition.[4] Due to the outbreak of World War II, the competition was not played between the 1938\u201339 and 1945\u201346 editions. Due to the wartime breaks, the competition did not celebrate its centenary year until 1980\u201381.  After some confusion over the rules in its first competition, the FA decided that any drawn match would lead to a replay, with teams competing in further replays until a game was eventually won.[5] Alvechurch and Oxford City contested the most replayed tie in the 1971\u201372 qualification, in a tie which went to 6 matches.[5] Multiple replays were scrapped for the competition proper in 1991\u201392, and the qualifying rounds in 1997\u201398.[5] Replays were removed altogether from the semi-final and final matches in 2000, from the quarter-finals in 2016\u201317 and the fifth round in 2019\u201320.[5]  Redevelopment of Wembley saw the final played outside of England for the first time, the 2001\u20132006 finals being played at the Millennium Stadium in Cardiff. The final returned to Wembley in 2007, followed by the semi-finals from 2008.  An application window is open to clubs before entry lists, round byes and scheduling are announced in July. All clubs in the top four levels (the Premier League and the three divisions of the English Football League) are automatically eligible. Clubs from Level 5\u20139 (non-league football) are also eligible provided they play in either the FA Trophy or FA Vase competitions in the current season. All participating clubs must also have a stadium suitable for the competition and The Association may reject applications at its discretion.[2]  Previously, Level 10 clubs were a prominent feature in early qualifying rounds. The gradual remodelling of the National League System to a 'perfect' 1\u20132\u20134\u20138\u201316 system, with a first phase in 2018\u201319, a final phase in 2021\u201322 (which included the promotion of 107 clubs), and played to a full quota in 2022\u201323 has resulted in a larger number of teams playing in Level 7\u20139.[6][7][8] Consequently, for the FA Cup, entries equal the number in tiers 1\u20139 and is cut off to those below.[2] Though still able to apply, Level 10 clubs are used as alternatives \"subject to availability\" in the event of a non\/rejected applicant (with vacancies filled by Level 10 applicants with the best PPG in the previous league season).[2]  The total number of entries in the FA Cup has changed as Non-League football has gradually been expanded and reorganised over time. In the 2004\u201305 season, 660 clubs entered the competition, beating the long-standing record of 656 from the 1921\u201322 season. In 2005\u201306 this increased to 674 entrants, in 2006\u201307 to 687, in 2007\u201308 to 731 clubs, in 2008\u201309 and 2009\u201310 to 762.[9] The total number of entries has also varied naturally from year-to-year as new clubs form and others dissolve at unequal rates. Though most leagues in the National League System maintain the same number of teams via reprieves, inevitably entry-level divisions (typically at tier 10) have to be impacted when a club leaves the pyramid.[10] Therefore, for example, 759 teams entered in 2010\u201311, a record 763 in 2011\u201312, 758 in 2012\u201313, 737 in 2013\u201314 and 736 in 2014\u201315.[9] However, since 2021\u201322, The FA has cut off automatic eligibility to the 10th tier (to appear only subject to availability) and instead set the size of the draw to match the more stable number of teams in Level 1\u20139.[11] This means that the competition may now see a standardised number of entries from one year to the next.[12] This number is currently 732 but could rise to 748 for 2023\u201324 with plans for a new SWPL 9th tier division to share the South East with the existing Western League.[13]  It is very rare for top clubs to miss the competition, although it can happen in exceptional circumstances. Manchester United did not defend their title in 1999\u20132000, as they were already in the inaugural Club World Championship. The club stated that entering both tournaments would overload their fixture schedule and make it more difficult to defend their Champions League and Premier League titles. The club claimed that they did not want to devalue the FA Cup by fielding a weaker side. The move benefited United as they received a two-week break and won the 1999\u20132000 league title by an 18-point margin, although they did not progress past the group stage of the Club World Championship. The withdrawal from the FA Cup, however, drew considerable criticism as this weakened the tournament's prestige and Sir Alex Ferguson later admitted his regret regarding their handling of the situation.[14][15][16]  Welsh sides that play in English leagues are eligible, although since the creation of the League of Wales there are only five clubs remaining: Cardiff City (the only non-English team to win the tournament, in 1927), Swansea City, Newport County, Wrexham, and Merthyr Town. In the early years other teams from Wales, Ireland and Scotland also took part in the competition, with Glasgow side Queen's Park losing the final to Blackburn Rovers in 1884 and 1885 before being barred from entering by the Scottish Football Association.  Entries from clubs affiliated to \"offshore\" associations are also eligible subject to consideration on an annual basis, with special provisions that may apply.[2] In the 2013\u201314 season the first Channel Island club entered the competition when Guernsey F.C. competed.[17] The first game played in the Channel Islands \u2013 and thus the southernmost FA Cup tie played \u2013 took place on 7 August 2021 between Jersey Bulls and Horsham YMCA. A third club, F.C. Isle of Man, was also eligible to play in 2022\u201323, but in the end all Crown Dependency teams either did not appear on the entry list or later withdrew.[18][19]  Beginning in August, the competition proceeds as a knockout tournament throughout, consisting of twelve rounds, a semi-final and then a final, in May. A system of byes ensures clubs above Level 9 enter the competition at later stages. There is no seeding, the fixtures in each round being determined by a random draw. Prior to the fifth round, fixtures ending in a tie are replayed once only (from the 2024\u201325 campaign, this will be prior to the first round proper).[20][21] The first six rounds are qualifiers, with the draws organised on a regional basis. The next six rounds are the \"proper\" rounds where all clubs are in one draw.  All entrants from Level 9 begin the competition in the extra preliminary round, as well as any Level 10 team filling in for a vacancy.[2] Teams from Level 8 are ranked on their PPG in the previous season, except newly promoted teams automatically ranked towards the bottom and newly relegated teams ranked to the top; teams are then split between entering at either the Extra-Preliminary or preliminary round so as to ensure the right balance of fixtures throughout the competition.[2] From there, clubs from higher levels are added in later rounds, as per the table below.  The months in which rounds are played are traditional, with exact dates subject to each calendar. The number of new entries, winners from previous rounds, and division of Level 8 teams in the two preliminary rounds are based on an entry list of 732 modelled on the English league system as of 2022\u201323. From 2023 to 2024, the entry list could rise to 746 in line with sixteen additional clubs at Level 9 meaning that the extra preliminary round will have 444 teams with only 50 Level 8 clubs entering at the preliminary round.[13]  previous round  Level 9 clubs  Level 8 clubs (96 lowest ranked)  The qualifying rounds are regionalised to reduce the travel costs for smaller non-league sides. The first and second proper rounds were also previously split into Northern and Southern sections, but this practice was ended after the 1997\u201398 competition. [citation needed]  The final is normally held the Saturday after the Premier League season finishes in May. The only seasons in recent times when this pattern was not followed were: 1999\u20132000, when most rounds were played a few weeks earlier than normal as an experiment; 2010\u201311 and 2012\u201313 when the FA Cup Final was played before the Premier League season had finished, to allow Wembley Stadium to be ready for the UEFA Champions League final,[22] as well as in 2011\u201312 to allow England time to prepare for that summer's European Championships;,[23] 2019\u201320 when the final was delayed until August due to the COVID-19 pandemic in the United Kingdom,[24][25] and the 2021-22 when the final was held a week before the end of the league.  The draws for the Extra Preliminary, Preliminary, and first qualifying rounds used to all occur at the same time. Thereafter, the draw for each subsequent round is not made until after the scheduled dates for the previous round, meaning that in the case of replays, clubs will often know their future opponents in advance.  The draw for each of the proper rounds is broadcast live on television, usually taking place at the conclusion of live coverage of one of the games of the previous round. Public interest is particularly high during the draw for the third round, which is where the top-ranked teams are added to the draw.  In rounds up to and including the fourth round proper, fixtures resulting in a draw (after normal time) go to a replay, played at the venue of the away team, at a later date; if that replay is still tied, the winner is settled by a period of extra time, and if still necessary, a penalty shootout. Since 2016\u201317, ties have been settled on the day from the quarter-finals onwards, using extra time and penalties. From 2018\u201319, Fifth round ties are also settled by extra time and penalties. Beginning with the 2024\u201325 competition, replays have been scrapped from the first round onwards.[26] The decision to scrap replays received criticism from a number of lower tier clubs and government officials.[27]  Until 1990\u201391, further replays would be played until one team was victorious. In 1971\u201372, a fourth qualifying round game between Alvechurch and Oxford City was played six times until Alvechurch won in the fifth replay.[28] In their 1975 campaign, Fulham played 12 games over six rounds, which remains the most games played by a team to reach a final.[29] Replays were traditionally played three or four days after the original game, but from 1991\u201392 they were staged at least 10 days later on police advice for the rounds proper. This led to penalty shoot-outs being introduced, the first of which came on 26 November 1991 when Rotherham United eliminated Scunthorpe United.[30]  From 1980\u201381 to 1998\u201399, the semi-finals went to extra time on the day if the score after 90 minutes was a draw. If the score was still level after extra time, the match would go to a replay. Replays for the semi-finals were scrapped for 1999\u20132000; the last semi-final to go into a replay was in 1998\u201399, when Manchester United beat rivals Arsenal 2\u20131 after extra time, following a 0\u20130 draw in the original match.  The first FA Cup Final to go to extra time and a replay was the 1875 final, between the Royal Engineers and the Old Etonians. The initial tie finished 1\u20131 but the Royal Engineers won the replay 2\u20130 in normal time. The last replayed final was the 1993 FA Cup Final, when Arsenal and Sheffield Wednesday fought a 1\u20131 draw. The replay saw Arsenal win the FA Cup, 2\u20131 after extra time.  The last quarter-final to go to a replay was Manchester United vs West Ham United in the 2015\u201316 FA Cup. The original game at Old Trafford ended in a 1\u20131 draw, while Manchester United won the replay at the Boleyn Ground, 2\u20131. It was also the last FA Cup game ever played at the Boleyn Ground.[31]  The last fifth round replay saw Tottenham Hotspur defeat Rochdale 6\u20131 at Wembley in the 2017\u201318 FA Cup after the first match at Spotland Stadium ended in a 2\u20132 draw.[32].  The FA Cup winners qualify for the following season's UEFA Europa League (formerly named the UEFA Cup; from its launch in 1960 until 1998, they entered the now-defunct UEFA Cup Winners' Cup instead). This European place applies even if the team is relegated or is not in the English top flight. In the past, if the FA Cup winning team also qualified for the following season's Champions League or Europa League through their league or European performance, then the losing FA Cup finalists were given the European berth of the League Cup winners and the League Cup winners would be given the league berth instead (in the Cup Winners' Cup era, teams qualifying for the UEFA Cup via other competitions would be promoted to the Cup Winners' Cup instead). FA Cup winners enter the Europa League at the group stage. Losing finalists, if they had not qualified for Europe via the league, began earlier, at the play-off or third qualifying round stage.[33] From the 2015\u201316 UEFA Europa League season, however, UEFA does not allow the runners-up to qualify for the Europa League through the competition.[34] If the winner of the FA Cup has already qualified for a European Competition through their Premier League position, the FA Cup berth is then given to the highest placed team in the Premier League who has not yet qualified for a European Competition.  The FA Cup winners also qualify for the following season's single-match FA Community Shield, the traditional season opener played against the previous season's Premier League champions (or the Premier League runners-up if the FA Cup winners also won the league \u2013 the double).  Fixtures in the 12 rounds of the competition are usually played at the home ground of one of the two teams. The semi-finals and final are played at a neutral venue \u2013 the rebuilt Wembley Stadium.  In the matches for the 12 competition rounds, the team who plays at home is decided when the fixtures are drawn \u2013 simply the first team drawn out for each fixture. Occasionally games may have to be moved to other grounds due to other events taking place, security reasons or a ground not being suitable to host popular teams. However, since 2003, clubs cannot move grounds to the away side's for capacity or financial reasons. If any move has to be made, it has to be to a neutral venue and any additional monies earned by the move goes into the central pot.[35] In the event of a draw, the replay is played at the ground of the team who originally played away from home.  In the days when multiple replays were possible, the second replay (and any further replays) were played at neutral grounds. The clubs involved could alternatively agree to toss for home advantage in the second replay.  The semi-finals have been played exclusively at the rebuilt Wembley Stadium since 2008, one year after it opened and after it had already hosted a final (in 2007). For the first decade of the competition, the Kennington Oval was used as the semi-final venue. In the period between this first decade and the reopening of Wembley, semi-finals were played at high-capacity neutral venues around England; usually the home grounds of teams not involved in that semi-final, chosen to be roughly equidistant between the two teams for fairness of travel. The top three most used venues in this period were Villa Park in Birmingham (55 times), Hillsborough in Sheffield (34 times) and Old Trafford in Manchester (23 times). The original Wembley Stadium was also used seven times for semi-final, between 1991 and 2000 (the last held there), but not always for fixtures featuring London teams. In 2005, both were held at the Millennium Stadium.  In 2003 the FA decided to permanently use the new Wembley for semi-finals to recoup debts in financing the new stadium.[36] This was controversial, with the move seen as both unfair to fans of teams located far from London, as well as taking some of the prestige away from a Wembley final.[37] In defending the move, the FA has also cited the extra capacity Wembley offers, although the 2013 fixture between Millwall and Wigan Athletic led to the unprecedented step of placing 6,000 tickets on sale to neutral fans after the game failed to sell out.[38] A fan poll by The Guardian in 2013 found 86% opposition to Wembley semi-finals.[38]  The final has been played at the rebuilt Wembley Stadium since it opened, in 2007.[39] The rebuilding process meant that between 2001 and 2006 they were hosted at the Millennium Stadium in Cardiff in Wales. Prior to rebuilding, the final was hosted by the original Wembley Stadium since it opened in 1923 (being originally named the Empire Stadium). One exception to this 78-year series of Empire Stadium finals (including five replays) was the 1970 replay between Leeds United and Chelsea, held at Old Trafford in Manchester.  In the 51 years prior to the Empire Stadium opening, the final (including 8 replays) was held in a variety of locations, predominantly in London, and mainly at the Kennington Oval and then Crystal Palace. It was played 22 times at The Oval (the inaugural competition in 1872, and then all but two times until 1892). After The Oval, Crystal Palace hosted 21 finals from 1895 to 1914, broken up by four replays elsewhere. The other London venues were Stamford Bridge from 1920 to 1922 (the last three finals before the move to Empire Stadium); and the University of Oxford's Lillie Bridge in Fulham for the second ever final, in 1873. The other venues used sparingly in this period were all outside of London, as follows:  The FA permitted artificial turf (3G) pitches in all rounds of the competition from the 2014\u201315 edition and beyond.[40] Under the 2015\u201316 rules, the pitch must be of FIFA One Star quality, or Two Star for ties if they involve one of the 92 professional clubs.[2] This followed approval two years previously for their use in the qualifying rounds only \u2013 if a team with a 3G pitch progressed to the competition proper, they had to switch their tie to the ground of another eligible entrant with a natural grass pitch.[41] Having been strong proponents of the surface, the first match in the proper rounds to be played on a 3G surface was a televised first round replay at Maidstone United's Gallagher Stadium on 20 November 2014.[42]  The winners of the competition receive the FA Cup. It is only loaned to the club by the FA; under the current (2015\u201316) rules it must be returned by 1 March, or earlier if given seven days' notice.[2] Traditionally, the holders had the Cup until the following year's presentation, although more recently the trophy has been taken on publicity tours by the FA in between finals.[43]  The trophy comes in three parts \u2013 the cup itself, plus a lid and a base. There have been two designs of trophy in use, but five physical trophies have been presented. The original trophy, known as the \"little tin idol\", was 18 inches high and made by Martin, Hall & Co. It was stolen in 1895 and never recovered, and so was replaced by an exact replica, used until 1910. The FA decided to change the design after the 1909 winners, Manchester United, made their own replica, leading the FA to realise they did not own the copyright.[44] This new, larger design was by Fattorini and Sons, and was used from 1911.[44] In order to preserve this original, from 1992 it was replaced by an exact replica, although this had to be replaced after just over two decades, after showing wear and tear from being handled more than in previous eras. This third replica, first used in 2014, was built heavier to withstand the increased handling.[43] Of the four surviving trophies, only the 1895 replica has entered private ownership.[45] The name of the winning team is engraved on the silver band around the base as soon as the final has finished, in order to be ready in time for the presentation ceremony.[43] This means the engraver has just five minutes to perform a task which would take 20 under normal conditions, although time is saved by engraving the year on during the match, and sketching the presumed winner.[46] During the final, the trophy is decorated with ribbons in the colours of both finalists, with the loser's ribbons being removed at the end of the game.[47] The tradition of tying ribbons started after Tottenham Hotspur won the 1901 FA Cup Final and the wife of a Spurs director decided to tie blue and white ribbons to the handles of the cup.[48] Traditionally, at Wembley finals, the presentation is made at the Royal Box, with players, led by the captain, mounting a staircase to a gangway in front of the box and returning by a second staircase on the other side of the box. At Cardiff the presentation was made on a podium on the pitch.  The tradition of presenting the trophy immediately after the game did not start until the 1882 final; after the first final in 1872 the trophy was not presented to the winners, Wanderers, until a reception held four weeks later in the Pall Mall Restaurant in London.[49] Under the original rules, the trophy was to be permanently presented to any club which won the competition three times, although when inaugural winners Wanderers achieved this feat by the 1876 final, the rules were changed by FA Secretary CW Alcock (who was also captain of Wanderers in their first victory).[50]  Portsmouth have the distinction of being the football club which has held the FA Cup trophy for the longest uninterrupted period - seven years. Portsmouth had defeated Wolverhampton Wanderers 4\u20131 in the 1939 FA Cup Final and were awarded the trophy as 1938\u201339 FA Cup winners. But with the outbreak of World War II in September 1939, the regular Football League and FA Cup competitions for the 1939\u201340 season were cancelled for the duration of the war. Portsmouth's manager Jack Tinn was rumoured to have kept the FA Cup trophy 'safe under his bed' throughout the duration of the war, but this is an urban myth. Because the naval city of Portsmouth was a primary strategic military target for German Luftwaffe bombing, the FA Cup trophy was actually taken ten miles to the north of Portsmouth, to the nearby Hampshire village of Lovedean, and there it resided in a quaint thatched roof country pub called The Bird in Hand for the seven years of the war.[51] After the conclusion of World War II, the FA Cup trophy was presented back to the Football Association by the club in time for the 1946 FA Cup Final.  The first trophy, the 'little tin idol', was made by Martin, Hall & Co at a cost of \u00a320.[52] It was stolen from a Birmingham shoe shop window belonging to William Shillcock while held by Aston Villa on 11 September 1895 and was never seen again. Despite a \u00a310 reward for information, the crime was never solved. As it happened while it was in their care, the FA fined Villa \u00a325 to pay for a replacement.  Just over 60 years later, 80 year old career criminal Henry (Harry) James Burge claimed to have committed the theft, confessing to a newspaper, with the story being published in the Sunday Pictorial newspaper on 23 February 1958. He claimed to have carried out the robbery with two other men, although when discrepancies with a contemporaneous report in the Birmingham Post newspaper (the crime pre-dated written police reports) in his account of the means of entry and other items stolen, detectives decided there was no realistic possibility of a conviction and the case was closed. Burge claimed the cup had been melted down to make counterfeit half-crown coins, which matched known intelligence of the time, in which stolen silver was being used to forge coins which were then laundered through betting shops at a local racecourse, although Burge had no history of forgery in a record of 42 previous convictions for which he had spent 42 years in prison. He had been further imprisoned in 1957 for seven years for theft from cars. Released in 1961, he died in 1964.[53]  After the theft, a replica of the trophy was made, which was used until a redesign of the trophy in 1911. The 1895 replica was then presented to the FA's long-serving president Lord Kinnaird.[44] Kinnaird died in 1923, and his family kept it in their possession, out of view, until putting it up for auction in 2005.[54] It was sold at Christie's auction house on 19 May 2005 for \u00a3420,000 (\u00a3478,400 including auction fees and taxes).[44] The sale price set a new world record for a piece of football memorabilia, surpassing the \u00a3254,000 paid for the Jules Rimet World Cup Trophy in 1997.[45] The successful bidder was David Gold, the then joint chairman of Birmingham City; claiming the FA and government were doing nothing proactive to ensure the trophy remained in the country, Gold stated his purchase was motivated by wanting to save it for the nation.[45] Accordingly, Gold presented the trophy to the National Football Museum in Preston on 20 April 2006, where it went on immediate public display.[54] It later moved with the museum to its new location in Manchester.[44] In November 2012, it was ceremonially presented to Royal Engineers, after they beat Wanderers 7\u20131 in a charity replay of the first FA Cup final. In September 2020, Gold sold the replica trophy for \u00a3760,000 through the Bonhams auction house.[55] In January 2021, it was revealed that the trophy had been purchased by Sheikh Mansour bin Zayed Al Nahyan, the owner of Manchester City, who stated that it would be returned on loan to the National Football Museum.[56]  The redesigned trophy first used in 1911 was larger at 61.5\u00a0cm (24.2 inches) high, and was designed and manufactured by Fattorini & Sons of Bradford, coincidentally being won by Bradford City in its first outing.[43][44]  On the 27 March 2016 episode of the BBC television programme Antiques Roadshow, this trophy was valued at \u00a31\u00a0million by expert Alastair Dickenson, although he suggested that, due to the design featuring depictions of grapes and vines, it may not have been specifically produced for the FA, but was instead an off-the-shelf design originally meant to be a wine or champagne cooler.[44] This was later disproved when Thomas Fattorini was invited to the Antiques Roadshow to \"ambush\" Alastair Dickenson with the competition winning design by Fattorini & Sons. The show was filmed at Baddesley Clinton and subsequently aired on 23 October 2016.  A smaller, but otherwise identical, replica was also made by the company Thomas Fattorini, the North Wales Coast FA Cup trophy, and is contested annually by members of that regional Association.[57]  The 1992 replica was made by Toye, Kenning and Spencer.[58] A copy of this trophy was also produced, in case anything happened to the primary trophy.[59]  The 2014 replica was made by Thomas Lyte, handcrafted in sterling 925 silver over 250 hours. A weight increase for greater durability has taken it to 6.3 kilograms (14\u00a0lb).[43]  Each club in the final receives 40 winners or runners-up medals to be distributed among players, staff and officials. The traditional styles of gold-cased medals \u2013 the winners' medal, which had remained largely unchanged since the 1890s, and runners-up medals, which were last updated in 1946 \u2013 were replaced for the 2021 final by new designs of gold winners' medals and silver runners-up medals suspended on a ribbon.[60]  Since the start of the 1994\u201395 season, the FA Cup has been sponsored. However, to protect the identity of the competition, the sponsored name has always included 'The FA Cup' in addition to the sponsor's name, unlike sponsorship deals for the League Cup where the word 'cup' is preceded by only the sponsor's name. Sponsorship deals run for four years, though \u2013 as in the case of E.ON \u2013 one-year extensions may be agreed. Emirates Airline has been the sponsor since 2015, initially renaming the competition as 'The Emirates FA Cup', unlike previous editions, which included 'The FA Cup in association with E.ON' and 'The FA Cup with Budweiser'.[61] The Emirates sponsorship deal, originally scheduled to terminate in 2018, was later extended until 2021 and again until 2024.[62]  From 2006 to 2013, Umbro supplied match balls for all FA Cup matches. They were replaced at the start of the 2013\u201314 season by Nike, who produced the competition's official match ball for five seasons. Mitre took over for the 2018\u201319 season, beginning a three-year partnership with the FA.[68]  The possibility of unlikely victories in the earlier rounds of the competition, where lower ranked teams beat higher placed opposition in what is known as a \"giant killing\", is much anticipated by the public. Such upsets are considered an integral part of the tradition and prestige of the competition, and the attention gained by giant-killing teams can be as great as that for winners of the cup.[76] Almost every club in the League Pyramid has a fondly remembered giant-killing act in its history.[77] It is considered particularly newsworthy when a top Premier League team suffers an upset defeat, or where the giant-killer is a non-league club, i.e. from outside The Football League.  One analysis of four years of FA Cup results showed that it was 99.85 per cent likely that at least one team would beat one from its next higher division in a given year. The probability drops to 48.8 per cent for a two-division gap, and 39.28 per cent for a three-division gap.[77]  The Football League was founded in 1888, 16 years after the first FA Cup competition. Before its establishment as the dominant football competition in England, teams from rival leagues did make the final of the FA Cup. The Wednesday (later Sheffield Wednesday) in 1890 reached the final as a member of the Football Alliance, two years before that competition merged with the Football League.[78] Later, with the Football League predominantly in the North and Midlands of England, leading clubs of the Southern Football League were of a level with Football League teams, and in 1901 Southern League members Tottenham Hotspur became the only non-League side to win the Cup,[79] while fellow Southern League team Southampton were losing finalists in 1900 and 1902. In 1920\u201321, the Football League expanded to incorporate teams from the Southern League's first division, and the following year it added a further division consisting of leading northern and midlands clubs. This consolidated the Football League's position as the leading competition in English football, and established the hierarchy in which non-League clubs in the English football league system competing in the FA Cup would face Football League teams as clear underdogs.  Since the expansion of the Football League in 1921, the best performance of a team from outside the Football League was National League side Lincoln City's run to the quarter-finals of the 2016\u201317 FA Cup, during which they defeated Championship side Brighton 3\u20131 in the fourth round and Premier League side Burnley 1\u20130 in the fifth, before falling to ultimate Cup champions Arsenal 5\u20130 at the Emirates. Lincoln's defeat of Burnley was only the third (and most recent) FA Cup victory for a non-league team over a top-flight side since 1989.[80] Giant-killings can also be applied where the defeated team is from lower down the Football League, particularly where the defeated club is very notable or the winning team particularly obscure. Liverpool, having already won five league titles in their history, were in the Second Division in 1959 when they lost 2\u20131 to Worcester City of the Southern League.[81]  The best-known non-league giant-killing came in the 1971\u201372 FA Cup, when non-league Hereford United defeated First Division Newcastle United.[82] Hereford were trailing 1\u20130 with less than seven minutes left in the Third round proper replay, when Hereford's Ronnie Radford scored the equaliser \u2013 a goal still shown regularly when FA Cup fixtures are broadcast.[83] Hereford finished the shocking comeback by defeating Newcastle 2\u20131 in the match. They finished that season as runners-up of the Southern League, behind Chelmsford City, and were voted into the Football League at the expense of Barrow.  Some small clubs gain a reputation for being \"cup specialists\" after two or more giant killing feats within a few years.[77] Yeovil Town hold the record for the most victories over league opposition as a non-league team, having recorded 20 wins through the years before they achieved promotion into The Football League in 2003.[84] The record for a club which has never entered the Football League is held by Altrincham, with 17 wins against league teams.  For non-League teams, reaching the third round proper \u2013 where all Level 1 sides now enter \u2013 is considered a major achievement. In the 2008\u201309 FA Cup, a record eight non-League teams achieved this feat.[85] As of the 2023\u201324 season, only eleven non-League teams have reached the fifth round proper (last 16) since 1925,[86] and only Lincoln City have progressed to the quarter-finals (last 8), during the 2016\u201317 edition of the tournament.[87]  Chasetown, while playing at Level 8 of English football during the 2007\u201308 competition, were the lowest-ranked team to ever play in the third round proper (final 64, of 731 teams entered that season). Chasetown was then a member of the Southern League Division One Midlands (a lower level within the Southern Football League), when they lost to Football League Championship (Level 2) team Cardiff City, the eventual FA Cup runners-up that year.[88] Their success earned the lowly organisation over \u00a360,000 in prize money. Marine matched this in the 2020\u201321 competition as a member of the Northern Premier League Division One North West, and were drawn against Premier League (Level 1) team Tottenham Hotspur, to whom they lost 5\u20130.  During the 2023\u201324 season, Maidstone United in the National League South (Level 6) had an 8\u2013game cup run, reaching the fifth round when they won 2\u20131 away at EFL Championship (Level 2) side Ipswich Town.[89] Their run ended at the fifth round after losing 5\u20130 away to another EFL Championship side Coventry City.[90] They became the eleventh non\u2013League team to reach the fifth round, and the lowest-ranked team to do so since Blyth Spartans (Level 7) in 1977\u201378. Maidstone's co\u2013owner Oliver Ash stated that their cup run had earned the club 'something like \u00a3700,000 before tax'.[91]  Giant-killings can apply to matches between league clubs, particularly where teams from tier 4 have defeated tier 1 sides. In games between League sides, one of the most notable results was the 1992 victory by Wrexham, bottom of the previous season's League (avoiding relegation due to expansion of The Football League), over reigning champions Arsenal. Another similar shock was when Shrewsbury Town beat Everton 2\u20131 in 2003. Everton finished seventh in the Premier League and Shrewsbury Town were relegated to the Football Conference that same season.  During the 2022\u201323 tournament, Grimsby Town who were 16th in EFL League Two won 2\u20131 away at Premier League side Southampton to advance into the quarter finals.[92]  Since its establishment, the FA Cup has been won by 44 clubs. Teams shown in italics are no longer in existence. Additionally, Queen's Park ceased to be eligible to enter the FA Cup after a Scottish Football Association ruling in 1887.[93]  Four clubs have won consecutive FA Cups on more than one occasion: Wanderers (1872, 1873 and 1876, 1877, 1878), Blackburn Rovers (1884, 1885, 1886 and 1890, 1891), Tottenham Hotspur (1961, 1962 and 1981, 1982) and Arsenal (2002, 2003 and 2014, 2015).  The record for most titles for a manager is held by Ars\u00e8ne Wenger, who won the FA Cup with Arsenal seven times (1998, 2002, 2003, 2005, 2014, 2015, 2017). Wenger is also the only manager to have won the Cup at the old Wembley Stadium, the Millennium Stadium, and the new Wembley Stadium.  Manchester City (2019) are the only club to have achieved a domestic treble of league, FA Cup and League Cup, having beaten Chelsea 4\u20133 on penalties in the League Cup Final, finished at the top of the Premier League, and beaten Watford 6\u20130 in the FA Cup Final.  Manchester United (1999) and Manchester City (2023)  are the only two English teams to have won the continental treble of league, FA Cup, and Champions League. They are two of only nine European sides to do so. Liverpool won the FA Cup, League Cup and UEFA Cup in (2001) to complete a cup treble.  Eight clubs have won the FA Cup as part of a League and Cup double, namely Preston North End (1889), Aston Villa (1897), Tottenham Hotspur (1961), Arsenal (1971, 1998, 2002), Liverpool (1986), Manchester United (1994, 1996, 1999), Chelsea (2010) and Manchester City (2019, 2023). In 1993, Arsenal became the first side to win both the FA Cup and the League Cup in the same season when they beat Sheffield Wednesday in both finals. Liverpool (2001, 2022), Chelsea (2007) and Manchester City (2019) have since repeated this feat. In 2012, Chelsea won both the FA Cup and the Champions League.  The FA Cup has only been won by a non-English team once. Cardiff City achieved this in 1927 when they beat Arsenal in the final at Wembley. They had previously made it to the final only to lose to Sheffield United in 1925 and lost another final to Portsmouth in 2008. Cardiff City are also the only team to win the national cups of two countries in the same season, having also won the Welsh Cup in 1927. The Scottish team Queen's Park reached and lost the final in both 1884 and 1885.  Since the creation of the Football League in 1888, the final has never been contested by two teams from outside the top division, and there have only been eight winners who were not in the top flight: Notts County (1894); Tottenham Hotspur (1901); Wolverhampton Wanderers (1908); Barnsley (1912); West Bromwich Albion (1931); Sunderland (1973), Southampton (1976) and West Ham United (1980). With the exception of Tottenham, these clubs were all playing in the second tier (the old Second Division) \u2013 Tottenham were playing in the Southern League and were only elected to the Football League in 1908, meaning they are the only non-League winners of the FA Cup since the League's creation. Other than Tottenham's victory, only 24 finalists have come from outside English football's top tier, with a record of 7 wins and 17 runners-up: and none at all from the third tier or lower, Southampton (1902, then in the Southern League) being the last finalist from outside the top two tiers.  Sunderland's win in 1973 was considered a major upset, having beaten Leeds United who finished third in the top flight that season,[95] as was West Ham's victory over Arsenal in 1980 as the Gunners were in their third successive FA Cup Final and were the cup holders as well as just having finished 4th in the First Division, whereas West Ham had ended the season 7th in Division 2. This also marked the last time (as of 2022\u201323) a team from outside the top division won the FA Cup. Uniquely, in 2008 three of the four semi-finalists (Barnsley, Cardiff City and West Bromwich) were from outside the top division, although the eventual winner was the last remaining top-flight team, Portsmouth.[96] West Bromwich (1931) are the only team to have won the FA Cup and earned promotion to the top flight in the same season; whereas Wigan Athletic (2013) are the only team to have won the Cup and been relegated from the top flight in the same season.  The FA Cup Final is one of 10 events reserved for live broadcast on UK terrestrial television under the Ofcom Code on Sports and Other Listed and Designated Events.  In the early years of coverage the BBC had exclusive radio coverage with a picture of the pitch marked in the Radio Times with numbered squares to help the listener follow the match on the radio. The first FA Cup Final on Radio was in 1926 between Bolton Wanderers and Manchester City but this was only broadcast in Manchester, the first national final on BBC Radio was between Arsenal and Cardiff City in 1927. The first final on BBC Television was in 1937 in a match which featured Sunderland and Preston North End but this was not televised in full. The following season's final between Preston and Huddersfield Town was covered in full by the BBC. When ITV was formed in 1955 they shared final coverage with the BBC in one of the only club matches shown live on television, during the 1970s and 1980s coverage became more elaborate with BBC and ITV trying to steal viewers from the others by starting coverage earlier and earlier some starting as early as 9\u00a0a.m. which was six hours before kick off. The sharing of rights between BBC and ITV continued from 1955 to 1988, when ITV lost coverage to the BBC.  From 1988 to 1997, the BBC was the exclusive broadcaster of the competition on terrestrial television and covered the competition from the third round onwards, showing one live match per round alongside highlights. In 1990, British Satellite Broadcasting (BSB) obtained rights to the competition, and showed a live match from rounds 1 and 2. This continued to be the case after Sky took over BSB in 1991.  From 1997 to 2001, ITV and Sky shared live coverage with both having two matches per round and BBC continuing with highlights on Match of the Day. From 2001 to 2008, BBC and Sky again shared coverage with BBC having two or three matches per round and Sky having one or two. From 2008\u201309 to 2013\u201314, FA Cup matches are shown live by ITV across England and Wales, with UTV broadcasting to Northern Ireland but STV refusing to show them. ITV shows 16 FA Cup games per season, including the first pick of live matches from each of the first to sixth rounds of the competition, plus one semi-final exclusively live. The final is also shown live on ITV. Under the same 2008 contract, Setanta Sports showed three games and one replay in each round from round three to five, two quarter-finals, one semi-final and the final. The channel also broadcast ITV's matches exclusively to Scotland, after the ITV franchise holder in Scotland, STV, decided not to broadcast FA Cup games. Setanta entered administration in June 2009 and as a result the FA terminated Setanta's deal to broadcast FA-sanctioned competitions and England internationals.[97] As a result of Setanta going out of business ITV showed the competition exclusively in the 2009\u201310 season with between three and four matches per round, all quarter finals, semi-finals and final live as the FA could not find a pay TV broadcaster in time. ESPN bought the competition for the 2010\u201311 to 2012\u201313 season and during this time Rebecca Lowe became the first woman to host the FA Cup Final in the UK.  In October 2009, The FA announced that ITV would show an additional match in the First and second rounds on ITV, with one replay match shown on ITV4. One match and one replay match from the first two rounds will broadcast on The FA website for free, in a similar situation to the 2010 World Cup Qualifier between Ukraine and England.[98] The 2009\u201310 first-round match between Oldham Athletic and Leeds United was the first FA Cup match to be streamed online live.[99]  Many[who?] expected BSkyB to make a bid to show some of the remaining FA Cup games for the remainder of the 2009\u201310 season which would include a semi-final and shared rights to the final. ESPN took over the package Setanta held for the FA Cup from the 2010\u201311 season.[100] The 2011 final was also shown live on Sky 3D in addition to ESPN (who provided the 3D coverage for Sky 3D) and ITV.[101] Following the sale of ESPN's UK and Ireland channels to BT, ESPN's rights package transferred to BT Sport from the 2013\u201314 season.[102]  BBC Radio 5 Live and Talksport provides radio coverage including several full live commentaries per round, with additional commentaries broadcast on BBC Local Radio.  Until the 2008\u201309 season, the BBC and Sky Sports shared television coverage, with the BBC showing three matches in the earlier rounds. Some analysts argued the decision to move away from the Sky and, in particular, the BBC undermined the FA Cup in the eyes of the public.  The early rounds of the 2008\u201309 competition were covered for the first time by ITV's online service, ITV Local. The first match of the competition, between Wantage Town and Brading Town, was broadcast live online. Highlights of eight games of each round were broadcast as catch up on ITV Local.[103][104] Since ITV Local closed, this coverage did not continue.  ITV lost the rights to the FA Cup beginning with the 2014\u201315 FA Cup, terrestrial rights returned to BBC Sport, with the final being shown on BBC One while BT Sport hold the pay TV rights. Under this deal, the BBC will show around the same number of games as ITV and still having the first pick for each round.[105]  Matches involving Welsh clubs are sometimes exclusively broadcast on Welsh language channel S4C, which is also available to view across the rest of the United Kingdom on satellite and cable television, and through the channel's website.[106] A similar arrangement is shared with BBC Cymru Wales when the corporation obtained the rights from 2014\u201315, potentially giving the BBC an extra match per round.[107]  On 23 May 2019, it was announced that ITV would replace BT Sport in broadcasting the FA Cup from the 2021\u201322 season, this new deal will see BBC and ITV become joint broadcasters of the tournament for the first time since 1988, this will mean for the first time that all FA Cup matches would all be exclusively broadcast on free-to-air television.[108]  The FA sells overseas rights separately from the domestic contract.[citation needed]  RCTI (2019-20 and 2021-22) "},{"title":"Referee (association football)","content":"  In association football, the referee is the person responsible for interpreting and enforcing the Laws of the Game during a match.  The referee is the final decision-making authority on all facts connected with play, and is the match official with the authority to start and stop play and impose disciplinary action against players and coaches during a match.[1]  At most levels of play, the referee is assisted by two assistant referees (formerly known as linesmen), who advise the referee on whether the ball leaves the playing area and any infringements of the Laws of the Game occurring outside of the view of the referee. The final decision on any decision of fact rests with the referee, who has authority to overrule an assistant referee. At higher levels of play, the referee may also be assisted by a fourth official who supervises the teams' technical areas and assists the referee with administrative tasks, and, at the very highest levels, additional assistant referees and\/or video assistant referees. Referees and other game officials are licensed and trained by its member national organisations.  The referee's powers and duties are described by Law 5 of the Laws of the Game.[2] The referee:  As well as other various duties and powers described fully in Law 5 of the Laws of the Game, pursuant to current updates.   Referees and assistant referees are regulated at a national level. FIFA requires that each national organisation establish a referees committee composed of former officials that has authority over refereeing in that territory.[3] FIFA also mandate that referees pass tests to show sufficient physical fitness and knowledge of the Laws of the Game, as well as an annual medical.[3] Generally, referees are required to have greater experience to officiate higher level matches (see, for example, the multiple tiers of refereeing in England). The most elite officials, those who are permitted to officiate international games, are listed on the FIFA International Referees List. Referees wear a kit distinguishing themselves from the players. Usually this comprises  a shirt of a different colour to the players of both teams.   In the early 20th century, referees wore a blazer rather than a shirt similar to that of the players. Traditionally that uniform was almost always all black, unless one of the teams was wearing a very dark shirt in which case the referee would wear another colour (usually red) to distinguish themself from both teams.   At the 1994 World Cup finals, new shirts were introduced that gave officials a choice of burgundy, yellow or white, and at the same time the creation of the Premier League in England saw referees wear green jerseys: both changes were motivated by television considerations. Since then, most referees have worn either yellow or black, but the colours and styles adopted by individual associations vary greatly. For international contests under the supervision of FIFA, Adidas uniforms are worn because Adidas is the current sponsor. FIFA allows referees to wear five colours: black, red, yellow, green and blue. Along with the jersey, referees are required to wear black shorts, black socks (with white stripes in some cases), and black shoes.  The badge, which displays the referee's license level and year of validity, is often affixed to the left chest pocket.  All referees carry a whistle, a watch, penalty cards, a data wallet with pen and paper, and a coin for determining which team has the choice of ends or kick-off. Most are encouraged to have more than one of each on them in case they drop a whistle or a pen runs out and so on. Often, referees use two watches so that they can use one to calculate time lost for stoppages for the purposes of added time. At the highest levels, referees wear a full duplex radio with customised headset to communicate between with their assistants, and assistant referees use electronic flags, which send a signal to the referee when a button is pushed.[4][5] In matches with goal-line technology, referees will have on their person a device to receive the system's alerts.[6]  Referees use a whistle to help them control matches. The whistle is sometimes needed to stop, start or restart play but should not be used for all stoppages, starts or restarts. FIFA's Laws of the Game document gives guidance as to when the whistle should and should not be used.[7] Overuse of the whistle is discouraged since, as stated in the Laws, \"A whistle which is used too frequently unnecessarily will have less impact when it is needed.\"[7] The whistle is an important tool for the referee along with verbal, body and eye communication.  Before the introduction of the whistle, referees indicated their decisions by waving a white handkerchief. The whistles that were first adopted by referees were made by Joseph Hudson at Mills Munitions in Birmingham, England. The Acme Whistle Company (based at Mills Munitions Factory) first began to mass-produce pea whistles in the 1870s for the Metropolitan Police Force. It is frequently stated the referee's whistle was first used in a game between Nottingham Forest and Sheffield Norfolk in 1878; however the last such fixture known to have taken place between the two clubs was in 1874. The Nottingham Forest account book of 1872 apparently recorded the purchase of an \"umpire's whistle\" and in 1928 an article by R M Ruck about his playing days in the early 1870s referred to the use of a whistle by umpires to indicate an infringement.[8]  The whistle was not mentioned in the Laws of the Game until 1936 when an IFAB Decision was added as footnote (b) to Law 2, stating \"A Referee's control over the players for misconduct or ungentlemanly behaviour commences from the time he enters the field of play, but his jurisdiction in connection with the Laws of the Game commences from the time he blows his whistle for the game to start.\"[9]  In 2007, when IFAB greatly expanded the Laws of the Game, an Additional Instructions section became available, which is a full page of advice on how and when the whistle should be used as a communication and control mechanism by the referee.[10]  Referees in football were first described by Richard Mulcaster in 1581.[11]  In this description of \"foteball\" he advocates the use of a \"judge over the parties\".  In the modern era, referees are first advocated in English public school football games, notably Eton football in 1845.[12]  A match report from Rochdale in 1842 shows their use in a football game between the Bodyguards Club and the Fearnought Club.[12]  In the early years of the codified sport it was assumed that disputes could be adequately settled by discussion between gentlemen players who would never deliberately commit a foul.  However, as play became more competitive, the need for officials grew. Initially there existed two umpires, one per team, who could be appealed to with the referee (the game's timekeeper) being \"referred\" to if the umpires could not agree.[13]  The promotion of referees to the dominant position they occupy today, and the reformation of umpires into the linesmen role, occurred as part of a major restructuring of the laws in 1891.[13]  The predominant system of positioning and division of responsibility used by football match officials throughout the world is known as the Diagonal system of control (DSC).  The referee has final decision-making authority on all matters. The referee is assisted by two assistant referees who advise the referee. An assistant referee's judgement is enforced only if the referee accepts that judgement, and the referee has the authority to unilaterally overrule an assistant referee. The referee is the only official empowered with starting and stopping play, and meting out disciplinary actions such as cautions or send-offs.  The two assistant referees are instructed by the referee to each patrol half of a single touchline on opposite sides of the field. For example, on a field running north\u2013south, one assistant referee (AR) would run on the eastern touchline from the north goal line to the halfway line, while the other assistant referee would run on the western touchline from the south goal line to the halfway line. In general, the assistant referees' duties would be to indicate (using their flags) when an offside offence has occurred in their half, when a ball has left the pitch, and if a foul has been executed out of the view of the referee (typically in their quadrant of the field). Generally, the ARs will position themselves in line with either the second to last opponent or the ball \u2013 whichever is closer to the goal line \u2013 to better judge offside infractions. However, the assistant referee will have specific positioning with respect to corner kicks, penalty kicks, and throw-ins.  The referee patrols the length of the field to cover the ground not covered by their two assistants, generally running in a diagonal pattern from the southeast quadrant of the field towards the northwest quadrant; hence the term \"diagonal system of control\" (DSC). This pattern is not a specific route but a general guideline that should be modified to the style of play, nature of the game, the location of play at a given time, etc. In some cases the referee may even exit the field if it aids in their decision-making ability. The main idea is that the referee and assistants using the DSC should be able to position themselves quickly and easily to observe the important aspects of play (offside, ball in or out of play, goal-scoring opportunities, challenges for the ball) from multiple angles with multiple sets of eyes.  The description above refers to a left diagonal system of control, known as \"running a left\" or \"standard diagonal\". If, before the match, the centre referee on this field decides to run from southwest to northeast, then the assistants must position themselves accordingly and the result will be a right diagonal system of control, otherwise referred to as \"running a right\" or \"reverse diagonal\".  In many cases in England, referees use more of \"curve\" based on a line running from the edge of the 18-yard (16\u00a0m) box, and when near the centre circle they then curve to a line level with the other 18-yard (16\u00a0m) box line. This is similar to the diagonal system, but with the speed of modern football it is easier to keep up with play. This also helps the referee avoid being in a common \"passing lane\" through the centre circle itself.  In international matches the left-wing diagonal shown above has been universal since the 1960s. It is now predominant across the world. England until recently was an exception to this convention. Until 1974 referees in the Football League were required to run both diagonals during a match, most opting to run from right wing to right wing in the first half before switching to the left-wing diagonal for the second half. The chief reason for this alternation was to avoid linesmen wearing down the same part of the touchline during matches \u2013 this was important given the generally lower quality of pitches at the time. However switching diagonal was also justified in terms of allowing officials to patrol different areas of the field during games. From the 1974\u201375 season English referees were allowed to run the same diagonal throughout the same match. Most initially opted for the right-wing diagonal although over the years the left-wing diagonal became increasingly popular and the preferred choice of most referees by the early 2000s. From 2007\u201308 the left-wing diagonal has been mandatory in English professional football although some referees at lower levels still use the opposite approach.  Its implementation as a standard practice for referees is attributed to Sir Stanley Rous, former referee and President of FIFA from 1961 to 1974.[14]  While the Laws of the Game mandate a single referee with assistants as described above, other systems are used experimentally or explicitly by some non-FIFA-affiliated governing organizations.  The dual system, has two referees with no assistants.[15] The system is used some matches played under the rules of the National Federation of State High School Associations (NFHS) in the United States, and in other youth or amateur matches. Both referees have equal authority, and the decision of one referee is binding on the other. Each referee is primarily responsible for a specific area of the field similar to those of the assistant referees in the diagonal system, except that the referees are allowed and encouraged to move away from the touch line into the field, particularly as play approaches the goal lines. Like the assistant referees in the diagonal system, each referee is responsible for patrolling one touch line and one goal line and determining possession for the restart if the ball goes out of play on either of those two boundaries.[16]  Positioning in the dual system is similar to that used by officials in basketball: each referee is either termed the \"lead\" or the \"trail\", depending on the direction of the attack. If the attack is against the goal to the referee's right (when facing the field from their assigned touch line), then that referee is the lead, and the other is the trail. The lead is positioned ahead of the play, even with the second-to-last defender to the extent possible, while the trail is positioned behind the play. Both are responsible for calling fouls and misconduct and determining the restart when the ball goes out of play on one of their assigned boundary lines. Since the lead is in a better position to determine offside, the lead is responsible for calling offside, while the trail provides an extra monitor for fouls and misconduct while the lead's attention is focused on offside. When the attack changes direction, the trail becomes the lead and vice versa.[16]  The double dual system uses three referees, all equipped with whistles, positioned much as in the traditional diagonal system of control mandated by IFAB.[17]  Each referee has the same authority for decision making.[18] It is authorized in the United States for college and high school matches although it is rarely used. "},{"title":"Majority","content":"A majority is more than half the total.[1] It is a subset of a set consisting of more than half of the set's elements. For example, if a group consists of 31 individuals, a majority would be 16 or more individuals, while having 15 or fewer individuals would not constitute a majority. \"Majority\" can be used to specify the voting requirement, as in a majority vote, which means more votes in favor than against. However, an absolute majority requires more than half all votes including ballots of abstention.  A majority is different from a plurality (sometimes called a relative majority in British English), which is a subset larger than any other subset, but not necessarily greater than half the set. For example, if there is a group with 20 members which is divided into subgroups with 9, 6, and 5 members, then the 9-member group would be the plurality. A plurality is not necessarily a majority, as the largest subset considered may consist of less than half the set's elements. This can occur when there are three or more possible choices.  In parliamentary procedure, the term \"majority\" means \"more than half.\"[2]:\u200a4\u200a As it relates to a vote, a majority vote is more than half of the votes cast.[3] Abstentions or blanks are excluded in calculating a majority vote.[2]:\u200a6\u200a Also, the totals do not include votes cast by someone not entitled to vote or improper multiple votes by a single member.[4]  Depending on the parliamentary authority used, there may be a difference in the total that is used to calculate a majority vote due to illegal votes. Illegal votes are votes which are cast for unidentifiable or ineligible candidates or choices.[4] In this definition, \"illegal\" refers to the choices made on the ballot and does not refer to the persons who cast the votes (i.e. the persons are eligible to vote).  In Robert's Rules of Order Newly Revised (abbreviated RONR), illegal votes are counted as votes cast, but are not credited to any candidate.[4] In The Standard Code of Parliamentary Procedure (abbreviated TSC), illegal votes are not included in the total and a majority vote is defined as being more than half of all eligible votes cast.[5] The issue of \"illegal votes\" does not exist when only two options are possible (e.g. \"yes\" or \"no\"), such as when a majority vote is required to adopt a proposal (motion). In this context, a majority vote is more \"yes\" votes than \"no\" votes.[6]  A majority vote is not the same as a vote of a \"majority of the members present\" or a vote of a \"majority of the entire membership\".  For example, assume that votes are cast for three people for an office: Alice, Bob, and Carol.  In Scenario 1, Alice received a majority vote. There were 20 votes cast and Alice received more than half of them.  In Scenario 2, assume all three candidates are eligible. In this case, no one received a majority vote. This example also illustrates that half the votes cast is not a majority vote.  In Scenario 3, assume that Alice and Bob are eligible candidates, but Carol is not. Using Robert's Rules of Order, no one received a majority vote, which is the same as Scenario 2. In this case, the 4 votes for Carol are counted in the total, but are not credited to Carol (which precludes the possibility of an ineligible candidate being credited with receiving a majority vote). However, using The Standard Code, Alice received a majority vote since only votes for eligible candidates are counted using this book. In this case, there are 16 votes for eligible candidates and Alice received more than half of those 16 votes.  In all three scenarios, Alice received a plurality, or the most votes among the candidates.[7] However, only in Scenario 1 did Alice receive a majority vote using Robert's Rules of Order.  Other related terms containing the word \"majority\" have their own meanings, which may sometimes be inconsistent in usage.[8]  A majority may sometimes be called a \"simple majority\" to contrast with other terms using \"majority\".[8]  A \"simple majority\" is normally differentiated from both \"absolute majority\" and from plurality in that it is more than half of votes cast excluding abstentions.[1][2][3] In an election with two candidates or a binary yes\/no vote, and having abstention an alternative, there is always a simple majority, unless they tie. Here, simple majority is a weaker requirement than absolute majority (more than half of votes including abstentions, more than the aggregate of all other alternatives) and a stronger requirement than plurality.    A \"simple majority\" may also mean a \"relative majority\", or a plurality.[9] These two definitions would conflict when a \"simple majority\" (i.e. plurality) is not a \"majority\" (also see the disambiguation page for simple majority).  An \"absolute majority\" may mean a majority of all electors, not just those who voted.[8][10] This usage would be equivalent to a \"majority of the entire membership\". However, the definition for \"absolute majority\" is not consistent, as it could also mean the same as \"majority\" or \"simple majority\".[8][11][12][13] The meanings for \"absolute majority\" and \"simple majority\" would have to be determined from the context in which these terms are used.  A \"supermajority\", or a \"qualified majority\", is a specified higher threshold than one half.[8] A common use of a supermajority is a \"two-thirds vote\", which is sometimes referred to as a \"two-thirds majority\".  In parliamentary systems, an \"overall majority\" is the difference of legislators between the government and its opposition.[14] In this context, the term \"majority\" could be also alternatively used to refer to the winning margin, i.e. the number of votes separating the first-place finisher from the second-place finisher.[1][14]  A \"double majority\" is a voting system which requires a majority of votes according to two separate criteria.[8]  A temporary majority exists when the positions of the members present and voting in a meeting of a deliberative assembly on a subject are not representative of the membership as a whole. Parliamentary procedure contains some provisions designed to protect against a temporary majority violating the rights of absentees. For instance, previous notice is required to rescind, repeal or annul or amend something previously adopted by a majority vote; if previous notice has not been given, a two-thirds vote is required.[15] However, in this and many other cases, previous notice is not required if a majority of the entire membership votes in favor, because that indicates that it is clearly not a temporary majority. Another protection against a decision being made by a temporary majority is the motion to reconsider and enter on the minutes, by which two members can suspend action on a measure until it is called up at a meeting on another day.[16]  \"Majority\" could be specified with respect to the voting body.  A \"majority of the entire membership\" means more than half of all the members of a body.[17] A \"majority of the fixed membership\" means more than half of all the seats of a body.[17] A majority of the entire membership is different from a majority of the fixed membership when there are vacancies.[17]  For example, say a board has 12 seats. If the board has the maximum number of members, or 12 members, a majority of the entire membership and a majority of the fixed membership would both be 7 members. However, if there are two vacancies (so that there are only 10 members on the board), then a majority of the entire membership would be 6 members (more than half of 10), but a majority of the fixed membership would still be 7 members.[17]  A \"majority of the members present\" means more than half of the members at the meeting.[17] If 30 members were at a meeting, a majority of the members present would be 16. In any situation which specifies such a requirement for a vote, an abstention would have the same effect as a \"no\" vote.[2]:\u200a6\u200a  A vote of a \"majority of the members present\" is not the same as a \"majority vote\". When unqualified, a \"majority vote\" is taken to mean more than half of the votes cast.[3] If 30 members were at a meeting, but only 20 votes were cast, a majority vote would be 11 votes.[17]  The expression \"at least 50% +1\" is sometimes used when \"majority\" is actually intended[2]:\u200a4\u200a but this is incorrect when the total number referred to is odd. For example, say a board has 7 members. \"Majority\" means \"at least 4\" in this case (more than half of 7). But 50% + 1 is 4.5, and since a number of people can only be integer, \"at least 50% + 1\" would mean \"at least 5\". An example of the expression's use to refer to a majority is the 50+1 rule. "},{"title":"Basketball","content":"  Basketball is a team sport in which two teams, most commonly of five players each, opposing one another on a rectangular court, compete with the primary objective of shooting a basketball (approximately 9.4 inches (24\u00a0cm) in diameter) through the defender's hoop (a basket 18 inches (46\u00a0cm) in diameter mounted 10 feet (3.048\u00a0m) high to a backboard at each end of the court), while preventing the opposing team from shooting through their own hoop. A field goal is worth two points, unless made from behind the three-point line, when it is worth three. After a foul, timed play stops and the player fouled or designated to shoot a technical foul is given one, two or three one-point free throws. The team with the most points at the end of the game wins, but if regulation play expires with the score tied, an additional period of play (overtime) is mandated.  Players advance the ball by bouncing it while walking or running (dribbling) or by passing it to a teammate, both of which require considerable skill. On offense, players may use a variety of shots\u00a0\u2013 the layup, the jump shot, or a dunk; on defense, they may steal the ball from a dribbler, intercept passes, or block shots; either offense or defense may collect a rebound, that is, a missed shot that bounces from rim or backboard. It is a violation to lift or drag one's pivot foot without dribbling the ball, to carry it, or to hold the ball with both hands then resume dribbling.  The five players on each side fall into five playing positions. The tallest player is usually the center, the second-tallest and strongest is the power forward, a slightly shorter but more agile player is the small forward, and the shortest players or the best ball handlers are the shooting guard and the point guard, who implement the coach's game plan by managing the execution of offensive and defensive plays (player positioning). Informally, players may play three-on-three, two-on-two, and one-on-one.  Invented in 1891 by Canadian-American gym teacher James Naismith in Springfield, Massachusetts, in the United States, basketball has evolved to become one of the world's most popular and widely viewed sports.[1][2] The National Basketball Association (NBA) is the most significant professional basketball league in the world in terms of popularity, salaries, talent, and level of competition[3][4] (drawing most of its talent from U.S. college basketball). Outside North America, the top clubs from national leagues qualify to continental championships such as the EuroLeague and the Basketball Champions League Americas. The FIBA Basketball World Cup and Men's Olympic Basketball Tournament are the major international events of the sport and attract top national teams from around the world. Each continent hosts regional competitions for national teams, like EuroBasket and FIBA AmeriCup.  The FIBA Women's Basketball World Cup and Women's Olympic Basketball Tournament feature top national teams from continental championships. The main North American league is the WNBA (NCAA Women's Division I Basketball Championship is also popular), whereas the strongest European clubs participate in the EuroLeague Women.  A game similar to basketball is mentioned in a 1591 book published in Frankfurt am Main that reports on the lifestyles and customs of coastal North American residents, Wahrhafftige Abconterfaytung der Wilden.[5] Among other things, a game of skill is described in which balls must be thrown against a target woven from twigs, mounted high on a pole. There's a small reward for the player if the target is being hit.[6]  In December 1891, James Naismith, a Canadian-American professor of physical education and instructor at the International Young Men's Christian Association Training School (now Springfield College) in Springfield, Massachusetts,[7] was trying to keep his gym class active on a rainy day.[8] He sought a vigorous indoor game to keep his students occupied and at proper levels of fitness during the long New England winters. After rejecting other ideas as either too rough or poorly suited to walled-in gymnasiums, he invented a new game in which players would pass a ball to teammates and try to score points by tossing the ball into a basket mounted on a wall. Naismith wrote the basic rules and nailed a peach basket onto an elevated track. Naismith initially set up the peach basket with its bottom intact, which meant that the ball had to be retrieved manually after each \"basket\" or point scored. This quickly proved tedious, so Naismith removed the bottom of the basket to allow the balls to be poked out with a long dowel after each scored basket.  Shortly after, Senda Berenson, instructor of physical culture at the nearby Smith College, went to Naismith to learn more about the game.[9] Fascinated by the new sport and the values it could teach, she started to organize games with her pupils, following adjusted rules.[10] The first official women's interinstitutional game was played barely 11 months later, between the University of California and the Miss Head's School.[11] In 1899, a committee was established at the Conference of Physical Training in Springfield to draw up general rules for women's basketball. Thus, the sport quickly spread throughout America's schools, colleges and universities with uniform rules for both sexes.[12]  Basketball was originally played with a soccer ball. These round balls from \"association football\" were made, at the time, with a set of laces to close off the hole needed for inserting the inflatable bladder after the other sewn-together segments of the ball's cover had been flipped outside-in.[13][14] These laces could cause bounce passes and dribbling to be unpredictable.[15] Eventually a lace-free ball construction method was invented, and this change to the game was endorsed by Naismith (whereas in American football, the lace construction proved to be advantageous for gripping and remains to this day). The first balls made specifically for basketball were brown, and it was only in the late 1950s that Tony Hinkle, searching for a ball that would be more visible to players and spectators alike, introduced the orange ball that is now in common use. Dribbling was not part of the original game except for the \"bounce pass\" to teammates. Passing the ball was the primary means of ball movement. Dribbling was eventually introduced but limited by the asymmetric shape of early balls.[dubious  \u2013 discuss] Dribbling was common by 1896, with a rule against the double dribble by 1898.[16]  The peach baskets were used until 1906 when they were finally replaced by metal hoops with backboards. A further change was soon made, so the ball merely passed through. Whenever a person got the ball in the basket, his team would gain a point. Whichever team got the most points won the game.[17] The baskets were originally nailed to the mezzanine balcony of the playing court, but this proved impractical when spectators in the balcony began to interfere with shots. The backboard was introduced to prevent this interference; it had the additional effect of allowing rebound shots.[18] Naismith's handwritten diaries, discovered by his granddaughter in early 2006, indicate that he was nervous about the new game he had invented, which incorporated rules from a children's game called duck on a rock, as many had failed before it.[19]  Frank Mahan, one of the players from the original first game, approached Naismith after the Christmas break, in early 1892, asking him what he intended to call his new game. Naismith replied that he had not thought of it because he had been focused on just getting the game started. Mahan suggested that it be called \"Naismith ball\", at which he laughed, saying that a name like that would kill any game. Mahan then said, \"Why not call it basketball?\" Naismith replied, \"We have a basket and a ball, and it seems to me that would be a good name for it.\"[20][21] The first official game was played in the YMCA gymnasium in Albany, New York, on January 20, 1892, with nine players. The game ended at 1\u20130; the shot was made from 25 feet (7.6\u00a0m), on a court just half the size of a present-day Streetball or National Basketball Association (NBA) court.  At the time, soccer was being played with 10 to a team (which was increased to 11). When winter weather got too icy to play soccer, teams were taken indoors, and it was convenient to have them split in half and play basketball with five on each side. By 1897\u201398, teams of five became standard.  Basketball's early adherents were dispatched to YMCAs throughout the United States, and it quickly spread through the United States and Canada. By 1895, it was well established at several women's high schools. While YMCA was responsible for initially developing and spreading the game, within a decade it discouraged the new sport, as rough play and rowdy crowds began to detract from YMCA's primary mission. However, other amateur sports clubs, colleges, and professional clubs quickly filled the void. In the years before World War I, the Amateur Athletic Union and the Intercollegiate Athletic Association of the United States (forerunner of the NCAA) vied for control over the rules for the game. The first pro league, the National Basketball League, was formed in 1898 to protect players from exploitation and to promote a less rough game. This league only lasted five years.  James Naismith was instrumental in establishing college basketball. His colleague C. O. Beamis fielded the first college basketball team just a year after the Springfield YMCA game at the suburban Pittsburgh Geneva College.[22] Naismith himself later coached at the University of Kansas for six years, before handing the reins to renowned coach Forrest \"Phog\" Allen. Naismith's disciple Amos Alonzo Stagg brought basketball to the University of Chicago, while Adolph Rupp, a student of Naismith's at Kansas, enjoyed great success as coach at the University of Kentucky. On February 9, 1895, the first intercollegiate 5-on-5 game was played at Hamline University between Hamline and the School of Agriculture, which was affiliated with the University of Minnesota.[23][24][25] The School of Agriculture won in a 9\u20133 game.  In 1901, colleges, including the University of Chicago, Columbia University, Cornell University, Dartmouth College, the University of Minnesota, the U.S. Naval Academy, the University of Colorado and Yale University began sponsoring men's games. In 1905, frequent injuries on the football field prompted President Theodore Roosevelt to suggest that colleges form a governing body, resulting in the creation of the Intercollegiate Athletic Association of the United States (IAAUS). In 1910, that body changed its name to the National Collegiate Athletic Association (NCAA). The first Canadian interuniversity basketball game was played at YMCA in Kingston, Ontario on February 6, 1904, when McGill University\u00a0\u2013 Naismith's alma mater\u00a0\u2013 visited Queen's University. McGill won 9\u20137 in overtime; the score was 7\u20137 at the end of regulation play, and a ten-minute overtime period settled the outcome. A good turnout of spectators watched the game.[26]  The first men's national championship tournament, the National Association of Intercollegiate Basketball tournament, which still exists as the National Association of Intercollegiate Athletics (NAIA) tournament, was organized in 1937. The first national championship for NCAA teams, the National Invitation Tournament (NIT) in New York, was organized in 1938; the NCAA national tournament began one year later. College basketball was rocked by gambling scandals from 1948 to 1951, when dozens of players from top teams were implicated in match fixing and point shaving. Partially spurred by an association with cheating, the NIT lost support to the NCAA tournament.  Before widespread school district consolidation, most American high schools were far smaller than their present-day counterparts. During the first decades of the 20th century, basketball quickly became the ideal interscholastic sport due to its modest equipment and personnel requirements. In the days before widespread television coverage of professional and college sports, the popularity of high school basketball was unrivaled in many parts of America. Perhaps the most legendary of high school teams was Indiana's Franklin Wonder Five, which took the nation by storm during the 1920s, dominating Indiana basketball and earning national recognition.  Today virtually every high school in the United States fields a basketball team in varsity competition.[27] Basketball's popularity remains high, both in rural areas where they carry the identification of the entire community, as well as at some larger schools known for their basketball teams where many players go on to participate at higher levels of competition after graduation. In the 2016\u201317 season, 980,673 boys and girls represented their schools in interscholastic basketball competition, according to the National Federation of State High School Associations.[28] The states of Illinois, Indiana and Kentucky are particularly well known for their residents' devotion to high school basketball, commonly called Hoosier Hysteria in Indiana; the critically acclaimed film Hoosiers shows high school basketball's depth of meaning to these communities.  \u2063There is currently no tournament to determine a national high school champion. The most serious effort was the National Interscholastic Basketball Tournament at the University of Chicago from 1917 to 1930. The event was organized by Amos Alonzo Stagg and sent invitations to state champion teams. The tournament started out as a mostly Midwest affair but grew. In 1929 it had 29 state champions. Faced with opposition from the National Federation of State High School Associations and North Central Association of Colleges and Schools that bore a threat of the schools losing their accreditation the last tournament was in 1930. The organizations said they were concerned that the tournament was being used to recruit professional players from the prep ranks.[29] The tournament did not invite minority schools or private\/parochial schools.  The National Catholic Interscholastic Basketball Tournament ran from 1924 to 1941 at Loyola University.[30] The National Catholic Invitational Basketball Tournament from 1954 to 1978 played at a series of venues, including Catholic University, Georgetown and George Mason.[31] The National Interscholastic Basketball Tournament for Black High Schools was held from 1929 to 1942 at Hampton Institute.[32] The National Invitational Interscholastic Basketball Tournament was held from 1941 to 1967 starting out at Tuskegee Institute. Following a pause during World War II it resumed at Tennessee State College in Nashville. The basis for the champion dwindled after 1954 when Brown v. Board of Education began an integration of schools. The last tournaments were held at Alabama State College from 1964 to 1967.[33]  Teams abounded throughout the 1920s. There were hundreds of men's professional basketball teams in towns and cities all over the United States, and little organization of the professional game. Players jumped from team to team and teams played in armories and smoky dance halls. Leagues came and went. Barnstorming squads such as the Original Celtics and two all-African American teams, the New York Renaissance Five (\"Rens\") and the (still existing) Harlem Globetrotters played up to two hundred games a year on their national tours.  In 1946, the Basketball Association of America (BAA) was formed. The first game was played in Toronto, Ontario, Canada between the Toronto Huskies and New York Knickerbockers on November 1, 1946. Three seasons later, in 1949, the BAA merged with the National Basketball League (NBL) to form the National Basketball Association (NBA). By the 1950s, basketball had become a major college sport, thus paving the way for a growth of interest in professional basketball. In 1959, a basketball hall of fame was founded in Springfield, Massachusetts, site of the first game. Its rosters include the names of great players, coaches, referees and people who have contributed significantly to the development of the game. The hall of fame has people who have accomplished many goals in their career in basketball. An upstart organization, the American Basketball Association, emerged in 1967 and briefly threatened the NBA's dominance until the ABA-NBA merger in 1976. Today the NBA is the top professional basketball league in the world in terms of popularity, salaries, talent, and level of competition.  The NBA has featured many famous players, including George Mikan, the first dominating \"big man\"; ball-handling wizard Bob Cousy and defensive genius Bill Russell of the Boston Celtics; charismatic center Wilt Chamberlain, who originally played for the barnstorming Harlem Globetrotters; all-around stars Oscar Robertson and Jerry West; more recent big men Kareem Abdul-Jabbar, Shaquille O'Neal, Hakeem Olajuwon and Karl Malone; playmakers John Stockton, Isiah Thomas and Steve Nash; crowd-pleasing forwards Julius Erving and Charles Barkley; European stars Dirk Nowitzki, Pau Gasol and Tony Parker; Latin American stars Manu Ginobili, more recent superstars, Allen Iverson, Kobe Bryant, Tim Duncan, LeBron James, Stephen Curry, Giannis Antetokounmpo, etc.; and the three players who many credit with ushering the professional game to its highest level of popularity during the 1980s and 1990s: Larry Bird, Earvin \"Magic\" Johnson, and Michael Jordan.  In 2001, the NBA formed a developmental league, the National Basketball Development League (later known as the NBA D-League and then the NBA G League after a branding deal with Gatorade). As of the 2023\u201324 season, the G League has 31 teams.  FIBA (International Basketball Federation) was formed in 1932 by eight founding nations: Argentina, Czechoslovakia, Greece, Italy, Latvia, Portugal, Romania and Switzerland. At this time, the organization only oversaw amateur players. Its acronym, derived from the French F\u00e9d\u00e9ration Internationale de Basket-ball Amateur, was thus \"FIBA\". Men's basketball was first included at the Berlin 1936 Summer Olympics, although a demonstration tournament was held in 1904. The United States defeated Canada in the first final, played outdoors. This competition has usually been dominated by the United States, whose team has won all but three titles. The first of these came in a controversial final game in Munich in 1972 against the Soviet Union, in which the ending of the game was replayed three times until the Soviet Union finally came out on top.[34] In 1950 the first FIBA World Championship for men, now known as the FIBA Basketball World Cup, was held in Argentina. Three years later, the first FIBA World Championship for women, now known as the FIBA Women's Basketball World Cup, was held in Chile. Women's basketball was added to the Olympics in 1976, which were held in Montreal, Quebec, Canada with teams such as the Soviet Union, Brazil and Australia rivaling the American squads.  In 1989, FIBA allowed professional NBA players to participate in the Olympics for the first time. Prior to the 1992 Summer Olympics, only European and South American teams were allowed to field professionals in the Olympics. The United States' dominance continued with the introduction of the original Dream Team. In the 2004 Athens Olympics, the United States suffered its first Olympic loss while using professional players, falling to Puerto Rico (in a 19-point loss) and Lithuania in group games, and being eliminated in the semifinals by Argentina. It eventually won the bronze medal defeating Lithuania, finishing behind Argentina and Italy. The Redeem Team, won gold at the 2008 Olympics, and the B-Team, won gold at the 2010 FIBA World Championship in Turkey despite featuring no players from the 2008 squad. The United States continued its dominance as they won gold at the 2012 Olympics, 2014 FIBA World Cup and the 2016 Olympics.  Worldwide, basketball tournaments are held for boys and girls of all age levels. The global popularity of the sport is reflected in the nationalities represented in the NBA. Players from all six inhabited continents currently play in the NBA. Top international players began coming into the NBA in the mid-1990s, including Croatians Dra\u017een Petrovi\u0107 and Toni Kuko\u010d, Serbian Vlade Divac, Lithuanians Arvydas Sabonis and \u0160ar\u016bnas Mar\u010diulionis, Dutchman Rik Smits and German Detlef Schrempf.  In the Philippines, the Philippine Basketball Association's first game was played on April 9, 1975, at the Araneta Coliseum in Cubao, Quezon City, Philippines. It was founded as a \"rebellion\" of several teams from the now-defunct Manila Industrial and Commercial Athletic Association, which was tightly controlled by the Basketball Association of the Philippines (now defunct), the then-FIBA recognized national association. Nine teams from the MICAA participated in the league's first season that opened on April 9, 1975. The NBL is Australia's pre-eminent men's professional basketball league. The league commenced in 1979, playing a winter season (April\u2013September) and did so until the completion of the 20th season in 1998. The 1998\u201399 season, which commenced only months later, was the first season after the shift to the current summer season format (October\u2013April). This shift was an attempt to avoid competing directly against Australia's various football codes. It features 8 teams from around Australia and one in New Zealand. A few players including Luc Longley, Andrew Gaze, Shane Heal, Chris Anstey and Andrew Bogut made it big internationally, becoming poster figures for the sport in Australia. The Women's National Basketball League began in 1981.  Women began to play basketball in the fall of 1892 at Smith College through Senda Berenson, substitute director of the newly opened gymnasium and physical education teacher, after having modified the rules for women. Shortly after Berenson was hired at Smith, she visited Naismith to learn more about the game.[9] Fascinated by the new sport and the values it could teach, she instantly introduced the game as a class exercise and soon after teams were organized. The first women's collegiate basketball game was played on March 21, 1893, when her Smith freshmen and sophomores played against one another.[10][35] The first official women's interinstitutional game was played later that year between the University of California and the Miss Head's School.[11] In 1899, a committee was established at the Conference of Physical Training in Springfield to draw up general rules for women's basketball.[36] These rules, designed by Berenson, were published in 1899.[12] In 1902 Berenson became the editor of A. G. Spalding's first Women's Basketball Guide.[10] The same year women of Mount Holyoke and Sophie Newcomb College (coached by Clara Gregory Baer), began playing basketball. By 1895, the game had spread to colleges across the country, including Wellesley, Vassar, and Bryn Mawr. The first intercollegiate women's game was on April 4, 1896. Stanford women played Berkeley, 9-on-9, ending in a 2\u20131 Stanford victory.  Women's basketball development was more structured than that for men in the early years. In 1905, the executive committee on Basket Ball Rules (National Women's Basketball Committee) was created by the American Physical Education Association.[37] These rules called for six to nine players per team and 11 officials. The International Women's Sports Federation (1924) included a women's basketball competition. 37 women's high school varsity basketball or state tournaments were held by 1925. And in 1926, the Amateur Athletic Union backed the first national women's basketball championship, complete with men's rules.[37] The Edmonton Grads, a touring Canadian women's team based in Edmonton, Alberta, operated between 1915 and 1940. The Grads toured all over North America, and were exceptionally successful. They posted a record of 522 wins and only 20 losses over that span, as they met any team that wanted to challenge them, funding their tours from gate receipts.[38] The Grads also shone on several exhibition trips to Europe, and won four consecutive exhibition Olympics tournaments, in 1924, 1928, 1932, and 1936; however, women's basketball was not an official Olympic sport until 1976. The Grads' players were unpaid, and had to remain single. The Grads' style focused on team play, without overly emphasizing skills of individual players. The first women's AAU All-America team was chosen in 1929.[37] Women's industrial leagues sprang up throughout the United States, producing famous athletes, including Babe Didrikson of the Golden Cyclones, and the All American Red Heads Team, which competed against men's teams, using men's rules. By 1938, the women's national championship changed from a three-court game to two-court game with six players per team.[37]  The NBA-backed Women's National Basketball Association (WNBA) began in 1997. Though it had shaky attendance figures, several marquee players (Lisa Leslie, Diana Taurasi, and Candace Parker among others) have helped the league's popularity and level of competition. Other professional women's basketball leagues in the United States, such as the American Basketball League (1996\u201398), have folded in part because of the popularity of the WNBA. The WNBA has been looked at by many as a niche league. However, the league has recently taken steps forward. In June 2007, the WNBA signed a contract extension with ESPN. The new television deal ran from 2009 to 2016. Along with this deal, came the first-ever rights fees to be paid to a women's professional sports league. Over the eight years of the contract, \"millions and millions of dollars\" were \"dispersed to the league's teams.\" In a March 12, 2009, article, NBA commissioner David Stern said that in the bad economy, \"the NBA is far less profitable than the WNBA. We're losing a lot of money among a large number of teams. We're budgeting the WNBA to break even this year.\"[39]  Measurements and time limits discussed in this section often vary among tournaments and organizations; international and NBA rules are used in this section.  The object of the game is to outscore one's opponents by throwing the ball through the opponents' basket from above while preventing the opponents from doing so on their own. An attempt to score in this way is called a shot. A successful shot is worth two points, or three points if it is taken from beyond the three-point arc 6.75 metres (22\u00a0ft 2\u00a0in) from the basket in international games[40] and 23\u00a0feet 9\u00a0inches (7.24\u00a0m) in NBA games.[41] A one-point shot can be earned when shooting from the foul line after a foul is made. After a team has scored from a field goal or free throw, play is resumed with a throw-in awarded to the non-scoring team taken from a point beyond the endline of the court where the points were scored.[42]  Games are played in four quarters of 10 (FIBA)[43] or 12 minutes (NBA).[44] College men's games use two 20-minute halves,[45] college women's games use 10-minute quarters,[46] and most United States high school varsity games use 8-minute quarters; however, this varies from state to state.[47][48] 15 minutes are allowed for a half-time break under FIBA, NBA, and NCAA rules[45][49][50] and 10 minutes in United States high schools.[47] Overtime periods are five minutes in length[45][51][52] except for high school, which is four minutes in length.[47] Teams exchange baskets for the second half. The time allowed is actual playing time; the clock is stopped while the play is not active. Therefore, games generally take much longer to complete than the allotted game time, typically about two hours.  Five players from each team may be on the court at one time.[53][54][55][56] Substitutions are unlimited but can only be done when play is stopped. Teams also have a coach, who oversees the development and strategies of the team, and other team personnel such as assistant coaches, managers, statisticians, doctors and trainers.  For both men's and women's teams, a standard uniform consists of a pair of shorts and a jersey with a clearly visible number, unique within the team, printed on both the front and back. Players wear high-top sneakers that provide extra ankle support. Typically, team names, players' names and, outside of North America, sponsors are printed on the uniforms.  A limited number of time-outs, clock stoppages requested by a coach (or sometimes mandated in the NBA) for a short meeting with the players, are allowed. They generally last no longer than one minute (100 seconds in the NBA) unless, for televised games, a commercial break is needed.  The game is controlled by the officials consisting of the referee (referred to as crew chief in the NBA), one or two umpires (referred to as referees in the NBA) and the table officials. For college, the NBA, and many high schools, there are a total of three referees on the court. The table officials are responsible for keeping track of each team's scoring, timekeeping, individual and team fouls, player substitutions, team possession arrow, and the shot clock.  The only essential equipment in a basketball game is the ball and the court: a flat, rectangular surface with baskets at opposite ends. Competitive levels require the use of more equipment such as clocks, score sheets, scoreboards, alternating possession arrows, and whistle-operated stop-clock systems.  A regulation basketball court in international games is 28 meters (92 feet) long and 15 meters (49 feet) wide. In the NBA and NCAA the court is 94 by 50 feet (29 by 15 meters).[41] Most courts have wood flooring, usually constructed from maple planks running in the same direction as the longer court dimension.[57][58] The name and logo of the home team is usually painted on or around the center circle.  The basket is a steel rim 18 inches (46\u00a0cm) diameter with an attached net affixed to a backboard that measures 6 by 3.5 feet (1.8 by 1.1 meters) and one basket is at each end of the court. The white outlined box on the backboard is 18 inches (46\u00a0cm) high and 2 feet (61\u00a0cm) wide. At almost all levels of competition, the top of the rim is exactly 10 feet (3.05 meters) above the court and 4 feet (1.22 meters) inside the baseline. While variation is possible in the dimensions of the court and backboard, it is considered important for the basket to be of the correct height \u2013 a rim that is off by just a few inches can have an adverse effect on shooting. The net must \"check the ball momentarily as it passes through the basket\" to aid the visual confirmation that the ball went through.[59]  The act of checking the ball has the further advantage of slowing down the ball so the rebound does not go as far.[60]  The size of the basketball is also regulated. For men, the official ball is 29.5 inches (75\u00a0cm) in circumference (size 7, or a \"295 ball\") and weighs 22\u00a0oz (620\u00a0g). If women are playing, the official basketball size is 28.5 inches (72\u00a0cm) in circumference (size 6, or a \"285 ball\") with a weight of 20\u00a0oz (570\u00a0g). In 3x3, a formalized version of the halfcourt 3-on-3 game, a dedicated ball with the circumference of a size 6 ball but the weight of a size 7 ball is used in all competitions (men's, women's, and mixed teams).[61]  The ball may be advanced toward the basket by being shot, passed between players, thrown, tapped, rolled or dribbled (bouncing the ball while running).  The ball must stay within the court; the last team to touch the ball before it travels out of bounds forfeits possession. The ball is out of bounds if it touches a boundary line, or touches any player or object that is out of bounds.  There are limits placed on the steps a player may take without dribbling, which commonly results in an infraction known as traveling. Nor may a player stop their dribble and then resume dribbling. A dribble that touches both hands is considered stopping the dribble, giving this infraction the name double dribble. Within a dribble, the player cannot carry the ball by placing their hand on the bottom of the ball; doing so is known as carrying the ball. A team, once having established ball control in the front half of their court, may not return the ball to the backcourt and be the first to touch it. A violation of these rules results in loss of possession.  The ball may not be kicked, nor be struck with the fist. For the offense, a violation of these rules results in loss of possession; for the defense, most leagues reset the shot clock and the offensive team is given possession of the ball out of bounds.  There are limits imposed on the time taken before progressing the ball past halfway (8 seconds in FIBA and the NBA; 10 seconds in NCAA and high school for both sexes), before attempting a shot (24 seconds in FIBA, the NBA, and U Sports (Canadian universities) play for both sexes, and 30 seconds in NCAA play for both sexes), holding the ball while closely guarded (5 seconds), and remaining in the restricted area known as the free-throw lane, (or the \"key\") (3 seconds). These rules are designed to promote more offense.  There are also limits on how players may block an opponent's field goal attempt or help a teammate's field goal attempt. Goaltending is a defender's touching of a ball that is on a downward flight toward the basket, while the related violation of basket interference is the touching of a ball that is on the rim or above the basket, or by a player reaching through the basket from below. Goaltending and basket interference committed by a defender result in awarding the basket to the offense, while basket interference committed by an offensive player results in cancelling the basket if one is scored. The defense gains possession in all cases of goaltending or basket interference.  An attempt to unfairly disadvantage an opponent through certain types of physical contact is illegal and is called a personal foul. These are most commonly committed by defensive players; however, they can be committed by offensive players as well. Players who are fouled either receive the ball to pass inbounds again, or receive one or more free throws if they are fouled in the act of shooting, depending on whether the shot was successful. One point is awarded for making a free throw, which is attempted from a line 15 feet (4.6\u00a0m) from the basket.  The referee is responsible for judging whether contact is illegal, sometimes resulting in controversy. The calling of fouls can vary between games, leagues and referees.  There is a second category of fouls called technical fouls, which may be charged for various rules violations including failure to properly record a player in the scorebook, or for unsportsmanlike conduct. These infractions result in one or two free throws, which may be taken by any of the five players on the court at the time. Repeated incidents can result in disqualification. A blatant foul involving physical contact that is either excessive or unnecessary is called an intentional foul (flagrant foul in the NBA). In FIBA and NCAA women's basketball, a foul resulting in ejection is called a disqualifying foul, while in leagues other than the NBA, such a foul is referred to as flagrant.  If a team exceeds a certain limit of team fouls in a given period (quarter or half) \u2013 four for NBA, NCAA women's, and international games \u2013 the opposing team is awarded one or two free throws on all subsequent non-shooting fouls for that period, the number depending on the league. In the US college men's game and high school games for both sexes, if a team reaches 7 fouls in a half, the opposing team is awarded one free throw, along with a second shot if the first is made. This is called shooting \"one-and-one\". If a team exceeds 10 fouls in the half, the opposing team is awarded two free throws on all subsequent fouls for the half.  When a team shoots foul shots, the opponents may not interfere with the shooter, nor may they try to regain possession until the last or potentially last free throw is in the air.  After a team has committed a specified number of fouls, the other team is said to be \"in the bonus\". On scoreboards, this is usually signified with an indicator light reading \"Bonus\" or \"Penalty\" with an illuminated directional arrow or dot indicating that team is to receive free throws when fouled by the opposing team. (Some scoreboards also indicate the number of fouls committed.)  If a team misses the first shot of a two-shot situation, the opposing team must wait for the completion of the second shot before attempting to reclaim possession of the ball and continuing play.  If a player is fouled while attempting a shot and the shot is unsuccessful, the player is awarded a number of free throws equal to the value of the attempted shot. A player fouled while attempting a regular two-point shot thus receives two shots, and a player fouled while attempting a three-point shot receives three shots.  If a player is fouled while attempting a shot and the shot is successful, typically the player will be awarded one additional free throw for one point. In combination with a regular shot, this is called a \"three-point play\" or \"four-point play\" (or more colloquially, an \"and one\") because of the basket made at the time of the foul (2 or 3 points) and the additional free throw (1 point).  Although the rules do not specify any positions whatsoever, they have evolved as part of basketball. During the early years of basketball's evolution, two guards, two forwards, and one center were used. In more recent times specific positions evolved, but the current trend, advocated by many top coaches including Mike Krzyzewski, is towards positionless basketball, where big players are free to shoot from outside and dribble if their skill allows it.[62] Popular descriptions of positions include:  Point guard (often called the \"1\")\u00a0: usually the fastest player on the team, organizes the team's offense by controlling the ball and making sure that it gets to the right player at the right time.  Shooting guard (the \"2\")\u00a0: creates a high volume of shots on offense, mainly long-ranged; and guards the opponent's best perimeter player on defense.  Small forward (the \"3\")\u00a0: often primarily responsible for scoring points via cuts to the basket and dribble penetration; on defense seeks rebounds and steals, but sometimes plays more actively.  Power forward (the \"4\"): plays offensively often with their back to the basket; on defense, plays under the basket (in a zone defense) or against the opposing power forward (in man-to-man defense).  Center (the \"5\"): uses height and size to score (on offense), to protect the basket closely (on defense), or to rebound.  The above descriptions are flexible. For most teams today, the shooting guard and small forward have very similar responsibilities and are often called the wings, as do the power forward and center, who are often called post players. While most teams describe two players as guards, two as forwards, and one as a center, on some occasions teams choose to call them by different designations.  There are two main defensive strategies: zone defense and man-to-man defense. In a zone defense, each player is assigned to guard a specific area of the court. Zone defenses often allow the defense to double team the ball, a manoeuver known as a trap. In a man-to-man defense, each defensive player guards a specific opponent.  Offensive plays are more varied, normally involving planned passes and movement by players without the ball. A quick movement by an offensive player without the ball to gain an advantageous position is known as a cut. A legal attempt by an offensive player to stop an opponent from guarding a teammate, by standing in the defender's way such that the teammate cuts next to him, is a screen or pick. The two plays are combined in the pick and roll, in which a player sets a pick and then \"rolls\" away from the pick towards the basket. Screens and cuts are very important in offensive plays; these allow the quick passes and teamwork, which can lead to a successful basket. Teams almost always have several offensive plays planned to ensure their movement is not predictable. On court, the point guard is usually responsible for indicating which play will occur.  Shooting is the act of attempting to score points by throwing the ball through the basket, methods varying with players and situations.  Typically, a player faces the basket with both feet facing the basket. A player will rest the ball on the fingertips of the dominant hand (the shooting arm) slightly above the head, with the other hand supporting the side of the ball. The ball is usually shot by jumping (though not always) and extending the shooting arm. The shooting arm, fully extended with the wrist fully bent, is held stationary for a moment following the release of the ball, known as a follow-through. Players often try to put a steady backspin on the ball to absorb its impact with the rim. The ideal trajectory of the shot is somewhat controversial, but generally a proper arc is recommended. Players may shoot directly into the basket or may use the backboard to redirect the ball into the basket.  The two most common shots that use the above described setup are the set shot and the jump shot. Both are preceded by a crouching action which preloads the muscles and increases the power of the shot. In a set shot, the shooter straightens up and throws from a standing position with neither foot leaving the floor; this is typically used for free throws. For a jump shot, the throw is taken in mid-air with the ball being released near the top of the jump. This provides much greater power and range, and it also allows the player to elevate over the defender. Failure to release the ball before the feet return to the floor is considered a traveling violation.  Another common shot is called the layup. This shot requires the player to be in motion toward the basket, and to \"lay\" the ball \"up\" and into the basket, typically off the backboard (the backboard-free, underhand version is called a finger roll). The most crowd-pleasing and typically highest-percentage accuracy shot is the slam dunk, in which the player jumps very high and throws the ball downward, through the basket while touching it.  Another shot that is less common than the layup, is the \"circus shot\". The circus shot is a low-percentage shot that is flipped, heaved, scooped, or flung toward the hoop while the shooter is off-balance, airborne, falling down or facing away from the basket. A back-shot is a shot taken when the player is facing away from the basket, and may be shot with the dominant hand, or both; but there is a very low chance that the shot will be successful.[63]  A shot that misses both the rim and the backboard completely is referred to as an air ball. A particularly bad shot, or one that only hits the backboard, is jocularly called a brick. The hang time is the length of time a player stays in the air after jumping, either to make a slam dunk, layup or jump shot.  The objective of rebounding is to successfully gain possession of the basketball after a missed field goal or free throw, as it rebounds from the hoop or backboard. This plays a major role in the game, as most possessions end when a team misses a shot. There are two categories of rebounds: offensive rebounds, in which the ball is recovered by the offensive side and does not change possession, and defensive rebounds, in which the defending team gains possession of the loose ball. The majority of rebounds are defensive, as the team on defense tends to be in better position to recover missed shots; for example, about 75% of rebounds in the NBA are defensive.[64]  A pass is a method of moving the ball between players. Most passes are accompanied by a step forward to increase power and are followed through with the hands to ensure accuracy.  A staple pass is the chest pass. The ball is passed directly from the passer's chest to the receiver's chest. A proper chest pass involves an outward snap of the thumbs to add velocity and leaves the defence little time to react.  Another type of pass is the bounce pass. Here, the passer bounces the ball crisply about two-thirds of the way from his own chest to the receiver. The ball strikes the court and bounces up toward the receiver. The bounce pass takes longer to complete than the chest pass, but it is also harder for the opposing team to intercept (kicking the ball deliberately is a violation). Thus, players often use the bounce pass in crowded moments, or to pass around a defender.  The overhead pass is used to pass the ball over a defender. The ball is released while over the passer's head.  The outlet pass occurs after a team gets a defensive rebound. The next pass after the rebound is the outlet pass.  The crucial aspect of any good pass is it being difficult to intercept. Good passers can pass the ball with great accuracy and they know exactly where each of their other teammates prefers to receive the ball. A special way of doing this is passing the ball without looking at the receiving teammate. This is called a no-look pass.  Another advanced style of passing is the behind-the-back pass, which, as the description implies, involves throwing the ball behind the passer's back to a teammate. Although some players can perform such a pass effectively, many coaches discourage no-look or behind-the-back passes, believing them to be difficult to control and more likely to result in turnovers or violations.  Dribbling is the act of bouncing the ball continuously with one hand and is a requirement for a player to take steps with the ball. To dribble, a player pushes the ball down towards the ground with the fingertips rather than patting it; this ensures greater control.  When dribbling past an opponent, the dribbler should dribble with the hand farthest from the opponent, making it more difficult for the defensive player to get to the ball. It is therefore important for a player to be able to dribble competently with both hands.  Good dribblers (or \"ball handlers\") tend to keep their dribbling hand low to the ground, reducing the distance of travel of the ball from the floor to the hand, making it more difficult for the defender to \"steal\" the ball. Good ball handlers frequently dribble behind their backs, between their legs, and switch directions suddenly, making a less predictable dribbling pattern that is more difficult to defend against. This is called a crossover, which is the most effective way to move past defenders while dribbling.  A skilled player can dribble without watching the ball, using the dribbling motion or peripheral vision to keep track of the ball's location. By not having to focus on the ball, a player can look for teammates or scoring opportunities, as well as avoid the danger of having someone steal the ball away from him\/her.  A block is performed when, after a shot is attempted, a defender succeeds in altering the shot by touching the ball. In almost all variants of play, it is illegal to touch the ball after it is in the downward path of its arc; this is known as goaltending. It is also illegal under NBA and Men's NCAA basketball to block a shot after it has touched the backboard, or when any part of the ball is directly above the rim. Under international rules it is illegal to block a shot that is in the downward path of its arc or one that has touched the backboard until the ball has hit the rim. After the ball hits the rim, it is again legal to touch it even though it is no longer considered as a block performed.  To block a shot, a player has to be able to reach a point higher than where the shot is released. Thus, height can be an advantage in blocking. Players who are taller and playing the power forward or center positions generally record more blocks than players who are shorter and playing the guard positions. However, with good timing and a sufficiently high vertical leap, even shorter players can be effective shot blockers.  At the professional level, most male players are above 6\u00a0feet 3\u00a0inches (1.91\u00a0m) and most women above 5\u00a0feet 7\u00a0inches (1.70\u00a0m). Guards, for whom physical coordination and ball-handling skills are crucial, tend to be the smallest players. Almost all forwards in the top men's pro leagues are 6\u00a0feet 6\u00a0inches (1.98\u00a0m) or taller. Most centers are over 6\u00a0feet 10\u00a0inches (2.08\u00a0m) tall. According to a survey given to all NBA teams,[when?] the average height of all NBA players is just under 6\u00a0feet 7\u00a0inches (2.01\u00a0m), with the average weight being close to 222 pounds (101\u00a0kg). The tallest players ever in the NBA were Manute Bol and Gheorghe Mure\u0219an, who were both 7\u00a0feet 7\u00a0inches (2.31\u00a0m) tall. At 7\u00a0feet 2\u00a0inches (2.18\u00a0m), Margo Dydek was the tallest player in the history of the WNBA.  The shortest player ever to play in the NBA is Muggsy Bogues at 5\u00a0feet 3\u00a0inches (1.60\u00a0m).[65] Other average-height or relatively short players have thrived at the pro level, including Anthony \"Spud\" Webb, who was 5\u00a0feet 7\u00a0inches (1.70\u00a0m) tall, but had a 42-inch (1.1\u00a0m) vertical leap, giving him significant height when jumping, and Temeka Johnson, who won the WNBA Rookie of the Year Award and a championship with the Phoenix Mercury while standing only 5\u00a0feet 3\u00a0inches (1.60\u00a0m). While shorter players are often at a disadvantage in certain aspects of the game, their ability to navigate quickly through crowded areas of the court and steal the ball by reaching low are strengths.  Players regularly inflate their height in high school or college. Many prospects exaggerate their height while in high school or college to make themselves more appealing to coaches and scouts, who prefer taller players. Charles Barkley stated; \"I've been measured at 6\u20135, 6-4+3\u20444. But I started in college at 6\u20136.\" Sam Smith, a former writer from the Chicago Tribune, said: \"We sort of know the heights, because after camp, the sheet comes out. But you use that height, and the player gets mad. And then you hear from his agent. Or you file your story with the right height, and the copy desk changes it because they have the 'official' N.B.A. media guide, which is wrong. So you sort of go along with the joke.\"[66]  Since the 2019-20 NBA season heights of NBA players are recorded definitively by measuring players with their shoes off.[67]  Variations of basketball are activities based on the game of basketball, using common basketball skills and equipment (primarily the ball and basket). Some variations only have superficial rule changes, while others are distinct games with varying degrees of influence from basketball. Other variations include children's games, contests or activities meant to help players reinforce skills.  An earlier version of basketball, played primarily by women and girls, was six-on-six basketball. Horseball is a game played on horseback where a ball is handled and points are scored by shooting it through a high net (approximately 1.5m\u00d71.5m). The sport is like a combination of polo, rugby, and basketball. There is even a form played on donkeys known as Donkey basketball, which has attracted criticism from animal rights groups.  Perhaps the single most common variation of basketball is the half-court game, played in informal settings without referees or strict rules. Only one basket is used, and the ball must be \"taken back\" or \"cleared\" \u2013 passed or dribbled outside the three-point line each time possession of the ball changes from one team to the other. Half-court games require less cardiovascular stamina, since players need not run back and forth a full court. Half-court raises the number of players that can use a court or, conversely, can be played if there is an insufficient number to form full 5-on-5 teams.  Half-court basketball is usually played 1-on-1, 2-on-2 or 3-on-3. The last of these variations is gradually gaining official recognition as 3x3, originally known as FIBA 33. It was first tested at the 2007 Asian Indoor Games in Macau and the first official tournaments were held at the 2009 Asian Youth Games and the 2010 Youth Olympics, both in Singapore. The first FIBA 3x3 Youth World Championships[68] were held in Rimini, Italy in 2011, with the first FIBA 3x3 World Championships for senior teams following a year later in Athens. The sport is highly tipped to become an Olympic sport as early as 2016.[69] In the summer of 2017, the BIG3 basketball league, a professional 3x3 half court basketball league that features former NBA players, began. The BIG3 features several rule variants including a four-point field goal.[70]  Variations of basketball with their own page or subsection include:  Spin-offs from basketball that are now separate sports include:  Basketball as a social and communal sport features environments, rules and demographics different from those seen in professional and televised basketball.  Basketball is played widely as an extracurricular, intramural or amateur sport in schools and colleges. Notable institutions of recreational basketball include:  Fantasy basketball was popularized during the 1990s by ESPN Fantasy Sports, NBA.com, and Yahoo! Fantasy Sports. On the model of fantasy baseball and football, players create fictional teams, select professional basketball players to \"play\" on these teams through a mock draft or trades, then calculate points based on the players' real-world performance. "},{"title":"Backboard shattering","content":"A backboard shattering (also known as backboard breaking or backboard smash) is an accident or stunt in basketball. It occurs when a player performs a slam dunk with sufficient force to shatter the tempered glass of the backboard, often causing the hoop to break off as well.  The stunt usually causes games to be canceled or delayed, incurring a foul for the offending player, serious injuries to occur and expensive costs of cleanup and replacement.  Shattering a backboard can be dangerous, sending various small pieces of the backboard glass flying over the players, sideline press personnel, referees, and spectators. In the National Basketball Association (NBA), shattering a backboard during a game is penalized with a \"non-unsportsmanlike\" technical foul and a possible fine towards the player. The player may not be ejected, nor shall the foul count towards a player's total towards either ejection or suspension. The referee also has latitude to waive off the foul, if it is determined the shattering was accidental due to a defect in the backboard or its structure, the board was broken during a rebound of the ball from a jump shot, or if the player had no intentions to dunk with force.[1]  Throughout the history of basketball there have always been athletes with the size and strength to slam dunk the ball through the rim. However, the first NBA player to shatter a backboard, Chuck Connors (who would become far more famous as an actor), did not do so with a dunk. When playing for the Boston Celtics in 1946, Connors took a set shot during pregame warmups, hitting the front of the rim. Because an arena worker had failed to place a protective piece between the rim and backboard, the backboard shattered.[2] All-star power forward Gus Johnson of the Baltimore Bullets became famous as a backboard breaker in the NBA, shattering three during his career in the 1960s and early 1970s.[3]  In the American Basketball Association (ABA), Charlie Hentz shattered two backboards in the same game on November 6, 1970, resulting in the game being canceled.[4] An invention by Arthur Ehrat to create the breakaway rim with a spring on it led to the return of the dunk in college basketball.[5]  An often cited game with a backboard smash was on August 26, 1985. Michael Jordan dunked so hard during a Nike exhibition game in Trieste that the backboard was completely broken. The signed jersey and shoes (including one of the tiny shards of glass in the sole of the left shoe) that Michael Jordan wore during the famous Shattered Backboard game were later auctioned. The moment the glass was broken in Trieste was filmed and is often cited around the world as a particularly important milestone in Jordan's rise.[6]  Darryl Dawkins and Shaquille O'Neal gained notoriety for shattering backboards during their careers; Dawkins's incidents are credited for being the impetus for the research and introduction of breakaway rims throughout the sport, while O'Neal slam dunked with enough force to break the supports holding two backboards during games against the New Jersey Nets and the Phoenix Suns during the 1992\u201393 NBA season. Following the 1992\u201393 season, the NBA increased steel brace strength and increased stability of the backboard to prevent the hoop from falling down. A technical foul for purposeful backboard shattering, differentiating from an accidental shatter by the determination of intent, was also introduced.[1][7]  Most venues with ceiling-mounted backboards and older backstops have their rings attached directly to the glass.  Modern FIBA Level 1 competition units (as used in the NCAA tournament, NBA, Euroleague and FIBA competitions) use a direct mount system, where the basket ring is attached to a metal beam, with a hole in the backboard where the beam is connected to the unit.  On a direct mount system, stress from a dunk is distributed to the beam to the entire unit (as seen in O'Neal's 1993 Phoenix dunk).  On a four-corner mount, the glass still bears stress from a dunking player, which leads to shattering the backboard.  The switch to a direct-mount system and the higher standards for backboard stability imposed by the NBA and later FIBA, including a 2020 rule change stating the homologation of an entire basket unit expires eight years from date of manufacture, have made backboard shattering impossible at major level competition.[8] "},{"title":"Laws of the Game (association football)","content":"  The Laws of the Game are the codified rules of association football. The laws mention the number of players a team should have, the game length, the size of the field and ball, the type and nature of fouls that referees may penalise, the offside law, and many other laws that define the sport. During a match, it is the task of the referee to interpret and enforce the Laws of the Game.  There were various attempts to codify rules among the various types of football in the mid-19th century. The extant Laws date back to 1863 where a ruleset was formally adopted by the newly formed Football Association (FA) and written by its first secretary, Ebenezer Cobb Morley. Over time, the Laws have been amended, and since 1886 they have been maintained by the International Football Association Board (IFAB).  The Laws are the only rules of association football FIFA permits its members to use.[1] The Laws currently allow some minor optional variations which can be implemented by national football associations, including some for play at the lowest levels, but otherwise almost all organised football worldwide is played under the same ruleset. Within the United States, Major League Soccer used a distinct ruleset during the 1990s[2] and the National Federation of State High School Associations and National Collegiate Athletic Association still use rulesets that are comparable to, but different from, the IFAB Laws.[3]  The Laws of the Game consist of seventeen individual laws, each law containing several rules and directions:[4]  All high-level association football is played according to the same laws. The Laws permit some variation for youth, veterans, disability and grassroots football, such as shortening the length of the game and the use of temporary dismissals.[4]  In 1997, a major revision dropped whole paragraphs and clarified many sections to simplify and strengthen the principles. These laws are written in English Common Law style and are meant to be guidelines and goals of principle that are then clarified through practice, tradition, and enforcement by the referees.  The actual law book had long contained 50 pages more of material, organised in numerous sections, that included many diagrams but were not officially part of the main 17 laws. In 2007, many of these additional sections along with much of the material from the FIFA Questions and Answers (Q&A), were restructured and put into a new \"Additional Instructions and Guidelines for the Referee\" section. In the 2016\/2017 revision of the Laws, the material from this section was folded into the Laws themselves.  Referees are expected to use their judgement and common sense in applying the laws; this is colloquially known as \"Law 18\".[5]  The laws are administered by the International Football Association Board (IFAB). They meet at least once a year to debate and decide any changes to the text as it exists at that time. The meeting in winter generally leads to an update to the laws on 1 July of each year that take effect immediately. The laws govern all international matches and national matches of member organisations.[6] A minimum of six of the eight-seat IFAB board needs to vote to accept a rule change. Four seats are held by FIFA to represent their 200+ member Nations, with the other four going to each of the British associations (the FA representing England, the SFA representing Scotland, FAW representing Wales and the IFA representing Northern Ireland), meaning that no change can be made without FIFA's approval, but FIFA cannot change the Laws without the approval of at least two of the British governing bodies.[6]  In the nineteenth century, the word \"football\" could signify a wide variety of games in which players attempted to move a ball into an opponent's goal.  The first published rules of \"football\" were those of Rugby School (1845), which permitted extensive handling, quickly followed by the Eton field game (1847), which was much more restrictive of handling the ball. Between the 1830s and 1850s, a number of sets of rules were created for use at Cambridge University \u2013 but they were generally not published at the time, and many have subsequently been lost.  The first detailed sets of rules published by football clubs (rather than a school or university) were those of Sheffield F.C. (written 1858, published 1859) which codified a game played for 20 years until being discontinued in favour of the Football Association code, and those of Melbourne FC (1859) which are the origins of Australian rules football. By the time the Football Association met in late 1863, many different sets of rules had been published, varying widely on such questions as the extent to which the ball could be handled, the treatment of offside, the amount of physical contact allowed with opponents, and the height at which a goal could be scored.  In 1863, some football clubs followed the example of Rugby School by allowing the ball to be carried in the hands, with players allowed to \"hack\" (kick in the shins) opponents who were carrying the ball. Other clubs forbade both practices.  During the FA meetings to draw up the first version of the laws, there was an acrimonious division between the \"hacking\" and \"non-hacking\" clubs. An FA meeting of 17 November 1863 discussed this question, with the \"hacking\" clubs predominating.[7] A further meeting was scheduled in order to finalise (\"settle\") the laws.[8] At this crucial 24 November meeting, the \"hackers\" were again in a narrow majority. During the meeting, however, the FA's secretary Ebenezer Cobb Morley brought the delegates' attention to a recently published set of football laws from Cambridge University which banned carrying and hacking.[8] Discussion of the Cambridge rules, and suggestions for possible communication with Cambridge on the subject, served to delay the final \"settlement\" of the laws to a further meeting, on 1 December.[9][10] A number of representatives who supported rugby-style football did not attend this additional meeting,[11] resulting in hacking and carrying being banned.[10]  Francis Campbell of Blackheath F.C., the most prominent \"hacking\" club, accused FA President Arthur Pember, Morley, and their allies of managing 24 November meeting improperly in order to prevent the \"pro-hacking\" laws from being adopted.[12] Pember strongly denied such an \"accusation of ungentlemanly conduct\".  The verdicts of later historians have been mixed:  Young accuses Campbell of \"arrogance\",[13] while Harvey supports Campbell's allegations, accusing the non-hackers of a \"coup\" against the pro-hacking clubs.[14] Blackheath, along with the other \"hacking\" clubs, would leave the FA as a result of this dispute.  The final version of the FA's laws was formally adopted and published in December 1863.  Some notable differences from the modern game are listed below:  At its meeting on 8 December 1863, the FA agreed that, as reported in Bell's Life in London, John Lillywhite would publish the Laws.[15] The first game to be played under the new rules occurred eleven days later between Barnes and Richmond.[15] Adoption of the laws was not universal among English football clubs. The Sheffield Rules continued to be used by many. Additionally, in preference for hacking as well as handling of the ball, several clubs, such as Blackheath, decided against being part of the FA in its early years and would later form the Rugby Football Union in 1871.[16]  Minor variations between the rules used in England (the jurisdiction of the Football Association) and the other Home Nations of the United Kingdom \u2013 Scotland, Wales and Ireland \u2013 led to the creation of the International Football Association Board to oversee the rules for all the home nations. Their first meeting was in 1886.[17] Before this, teams from different countries had to agree to which country's rules were used before playing.  When the international football body on the continent FIFA was founded in Paris in 1904, it immediately declared that FIFA would adhere to the rules laid down by the IFAB. The growing popularity of the international game led to the admittance of FIFA representatives to the IFAB in 1913. Up until 1958, it was still possible for the British associations to vote together to impose changes against the wishes of FIFA. This changed with the adoption of the current voting system whereby FIFA's support is necessary, but not sufficient, for any amendment to pass.[6]  Notable amendments to the rules include:[16][18]  The 1938 rewriting of the laws introduced the scheme of 17 named laws that has lasted until today, with only minor alterations.  The history of the numbering and titles of the laws since 1938 is shown in the table below:  Notes "},{"title":"Isle of Man","content":"  The Isle of Man (Manx: Mannin [\u02c8man\u026an\u02b2], also Ellan Vannin [\u02c8\u025bl\u02b2an \u02c8van\u026an\u02b2]) or Mann (\/m\u00e6n\/ man),[10] is a self-governing British Crown Dependency in the Irish Sea, between Great Britain and Ireland. As head of state, Charles III holds the title Lord of Mann and is represented by a Lieutenant Governor. The government of the United Kingdom is responsible for the isle's military defence and represents it abroad.  Humans have lived on the island since before 6500 BC. Gaelic cultural influence began in the 5th century AD, when Irish missionaries following the teaching of St. Patrick began settling the island,[11] and the Manx language, a branch of the Goidelic languages, emerged. In 627, King Edwin of Northumbria conquered the Isle of Man along with most of Mercia. In the 9th century, Norsemen established the thalassocratic Kingdom of the Isles, which included the Isle of Man. Magnus III, King of Norway from 1093 to 1103, reigned as King of Man and the Isles between 1099 and 1103.[12]  In 1266, King Magnus VI of Norway sold his suzerainty over Man to King Alexander III of Scotland under the Treaty of Perth.[13] After a period of alternating rule by the Kings of Scotland and England, the island came under the feudal lordship of the English Crown in 1399. The lordship revested in the British Crown in 1765, but the island did not become part of the 18th-century Kingdom of Great Britain, nor of its successors, the United Kingdom of Great Britain and Ireland and the present-day United Kingdom of Great Britain and Northern Ireland. It has always retained its internal self-government. In 1881, the Isle of Man Parliament, Tynwald, became the first national legislative body in the world to give women the right to vote in a general election, although this excluded married women.[14][b]  The Manx economy is bolstered by its status as a tax haven and offshore banking destination.[15][16][17] Insurance and online gambling each generate 17% of the GNP, followed by information and communications technology and banking with 9% each.[18] This status has also brought the problems of money laundering, financial crime, and terrorism financing.[19]  Internationally, the Isle of Man is known for the TT Motorcycle Races,[20] and the Manx cat, a breed with short or no tails.[21] In 2016, UNESCO awarded the Isle of Man biosphere reserve status.[22]  The Manx name of the Isle of Man is Ellan Vannin: ellan (Manx pronunciation: [\u025bl\u02b2an]), a Manx word meaning \"island\"; Mannin (IPA: [man\u026an\u02b2]) appears in the genitive case as Vannin (IPA: [van\u026an\u02b2]), with initial consonant mutation, hence Ellan Vannin, \"Island of Mann\". The short form used in English is spelled either Mann or Man. The earliest recorded Manx form of the name is Manu or Mana.[23]  The Old Irish form of the name is Manau or Mano. Old Welsh records named it as Manaw, also reflected in Manaw Gododdin, the name for an ancient district in north Britain along the lower Firth of Forth.[24] In the 1st century AD, Pliny the Elder records it as Monapia or Monabia, and Ptolemy (2nd century) as Mon\u0153da (M\u03bf\u03bd\u03b1\u03bf\u03b9\u03b4\u03b1, Monaoida) or M\u03bf\u03bd\u03b1\u03c1\u03b9\u03bd\u03b1 (Monarina), in Koine Greek. Later Latin references have Mevania or M\u00e6navia (Orosius, 416),[25] and Eubonia or Eumonia by Irish writers. It is found in the Sagas of Icelanders as M\u00f6n.[26]  The name is probably cognate with the Welsh name of the island of Anglesey, Ynys M\u00f4n,[24] usually derived from a Celtic word for 'mountain' (reflected in Welsh mynydd, Breton menez, and Scottish Gaelic monadh),[27][28] from a Proto-Celtic *moniyos.  The name was at least secondarily associated with that of Manann\u00e1n mac Lir in Irish mythology (corresponding to Welsh Manawydan fab Ll\u0177r).[29] In the earliest Irish mythological texts, Manann\u00e1n is a king of the otherworld, but the 9th-century Sanas Cormaic identifies a euhemerised Manann\u00e1n as \"a famous merchant who resided in, and gave name to, the Isle of Man\".[30] Later, a Manann\u00e1n is recorded as the first king of Man in a Manx poem (dated 1504).[31]  The island was cut off from the surrounding islands around 8000\u00a0BC as sea levels rose following the end of the last ice age. Humans colonised it by travelling by sea some time before 6500\u00a0BC.[32] The first occupants were hunter-gatherers and fishermen. Examples of their tools are kept at the Manx Museum.[33]  The Neolithic Period marked the beginning of farming, and the people began to build megalithic monuments, such as Cashtal yn Ard in Maughold parish, King Orry's Grave in Laxey, Mull Hill near Cregneash, and Ballaharra Stones at St John's. There were also the local Ronaldsway and Bann cultures.[34]  During the Bronze Age, the size of burial mounds decreased. The people put bodies into stone-lined graves with ornamental containers. The Bronze Age burial mounds survived as long-lasting markers around the countryside.[35]  The ancient Romans knew of the island and called it Insula Manavia.[36] During the four centuries when Rome ruled the Province of Britannia, the Roman military controlled the Irish Sea, providing safe passage of agricultural goods from the productive farms of Anglesey to Roman settlements at the English \u2013 Scottish frontier. Only a few Roman artifacts have been found on Man, suggesting a lack of strategic value of Man during the era of Britannia. No Roman lighthouses or signal towers have yet been found on Man.[37]  Around the 5th century AD, large-scale migration from Ireland precipitated a process of Gaelicisation, evidenced by Ogham inscriptions, and the Manx language developed. It is a Goidelic language closely related to Irish and Scottish Gaelic.[38]  In the 7th century, Man came under control of the Anglo-Saxon King Edwin of Northumbria, who then launched raids from Man into Ireland. How much influence the Northumbrians exerted on Man is unknown, but very few place names on Man are of Old English origin.[39]  Vikings arrived at the end of the 8th century. They established Tynwald and introduced many land divisions that still exist. In 1266 King Magnus VI of Norway ceded the islands to Alexander III, King of Scots, in the Treaty of Perth. But Scottish rule over Man did not become firmly established until 1275, when the Manx were defeated in the Battle of Ronaldsway, near Castletown.  In 1290 King Edward I of England sent Walter de Huntercombe to take possession of Man. It remained in English hands until 1313, when Robert the Bruce took it after besieging Castle Rushen for five weeks.[40] In 1314, it was retaken for the English by John Bacach of Argyll. In 1317, it was retaken for the Scots by Thomas Randolph, 1st Earl of Moray and Lord of the Isle of Man. It was held by the Scots until 1333. For some years thereafter control passed back and forth between the two kingdoms until the English took it for the final time in 1346.[41] The English Crown delegated its rule of the island to a series of lords and magnates. Tynwald passed laws concerning the government of the island in all respects and had control over its finances but was subject to the approval of the Lord of Mann.  In 1765, the Act of Revestment occurred, whereby the feudal rights of the Dukes of Atholl as Lords of Man were purchased and revested into the British Crown.[42]  In 1866, the Isle of Man obtained limited home rule, with partly democratic elections to the House of Keys, but the Legislative Council was appointed by the Crown. Since then, democratic government has been gradually extended.  During both World Wars, the island was used for the internment of people originating from enemy countries.  In recent times, the economy of the island has benefited from regulatory arbitrage in various contexts, such as low taxes, which have attracted wealthy individuals, and which together with arguably lax regulation have attracted industries such as offshore financial services and more recently gambling.  The Isle of Man has designated more than 250 historic sites as registered buildings.  The Isle of Man is an island located in the middle of the northern Irish Sea, almost equidistant from England to the east, Northern Ireland to the west, and Scotland (closest) to the north, while Wales to the south is almost the distance of the Republic of Ireland to the southwest. It is 52 kilometres (32\u00a0mi) long and, at its widest point, 22 kilometres (14\u00a0mi) wide. It has an area of around 572 square kilometres (221\u00a0sq\u00a0mi).[43] Besides the island of Man itself, the political unit of the Isle of Man includes some nearby small islands: the seasonally inhabited Calf of Man,[44] Chicken Rock (on which stands an unstaffed lighthouse), St Patrick's Isle and St Michael's Isle. The last two of these are connected to the main island by permanent roads\/causeways.  Ranges of hills in the north and south are separated by a central valley. The northern plain, by contrast, is relatively flat, consisting mainly of deposits from glacial advances from western Scotland during colder times. There are more recently deposited shingle beaches at the northernmost point, the Point of Ayre. The island has one mountain higher than 600 metres (2,000\u00a0ft), Snaefell, with a height of 620 metres (2,034\u00a0ft).[43] According to an old saying, from the summit one can see six kingdoms: those of Man, Scotland, England, Ireland, Wales, and Heaven.[45][46] Some versions add a seventh kingdom, that of the sea, or Neptune.[47]  The Isle of Man has a temperate oceanic climate (K\u00f6ppen Cfb). Average rainfall is higher than averaged over the territory of the British Isles, because the Isle of Man is far enough from Ireland for the prevailing south-westerly winds to accumulate moisture. Average rainfall is highest at Snaefell, where it is around 1,900 millimetres (75\u00a0in) a year. At lower levels it can be around 800 millimetres (31\u00a0in) a year. In drier spots, the Isle of Man is sunnier than either Ireland or the majority of England at 1,651 hours per year at the official Ronaldsway station.[48] The highest recorded temperature was 28.9\u00a0\u00b0C (84.0\u00a0\u00b0F) in Ronaldsway on 12 July 1983. Due to the moderate surface temperatures of the Irish Sea, the island does not receive bursts of heat that sometimes can hit Northern England. The stable water temperature also means that air frost is rare, averaging just ten occasions per year.[48]  On 10 May 2019 Chief Minister Howard Quayle stated that the Isle of Man Government recognises that a state of emergency exists due to the threat of anthropogenic climate change.[49]  The United Kingdom is responsible for the island's defence and ultimately for good governance, and for representing the island in international forums, while the island's own parliament and government have competence over all domestic matters.[53]  The island's parliament, Tynwald, is claimed to have been in continuous existence since 979 or earlier, purportedly making it the oldest continuously governing body in the world, though evidence supports a much later date.[54] Tynwald is a bicameral or tricameral legislature, comprising the House of Keys (directly elected by universal suffrage with a voting age of 16 years) and the Legislative Council (consisting of indirectly elected and ex-officio members). These two bodies also meet together in joint session as Tynwald Court.  The executive branch of government is the Council of Ministers, which is composed of Members of Tynwald (usually Members of the House of Keys, though Members of the Legislative Council may also be appointed as Ministers). It is headed by the Chief Minister.  Vice-regal functions of the head of state are performed by a lieutenant governor.  In various laws of the United Kingdom, \"the United Kingdom\" is defined to exclude the Isle of Man. Historically, the UK has taken care of its external and defence affairs and retains paramount power to legislate for the Island. However, in 2007, the Isle of Man and the UK signed an agreement that established frameworks for the development of the international identity of the Isle of Man.[55] There is no separate Manx citizenship. Citizenship is covered by UK law, and Manx people are classed as British citizens. There is a long history of relations and cultural exchange between the Isle of Man and Ireland. The Isle of Man's historic Manx language (and its modern revived variant) are closely related to both Scottish Gaelic and the Irish language, and in 1947, Irish Taoiseach \u00c9amon de Valera spearheaded efforts to save the dying Manx language.[56]  The Isle of Man is not part of the United Kingdom; however, the UK is responsible for its defence and external affairs.[57] There are no independent military forces on the Isle of Man, although HMS Ramsey was affiliated with the town of the same name.[58] From 1938 to 1955 there existed the Manx Regiment of the British Territorial Army, which saw extensive action during the Second World War.[59] During the English Civil War the 7th Earl of Derby and Lord of Mann James Stanley conscripted 10 men from each parish (170 in total) to fight for the Royalist cause; the majority were killed at the Battle of Wigan Lane in 1651. In 1779, the Manx Fencible Corps, a fencible regiment of three companies, was raised; it was disbanded in 1783 at the end of the American War of Independence. Later, the Royal Manx Fencibles was raised at the time of the French Revolutionary Wars and Napoleonic Wars. The 1st Battalion (of 3 companies) was raised in 1793. A 2nd Battalion (of 10 companies) was raised in 1795,[60] and it saw action during the Irish Rebellion of 1798. The regiment was disbanded in 1802.[61] A third body of Manx Fencibles was raised in 1803 to defend the island during the Napoleonic Wars and to assist the Revenue. It was disbanded in 1811.[62] The Isle of Man Home Guard was raised during the Second World War for home defence.[63] In 2015 a multi-capability recruiting and training unit of the British Army Reserve was established in Douglas.[64]  There is no citizenship of the Isle of Man as such; Isle of Man residents are entitled to British citizenship and can obtain a full UK British passport or British Isle of Man passport.  The Passport Office, Isle of Man, Douglas, accepts and processes applications for the Lieutenant Governor of the Isle of Man, who is formally responsible for issuing Isle of Man\u2013issued British passports, titled \"British passport \u2013 Isle of Man\". The powers conferred on the UK Secretary of State by the British Nationality Act 1981 extend to and are exercised in the Isle of Man by the Lieutenant Governor.[65]  Isle of Man-issued British passports can presently be issued to any British citizen resident in the Isle of Man, and also to British citizens who have a qualifying close personal connection to the Isle of Man but are now resident either in the UK or in either one of the two other Crown Dependencies.  The Isle of Man was never part of the European Union, nor did it have a special status, and thus it did not take part in the 2016 (Brexit) referendum on the UK's EU membership.[66] However, it was included within the EU's customs area, as part of Protocol 3 of the UK's Act of Accession to the Treaty of Rome, allowing Manx goods to be traded throughout the EU without tariffs.[67]  It was not part of the EU's internal market and there were still limitations on the movement of capital, services and labour.  EU citizens were entitled to travel and reside, but not work, in the island without restriction. British citizens with Manxman status were under the same circumstances and restrictions as any other non-EU European relating country to work in the EU.[68][69]  The political and diplomatic impacts of Brexit on the island are still uncertain. The UK confirmed that the Crown Dependencies' positions were included in the Brexit negotiations.[70] The Brexit withdrawal agreement explicitly included the Isle of Man in its territorial scope, but makes no other mention of it.[71] The island's government website stated that after the end of the implementation period, the Isle of Man's relationship with the EU would depend on the agreement reached between the UK and the EU on their future relationship.[72]  The Isle of Man is not a member of the Commonwealth of Nations. By virtue of its relationship with the United Kingdom, it takes part in several Commonwealth institutions, including the Commonwealth Parliamentary Association and the Commonwealth Games. The Government of the Isle of Man has made calls for a more integrated relationship with the Commonwealth,[73] including more direct representation and enhanced participation in Commonwealth organisations and meetings, including Commonwealth Heads of Government Meetings.[74] The Chief Minister of the Isle of Man has said: \"A closer connection with the Commonwealth itself would be a welcome further development of the island's international relationships.\"[75]  Most Manx politicians stand for election as independents rather than as representatives of political parties. Although political parties do exist, their influence is not as strong as in the United Kingdom.  There are three political parties in the Isle of Man:  There are also a number of pressure groups on the island. Mec Vannin advocate the establishment of a sovereign republic.[77] The Positive Action Group campaign for three key elements to be introduced into the governance of the island: open accountable government, rigorous control of public finances, and a fairer society.[78]  Local government on the Isle of Man is based partly on the island's 17 ancient parishes. There are four types of local authorities:  Each of these districts has its own body of commissioners.  The Isle of Man was the last place in the British Isles to legalise same-sex sexual activity. While it had been legal in England and Wales since 1967, it remained illegal in the Isle of Man until 1992.[79][80]  The Isle of Man's former Chief Minister Howard Quayle issued an \"unqualified apology\" to gay men convicted of same-sex offences under previous Manx laws.  Public education is overseen by the Department of Education, Sport & Culture. Thirty-two primary schools, five secondary schools and the University College Isle of Man function under the department.[81]  Two-thirds of residents of Man are overweight or obese, four in ten are physically inactive, one-quarter are binge drinkers, one in twelve smoke cigarettes, and about 15% are in poor general health.[82] Healthcare is provided via a public health scheme by the Department of Health and Social Care for residents and visitors from the UK.[83]  The Crime Severity Rate in Man, which largely measures crimes directed against persons or property, remains substantially less than that in the United Kingdom, although the rate of violent crime has been increasing in recent years. Most violent crime is associated with the trade in illegal drugs.[84]  The Government of Man has laid out a strategy entailing a \"whole-Island approach\" to address the serious problems of money laundering, financial crime, and terrorism financing.[85]  The Isle of Man Government maintains five emergency services.[86] These are:  All of these services are controlled directly by the Department of Home Affairs of the Isle of Man Government and are independent of the United Kingdom. Nonetheless, the Isle of Man Constabulary voluntarily submits to inspection by the British inspectorate of police,[87] and the Isle of Man Coastguard contracts His Majesty's Coastguard (UK) for air-sea rescue operations.  The island's sole crematorium is located in Glencrutchery Road, Douglas, and is operated by the Douglas Borough Council. Usually staffed by four, in March 2020 an increase of staff to 12 was announced by the Council leader, responding to the threat of the COVID-19 pandemic, which could require more staff.[88]  The Isle of Man has no capital gains tax, wealth tax, stamp duty, or inheritance tax[89] and a top rate of income tax of 20%.[90] A tax cap is in force: the maximum amount of tax payable by an individual is \u00a3200,000 or \u00a3400,000 for couples choosing to have their incomes jointly assessed. Personal income is assessed and taxed on a worldwide income basis rather than a remittance basis. This means that all income earned throughout the world is assessable for Manx tax rather than only income earned in or brought into the island. The standard rate of corporation tax for residents and non-residents is 0%. Retail business profits above \u00a3500,000 and banking business income are taxed at 10%, and rental (or other) income from land and buildings situated on the Isle of Man is taxed at 20%.[91]  Man's low corporate tax burden[92] and absence of public registries of corporate ownership[93] provides tax avoidance and tax evasion strategies for individuals and corporations, resulting in a large influx of funds from those in pursuit of tax advantage and financial confidentiality.[94] The relative importance of agriculture, fishing, and tourism in the Isle of Man, the former mainstays of the economy, has accordingly declined.[95] As is typical of the low-tax crown dependencies, Man's economy features financial services, shell corporations for high-technology companies, online gambling and online gaming,[96] cinema production, and tax havens for high net worth individuals.[97][98] These activities have brought some high-income jobs to Man, as hundreds of local residents serve as \"straw man\" directors and shareholders of shell companies.[99] Similar schemes provide a means for high net worth individuals to reduce their tax obligations and to shield their financial dealings from public scrutiny.[100][95] As described in the Paradise Papers,[101] the Isle of Man economy features extensive illegal economic activity including tax evasion, money laundering from drug sales, money transfers from weapons sales, and looting of public treasuries of other nation states (particularly Russia).[102] These funds are mostly funneled into the London financial markets.[103] Online gambling sites provided about 10% of the Man government's revenue in 2014.[104][full citation needed]  There has been an effort to regulate these illicit activities on Man, though the impact of legal measures instituted by the Man government remains uncertain.[105] As of June, 2023, Man remains out of compliance with standards for Anti-Money Laundering & Countering the Financing of Terrorism requirements according to Moneyval, the European Union's Committee of Experts on the Evaluation of Anti-Money Laundering Measures and the Financing of Terrorism[106]  The Isle of Man Department for Enterprise manages the diversified economy in 12 key sectors.[107] The largest sectors by GNP are insurance and online casino operations with 17% of GNP each, followed by ICT and banking with 9% each. The 2016 census lists 41,636 total employed.[108] The largest sectors by employment are \"medical and health\", \"financial and business services\", construction, retail and public administration.[109] Manufacturing, focused on aerospace and the food and drink industry,[110] employs almost 2000 workers and contributes about 5% of gross domestic product (GDP). The sector provides laser optics, industrial diamonds, electronics, plastics and aerospace precision engineering. Tourism, agriculture, and fishing, once the mainstays of the economy, now make very little contributions to the island's GDP. The unemployment rate on Man is less than 1%.[111]  Trade takes place mostly with the United Kingdom. The island is in customs union with the UK, and related revenues are pooled and shared under the Common Purse Agreement. This means that the Isle of Man cannot have the lower excise revenues on alcohol and other goods that are enjoyed in the Channel Islands.  The Manx government promotes island locations for making films by offering financial support. Since 1995, over 100 films have been made on the island.[112] Most recently the island has taken a much wider strategy to attract the general digital media industry in film, television, video and esports.[113]  The Isle of Man Government Lottery operated from 1986 to 1997. Since 2 December 1999 the island has participated in the United Kingdom National Lottery.[114][115] The island is the only jurisdiction outside the United Kingdom where it is possible to play the UK National Lottery.[116] Since 2010 it has also been possible for projects in the Isle of Man to receive national lottery Good Causes Funding.[117][118] The good causes funding is distributed by the Manx Lottery Trust.[119] Tynwald receives the 12% lottery duty for tickets sold in the island.  Tourist numbers peaked in the first half of the 20th century, prior to the boom in cheap travel to Southern Europe that also saw the decline of tourism in many similar English seaside resorts. The Isle of Man tourism board has recently invested in \"Dark Sky Discovery\" sites to diversify its tourism industry. It is expected that dark skies will generally be nominated by the public across the UK. However, the Isle of Man tourism board tasked someone from their team to nominate 27 places on the island as a civil task. This cluster of the highest quality \"Milky Way\" sites[120] is now well promoted within the island. This government push has effectively given the island a headstart in the number of recognised Dark Sky sites. However, this has created a distorted view when compared to the UK where this is not promoted on a national scale. There, Dark Sky sites are expected to be nominated over time by the public across a full range of town, city and countryside locations rather than en masse by government departments.[121]  In 2017 an office of The International Stock Exchange was opened to provide a boost for the island's finance industry.[122]  The main telephone provider on the Isle of Man is Manx Telecom. The island has two mobile operators: Manx Telecom, previously known as Manx Pronto, and Sure. Cloud9 operated as a third mobile operator on the island for a short time but has since withdrawn.[123]  Broadband internet services are available through four local providers: Wi-Manx, Domicilium, Manx Computer Bureau and Manx Telecom. The island does not have its own ITU country code but is accessed via the British country code (+44), and the island's telephone numbers are part of the British telephone numbering plan, with local dialling codes 01624 for landlines and 07524, 07624 and 07924 for mobiles. Calls to the island from the UK, however, are generally charged differently from those within the UK, and may or may not be included in any \"inclusive minutes\" packages.[124][125]  In 1996, the Isle of Man Government obtained permission to use the .im national top-level domain (TLD) and has ultimate responsibility for its use. The domain is managed from day to day by Domicilium, an island-based internet service provider. In December 2007, the Manx Electricity Authority and its telecommunications subsidiary, e-llan Communications, commissioned the laying of a new fibre-optic link that connects the island to a worldwide fibre-optic network. In August 2021 it was reported that Elon Musk's satellite internet service, Starlink, had been granted a licence to operate from a ground station on the island.  The Isle of Man has three radio stations: Manx Radio, Energy FM and 3FM.  There is no insular television service, but local transmitters retransmit British mainland digital broadcasts via the free-to-air digital terrestrial service Freeview. The Isle of Man is served by BBC North West for BBC One and BBC Two television services, and ITV Granada for ITV.  Many television services are available by satellite, such as Sky, and Freesat from the group of satellites at 28.2\u00b0 East, as well as services from a range of other satellites around Europe such as the Astra satellites at 19.2\u00b0 east and Hot Bird.  The Isle of Man has three newspapers, all weeklies, and all owned by Isle of Man Newspapers, a division of the Edinburgh media company Johnston Press.[126] The Isle of Man Courier (distribution 36,318) is free and distributed to homes on the island. The other two newspapers are Isle of Man Examiner (circulation 13,276) and the Manx Independent (circulation 12,255).[127]  Postal services are the responsibility of the Isle of Man Post Office, which took over from the UK's General Post Office in 1973.  There is a comprehensive bus network, operated by the government-owned bus operator Bus Vannin.[128]  The Isle of Man Sea Terminal in Douglas has regular ferries to and from Heysham and to and from Liverpool, with a more restricted timetable operating in winter. The two vessels are Manannan and Manxman; in 2023 Manxman has now largely taken over from the Ben My Chree. Manxman arrived in 2023, and was made by Hyundai; she was named Manxman by the public in mid 2020. There are also limited summer-only services to and from Belfast and Dublin. The Dublin route also operates at Christmas. At the time of the Isle of Man TT a limited number of sailings operate to and from Larne in Northern Ireland. All ferries are operated by the Isle of Man Steam Packet Company.[129]  The only commercial airport on the island is the Isle of Man Airport at Ronaldsway. There are direct scheduled and chartered flights to numerous airports in the United Kingdom and Ireland.[130]  The island has a total of 688 miles (1,107\u00a0km)[131] of public roads, all of which are paved. There is no overriding national speed limit; only local speed limits are set, and some roads have no speed limit. Rules about reckless driving and most other driving regulations are enforced in a similar way to the UK.[132] There is a requirement for regular vehicle examinations for some vehicles (similar to the MoT test in the UK).[133]  The island used to have an extensive narrow-gauge railway system, both steam-operated and electric, but the majority of the steam railway tracks were taken out of service many years ago, and the track removed. As of 2023[update], there is a steam railway between Douglas and Port Erin, an electric railway between Douglas and Ramsey and an electric mountain railway which climbs Snaefell.[134]  One of the oldest operating horse tram services is located on the sea front in the capital, Douglas. It was founded in 1876.[134]  The Isle of Man has become a centre for emerging private space travel companies.[135] A number of the competitors in the Google Lunar X Prize, a $30\u00a0million competition for the first privately funded team to send a robot to the Moon, are based on the island. The team summit for the X Prize was held on the island in October 2010.[136] In January 2011 two research space stations owned by Excalibur Almaz arrived on the island and were kept in an aircraft hangar at the airfield at the former RAF Jurby near Jurby.[137]  The electricity supply on the Isle of Man is run by the Manx Utilities Authority. The Isle of Man is connected to Great Britain's national grid by a 40\u00a0MW alternating current link (Isle of Man to England Interconnector). There are also hydroelectric, natural gas and diesel generators. The government has also planned a 700 MW offshore wind farm, roughly half the size of Walney Wind Farm.[138]  Gas for lighting and heating has been supplied to users on the Isle of Man since 1836, firstly as town gas, then as liquefied petroleum gas (LPG); since 2003 natural gas has been available. The future use of hydrogen as a supplementary or substitute fuel is being studied.[139]  In June 2021, the law prohibiting commercial cultivation of cannabis on Ellan Vannin was repealed, and the government of Man, for the first time, offered licences for production and export of cannabis. In February 2022, Man resident and local billionaire John Whittaker, through his firm Peel NRE, proposed to spend US$136 million for the construction of warmhouses for cannabis cultivation, and research facilities, and to develop the business. It was announced that zoning permits had been granted for development of the facility. Although the availability of medical cannabis is heavily restricted within the U.K., there has been an effort to develop the cannabis industry on the Channel Islands of Jersey and Guernsey.[140][141][142]  The Manx are a Celtic nation.[143]  The culture of the Isle of Man is often promoted as being influenced by its Celtic and, to a lesser extent, its Norse origins. Proximity to the UK, popularity as a UK tourist destination in Victorian times, and immigration from Britain have all meant that the cultures of Great Britain have been influential at least since Revestment. Revival campaigns have attempted to preserve the surviving vestiges of Manx culture after a long period of Anglicisation, and there has been significantly increased interest in the Manx language, history and musical tradition.  The official languages of the Isle of Man are English and Manx. Manx has traditionally been spoken but has been stated to be \"critically endangered\".[144] However, it now has a growing number of young speakers. It is increasingly evident on the island: for instance, in public notices and its increasing use in the Tynwald ceremony.  Manx is a Goidelic Celtic language and is one of a number of insular Celtic languages spoken in the British Isles.[145] Manx has been officially recognised as a legitimate autochthonous regional language under the European Charter for Regional or Minority Languages, ratified by the United Kingdom on 27 March 2001 on behalf of the Isle of Man government.[146]  Manx is closely related to Irish and Scottish Gaelic but is orthographically sui generis.  On the island, the Manx greetings moghrey mie (good morning) and fastyr mie (good afternoon) can often be heard.[147] As in Irish and Scottish Gaelic, the concepts of \"evening\" and \"afternoon\" are referred to with one word.[148] Two other Manx expressions often heard are Gura mie eu (\"Thank you\"; familiar 2nd person singular form Gura mie ayd) and traa dy liooar, meaning \"time enough\", which represents a stereotypical view of the Manx attitude to life.[149][150]  In the 2011 Isle of Man census, approximately 1,800 residents stated that they could read, write, and speak the Manx language.[151]  For centuries, the island's symbol has been the so-called \"three legs of Man\" (Manx: Tree Cassyn Vannin), a triskelion of three legs conjoined at the thigh. The Manx triskelion, which dates back with certainty to the late 13th century, is of uncertain origin. It has been suggested that its origin lies in Sicily, an island which has been associated with the triskelion since ancient times.[152][153]  The symbol appears in the island's official flag and official coat of arms, as well as its currency. The Manx triskelion may be reflected in the island's motto, Quocunque jeceris stabit, which appears as part of the island's coat of arms. The Latin motto translates as \"whichever way you throw, it will stand\"[154] or \"whithersoever you throw it, it will stand\".[155] It dates to the late 17th century when it is known to have appeared on the island's coinage.[154] It may be understood to refer to the Caltrop, a military device with one spike always pointing upwards. The motto itself originally featured on the family badge of the Byzantine\/Roman General Flavius Belisarius (505 \u2013 565 AD) along with a representation of a caltrop.\"IOM Stamps \u2013 The Three Legs of Man\". 20 May 2013. It has also been suggested that the motto originally referred to the poor quality of coinage which was common at the time\u2014as in \"however it is tested it will pass\".[156]  The ragwort or cushag has been referred to as the Manx national flower.[157]  The predominant religious tradition of the Isle of Man is Christianity, adhered to by 54.7% of the Manx according to the 2021 census.[5] At the same time, 43.8% of the population had no religion, 0.5% adhered to Islam, 0.5% to Buddhism, 0.4% to Hinduism, 0.2% to Judaism, and 0.2% to other religions.[5]  Before the Protestant Reformation, the island had a long history as part of the unified Catholic Church, and in the years following the Reformation, the religious authorities on the island, and later the population of the island, accepted the religious authority of the British monarchy, Anglicanism and the Church of England.[158] The Isle of Man also came under the influence of Irish religious tradition. The island forms a separate diocese called Sodor and Man, which in the distant past comprised the medieval kingdom of Man and the Scottish isles (\"Su\u00f0reyjar\" in Old Norse). Nowadays, it consists of sixteen parishes,[159] and since 1541[160] has been part of the Province of York.[161]  Other Christian denominations and other religions also operate on the Isle of Man. The second largest denomination is the Methodist Church, whose Isle of Man District is close in numbers to the Anglican diocese. Then, there are eight Catholic parish churches, included in the Catholic Archdiocese of Liverpool,[162] as well as a presence of Eastern Orthodox Christians. Additionally, there are five Baptist churches, four Pentecostal churches, the Salvation Army, a ward of the Church of Jesus Christ of Latter-day Saints, two congregations of Jehovah's Witnesses, two United Reformed churches, as well as other Christian churches.[citation needed]  The Manx Muslim community has a mosque in Douglas, and Jews also have a history on the island.[163] In 2022, the island's first Buddhist temple was established in Baldrine.[164]  In Manx mythology, the island was ruled by the sea god Manann\u00e1n, who would draw his misty cloak around the island to protect it from invaders. One of the principal folk theories about the origin of the name Man is that it is named after Manann\u00e1n.  In the Manx tradition of folklore, there are many stories of mythical creatures and characters. These include the Buggane, a malevolent spirit which according to legend, blew the roof off St Trinian's Church in a fit of rage; the Fenodyree; the Glashtyn; and the Moddey Dhoo, a ghostly black dog which wandered the walls and corridors of Peel Castle.  The Isle of Man is also said to be home to fairies, known locally as \"the little folk\" or \"themselves\". There is a famous Fairy Bridge, and it is said to be bad luck if one fails to wish the fairies good morning or afternoon when passing over it. It used to be a tradition to leave a coin on the bridge to ensure good luck. Other types of fairies include the Arkan Sonney.  An old Irish story tells how Lough Neagh was formed when Ireland's legendary giant Fionn mac Cumhaill (commonly anglicised to Finn McCool) ripped up a portion of the land and tossed it at a Scottish rival. He missed and the chunk of earth landed in the Irish Sea, thus creating the island.  Peel Castle has been proposed as a possible location of the Arthurian Avalon[165] or as the location of the Grail Castle, site of Lancelot's encounter with the sword bridge of King Maleagant.[166]  One of the most oft-repeated myths is that people found guilty of witchcraft were rolled down Slieau Whallian, a hill near St John's, in a barrel. However, this is a 19th-century legend derived from a Scottish legend, which in turn comes from a German legend. Separately, a witchcraft museum was opened at the Witches Mill, Castletown in 1951. There has never actually been a witches' coven on that site; the myth was only created with the opening of the museum.[167] However, there has been a strong tradition of herbalism and the use of charms to prevent and cure illness and disease in people and animals.[168][169]  The music of the Isle of Man reflects Celtic, Norse and other influences, including from its neighbours, Scotland, Ireland, England and Wales. A wide range of music is performed on the island, such as rock, blues, jazz and pop.  Its traditional folk music has undergone a revival since the 1970s, starting with a music festival called Yn Chruinnaght in Ramsey.[170] This was part of a general revival of the Manx language and culture after the death of the last native speaker of Manx in 1974.  Orchestral and song composer Haydn Wood grew up on the Isle of Man, moving there in 1885, aged three years old. The island and its folk tunes inspired Wood's music, resulting in the compositions Manx Rhapsody (Mylecharaine), Manx Countryside Sketches, Manx Overture, and the 1933 tone poem Mannin Veen (Manx for \"Dear Isle of Man\"), based on four Manx folk tunes and scored for wind band.[171] His older brother Harry Wood (1868\u20131939) was also a musician: a violinist, composer and conductor who became known as \"Manxland's King of Music\".[172]  The Isle of Man is mentioned in the Who song \"Happy Jack\" as the homeland of the song's titular character, who is always in a state of ecstasy, no matter what happens to him. The song \"The Craic was 90 in the Isle of Man\" by Christy Moore describes a lively visit during the Island's tourism heyday. The Island is also the birthplace of Maurice, Robin and Barry Gibb, of the Bee Gees; a bronze statue of the trio was unveiled on Douglas promenade in July 2021.[173]  In the past, the basic national dish of the island was spuds and herrin, boiled potatoes and herring. This plain dish was supported by the subsistence farmers of the island, who for centuries crofted the land and fished the sea. Chips, cheese and gravy, a dish similar to poutine, is found in most of the island's fast-food outlets, and consists of thick-cut chips, covered in shredded Cheddar cheese and topped with a thick gravy.[174] However, as of the Isle of Man Food & Drink Festival 2018, queen scallops (queenies) have been crowned the Manx national dish[175][176] with many restaurants, hotels and pubs serving local wild queen scallops.  Seafood has traditionally accounted for a large proportion of the local diet. Although commercial fishing has declined in recent years, local delicacies include Manx kippers (smoked herrings) which are produced by the smokeries in Peel on the west coast of the island, albeit mainly from North Sea herring these days.[177] The smokeries also produce other specialities including smoked salmon and bacon.  Crab, lobster and scallops are commercially fished, and the queen scallop is regarded as a particular delicacy, with a light, sweet flavour.[178] Cod, ling and mackerel are often angled for the table, and freshwater trout and salmon can be taken from the local rivers and lakes, supported by the government fish hatchery at Cornaa on the east coast.  Cattle, sheep, pigs and poultry are all commercially farmed; Manx lamb from the hill farms is a popular dish. The Loaghtan, the indigenous breed of Manx sheep, has a rich, dark meat that has found favour with chefs,[179][180] featuring in dishes on the BBC's MasterChef series.  Manx cheese has also found some success, featuring smoked and herb-flavoured varieties, and is stocked by many of the UK's supermarket chains.[181][182][183] Manx cheese took bronze medals in the 2005 British Cheese Awards, and sold 578 tonnes over the year. Manx cheddar has been exported to Canada where it is available in some supermarkets.[184]  Beer is brewed on a commercial scale by Okells Brewery, which was established in 1850 and is the island's largest brewer, and by Bushy's Brewery, Hooded Ram, Odin, Radical Brewing, Noa Brewhouse and Kaneens Brewery. The Isle of Man's Pure Beer Act of 1874, which resembles the German Reinheitsgebot, is still in effect: under this Act, brewers may only use water, malt, sugar and hops in their brews.[185]  The Isle of Man is represented as a nation in the Commonwealth Games and the Island Games and hosted the IV Commonwealth Youth Games in 2011. Manx athletes have won three gold medals at the Commonwealth Games, including the one by cyclist Mark Cavendish in 2006 in the Scratch race. The Island Games were first held on the island in 1985, and again in 2001. FC Isle of Man was founded in 2019 and is a North West Counties League team.  Isle of Man teams and individuals participate in many sports both on and off the island including rugby union, football, gymnastics, field hockey, netball, taekwondo, bowling, obstacle course racing and cricket. The FC Isle of Man will compete in the North West Counties Football League Premier Division in the next league campaign.[186] It being an island, many types of watersports are also popular with residents.  The main international event associated with the island is the Isle of Man Tourist Trophy race, colloquially known as \"The TT\",[187] which began in 1907. It takes place in late May and early June. The TT is now an international road racing event for motorcycles, which used to be part of the World Championship, and is long considered to be one of the \"greatest motorcycle sporting events of the world\".[188] Taking place over a two-week period, it has become a festival for motorcycling culture, makes a huge contribution to the island's economy and has become part of Manx identity.[189] For many, the Isle carries the title \"road racing capital of the world\".[190]  The Manx Grand Prix is a separate motorcycle event for amateurs and private entrants that uses the same 60.70\u00a0km (37.72\u00a0mi)[191] Snaefell Mountain Course in late August and early September.  Prior to the introduction of football in the 19th century, cammag was the island's traditional sport.[192] It is similar to the Irish hurling and the Scottish game of shinty. Nowadays there is an annual match at St John's.  Built in 1899, to the designs of architect Frank Matcham,[193] and restored in 1976 to its original splendor, the government-owned Gaiety Theatre and Opera House[194] on the Douglas Promenade presents plays, musicals, concerts and comedy shows year-round. Within the Gaiety Theatre Complex, the Broadway Cinema has a capacity of 154 and doubles as a conference venue.[195]  The Palace Cinema is located next to the derelict Castle Mona hotel and is operated by the Sefton Group. It has two screens: Screen One holds 293 customers, while Screen Two is smaller with a capacity of just 95. It was extensively refurbished in August 2011.[196]  Two domestic animals are specifically connected to the Isle of Man, though they are also found elsewhere.  The Manx cat is a breed of cat noted for its genetic mutation resulting in a shortened tail. The length of this tail can range from a few inches[clarification needed], known as a \"stumpy\", to being completely nonexistent, or \"rumpy\". Manx cats display a range of colours and usually have somewhat longer hind legs compared to most cats. The cats have been used as a symbol of the Isle of Man on coins and stamps; and at one time the Manx government operated a breeding centre to ensure the continuation of the breed.[197]  The Manx Loaghtan sheep is a breed native to the island. It has dark brown wool and four, or sometimes six, horns. The meat is considered to be a delicacy.[198] There are several flocks on the island and others have been started in England and Jersey.  A more recent arrival on the island is the red-necked wallaby, which is now established on the island following an escape from the Wildlife Park.[199] The local police report an increasing number of wallaby-related calls.[200]  There are also many feral goats in Garff, a matter which was raised in Tynwald Court in January 2018.[201]  In March 2016, the Isle of Man became the first entire territory to be adopted into UNESCO's Network of Biosphere Reserves.[202]  At the 2021 census,[5] the Isle of Man was home to 84,069 people, of whom 26,677 resided in the island's capital, Douglas. The population increased by 755 persons between the 2016 and 2021 censuses.  The Isle of Man Full Census, last held in 2021,[5] has been a decennial occurrence since 1821, with interim censuses being introduced from 1966. It is separate from, but similar to, the Census in the United Kingdom. "},{"title":"County football association","content":"  The county football associations are the local governing bodies of association football in England and the Crown dependencies. County FAs exist to govern all aspects of football in England. They are responsible for administering club and player registration as well as promoting development amongst those bodies and referees.  There are currently 50 county FAs. Most county FAs align roughly along historic county boundaries, although some cover more than one county, and some of the major cities, particularly those with a strong football tradition, have their own FAs.[1] The Sheffield FA was the first to be created, in 1867. Additionally, the three branches of the British Armed Forces, as well as the Amateur Football Alliance, which has a strong presence in the south-east of England, are listed as having their own County FAs not corresponding to geography.[2][3]  County football associations host 'county cups' \u2013 knockout cup competitions held at a sub-regional level, which are open to affiliated members of the county FA. Typically, county FAs will host cup competitions at the following levels: senior, intermediate, junior, women's, veterans, senior Sunday football, intermediate Sunday football and junior Sunday football.  There are an additional five recognised bodies that have representation on the FA Council on the same level as County FAs.[3] "},{"title":"FIFA","content":"  The F\u00e9d\u00e9ration internationale de football association (French for 'International Association Football Federation';[3] abbreviated as FIFA and pronounced in English as \/\u02c8fi\u02d0f\u0259\/ FEE-f\u0259) is an international self-regulatory governing body of association football, beach soccer, and futsal. It was founded in 1904[4] to oversee international competition among the national associations of Belgium, Denmark, France, Germany, the Netherlands, Spain (represented by the Madrid Football Club), Sweden, and Switzerland. Headquartered in Z\u00fcrich, Switzerland, its membership now comprises 211 national associations. These national associations must also be members of one of the six regional confederations into which the world is divided: CAF (Africa), AFC (Asia and Australia), UEFA (Europe), CONCACAF (North & Central America and the Caribbean), OFC (Oceania), and CONMEBOL (South America).  FIFA outlines several objectives in its organizational statutes, including growing association football internationally, providing efforts to ensure it is accessible to everyone, and advocating for integrity and fair play.[5] It is responsible for the organization and promotion of association football's major international tournaments, notably the World Cup which commenced in 1930, and the Women's World Cup which began in 1991. Although FIFA does not solely set the laws of the game, that being the responsibility of the International Football Association Board of which FIFA is a member, it applies and enforces the rules across all FIFA competitions.[6] All FIFA tournaments generate revenue from sponsorships; in 2022, FIFA had revenues of over US $5.8\u00a0billion, ending the 2019\u20132022 cycle with a net positive of US$1.2\u00a0billion, and cash reserves of over US$3.9\u00a0billion.[7]  Reports by investigative journalists have linked FIFA leadership with corruption, bribery, and vote-rigging related to the election of FIFA president Sepp Blatter and the organization's decision to award the 2018 and 2022 World Cups to Russia and Qatar, respectively. These allegations led to the indictments of nine high-ranking FIFA officials and five corporate executives by the U.S. Department of Justice on charges including racketeering, wire fraud, and money laundering. On 27 May 2015, several of these officials were arrested by Swiss authorities, who launched a simultaneous but separate criminal investigation into how the organization awarded the 2018 and 2022 World Cups. Those among these officials who were also indicted in the U.S. are expected to be extradited to face charges there as well.[8][9][10]  Many officials were suspended by FIFA's ethics committee including Sepp Blatter[11] and Michel Platini.[12] In early 2017, reports became public about FIFA president Gianni Infantino attempting to prevent the re-elections[13] of both chairmen of the ethics committee, Cornel Borb\u00e9ly and Hans-Joachim Eckert, during the FIFA congress in May 2017.[14][15] On 9 May 2017, following Infantino's proposal,[16] FIFA Council decided not to renew the mandates of Borb\u00e9ly and Eckert.[16] Together with the chairmen, 11 of 13 committee members were removed. FIFA has been suspected of corruption regarding the Qatar 2022 FIFA World Cup.[17]  The need for a single body to oversee association football became increasingly apparent at the beginning of the 20th century with the increasing popularity of international fixtures. The F\u00e9d\u00e9ration Internationale de Football Association (FIFA) was founded in the rear of the headquarters of the Union des Soci\u00e9t\u00e9s Fran\u00e7aises de Sports Athl\u00e9tiques (USFSA) at the Rue Saint Honor\u00e9 229 in Paris on 21 May 1904.[18] The French name and acronym are universally adopted outside French-speaking countries. The founding members were the national associations of Belgium, Denmark, France, the Netherlands, Spain (represented by then-Real Madrid CF; the Royal Spanish Football Federation was not created until 1913), Sweden and Switzerland.  On the same day, the German Football Association (DFB) declared its intention to affiliate through a telegram.[1]  The first president of FIFA was Robert Gu\u00e9rin. Gu\u00e9rin was replaced in 1906 by Daniel Burley Woolfall from England, by then a member of the association. The first tournament FIFA staged, the association football competition for the 1908 Olympics in London was more successful than its Olympic predecessors, despite the presence of professional footballers, contrary to the founding principles of FIFA.[19][20][21][22]  Membership of FIFA expanded beyond Europe with the application of South Africa in 1909, Argentina in 1912, Canada and Chile in 1913, and the United States in 1914.[23]  The 1912 Spalding Athletic Library \"Official Guide\" includes information on the 1912 Olympics (scores and stories), AAFA, and FIFA. The 1912 FIFA President was Dan B Woolfall.[24] Daniel Burley Woolfall was president from 1906 to 1918.[25]  During World War I, with many players sent off to war and the possibility of travel for international fixtures severely limited, the organization's survival was in doubt. Post-war, following the death of Woolfall, the organization was run by Dutchman Carl Hirschmann. It was saved from extinction but at the cost of the withdrawal of the Home Nations (of the United Kingdom), who cited an unwillingness to participate in international competitions with their World War enemies. The Home Nations later resumed their membership. The FIFA collection is held by the National Football Museum at Urbis in Manchester, England.[26] The first World Cup was held in 1930 in Montevideo, Uruguay.[26]  The FIFA flag is blue, with the organization's wordmark logo in the middle. The current FIFA flag was first flown during the 2018 FIFA World Cup opening ceremony in Moscow, Russia.[27]  Akin to the UEFA Champions League, FIFA has adopted an anthem composed by the German composer Franz Lambert since the 1994 FIFA World Cup. It has been re-arranged and produced by Rob May and Simon Hill.[28][29] The FIFA Anthem is played at the beginning of official FIFA sanctioned matches and tournaments such as international friendlies, the FIFA World Cup, FIFA Women's World Cup, FIFA U-20 World Cup, FIFA U-17 World Cup, Football at the Summer Olympics, FIFA U-20 Women's World Cup, FIFA Women's U-17 World Cup, FIFA Futsal World Cup, FIFA Beach Soccer World Cup and FIFA Club World Cup.[30]  Since 2007, FIFA has also required most of its broadcast partners to use short sequences including the anthem at the beginning and end of FIFA event coverage and for break bumpers to help promote FIFA's sponsors. This emulates practices long used by international football events, such as the UEFA Champions League. Exceptions may be made for specific circumstances; for example, an original piece of African music was used for bumpers during the 2010 FIFA World Cup.[31]    Besides its worldwide institutions, there are six confederations recognized by FIFA which oversee the game in the different continents and regions of the world. National associations, and not the continental confederations, are members of FIFA. The continental confederations are provided for in FIFA's statutes, and membership of a union is a prerequisite to FIFA membership.  In total, FIFA recognizes 211 national associations and their associated men's national teams as well as 129 women's national teams; see the list of national football teams and their respective country codes. The number of FIFA member associations is higher than the number of UN member states as FIFA has admitted associations from 23 non-sovereign entities as members in their own right, such as the four Home Nations within the United Kingdom and the two special administrative regions of China: Hong Kong and Macau.  On 28 February 2022, FIFA suspended Russia from all competitions due to controversy surrounding Russia's invasion of Ukraine.[32]  FIFA can suspend countries due to numerous multifaceted issues. Common reasons include governance interference, corruption, and financial irregularities. Doping or the misappropriation of drugs is also a consideration for expulsion.  The FIFA Men's World Rankings are updated monthly and rank each team based on their performance in international competitions, qualifiers, and friendly matches. There is also a world ranking for women's football, amended on a quarterly schedule.  FIFA's headquarters is in Z\u00fcrich, and it is an association established under the law of Switzerland.  FIFA's supreme body is the FIFA Congress, an assembly of representatives from each affiliated member association. Each national football association has one vote, regardless of size or footballing strength. The Congress assembles in ordinary sessions once every year, and extraordinary sessions have been held once a year since 1998. Congress makes decisions relating to FIFA's governing statutes and their method of implementation and application. Only Congress can pass changes to FIFA's statutes. The congress approves the annual report and decides on the acceptance of new national associations, and holds elections. Congress elects the President of FIFA, its general secretary, and the other members of the FIFA Council in the year following the FIFA World Cup.[33]  FIFA Council \u2013 formerly called the FIFA Executive Committee and chaired by the president \u2013 is the organization's main decision-making body in the intervals of Congress. The council comprises 37 people: the president; 8 vice-presidents; and 28 members from the confederations, with at least one of them being a woman. The executive committee is the body that decides which country will host the World Cup.  The president and the general secretary are the main office holders of FIFA and are in charge of its daily administration, carried in by the general secretariat, with its staff of approximately 280 members. Gianni Infantino is the current president, elected on 26 February 2016 at an extraordinary FIFA Congress session after former president Sepp Blatter was suspended pending a corruption investigation.[34][35]  FIFA's worldwide organizational structure also consists of several other bodies under the authority of the FIFA Council or created by Congress as standing committees. Among those bodies are the FIFA Emergency Committee, the FIFA Ethics Committee, the Finance Committee, the Disciplinary Committee, and the Referees Committee.  The FIFA Emergency Committee deals with all matters requiring immediate settlement in the time frame between the regular meetings of the FIFA Council.[36][37] The Emergency Committee consists of the FIFA president as well as one member from each confederation.[38] Emergency Committee decisions made are immediately put into legal effect, although they need to be ratified at the next Executive Committee meeting.[39]  FIFA publishes its results according to International Financial Reporting Standards. The total compensation for the management committee in 2011 was 30 million for 35 people. Blatter, the only full-time person on the committee, earned approximately two million Swiss francs, 1.2 million in salary, and the rest in bonuses.[40][41][42] A report in London's The Sunday Times in June 2014 said the members of the committee had their salaries doubled from $100,000 to $200,000 during the year. The report also said leaked documents had indicated $4.4 million in secret bonuses had been paid to the committee members following the 2010 FIFA World Cup in South Africa.[43]  The laws that govern football known officially as the Laws of the Game, are not solely the responsibility of FIFA; they are maintained by a body called the International Football Association Board (IFAB). FIFA has members on its board (four representatives); the other four are provided by the football associations of the United Kingdom: England, Scotland, Wales, and Northern Ireland, who jointly established IFAB in 1882 and are recognized for the creation and history of the game. Changes to the Laws of the Game must be agreed upon by at least six delegates.  The FIFA Statutes form the overarching document guiding FIFA's governing system. The governing system is divided into separate bodies with the appropriate powers to create a system of checks and balances. It consists of four general bodies: the Congress, the executive committee, the general Secretariat, and standing and ad hoc committees.[44]  FIFA frequently takes active roles in the running of the sport and developing the game around the world. One of its sanctions is to suspend teams and associated members from international competition when a government interferes in the running of FIFA's associate member organizations or if the associate is not functioning correctly.  A 2007 FIFA ruling that a player can be registered with a maximum of three clubs and appear in official matches for a maximum of two in a year measured from 1 July to 30 June has led to controversy, especially in those countries whose seasons cross that date barrier, as in the case of two former Ireland internationals. As a direct result of this controversy, FIFA modified this ruling the following year to accommodate transfers between leagues with out-of-phase seasons.  FIFA now permits the use of video evidence during matches, as well as for subsequent sanctions. However, for most of FIFA's history it stood opposed to its use.[45] The 1970 meeting of the International Football Association Board \"agreed to request the television authorities to refrain from any slow-motion play-back which reflected, or might reflect, adversely on any decision of the referee\".[46] As recently as 2008 FIFA president Sepp Blatter said: \"Let it be as it is and let's leave [football] with errors. The television companies will have the right to say [the referee] was right or wrong, but still, the referee makes the decision \u2013 a man, not a machine.\"[47] This stance was finally overturned on 3 March 2018, when the IFAB wrote video assistant referees (also known as VARs) into the Laws of the Game permanently.[48] Their use remains optional for competitions.  In early July 2012 FIFA sanctioned the use of goal-line technology, subject to rules specified by the International Football Association Board (IFAB), who had officially approved its use by amending the Laws of the Game to permit (but not require) its use.[49][50] This followed a high-profile incident during a second-round game in the 2010 FIFA World Cup between England and Germany, where a shot by Englishman Frank Lampard, which would have levelled the scores at 2\u20132 in a match that ultimately ended in a 4\u20131 German victory, crossed the line but was not seen to do so by the match officials, which led FIFA officials to declare that they would re-examine the use of goal-line technology.[51]  On 28 February 2022, due to the 2022 Russian invasion of Ukraine and by a recommendation by the International Olympic Committee (IOC), FIFA suspended the participation of Russia.[52][53]  The Russian Football Union unsuccessfully appealed the FIFA ban to the Court of Arbitration for Sport, which upheld the ban.[54] Some observers, while approving of the boycott of Russia, have pointed out that FIFA did not boycott Saddam Hussein's Iraq as an aggressor during the Iran\u2013Iraq War,[55] Saudi Arabia for its military intervention in Yemen,[56] Qatar for its human rights violations,[57][58] or the United States for the actions of the U.S. military during the Iraq War.[59] However, this full ban was partially lifted in October 2023 when it was decided that their men's and women's U-17 teams were allowed to return to international competitions.   FIFA previously banned Indonesia due to government intervention within the team. FIFA requires members to play \"with no influence from third parties\".[60]  FIFA holds an annual awards ceremony, The Best FIFA Football Awards since 2016, which recognizes both individual and team achievements in international association football. Individually, the top men's player is awarded The Best FIFA Men's Player, and the top women's player is The Best FIFA Women's Player. Other prominent awards are The Best FIFA Football Coach and FIFA FIFPro World11.  In 2000, FIFA presented two awards, FIFA Club of the Century and FIFA Player of the Century, to decide the greatest football club and player of the 20th century. Real Madrid was the club winner, while Diego Maradona and Pel\u00e9 were the joint player's winners.  Men's  Women's  Men's  Women's  Individual  Team    (Paulo Henrique Chaves)(Pedro Henrique Soares)(Paulo Neto)  (Levi de Weerd)(Manuel Bachoore)(Emre Yilmaz)  The following table has the Top 20 ranked men's football countries worldwide.[71]  The following table has the Top 20 ranked women's football countries in the world.[73]    In April 2022 FIFA launched FIFA+,[82] an OTT service providing up to 40,000 live matches per year, including 11,000 women's matches.[83] It was also confirmed that FIFA would make available archival content, including every FIFA World Cup and FIFA Women's World Cup match recorded on camera,[84] together with original documentary content.[85] Eleven Sports was later reported to be responsible for populating the FIFA+ platform with live matches.[86]  FIFA+ showed the 2023 FIFA Women's World Cup live in selected regions such as Japan, Brazil, Indonesia, and Thailand.[87]  FIFA+ have the rights to competitions in Oceania including the OFC Champions League and the OFC Women's Olympic Qualifying Tournament.[88][89][90] They also have rights to the New Zealand domestic competitions and national teams.[91][92]  2021-23 Members:  In May 2006, British investigative reporter Andrew Jennings' book Foul! The Secret World of FIFA: Bribes, Vote-Rigging, and Ticket Scandals (HarperCollins) caused controversy within the football world by detailing an alleged international cash-for-contracts scandal following the collapse of FIFA's marketing partner International Sport and Leisure (ISL) and revealed how some football officials had been urged to secretly repay the sweeteners they received. The book also alleged that vote-rigging had occurred in the fight for Sepp Blatter's continued control of FIFA as the organization's president. Shortly after the release of Foul! a BBC Panorama expos\u00e9 by Jennings and BBC producer Roger Corke, screened on 11 June 2006, reported that Blatter was being investigated by Swiss police over his role in a secret deal to repay more than \u00a31m worth of bribes pocketed by football officials. Lord Triesman, the former chairman of the English Football Association, described FIFA as an organization that \"behaves like a mafia family,\" highlighting the organization's \"decades-long traditions of bribes, bungs, and corruption\".[96]  All testimonies offered in the Panorama expos\u00e9 were provided through a disguised voice, appearance, or both, save one: Mel Brennan, a former CONCACAF official, became the first high-level football insider to go public with substantial allegations of corruption, nonfeasance, and malfeasance by CONCACAF and FIFA leadership. Brennan\u2014the highest-level African-American in the history of world football governance\u2014joined Jennings, Trinidadian journalist Lisana Liburd, and many others in exposing allegedly inappropriate allocations of money by CONCACAF and drew connections between ostensible CONCACAF criminality and similar behaviours at FIFA. Since then, and in the light of fresh allegations of corruption by FIFA in late 2010,[97] both Jennings and Brennan remain highly critical of FIFA. Brennan has called directly for an alternative to FIFA to be considered by the stakeholders of the sport worldwide.[98]  In a further Panorama expos\u00e9 broadcast on 29 November 2010, Jennings alleged that three senior FIFA officials, Nicolas Leoz, Issa Hayatou and Ricardo Teixeira, had been paid huge bribes by ISL between 1989 and 1999, which FIFA had failed to investigate. Jennings claimed they appeared on a list of 175 bribes paid by ISL, totalling about $100 million. A former ISL executive said there were suspicions within the company that they were only awarded the marketing contract for successive World Cups by paying bribes to FIFA officials. The program also alleged that another current official, Jack Warner, has been repeatedly involved in reselling World Cup tickets to touts; Blatter said that FIFA had not investigated the allegation because it had not been told about it via 'official channels.'  Panorama also alleged that FIFA requires nations bidding to host the World Cup to agree to implement special laws, including a blanket tax exemption for FIFA and its corporate sponsors and limitation of workers rights. Contrary to FIFA's demands, these conditions were revealed by the Dutch government, resulting in them being told by FIFA that their bid could be adversely affected. Following Jennings' earlier investigations, he was banned from all FIFA press conferences for reasons he claimed had not been made clear. The accused officials failed to answer questions about his latest allegations verbally or by letter.  Prime Minister David Cameron and Andy Anson, head of England's World Cup bid, criticized the timing of the broadcast three days before FIFA decided on the host for the 2018 FIFA World Cup, because it might damage England's bid; the voters included officials accused by the program.[99][100]  In June 2011, it came to light that the International Olympic Committee had started inquiry proceedings against FIFA honorary president Jo\u00e3o Havelange into claims of bribery. Panorama alleged that Havelange accepted a $1\u00a0million 'bung' in 1997 from ISL. The IOC stated that it \"takes all allegations of corruption very seriously, and we would always ask for any evidence of wrongdoing involving any IOC members to be passed to our ethics commission\".[101]  In a 2014 interview, American sportswriter Dave Zirin said that corruption is endemic to FIFA leadership and that the organization should be abolished for the game's good. He said that currently, FIFA is in charge of both monitoring corruption in association football matches and marketing and selling the sport, but that two \"separate\" organizational bodies are needed: an organizational body that monitors corruption and match-fixing and the like and an organization that's responsible for marketing and sponsorships and selling the sport. Zirin said the idea of having a single organization responsible for both seems highly ineffective and detrimental to the sport.[102]  In May 2015, 14 people were arrested, including nine FIFA officials, after being accused of corruption.[103]  In the 2022 World Cup bid, Qatar was honoured to host the World Cup.  Since then it has been discovered that Qatar paid as much as 200 billion dollars to host the World Cup. This information was discovered by the Tass news agency in Russia.[104]  Between 2013 and 2015 four individuals, and two sports television rights corporations pleaded guilty to United States financial misconduct charges. The pleas of Chuck Blazer, Jos\u00e9 Hawilla, Daryan Warner, Darrell Warner, Traffic Group and Traffic Sports USA were unsealed in May 2015.[9] In another 2015 case, Singapore also imposed a 6-year \"harshest sentence ever received for match-fixing\" on match-fixer Eric Ding who had bribed three Lebanese FIFA football officials with prostitutes as an inducement to fix future matches that they would officiate, as well as perverting the course of justice.[105]  Fourteen FIFA officials and marketing executives were indicted by the United States Department of Justice in May 2015. The officials were arrested in Switzerland and are in the process of extradition to the US. Specific charges (brought under the RICO act) include wire fraud, racketeering, and money laundering.[106]  \"Swiss authorities say they have also opened a separate criminal investigation into FIFA's operations pertaining to the 2018 and 2022 World Cup bids\".[107]  FIFA's top officials were arrested at a hotel in Switzerland on suspicion of receiving bribes totalling $100m (\u00a365m). The US Department of Justice stated that nine FIFA officials and four executives of sports management companies were arrested and accused of over $150m in bribes.[108] The UK Shadow Home Secretary and Labour Member of Parliament, Andy Burnham, stated in May 2015 that England should boycott the 2018 World Cup against corruption in FIFA and military aggression by Russia.[109]  FIFA's choice to award the 2018 World Cup to Russia and the 2022 World Cup to Qatar has been widely criticized by media.[110][111][112][113] It has been alleged that some FIFA inside sources insist that the Russian kickbacks of cash and gifts given to FIFA executive members were enough to secure the Russian 2018 bid weeks before the result was announced.[114] Sepp Blatter was widely criticized in the media for giving a warning about the \"evils of the media\" in a speech to FIFA executive committee members shortly before they voted on the hosting of the 2018 World Cup, a reference to The Sunday Times expos\u00e9s,[115] and the Panorama investigation.[116]  Two members of FIFA's executive committee were banned from all football-related activity in November 2010 for allegedly offering to sell their votes to undercover newspaper reporters. In early May 2011, a British parliamentary inquiry into why England failed to secure the 2018 finals was told by a member of parliament, Damian Collins, that there was evidence from The Sunday Times newspaper that Issa Hayatou of Cameroon and Jacques Anouma of Ivory Coast were paid by Qatar. Qatar has categorically denied the allegations, as have Hayatou and Anouma.[117]  FIFA president Blatter said, as of 23\u00a0May\u00a02011[update], that the British newspaper The Sunday Times has agreed to bring its whistle-blowing source to meet senior FIFA officials, who will decide whether to order a new investigation into alleged World Cup bidding corruption. \"[The Sunday Times] are happy, they agreed that they will bring this whistleblower here to Z\u00fcrich and then we will have a discussion, an investigation of this\", Blatter said.  Specifically, the whistle-blower claims that FIFA executive committee members Issa Hayatou and Jacques Anouma were paid $1.5\u00a0million to vote for Qatar.[118][119] The emirate's bid beat the United States in a final round of voting last December. Blatter did not rule out reopening the 2022 vote if corruption could be proved, but urged taking the matter \"step by step\". The FIFA president said his organization is \"anxiously awaiting\" more evidence before asking its ethics committee to examine allegations made in Britain's Parliament in early May 2011.  Hayatou, who is from Cameroon, leads the Confederation of African Football and is a FIFA vice-president. Anouma is president of Ivorian Football Federation. The whistle-blower said Qatar agreed to pay a third African voter, Amos Adamu, for his support. The Nigerian was later suspended from voting after a FIFA ethics court ruled he solicited bribes from undercover Sunday Times reporters posing as lobbyists. Blatter said the newspaper and its whistle-blower would meet with FIFA secretary general, J\u00e9r\u00f4me Valcke, and legal director, Marco Villiger.  Allegations against FIFA officials have also been made to the UK Parliament by David Triesman, the former head of England's bid and the English Football Association. Triesman told the lawmakers that four long-standing FIFA executive committee members\u2014Jack Warner, Nicol\u00e1s Leoz, Ricardo Teixeira and Worawi Makudi\u2014engaged in \"improper and unethical\" conduct in the 2018 bidding, which was won by Russia. All six FIFA voters have denied wrongdoing.[120]  On 28 September 2015, Sepp Blatter suggested that the 2018 World Cup being awarded to Russia was planned before the voting, and that the 2022 World Cup would have then been awarded to the United States. However, this plan changed after the election ballot, and the 2022 World Cup was awarded to Qatar instead of the U.S.[121][122]  According to leaked documents seen by The Sunday Times, Qatari state-run television channel Al Jazeera secretly offered $400\u00a0million to FIFA, for broadcasting rights, just 21 days before FIFA announced that Qatar would hold the 2022 World Cup.[123][124]  On 17 July 2012, in the wake of announced anti-corruption reforms by Sepp Blatter, the president of the FIFA,[125] the organization appointed U.S. lawyer Michael J. Garcia as the chairman of the investigative chamber of FIFA Ethics Committee, while German judge Hans-Joachim Eckert was appointed as the chairman of the Ethics Committee's adjudication chamber.[126]  In August 2012, Garcia declared his intention to investigate the bidding process and decision to respectively award the right to host the 2018 and 2022 FIFA World Cup to Russia and Qatar by the FIFA Executive Committee.[127] Garcia delivered his subsequent 350-page report in September 2014, and Eckert then announced that it would not be made public for legal reasons.[128]  On 13 November 2014, Eckert released a 42-page summary of his findings after reviewing Garcia's report. The summary cleared both Russia and Qatar of any wrongdoing during the bidding for the 2018 and 2022 World Cups,[129] leaving Russia and Qatar free to stage their respective World Cups.[130]  FIFA welcomed \"the fact that a degree of closure has been reached\", while the Associated Press wrote that the Eckert summary \"was denounced by critics as a whitewash\".[130] Hours after the Eckert summary was released, Garcia himself criticized it for being \"materially incomplete\" with \"erroneous representations of the facts and conclusions\", while declaring his intention to appeal to FIFA's Appeal Committee.[129] On 16 December 2014, FIFA's Appeal Committee dismissed Garcia's appeal against the Eckert summary as \"not admissible\". FIFA also stated that Eckert's summary was \"neither legally binding nor appealable\".[131] A day later, Garcia resigned from his role as FIFA ethics investigator in protest of FIFA's conduct, citing a \"lack of leadership\" and lost confidence in the independence of Eckert from FIFA.[132] In June 2015, Swiss authorities claimed the report was of \"little value\".[133]  In November 2022, the FIFA officials told players not to get involved in politics but focus on sports when they are in Qatar.[134] A few weeks earlier, the football associations and players of Denmark and Australia criticized Qatar for this.[135][136]  FIFA announced on 25 May 2011 that it had opened the investigation to examine the conduct of four officials\u2014Mohamed Bin Hammam and Jack Warner, along with Caribbean Football Union (CFU) officials Debbie Minguell and Jason Sylvester\u2014in relation to claims made by executive committee member, Chuck Blazer.[137][138][139] Blazer, who was at the time, the general secretary of the CONCACAF confederation, has alleged that violations were committed under the FIFA code of ethics during a meeting organized by Bin Hammam and Warner on 10 and 11 May\u2014the same time Lord Triesman had accused Warner of demanding money for a World Cup 2018 vote\u2014in relation to the 2011 FIFA presidential election,[140] in which Bin Hammam, who also played a key role in the Qatar 2022 FIFA World Cup bid, allegedly offered financial incentives for votes cast in his favour during the presidential election.  As a result of the investigation both Bin Hammam and Warner were suspended.[141] Warner reacted to his suspension by questioning Blatter's conduct and adding that FIFA secretary general, J\u00e9r\u00f4me Valcke, had told him via e-mail that Qatar had bought the 2022 World Cup.[142][143] Valcke subsequently issued a statement denying he had suggested it was bribery, saying instead that the country had \"used its financial muscle to lobby for support\". Qatar officials denied any impropriety.[144] Bin Hammam also responded by writing to FIFA, protesting unfair treatment in suspension by the FIFA Ethics Committee and FIFA administration.[145]  Further evidence emerged of alleged corruption. On 30 May 2011, Fred Lunn, vice-president of the Bahamas Football Association, said that he was given $40,000 in cash[146] as an incitement to vote for FIFA presidential candidate, Mohamed bin Hammam. In addition, on 11 June 2011 Louis Giskus, president of the Surinamese Football Association, alleged that he was given $40,000 in cash for \"development projects\" as an incentive to vote for Bin Hammam.[147]  After being re-elected as president of FIFA, Sepp Blatter responded to the allegations by promising to reform FIFA in wake of the bribery scandal, with Danny Jordaan, CEO of the 2010 FIFA World Cup in South Africa, saying there is great expectation for reform.[148] Former US Secretary of State Henry Kissinger is being tipped for a role on the newly proposed 'Solutions Committee', and former Netherlands national football team player Johan Cruyff was also being linked with a role.[143][149]  UEFA secretary-general Gianni Infantino said he hopes for \"concrete\" measures to be taken by the world game's authority. Saying that \"the UEFA executive committee has taken note of the will of FIFA to take concrete and effective measures for good governance ... [and is] following the situation closely.\"[150]  IOC president Jacques Rogge commented on the situation by saying that he believes FIFA \"can emerge stronger\" from its worst-ever crisis, stating that \"I will not point a finger and lecture ... I am sure FIFA can emerge stronger and from within\".[151]  Several of FIFA's partners and sponsors have raised concerns about the allegations of corruption, including Coca-Cola, Adidas, Emirates and Visa.[152][153][154] Coca-Cola raised concerns by saying \"the current allegations being raised are distressing and bad for the sport\"; with Adidas saying \"the negative tenor of the public debate around Fifa at the moment is neither good for football nor for Fifa and its partners\"; moreover Emirates raised its concerns by saying \"we hope that these issues will be resolved as soon as possible\"; and Visa adding \"the current situation is clearly not good for the game and we ask that Fifa take all necessary steps to resolve the concerns that have been raised.\"[152]  Australian Sports Minister Mark Arbib said it was clear FIFA needed to change, saying \"there is no doubt there needs to be reform of FIFA. This is something that we're hearing worldwide\", with Australian Senator Nick Xenophon accusing FIFA of \"scamming\" the country out of the A$46\u00a0million (US$35\u00a0million) it spent on the Australia 2022 FIFA World Cup bid, saying that \"until the investigation into FIFA has been completed, Australia must hold off spending any more taxpayers' money on any future World Cup bids.\"[155]  Theo Zwanziger, president of the German Football Association, also called on FIFA to re-examine the awarding of the 2022 World Cup to Qatar.[156]  Transparency International, which had called on FIFA to postpone the election pending a full independent investigation, renewed its call on FIFA to change its governance structure.[157]  Moreover, former Argentine football player Diego Maradona was critical of FIFA in light of the corruption scandal, comparing members of the board to dinosaurs. He said \"Fifa is a big museum. They are dinosaurs who do not want to relinquish power. It's always going to be the same.\"[158] In October 2011, Dick Pound criticized the organization, saying, \"FIFA has fallen far short of a credible demonstration that it recognizes the many problems it faces, that it has the will to solve them, that it is willing to be transparent about what it is doing and what it finds, and that its conduct in the future will be such that the public can be confident in the governance of the sport.\"[159]  In 2018, FIFA revised its code of ethics to remove corruption as one of the enumerated bases of ethical violations.[160] It retained bribery, misappropriation of funds and manipulation of competitions as offences, but added a statute of limitation clause that those offences could not be pursued after a ten-year period.[160]  The revision also made it an offence to make public statements of a defamatory nature against FIFA.[160] Alexandra Wrage, a former member of the FIFA governance committee and an expert in anti-bribery compliance, said that of the revision that \"the real value to FIFA is the chilling effect this will have on critics\".[160] "},{"title":"Poly(methyl methacrylate)","content":"Poly(methyl methacrylate) (PMMA) is the synthetic polymer derived from methyl methacrylate. It is used as an engineering plastic, and it is a transparent thermoplastic. PMMA is also known as acrylic, acrylic glass, as well as by the trade names and brands Crylux, Hesalite, Plexiglas, Acrylite, Lucite, and Perspex, among several others (see below). This plastic is often used in sheet form as a lightweight or shatter-resistant alternative to glass. It can also be used as a casting resin, in inks and coatings, and for many other purposes.  It is often technically classified as a type of glass, in that it is a non-crystalline vitreous substance\u2014hence its occasional historic designation as acrylic glass.  The first acrylic acid was created in 1843. Methacrylic acid, derived from acrylic acid, was formulated in 1865. The reaction between methacrylic acid and methanol results in the ester methyl methacrylate.   It was developed in 1928[4] in several different laboratories by many chemists, such as William R. Conn, Otto R\u00f6hm, and Walter Bauer, and first brought to market in 1933 by German R\u00f6hm & Haas AG (as of January 2019, part of Evonik Industries) and its partner and former U.S. affiliate Rohm and Haas Company under the trademark Plexiglas.[5]  Polymethyl methacrylate was discovered in the early 1930s by British chemists Rowland Hill and John Crawford at Imperial Chemical Industries (ICI) in the United Kingdom. [citation needed] ICI registered the product under the trademark Perspex. About the same time, chemist and industrialist Otto R\u00f6hm of R\u00f6hm and Haas AG in Germany attempted to produce safety glass by polymerizing methyl methacrylate between two layers of glass. The polymer separated from the glass as a clear plastic sheet, which R\u00f6hm gave the trademarked name Plexiglas in 1933.[6] Both Perspex and Plexiglas were commercialized in the late 1930s. In the United States, E.I. du Pont de Nemours & Company (now DuPont Company) subsequently introduced its own product under the trademark Lucite. In 1936 ICI Acrylics (now Lucite International) began the first commercially viable production of acrylic safety glass. During World War II both Allied and Axis forces used acrylic glass for submarine periscopes and aircraft windscreen, canopies, and gun turrets.[7] Civilian applications followed after the war.[8]  Common orthographic stylings include polymethyl methacrylate[9][10] and polymethylmethacrylate. The full IUPAC chemical name is poly(methyl 2-methylpropenoate). (It is a common mistake to use \"an\" instead of \"en\".)  Although PMMA is often called simply \"acrylic\", acrylic can also refer to other polymers or copolymers containing polyacrylonitrile. Notable trade names and brands include Acrylite,[11] Altuglas,[12] Astariglas,[13] Cho Chen,[14] Crystallite, Cyrolite,[15] Hesalite (when used in Omega watches), Lucite,[16] Optix,[15] Oroglas,[17] PerClax, Perspex,[15] Plexiglas,[15][18] R-Cast,[19] and Sumipex.   PMMA is an economical alternative to polycarbonate (PC) when tensile strength, flexural strength, transparency, polishability, and UV tolerance are more important than impact strength, chemical resistance, and heat resistance.[20] Additionally, PMMA does not contain the potentially harmful bisphenol-A subunits found in polycarbonate and is a far better choice for laser cutting.[21] It is often preferred because of its moderate properties, easy handling and processing, and low cost. Non-modified PMMA behaves in a brittle manner when under load, especially under an impact force, and is more prone to scratching than conventional inorganic glass, but modified PMMA is sometimes able to achieve high scratch and impact resistance.  PMMA is a strong, tough, and lightweight material. It has a density of 1.17\u20131.20\u00a0g\/cm3,[1][22] which is less than half that of glass.[1] It also has good impact strength, higher than both glass and polystyrene, but significantly lower than polycarbonate and some engineered polymers. PMMA ignites at 460\u00a0\u00b0C (860\u00a0\u00b0F) and burns, forming carbon dioxide, water, carbon monoxide, and low-molecular-weight compounds, including formaldehyde.[23]  PMMA transmits up to 92% of visible light (3\u00a0mm thickness), and gives a reflection of about 4% from each of its surfaces due to its refractive index (1.4905 at 589.3\u00a0nm).[3] It filters ultraviolet (UV) light at wavelengths below about 300 nm (similar to ordinary window glass). Some manufacturers[24] add coatings or additives to PMMA to improve absorption in the 300\u2013400\u00a0nm range. PMMA passes infrared light of up to 2,800\u00a0nm and blocks IR of longer wavelengths up to 25,000\u00a0nm. Colored PMMA varieties allow specific IR wavelengths to pass while blocking visible light (for remote control or heat sensor applications, for example).  PMMA swells and dissolves in many organic solvents; it also has poor resistance to many other chemicals due to its easily hydrolyzed ester groups. Nevertheless, its environmental stability is superior to most other plastics such as polystyrene and polyethylene, and therefore it is often the material of choice for outdoor applications.[25]  PMMA has a maximum water absorption ratio of 0.3\u20130.4% by weight.[22] Tensile strength decreases with increased water absorption.[26] Its coefficient of thermal expansion is relatively high at (5\u201310)\u00d710\u22125\u00a0\u00b0C\u22121.[27]  The Futuro house was made of fibreglass-reinforced polyester plastic, polyester-polyurethane, and poly(methylmethacrylate); one of them was found to be degrading by cyanobacteria and Archaea.[28][29]  PMMA can be joined using cyanoacrylate cement (commonly known as superglue), with heat (welding), or by using chlorinated solvents such as dichloromethane or trichloromethane[30] (chloroform) to dissolve the plastic at the joint, which then fuses and sets, forming an almost invisible weld. Scratches may easily be removed by polishing or by heating the surface of the material. Laser cutting may be used to form intricate designs from PMMA sheets. PMMA vaporizes to gaseous compounds (including its monomers) upon laser cutting, so a very clean cut is made, and cutting is performed very easily. However, the pulsed lasercutting introduces high internal stresses, which on exposure to solvents produce undesirable \"stress-crazing\" at the cut edge and several millimetres deep. Even ammonium-based glass-cleaner and almost everything short of soap-and-water produces similar undesirable crazing, sometimes over the entire surface of the cut parts, at great distances from the stressed edge.[31] Annealing the PMMA sheet\/parts is therefore an obligatory post-processing step when intending to chemically bond lasercut parts together.  In the majority of applications, it will not shatter. Rather, it breaks into large dull pieces. Since PMMA is softer and more easily scratched than glass, scratch-resistant coatings are often added to PMMA sheets to protect it (as well as possible other functions).  Pure poly(methyl methacrylate) homopolymer is rarely sold as an end product, since it is not optimized for most applications. Rather, modified formulations with varying amounts of other comonomers, additives, and fillers are created for uses where specific properties are required. For example,  PMMA is routinely produced by emulsion polymerization, solution polymerization, and bulk polymerization. Generally, radical initiation is used (including living polymerization methods), but anionic polymerization of PMMA can also be performed.[33]  The glass transition temperature (Tg) of atactic PMMA is 105\u00a0\u00b0C (221\u00a0\u00b0F).  The Tg values of commercial grades of PMMA range from 85 to 165\u00a0\u00b0C (185 to 329\u00a0\u00b0F); the range is so wide because of the vast number of commercial compositions that are copolymers with co-monomers other than methyl methacrylate.  PMMA is thus an organic glass at room temperature; i.e., it is below its Tg.  The forming temperature starts at the glass transition temperature and goes up from there.[34]  All common molding processes may be used, including injection molding, compression molding, and extrusion.  The highest quality PMMA sheets are produced by cell casting, but in this case, the polymerization and molding steps occur concurrently.  The strength of the material is higher than molding grades owing to its extremely high molecular mass. Rubber toughening has been used to increase the toughness of PMMA to overcome its brittle behavior in response to applied loads.  Being transparent and durable, PMMA is a versatile material and has been used in a wide range of fields and applications such as rear-lights and instrument clusters for vehicles, appliances, and lenses for glasses. PMMA in the form of sheets affords to shatter resistant panels for building windows, skylights, bulletproof security barriers, signs & displays, sanitary ware (bathtubs), LCD screens, furniture and many other applications.  It is also used for coating polymers based on MMA provides outstanding stability against environmental conditions with reduced emission of VOC.  Methacrylate polymers are used extensively in medical and dental applications where purity and stability are critical to performance.[33]  In particular, acrylic-type lenses are useful for cataract surgery in patients that have recurrent ocular inflammation (uveitis), as acrylic material induces less inflammation.  Due to its aforementioned biocompatibility, poly(methyl methacrylate) is a commonly used material in modern dentistry, particularly in the fabrication of dental prosthetics, artificial teeth, and orthodontic appliances.  Methyl methacrylate \"synthetic resin\" for casting (simply the bulk liquid chemical) may be used in conjunction with a polymerization catalyst such as methyl ethyl ketone peroxide (MEKP), to produce hardened transparent PMMA in any shape, from a mold. Objects like insects or coins, or even dangerous chemicals in breakable quartz ampules, may be embedded in such \"cast\" blocks, for display and safe handling. "},{"title":"England national football team","content":"  The England national football team have represented England in international football since the first international match in 1872. It is controlled by The Football Association (FA), the governing body for football in England, which is affiliated with UEFA and comes under the global jurisdiction of world football's governing body FIFA.[3][4] England competes in the three major international tournament contested by European nations: the FIFA World Cup, the UEFA European Championship and the UEFA Nations League.  England is the joint oldest national team in football having played in the world's first international football match in 1872, against Scotland. England's home ground is Wembley Stadium, London, and its training headquarters is at St George's Park, Burton upon Trent. Gareth Southgate is the current manager of the team.  England won the 1966 World Cup final on home soil, making it one of eight nations to have won the World Cup. They have qualified for the World Cup sixteen times, with their next best performance fourth-place finishes in the 1990 and 2018 editions. England has never won the European Championship, with their best performance to date being runners-up in 2020. As a constituent country of the United Kingdom, England is not a member of the International Olympic Committee and so does not compete at the Olympic Games. England is currently the only team to have won the World Cup at senior level, but not their major continental title, and the only non-sovereign entity to have won the World Cup.  The England men's national football team is the joint-oldest in the world; it was formed at the same time as Scotland. A representative match between England and Scotland was played on 5 March 1870, having been organised by the Football Association.[5] A return fixture was organised by representatives of Scottish football teams on 30 November 1872. This match, played at Hamilton Crescent in Scotland, is viewed as the first official international football match, because the two teams were independently selected and operated, rather than being the work of a single football association.[6] Over the next 40 years, England played exclusively with the other three Home Nations\u2014Scotland, Wales and Ireland\u2014in the British Home Championship.  At first, England had no permanent home stadium. They joined FIFA in 1906 and played their first games against countries other than the Home Nations on a tour of Central Europe in 1908.[7] Wembley Stadium was opened in 1923 and became their home ground.[7] The relationship between England and FIFA became strained, and this resulted in their departure from FIFA in 1928, before they rejoined in 1946.[8] As a result, they did not compete in a World Cup until 1950, in which they were beaten in a 1\u20130 defeat by the United States, failing to get past the first round in one of the most embarrassing defeats in the team's history.[9]  Their first defeat on home soil to a foreign team was a 2\u20130 loss to Ireland, on 21 September 1949 at Goodison Park.[10] A 6\u20133 loss in 1953 to Hungary, was their second defeat by a foreign team at Wembley.[11] In the return match in Budapest, Hungary won 7\u20131. This stands as England's largest ever defeat. After the game, a bewildered Syd Owen said, \"it was like playing men from outer space\".[12] In the 1954 FIFA World Cup, England reached the quarter-finals for the first time, and lost 4\u20132 to reigning champions Uruguay.[13]  Although Walter Winterbottom was appointed as England's first full-time manager in 1946, the team was still picked by a committee until Alf Ramsey took over in 1963.[14][15] The 1966 FIFA World Cup was hosted in England and Ramsey guided England to victory with a 4\u20132 win against West Germany after extra time in the final, during which Geoff Hurst scored a hat-trick.[16] In UEFA Euro 1968, the team reached the semi-finals for the first time, being eliminated by Yugoslavia.[17]  England qualified automatically for the 1970 World Cup in Mexico as reigning champions, and reached the quarter-finals, where they were knocked out by West Germany. England had been 2\u20130 up, but were eventually beaten 3\u20132 after extra time.[18] They then failed to qualify for the 1974 World Cup, leading to Ramsey's dismissal by the FA.[19]  Following Ramsey's dismissal, Joe Mercer took immediate temporary charge of England for a seven-match spell until Don Revie was appointed as new permanent manager in 1974.[20] Under Revie, the team underperformed and failed to qualify for either UEFA Euro 1976 or the 1978 World Cup.[21] Revie resigned in 1977 and was replaced by Ron Greenwood, under whom performances improved. The team qualified for Euro 1980 without losing any of their games, but exited in the group stage of the final tournament.[22] They also qualified for the 1982 World Cup in Spain; despite not losing a game, they were eliminated at the second group stage.[23][24]  Bobby Robson managed England from 1982 to 1990.[25] Although the team failed to qualify for UEFA Euro 1984, they reached the quarter-finals of the 1986 World Cup, losing 2\u20131 to Argentina in a game made famous by two highly contrasting goals scored by Diego Maradona \u2013 the first being blatantly knocked in by his hand, prompting his \"Hand of God\" remark, the second being an outstandingly skilful individual goal, involving high speed dribbling past several opponents.[26][27] England striker Gary Lineker finished as the tournament's top scorer with six goals.[28]  England went on to lose every match at UEFA Euro 1988.[29] They next achieved their second best result in the 1990 FIFA World Cup by finishing fourth\u00a0\u2013 losing again to West Germany after a closely contested semi-final finishing 1\u20131 after extra time, then 3\u20134 in England's first penalty shoot-out.[30] Despite losing to Italy in the third place play-off, the members of the England team were given bronze medals identical to the Italians'. Due to the team's good performance at the tournament against general expectations, and the emotional nature of the narrow defeat to West Germany,[31] the team were welcomed home as heroes and thousands of people lined the streets for an open-top bus parade.[32]  The 1990s saw four England managers follow Robson, each in the role for a relatively brief period. Graham Taylor was Robson's immediate successor.[33] England failed to win any matches at UEFA Euro 1992, drawing with tournament winners Denmark and later with France, before being eliminated by host nation Sweden. The team then failed to qualify for the 1994 FIFA World Cup after losing a controversial game against the Netherlands in Rotterdam, which resulted in Taylor's resignation. Taylor faced much newspaper criticism during his tenure for his tactics and team selections.[34]  Between 1994 and 1996, Terry Venables took charge of the team. At UEFA Euro 1996, held in England, they equalled their best performance at a European Championship, reaching the semi-finals as they did in 1968, before exiting via another penalty shoot-out loss to Germany.[35] England striker Alan Shearer was the tournament's top scorer with five goals.[36] At Euro 96, the song \"Three Lions\" by Baddiel, Skinner and The Lightning Seeds became the definitive anthem for fans on the terraces.[37] Venables announced before the tournament that he would resign at the end of it, following investigations into his personal financial activities and ahead of upcoming court cases. Due to the controversy around him, the FA stressed that he was the coach, not the manager, of the team.[38][39]  Venables' successor, Glenn Hoddle, took the team to the 1998 World Cup\u00a0\u2014 in which England were eliminated in the second round, again by Argentina and again on penalties (after a 2\u20132 draw).[40] In February 1999, Hoddle was sacked by the FA due to controversial comments he had made about disabled people to a newspaper.[41] Howard Wilkinson took over as caretaker manager for two matches.[42] Kevin Keegan was then appointed as the new permanent manager and took England to UEFA Euro 2000, but the team exited in the group stage and he unexpectedly resigned shortly afterwards.[43]  Peter Taylor was appointed as caretaker manager for one match, before Sven-G\u00f6ran Eriksson took charge between 2001 and 2006, and was the team's first non-English manager.[44][45] Although England's players in this era were dubbed a \"golden generation\" and only lost five competitive matches during Eriksson's tenure,[46] they exited at the quarter-finals of the 2002 FIFA World Cup, UEFA Euro 2004 and the 2006 FIFA World Cup.[47] In January 2006 it was announced that Eriksson would leave the role following that year's World Cup.[48]  Steve McClaren was then appointed as manager, but after failing to qualify for Euro 2008 he was sacked on 22 November 2007 after 18 matches in charge.[49] The following month, he was replaced by a second foreign manager, Italian Fabio Capello.[50] England won all but one of their qualifying games for the 2010 FIFA World Cup,[51] but at the tournament itself, England drew their opening two games; this led to questions about the team's spirit, tactics and ability to handle pressure.[52] They progressed to the next round, where they were beaten 4\u20131 by Germany, their heaviest defeat in a World Cup finals tournament match.[53] The match became even more famous as a pivotal moment in the refereeing of the sport, leading directly to the introduction of goal line technology, after Frank Lampard scored a goal to tie the game at 2-2 and it was incorrectly ruled out for \"failing to cross the goal line\", potentially altering the course of the match and certainly exacerbating the discrepancy of its outcome.[54] In February 2012, Capello resigned from his role as England manager, following a disagreement with the FA over their request to remove John Terry from team captaincy after accusations of racial abuse concerning the player.[55]  Following Capello's departure, Stuart Pearce was appointed as caretaker manager for one match, after which in May 2012, Roy Hodgson was announced as the new manager, just six weeks before UEFA Euro 2012.[56] England managed to finish top of their group, but exited the Championships in the quarter-finals via a penalty shoot-out against Italy.[57] In the 2014 FIFA World Cup, England were eliminated at the group stage for the first time since the 1958 World Cup.[58] At UEFA Euro 2016, England were eliminated in the round of 16, losing 2\u20131 to Iceland.[59] Hodgson resigned as manager in June 2016,[60] and just under a month later was replaced by Sam Allardyce.[61] After only 67 days in charge, Allardyce resigned from his managerial post by mutual agreement, after an alleged breach of FA rules, making him the shortest serving permanent England manager.[62]  Gareth Southgate, then the coach of the England under-21 team, was put in temporary charge of the national team until November 2016,[63] before being given the position on a permanent basis.[64] At the 2018 FIFA World Cup, England reached the semi-finals for only the third time. After finishing second in their group, England won on penalties against Colombia in the round of 16 before beating Sweden in the quarter-finals.[65][66][67] In the semi-final, they were beaten 2\u20131 in extra time by Croatia and finished 4th after losing the third place play-off match against Belgium.[68][69] England striker Harry Kane finished the tournament as top scorer with six goals.[70]  On 14 November 2019, England played their 1000th International match, defeating Montenegro 7\u20130 at Wembley in a UEFA Euro 2020 qualifying match.[71][72]  At the delayed UEFA Euro 2020, England reached the final of a major tournament for the first time since 1966 and their first ever European Championship final appearance.[73] After finishing top of a group including Croatia, Scotland and Czech Republic, the Three Lions would subsequently defeat Germany, Ukraine and Denmark to advance to the final.[74] In the final held at Wembley, England were defeated by Italy on penalties after a 1\u20131 draw.[75]  At the 2022 World Cup, England defeated Iran and Wales in the group stage to qualify for the round of 16.[76][77] In the round of 16, England defeated the reigning African champions Senegal by 3\u20130,[78] but were eliminated by the reigning world champions France in the quarter-finals, 2\u20131.[79] Harry Kane's goal against France was his 53rd for England, equalling the all-time record.[80] He would later miss an 84th-minute penalty with the chance to level the match.[81]  The motif of the England national football team has three lions passant guardant, the emblem of King Richard I, who reigned from 1189 to 1199.[92] In 1872, English players wore white jerseys emblazoned with the three lions crest of the Football Association.[93] The lions, often blue, have had minor changes to colour and appearance.[94] Initially topped by a crown, this was removed in 1949 when the FA was given an official coat of arms by the College of Arms; this introduced ten Tudor roses, one for each of the regional branches of the FA.[93][95] Since 2003, England top their logo with a star to recognise their World Cup win in 1966; this was first embroidered onto the left sleeve of the home kit, and a year later was moved to its current position, first on the away shirt.[96]  England's traditional home colours are white shirts, navy blue shorts and white or black socks. The team has periodically worn an all-white kit.  Although England's first away kits were blue, England's traditional away colours are red shirts, white shorts and red socks. In 1996, England's away kit was changed to grey shirts, shorts and socks. This kit was only worn three times, including against Germany in the semi-final of Euro 1996 but the deviation from the traditional red was unpopular with supporters and the England away kit remained red until 2011, when a navy blue away kit was introduced. The away kit is also sometimes worn during home matches, when a new edition has been released to promote it.  England have occasionally had a third kit. At the 1970 World Cup England wore a third kit with pale blue shirts, shorts and socks against Czechoslovakia. They had a kit similar to Brazil's, with yellow shirts, yellow socks and blue shorts which they wore in the summer of 1973. For the World Cup in 1986 England had a third kit of pale blue, imitating that worn in Mexico 16 years before and England retained pale blue third kits until 1992, but they were rarely used.  Umbro first agreed to manufacture the kit in 1954 and since then has supplied most of the kits, the exceptions being from 1959 to 1965 with Bukta and 1974\u20131984 with Admiral. Nike purchased Umbro in 2008 and took over as kit supplier in 2013 following their sale of the Umbro brand.[97]  For the first 50 years of their existence, England played their home matches all around the country. They initially used cricket grounds before later moving on to football club stadiums. The original Empire Stadium was built in Wembley, London, for the British Empire Exhibition.[98][99]  England played their first match at the stadium in 1924 against Scotland[100] and for the next 27 years Wembley was used as a venue for matches against Scotland only. The stadium later became known simply as Wembley Stadium and it became England's permanent home stadium during the 1950s. In October 2000, the stadium closed its doors, ending with a defeat against Germany.[101]  This stadium was demolished during the period of 2002\u201303, and work began to completely rebuild it.[102] During this time, England played at venues across the country, though by the time of the 2006 World Cup qualification, this had largely settled down to having Manchester United's Old Trafford stadium as the primary venue, with Newcastle United's St. James' Park used on occasions when Old Trafford was unavailable.[103]  Their first match in the new Wembley Stadium was in March 2007 when they drew with Brazil.[104] The stadium is now owned by the Football Association, via its subsidiary Wembley National Stadium Limited.[105]  England's three main rivalries are Scotland, Germany and Argentina.[106] Smaller rivalries with France, Wales and the Republic of Ireland have also been observed.[107][108][109]  England's rivalry with Scotland is one of the fiercest international rivalries that exists.[110][111] It is the oldest international fixture in the world, first played in 1872 at Hamilton Crescent, Glasgow.[112] The history of the British Isles has led to much rivalry between the nations in many forms, and the social and cultural effects of centuries of antagonism and conflict between the two has contributed to the intense nature of the sporting contests. Scottish nationalism has also been a factor in the Scots' desire to defeat England above all other rivals, with Scottish sports journalists traditionally referring to the English as the \"Auld Enemy\".[113] The footballing rivalry has diminished somewhat since the late 1970s, particularly since the annual fixture stopped in 1989. For England, games against Germany and Argentina are now considered to be more important than the historic rivalry with Scotland.[114]  England's rivalry with Germany is considered to be mainly an English phenomenon\u2014in the run-up to any competition match between the two teams, many UK newspapers will print articles detailing results of previous encounters, such as those in 1966 and 1990.[115] However, this rivalry has diminished significantly in recent years.[116]  England's rivalry with Argentina is highly competitive. Games between the two teams, even those that are only friendly matches, are often marked by notable and sometimes controversial incidents such as the hand of God in 1986.[117][118] The rivalry is unusual in that it is an intercontinental one; typically such footballing rivalries exist between bordering nations. England is regarded in Argentina as one of the major rivals of the national football team, matched only by Brazil and Uruguay.[118] The rivalry is, to a lesser extent reciprocal in England, locally described as a grudge match although matches against Germany carry a greater significance in popular perception. The rivalry emerged across several games during the latter half of the 20th century, even though as of 2008 the teams have played each other on only 14 occasions in full internationals.[119] The rivalry was intensified, particularly in Argentina, by non-footballing events, especially the 1982 Falklands War between Argentina and the United Kingdom.[120] However, England and Argentina have not met since a friendly in November 2005.[119]  Numerous songs have been released about the England national football team.  All England matches are broadcast with full commentary on talkSPORT and BBC Radio 5 Live. From the 2008\u201309 season until the 2017\u201318 season, England's home and away qualifiers, and friendlies both home and away were broadcast live on ITV Sport (often with the exception of STV, the ITV franchisee in central and northern Scotland). England's away qualifiers for the 2010 World Cup were shown on Setanta Sports until that company's collapse. As a result of Setanta Sports's demise, England's World Cup qualifier in Ukraine on 10 October 2009 was shown in the United Kingdom on a pay-per-view basis via the internet only. This one-off event was the first time an England game had been screened in such a way. The number of subscribers, paying between \u00a34.99 and \u00a311.99 each, was estimated at between 250,000 and 300,000 and the total number of viewers at around 500,000.[121] In 2018, Sky Sports broadcast the England Nations League and in-season friendlies, until 2021 and ITV Sport broadcast the European Qualifiers for Euro-World Cups and pre-tournament friendlies (after the Nations League group matches end), until 2022.[122] In April 2022, Channel 4 won the rights for England matches until June 2024, including 2022\u201323 UEFA Nations League matches, UEFA Euro 2024 qualifying games, and friendlies. 2022 World Cup rights remained with the BBC and ITV.[123]  The following is a list of match results in the last 12 months, as well as any future matches that have been scheduled.  \u00a0\u00a0Win \u00a0\u00a0Draw \u00a0\u00a0Loss \u00a0\u00a0Fixture  The following 23 players were named in the squad for the friendly matches against Brazil and Belgium on 23 and 26 March 2024, respectively.[127][128]  Caps and goals are correct as of 26 March 2024, after the match against Belgium.[129][130]  The following players have also been called up to the England squad within the last twelve months.   INJ Withdrew due to injury PRE Preliminary squad \/ standby RET Retired from the national team SUS Serving suspension WD Player withdrew from the squad due to non-injury issue.  For the all-time record of the national team against opposing nations, see the team's all-time record page  England first appeared at the 1950 FIFA World Cup, and have subsequently qualified for a total of 16 FIFA World Cup finals tournaments, tied for sixth best by number of appearances.[145][146] They are also placed sixth by number of wins, with 32. The national team is one of only eight nations to have won at least one FIFA World Cup title.[147] The England team won their first and only World Cup title in 1966.[148] The tournament was played on home soil, and England defeated West Germany 4\u20132 in the final.[148] In 1990, England finished in fourth place, losing 2\u20131 to host nation Italy in the third place play-off, following defeat on penalties, after extra time, to champions West Germany in the semi-final.[149] They also finished in fourth place in 2018, losing 2\u20130 to Belgium in the third place play-off, following a 2\u20131 defeat to Croatia, again after extra time, in the semi-final.[150] The team also reached the quarter-final stage in 1954, 1962, 1970, 1986, 2002, 2006 and 2022.[151]  England failed to qualify for the World Cup in 1974, 1978 and 1994.[152] The team's earliest exit in the finals tournament was its elimination in the first round in 1950, 1958 and, most recently, 2014.[153][154] This was after being defeated in both their opening two matches for the first time, against Italy and Uruguay in Group D.[154] In 1950, four teams remained after the first round, in 1958 eight teams remained and in 2014 sixteen teams remained. In 2010, England suffered its most resounding World Cup defeat, 4\u20131 to Germany, in the round of 16 stage.[155]  England first entered the UEFA European Championship in 1964,[157] and have since qualified for eleven finals tournaments,[157] tied for fourth-best by number of finals appearances. England's best results at the tournament were finishing as runners-up in the 2020 edition (held in 2021), and a third-place finish in 1968, 1996[158] a tournament they hosted.[159] In addition, England have reached the quarter-finals on two further occasions, in 2004 and 2012.[158]  England's worst results in the finals tournament to date have been first round eliminations in 1980, 1988, 1992 and 2000, whilst they failed to qualify for the finals in 1964, 1972, 1976, 1984 and 2008.[157]  England have competed in the UEFA Nations League since its inaugural season in 2018\u201319, when they qualified for the 2019 finals and finished third overall. To date this is their only appearance in the finals and their best performance in the competition. "},{"title":"Countries of the United Kingdom","content":"  Since 1922, the United Kingdom has been made up of four countries: England, Scotland, Wales (which collectively make up Great Britain) and Northern Ireland (variously described as a country,[1] province,[2][3][4] jurisdiction[5] or region[6][7]). The UK Prime Minister's website has used the phrase \"countries within a country\" to describe the United Kingdom.[8] Some statistical summaries, such as those for the twelve NUTS 1 regions of the UK, refer to Northern Ireland, Scotland, and Wales as \"regions\".[9][10] With regard to Northern Ireland, Scotland and Wales particularly, the descriptive name one uses \"can be controversial, with the choice often revealing one's political preferences\".[11]  Although the United Kingdom is a unitary sovereign country, it contains three distinct legal jurisdictions in Scotland, England and Wales, and Northern Ireland, each retaining its own legal system even after joining the UK.[12] Since 1998, Northern Ireland, Scotland, and Wales have also gained significant autonomy through the process of devolution. The Parliament of the United Kingdom and British Government deal with all reserved matters for Northern Ireland, Scotland, and Wales, but not in general matters that have been devolved to the Northern Ireland Assembly, Scottish Parliament, and the Welsh Senedd. Additionally, devolution in Northern Ireland is conditional on co-operation between the Northern Ireland Executive and the Government of Ireland (see North\/South Ministerial Council) and the British Government consults with the Government of Ireland to reach agreement on some non-devolved matters for Northern Ireland (see British\u2013Irish Intergovernmental Conference). England, comprising the majority of the population and area of the United Kingdom,[13][14] remains fully the responsibility of the United Kingdom Parliament centralised in London.   England, Northern Ireland, Scotland, and Wales are not themselves listed in the International Organization for Standardization (ISO) list of countries. However, the ISO list of the subdivisions of the United Kingdom, compiled by British Standards and the United Kingdom's Office for National Statistics, uses \"country\" to describe England, Scotland, and Wales.[15] Northern Ireland, in contrast, is described as a \"province\" in the same lists.[15] Each has separate national governing bodies for sports and compete separately in many international sporting competitions, including the Commonwealth Games. Northern Ireland also forms joint All-Island sporting bodies with the Republic of Ireland for some sports, including rugby union.[16]  The Channel Islands and the Isle of Man are dependencies of the Crown and are not part of the UK. Similarly, the British Overseas Territories, remnants of the British Empire, are not part of the UK.  From 1801, following the Acts of Union, until 1922 the whole island of Ireland was a country within the UK. Ireland was split into two separate jurisdictions in 1921, becoming Southern Ireland and Northern Ireland. Pursuant to the Anglo-Irish Treaty, the institutions of the revolutionary Irish Republic were assimilated into Southern Ireland, which then became the Irish Free State and left the United Kingdom in 1922. The Irish Free State adopted a new, essentially republican constitution in 1937 \u2013 albeit retaining the King for diplomatic functions \u2013 by which it would be known as simply Ireland. In 1949, by the Republic of Ireland Act, it transferred these diplomatic functions to its own president, left the Commonwealth of Nations and adopted the description Republic of Ireland, by which it is now known.  * Extra-regio comprises activity that cannot be assigned to regions.     Various terms have been used to describe England, Northern Ireland, Scotland and Wales.  The Interpretation Act 1978 provides statutory definitions of the terms \"England\", \"Wales\" and the \"United Kingdom\", but neither that Act nor any other current statute defines \"Scotland\" or \"Northern Ireland\". Use of the first three terms in other legislation is interpreted following the definitions in the 1978 Act. The definitions in the 1978 Act are listed below:  For Welsh law, \"Wales\" and \"Cymru\" are defined in the Legislation (Wales) Act 2019 as \"(a)the combined area of the counties and county boroughs in Wales (see Parts 1 and 2 of Schedule 4 to the Local Government Act 1972 (c. 70)), together with (b)the sea adjacent to Wales within the seaward limits of the territorial sea.\"  In the Scotland Act 1998 there is no delineation of Scotland, with the definition in section 126 simply providing that Scotland includes \"so much of the internal waters and territorial sea of the United Kingdom as are adjacent to Scotland\".[27]  The Parliamentary Voting System and Constituencies Act 2011 refers to England, Scotland, Wales and Northern Ireland as \"parts\" of the United Kingdom in the following clause: \"Each constituency shall be wholly in one of the four parts of the United Kingdom (England, Wales, Scotland and Northern Ireland).\"  The Royal Fine Art Commission's 1847 report on decorating the Palace of Westminster referred to \"the nationality of the component parts of the United Kingdom\" being represented by their four respective patron saints.[28]  For the purposes of NUTS 1 collection of statistical data in a format that is compatible with similar data collected in the European Union (on behalf of Eurostat), the United Kingdom was divided into twelve regions of approximately equal size.[29] Scotland, Wales and Northern Ireland were regions in their own right while England was divided into nine regions. Following Brexit, the Office for National Statistics uses International Territorial Level, which is currently a mirror of the NUTS 1 system until the 2024 review.[30]  The official term rest of the UK (RUK or rUK) is used in Scotland, for example in export statistics[31] and in legislating for student funding.[32]  The alternative term Home Nations is sometimes used in sporting contexts and may include all of the island of Ireland.  According to the British Social Attitudes Survey, there are broadly two interpretations of British identity, with ethnic and civic dimensions:  The first group, which we term the ethnic dimension, contained the items about birthplace, ancestry, living in Britain, and sharing British customs and traditions. The second, or civic group, contained the items about feeling British, respecting laws and institutions, speaking English, and having British citizenship.[33] Of the two perspectives of British identity, the civic definition has become the dominant idea and in this capacity, Britishness is sometimes considered an institutional or overarching state identity.[34][35] This has been used to explain why first-, second- and third-generation immigrants are more likely to describe themselves as British, rather than English, Northern Irish, Scottish or Welsh, because it is an \"institutional, inclusive\" identity, that can be acquired through naturalisation and British nationality law; the vast majority of people in the United Kingdom who are from an ethnic minority feel British.[36] However, this attitude is more common in England than in Scotland or Wales; \"white English people perceived themselves as English first and as British second, and most people from ethnic minority backgrounds perceived themselves as British, but none identified as English, a label they associated exclusively with white people\".[37] Contrariwise, in Scotland and Wales \"there was a much stronger identification with each country than with Britain.\"[38]  Studies and surveys have reported that the majority of the Scots and Welsh see themselves as both Scottish\/Welsh and British though with some differences in emphasis. The Commission for Racial Equality found that with respect to notions of nationality in Britain, \"the most basic, objective and uncontroversial conception of the British people is one that includes the English, the Scots and the Welsh\".[39] However, \"English participants tended to think of themselves as indistinguishably English or British, while both Scottish and Welsh participants identified themselves much more readily as Scottish or Welsh than as British\".[39] Some people opted \"to combine both identities\" as \"they felt Scottish or Welsh, but held a British passport and were therefore British\", whereas others saw themselves as exclusively Scottish or exclusively Welsh and \"felt quite divorced from the British, whom they saw as the English\".[39] Commentators have described this latter phenomenon as \"nationalism\", a rejection of British identity because some Scots and Welsh interpret it as \"cultural imperialism imposed\" upon the United Kingdom by \"English ruling elites\",[40] or else a response to a historical misappropriation of equating the word \"English\" with \"British\",[41] which has \"brought about a desire among Scots, Welsh and Irish to learn more about their heritage and distinguish themselves from the broader British identity\".[42] The propensity for nationalistic feeling varies greatly across the UK, and can rise and fall over time.[43]  The 2011 census which asked about national identity found that responders in Great Britain predominantly chose English, Welsh and Scottish rather than British.[44][45] Other research suggests that most people in England, Wales and Scotland tend to see themselves as British but that in Wales and Scotland in particular Scottish and Welshness tends to receive more emphasis.  A poll of 1039 Scottish adults conducted by YouGov in August 2016[46] found that 28% of responders saw themselves as Scottish not British, 28% as more Scottish than British, 29% as Scottish and British whilst 10% described being British as their dominate identity (either more British than Scottish or British not Scottish).[47] A similar poll conducted in Wales during spring 2019 found that 21% saw themselves as Welsh not British, 27% as more Welsh than British, 44% as equally Welsh and British whilst 7% saw themselves as either more or exclusively British.[48] A 2018 survey of 20,000 adults in England found that 80% identified strongly as English and 82% identified strongly as British with the two identities appearing to be closely intertwined.[49]  The state-funded Northern Ireland Life and Times Survey,[50] part of a joint project between the University of Ulster and Queen's University Belfast, has addressed the issue of identity since it started polling in 1998. It reported that 37% of people identified as British, whilst 29% identified as Irish and 24% identified as Northern Irish. 3% opted to identify themselves as Ulster, whereas 7% stated 'other'. Of the two main religious groups, 68% of Protestants identified as British as did 6% of Catholics; 60% of Catholics identified as Irish as did 3% of Protestants. 21% of Protestants and 26% of Catholics identified as Northern Irish.[51]  For Northern Ireland, however, the results of the Life & Times Survey are not the whole story. The poll asks for a single preference, whereas many people easily identify as any combination of British and Irish, or British, Northern Irish and Irish, or Irish and Northern Irish. The 2014 Life & Times Survey addressed this to an extent by choosing two of the options from the identity question: British and Irish. It found that, while 28% of respondents stated they felt \"British not Irish\" and 26% felt \"Irish not British\", 39% of respondents felt some combination of both identities. Six percent chose 'other description'.[52][failed verification]  The identity question is confounded further by identity with politics and religion, and particularly by a stance on the constitutional status of Northern Ireland. Again in 2014, the Life & Times Survey asked what respondents felt should be the \"long term future for Northern Ireland\". 66% of respondents felt the future should be as a part of the UK, with or without devolved government. 17% felt that Northern Ireland should unify with the Republic of Ireland. 50% of specifically Roman Catholics considered that the long-term future should be as part of the UK, with 32% opting for separation. 87% of respondents identifying as any Protestant denomination opted for remaining part of the UK, with only 4% opting for separation. Of those respondents who declared no religion, 62% opted for remaining part of the UK, with 9% opting for separation.[52]  Following devolution and the significant broadening of autonomous governance throughout the UK in the late 1990s, debate has taken place across the United Kingdom on the relative value of full independence,[53] an option that was rejected[54] by the Scottish people in the 2014 Scottish independence referendum.  Cornwall is administered as a county of England, but the Cornish people are a recognised national minority, included under the terms of the Framework Convention for the Protection of National Minorities in 2014.[55][56] Within Cornwall, 13.8 per cent of the population associated themselves with a Cornish identity, either on its own or combined with other identities, according to the 2011 census. This data, however, was recorded without an available tick box for Cornish, as a result the percentage of the population within Cornwall associating with Cornish identity is likely higher.[57]  Each of England, Northern Ireland, Scotland, and Wales has separate national governing bodies for sports and competes separately in many international sporting competitions.[58][59][60][61] Each country of the United Kingdom has a national football team, and competes as a separate national team in the various disciplines in the Commonwealth Games.[62] At the Olympic Games, the United Kingdom is represented by the Great Britain and Northern Ireland team, although athletes from Northern Ireland can choose to join the Republic of Ireland's Olympic team.[62][63] In addition to Northern Ireland having its own national governing bodies for some sports such as association football and netball, for others, such as rugby union and cricket, Northern Ireland participates with the Republic of Ireland in a joint All-Ireland team. England and Wales field a joint cricket team.  The United Kingdom participates in the Eurovision Song Contest as a single entity, though there have been calls for separate Scottish and Welsh entrants. In 2017, Wales participated alone in the spin-off Eurovision Choir, followed by a separate entry for Scotland in 2019. [64] "},{"title":"Welsh language","content":"  Welsh (Cymraeg [k\u0259m\u02c8ra\u02d0i\u0261] \u24d8 or y Gymraeg [\u0259 \u0261\u0259m\u02c8ra\u02d0i\u0261]) is a Celtic language of the Brittonic subgroup that is native to the Welsh people. Welsh is spoken natively in Wales, by some in England, and in Y Wladfa (the Welsh colony in Chubut Province, Argentina).[7]  It is spoken by smaller numbers of people in Canada and the United States descended from Welsh immigrants, within their households (especially in Nova Scotia). Historically, it has also been known in English as \"British\",[8] \"Cambrian\",[9] \"Cambric\"[10] and \"Cymric\".[11]  The Welsh Language (Wales) Measure 2011 gave the Welsh language official status in Wales.[12] Welsh and English are de jure official languages of the Welsh Parliament, the Senedd,[13] with Welsh being the only de jure official language in any part of the United Kingdom, with English being de facto official.  According to the 2021 census, the Welsh-speaking population of Wales aged three or older was 538,300 (17.8%) and nearly three quarters of the population in Wales said they had no Welsh language skills.[14] Other estimates suggest that 896,300 people (29.2%) aged three or older in Wales could speak Welsh in December 2023.[15] Almost half of all Welsh speakers consider themselves fluent, while 20 per cent are able to speak a fair amount.[16] 56 per cent of Welsh speakers speak the language daily, and 19 per cent speak the language weekly.[16]  The Welsh government plans to increase the number of Welsh-language speakers to one million by 2050. Since 1980, the number of children attending Welsh-medium schools has increased, while the number going to Welsh bilingual and dual-medium schools has decreased.[17] Welsh is considered the least endangered Celtic language by UNESCO.[18]  The language of the Welsh developed from the language of Britons.[19] The emergence of Welsh was not instantaneous and clearly identifiable. Instead, the shift occurred over a long period, with some historians claiming that it had happened by as late as the 9th century, with a watershed moment being that proposed by linguist Kenneth H. Jackson, the Battle of Dyrham, a military battle between the West Saxons and the Britons in 577 AD,[20] which split the South Western British from direct overland contact with the Welsh.  Four periods are identified in the history of Welsh, with rather indistinct boundaries: Primitive Welsh, Old Welsh, Middle Welsh, and Modern Welsh. The period immediately following the language's emergence is sometimes referred to as Primitive Welsh,[20] followed by the Old Welsh period \u2013 which is generally considered to stretch from the beginning of the 9th century to sometime during the 12th century.[20] The Middle Welsh period is considered to have lasted from then until the 14th century, when the Modern Welsh period began, which in turn is divided into Early and Late Modern Welsh.  The word Welsh is a descendant, via Old English wealh, wielisc, of the Proto-Germanic word *Walhaz, which was derived from the name of the Celtic people known to the Romans as Volcae and which came to refer to speakers of Celtic languages, and then indiscriminately to the people of the Western Roman Empire. In Old English the term went through semantic narrowing, coming to refer to either Britons in particular or, in some contexts, slaves.[21] The plural form W\u0113alas evolved into the name for their territory, Wales.[22]  The modern names for various Romance-speaking people in Continental Europe (e.g. Walloons, Valaisans, Vlachs\/Wallachians, and W\u0142osi, the Polish name for Italians) have a similar etymology.[23] The Welsh term for the language, Cymraeg, descends from the Brythonic word combrogi, meaning 'compatriots' or 'fellow countrymen'.[24]  Welsh evolved from Common Brittonic, the Celtic language spoken by the ancient Celtic Britons. Classified as Insular Celtic, the British language probably arrived in Britain during the Bronze Age or Iron Age and was probably spoken throughout the island south of the Firth of Forth.[25] During the Early Middle Ages the British language began to fragment due to increased dialect differentiation, thus evolving into Welsh and the other Brittonic languages. It is not clear when Welsh became distinct.[20][26][27]  Linguist Kenneth H. Jackson has suggested that the evolution in syllabic structure and sound pattern was complete by around AD 550, and labelled the period between then and about AD 800 \"Primitive Welsh\".[28] This Primitive Welsh may have been spoken in both Wales and the Hen Ogledd ('Old North') \u2013 the Brittonic-speaking areas of what are now northern England and southern Scotland \u2013 and therefore may have been the ancestor of Cumbric as well as Welsh. Jackson, however, believed that the two varieties were already distinct by that time.[20]  The earliest Welsh poetry \u2013 that attributed to the Cynfeirdd or \"Early Poets\" \u2013 is generally considered to date to the Primitive Welsh period. However, much of this poetry was supposedly composed in the Hen Ogledd, raising further questions about the dating of the material and language in which it was originally composed.[20] This discretion stems from the fact that Cumbric was widely believed to have been the language used in Hen Ogledd. An 8th-century inscription in Tywyn shows the language already dropping inflections in the declension of nouns.[29]  Janet Davies proposed that the origins of the Welsh language were much less definite; in The Welsh Language: A History, she proposes that Welsh may have been around even earlier than 600 AD. This is evidenced by the dropping of final syllables from Brittonic: *bardos 'poet' became bardd, and *abona 'river' became afon.[26] Though both Davies and Jackson cite minor changes in syllable structure and sounds as evidence for the creation of Old Welsh, Davies suggests it may be more appropriate to refer to this derivative language as Lingua Britannica rather than characterising it as a new language altogether.  The argued dates for the period of \"Primitive Welsh\" are widely debated, with some historians' suggestions differing by hundreds of years.  The next main period is Old Welsh (Hen Gymraeg, 9th to 11th centuries); poetry from both Wales and Scotland has been preserved in this form of the language. As Germanic and Gaelic colonisation of Britain proceeded, the Brittonic speakers in Wales were split off from those in northern England, speaking Cumbric, and those in the southwest, speaking what would become Cornish, so the languages diverged. Both the works of Aneirin (Canu Aneirin, c.\u2009600) and the Book of Taliesin (Canu Taliesin) were written during this era.  Middle Welsh (Cymraeg Canol) is the label attached to the Welsh of the 12th to 14th centuries, of which much more remains than for any earlier period. This is the language of nearly all surviving early manuscripts of the Mabinogion, although the tales themselves are certainly much older. It is also the language of the existing Welsh law manuscripts. Middle Welsh is reasonably intelligible to a modern-day Welsh speaker.  The Bible translations into Welsh helped maintain the use of Welsh in daily life, and standardised spelling. The New Testament was translated by William Salesbury in 1567,[31] and the complete Bible by William Morgan in 1588.[32] Modern Welsh is subdivided into Early Modern Welsh and Late Modern Welsh.[33] Early Modern Welsh ran from the 15th century through to the end of the 16th century,[34] and the Late Modern Welsh period roughly dates from the 16th century onwards. Contemporary Welsh differs greatly from the Welsh of the 16th century, but they are similar enough for a fluent Welsh speaker to have little trouble understanding it.  During the Modern Welsh period, there has been a decline in the popularity of the Welsh language: the number of Welsh speakers declined to the point at which there was concern that the language would become extinct. During industrialisation in the late 19th century, immigrants from England led to the decline in Welsh speakers particularly in the South Wales Valleys.[35] Welsh government processes and legislation have worked to increase the proliferation of the Welsh language, for example through education.[36]  Welsh has been spoken continuously in Wales throughout history; however, by 1911, it had become a minority language, spoken by 43.5 per cent of the population.[37] While this decline continued over the following decades, the language did not die out. The smallest number of speakers was recorded in 1981 with 503,000 although the lowest percentage was recorded in the most recent census in 2021 at 17.8 per cent.[38] By the start of the 21st century, numbers began to increase once more, at least partly as a result of the increase in Welsh-medium education.[39][40]  The 2004 Welsh Language Use Survey showed that 21.7 per cent of the population of Wales spoke Welsh,[41] compared with 20.8 per cent in the 2001 census, and 18.5 per cent in the 1991 census. Since 2001, however, the number of Welsh speakers has declined in both the 2011 and 2021 censuses to about  538,300 or 17.8 per cent in 2021 lower than 1991, although it is still higher in absolute terms.[42][43] The 2011 census also showed a \"big drop\" in the number of speakers in the Welsh-speaking heartlands, with the number dropping to under 50 per cent in Ceredigion and Carmarthenshire for the first time.[44] However, according to the Welsh Language Use Survey in 2019\u201320, 22 per cent of people aged three and over were able to speak Welsh.[45]  The Annual Population Survey (APS) by the Office for National Statistics (ONS) estimated that as of December 2023, approximately 896,300, or 29.2 per cent of the population of Wales aged 3 and over, were able to speak the language.[46] Children and young people aged three to 15 years old were more likely to report that they could speak Welsh than any other age group (49.9 per cent, 245,400). Around 1,020,800 people, or 33.3 per cent, reported that they could understand spoken Welsh. The APS estimates of Welsh language ability are historically higher than those produced by the census.[47]  In terms of usage, ONS also reported that 14.9 per cent (458,500) of people aged three or older in Wales reported that they spoke Welsh daily in December 2023, with 5.6 per cent (172,100) speaking it weekly and 7.0 per cent (215,000) less often. Approximately 1.6 per cent (50,100) reported that they never spoke Welsh despite being able to speak the language, with the remaining 70.8 per cent of the population not being able to speak it.[48]  The National Survey for Wales, conducted by Welsh Government, has also tended to have a higher percentage of Welsh speakers than the census, with the most recent results for 2022\u20132023 suggesting that 18 per cent of the population aged 3 and over were able to speak Welsh, with an additional 16 per cent noting that they had some Welsh-speaking ability.[49]  Historically, large numbers of Welsh people spoke only Welsh.[50] Over the course of the 20th century this monolingual population all but disappeared, but a small percentage remained at the time of the 1981 census.[51] Most Welsh-speaking people in Wales also speak English. However, many[quantify] Welsh-speaking people are more comfortable expressing themselves in Welsh than in English. A speaker's choice of language can vary according to the subject domain and the social context, even within a single discourse (known in linguistics as code-switching).[52]  Welsh speakers are largely concentrated in the north and west of Wales, principally Gwynedd, Conwy County Borough, Denbighshire, Anglesey, Carmarthenshire, north Pembrokeshire, Ceredigion, parts of Glamorgan, and north-west and extreme south-west Powys. However, first-language and other fluent speakers can be found throughout Wales.[53]  Welsh-speaking communities persisted well into the modern period across the border in England. Archenfield was still Welsh enough in the time of Elizabeth I for the Bishop of Hereford to be made responsible, together with the four Welsh bishops, for the translation of the Bible and the Book of Common Prayer into Welsh. Welsh was still commonly spoken there in the first half of the 19th century, and churchwardens' notices were put up in both Welsh and English until about 1860.[54] Alexander John Ellis in the 1880s identified a small part of Shropshire as still then speaking Welsh, with the \"Celtic Border\" passing from Llanymynech through Oswestry to Chirk.[55]  The number of Welsh-speaking people in the rest of Britain has not yet been counted for statistical purposes. In 1993, the Welsh-language television channel S4C published the results of a survey into the numbers of people who spoke or understood Welsh, which estimated that there were around 133,000 Welsh-speaking people living in England, about 50,000 of them in the Greater London area.[56] The Welsh Language Board, on the basis of an analysis of the Office for National Statistics Longitudinal Study, estimated there were 110,000 Welsh-speaking people in England, and another thousand in Scotland and Northern Ireland.[57]  In the 2011 census, 8,248 people in England gave Welsh in answer to the question \"What is your main language?\"[58] The Office for National Statistics subsequently published a census glossary of terms to support the release of results from the census, including their definition of \"main language\" as referring to \"first or preferred language\" (though that wording was not in the census questionnaire itself).[59][60] The wards in England with the most people giving Welsh as their main language were the Liverpool wards of Central and Greenbank; and Oswestry South in Shropshire.[58] The wards of Oswestry South (1.15%), Oswestry East (0.86%) and St Oswald (0.71%) had the highest percentage of residents giving Welsh as their main language.  The census also revealed that 3,528 wards in England, or 46% of the total number, contained at least one resident whose main language is Welsh. In terms of the regions of England, North West England (1,945), London (1,310) and the West Midlands (1,265) had the highest number of people noting Welsh as their main language.[61] According to the 2021 census, 7,349 people in England recorded Welsh to be their \"main language\".[62]  In the 2011 census, 1,189 people aged three and over in Scotland noted that Welsh was a language (other than English) that they used at home.[63]  It is believed that there are as many as 5,000 speakers of Patagonian Welsh.[64]  In response to the question 'Does the person speak a language other than English at home?' in the 2016 Australian census, 1,688 people noted that they spoke Welsh.[65]  In the 2011 Canadian census, 3,885 people reported Welsh as their first language.[66] According to the 2021 Canadian census, 1,130 people noted that Welsh was their mother tongue.[67][68]  The 2018 New Zealand census noted that 1,083 people in New Zealand spoke Welsh.[69]  The American Community Survey 2009\u20132013 noted that 2,235 people aged five years and over in the United States spoke Welsh at home. The highest number of those (255) lived in Florida.[70]    Calls for the Welsh language to be granted official status grew with the establishment of the nationalist political party Plaid Cymru in 1925, the establishment of the Welsh Language Society in 1962 and the rise of Welsh nationalism in the later 20th century. Of the six living Celtic languages (including two revived), Welsh has the highest number of native speakers who use the language on a daily basis, and it is the only Celtic language which is not considered to be endangered by UNESCO.  The Welsh Language Act 1993 and the Government of Wales Act 1998 provide that the Welsh and English languages be treated equally in the public sector, as far as is reasonable and practicable. Each public body is required to prepare for approval a Welsh Language Scheme, which indicates its commitment to the equality of treatment principle. This is sent out in draft form for public consultation for a three-month period, whereupon comments on it may be incorporated into a final version. It requires the final approval of the now defunct Welsh Language Board (Bwrdd yr Iaith Gymraeg). Thereafter, the public body is charged with implementing and fulfilling its obligations under the Welsh Language Scheme. The list of other public bodies which have to prepare Schemes could be added to by initially the Secretary of State for Wales, from 1993 to 1997, by way of statutory instrument. Subsequent to the forming of the National Assembly for Wales in 1997, the Government Minister responsible for the Welsh language can and has passed statutory instruments naming public bodies who have to prepare Schemes. Neither the 1993 Act nor secondary legislation made under it covers the private sector, although some organisations, notably banks and some railway companies, provide some of their information in Welsh.[71][72]  On 7 December 2010, the Welsh Assembly unanimously approved a set of measures to develop the use of the Welsh language within Wales.[73][74] On 9 February 2011 this measure, the Welsh Language (Wales) Measure 2011, was passed and received Royal Assent, thus making the Welsh language an officially recognised language within Wales. The measure:  The measure requires public bodies and some private companies to provide services in Welsh. The Welsh government's Minister for Heritage at the time, Alun Ffred Jones, said, \"The Welsh language is a source of great pride for the people of Wales, whether they speak it or not, and I am delighted that this measure has now become law. I am very proud to have steered legislation through the Assembly which confirms the official status of the Welsh language; which creates a strong advocate for Welsh speakers and will improve the quality and quantity of services available through the medium of Welsh. I believe that everyone who wants to access services in the Welsh language should be able to do so, and that is what this government has worked towards. This legislation is an important and historic step forward for the language, its speakers and for the nation.\"[75] The measure was not welcomed warmly by all supporters: Bethan Williams, chairman of the Welsh Language Society, gave a mixed response to the move, saying, \"Through this measure we have won official status for the language and that has been warmly welcomed. But there was a core principle missing in the law passed by the Assembly before Christmas. It doesn't give language rights to the people of Wales in every aspect of their lives. Despite that, an amendment to that effect was supported by 18 Assembly Members from three different parties, and that was a significant step forward.\"[76]  On 5 October 2011, Meri Huws, Chair of the Welsh Language Board, was appointed the new Welsh Language Commissioner.[77] She released a statement that she was \"delighted\" to have been appointed to the \"hugely important role\", adding, \"I look forward to working with the Welsh Government and organisations in Wales in developing the new system of standards. I will look to build on the good work that has been done by the Welsh Language Board and others to strengthen the Welsh language and ensure that it continues to thrive.\" First Minister Carwyn Jones said that Huws would act as a champion for the Welsh language, though some had concerns over her appointment: Plaid Cymru spokeswoman Bethan Jenkins said, \"I have concerns about the transition from Meri Huws's role from the Welsh Language Board to the language commissioner, and I will be asking the Welsh government how this will be successfully managed. We must be sure that there is no conflict of interest, and that the Welsh Language Commissioner can demonstrate how she will offer the required fresh approach to this new role.\" Huws started her role as the Welsh Language Commissioner on 1 April 2012.  Local councils and the Senedd use Welsh, issuing Welsh versions of their literature, to varying degrees.  Road signs in Wales are in Welsh and English.[78] Prior to 2016, the choice of which language to display first was the responsibility of the local council. Since then, as part of the Welsh Language (Wales) Measure 2011, all new signs have Welsh displayed first.[79] There have been incidents of one of the languages being vandalised, which may be considered a hate crime.[80][81]  Since 2000, the teaching of Welsh has been compulsory in all schools in Wales up to age 16; this has had an effect in stabilising and reversing the decline in the language.[82]  Text on UK coins tends to be in English and Latin.  However, a Welsh-language edge inscription was used on pound coins dated 1985, 1990 and 1995, which circulated in all parts of the UK prior to their 2017 withdrawal. The wording is Pleidiol wyf i'm gwlad (Welsh for 'True am I to my country'), and derives from the national anthem of Wales, Hen Wlad Fy Nhadau.  UK banknotes are in English only.  Some shops employ bilingual signage. Welsh sometimes appears on product packaging or instructions.  The UK government has ratified the European Charter for Regional or Minority Languages in respect of Welsh.[83]  The language has greatly increased its prominence since the creation of the television channel S4C in November 1982, which until digital switchover in 2010 broadcast 70 per cent of Channel 4's programming along with a majority of Welsh language shows[84] during peak viewing hours. The all-Welsh-language digital station S4C Digidol is available throughout Europe on satellite and online throughout the UK. Since the digital switchover was completed in South Wales on 31 March 2010, S4C Digidol became the main broadcasting channel and fully in Welsh. The main evening television news provided by the BBC in Welsh is available for download.[85] There is also a Welsh-language radio station, BBC Radio Cymru, which was launched in 1977.[86]  The only Welsh-language national newspaper Y Cymro (The Welshman) was published weekly until 2017, and monthly thereafter, following a change in ownership. There is no daily newspaper in Welsh. A daily newspaper called Y Byd (The World) was scheduled to be launched on 3 March 2008, but was scrapped, owing to insufficient sales of subscriptions and the Welsh Government offering only one third of the \u00a3600,000 public funding it needed.[87] There is a Welsh-language online news service which publishes news stories in Welsh called Golwg360 ('360 [degree] view').  As of March 2021, there were 58 local Welsh language community newspapers, known as Papurau Bro, in circulation.[88]  The decade around 1840 was a period of great social upheaval in Wales, manifested in the Chartist movement. In 1839, 20,000 people marched on Newport, resulting in a riot when 20 people were killed by soldiers defending the Westgate Hotel, and the Rebecca Riots where tollbooths on turnpikes were systematically destroyed.  This unrest brought the state of education in Wales to the attention of the British government since social reformers of the time considered education as a means of dealing with social ills. The Times newspaper was prominent among those who considered that the lack of education of the Welsh people was the root cause of most of the problems.  In July 1846, three commissioners, R.R.W. Lingen, Jellynger C. Symons and H.R. Vaughan Johnson, were appointed to inquire into the state of education in Wales; the Commissioners were all Anglicans and thus presumed unsympathetic to the nonconformist majority in Wales. The Commissioners presented their report to the Government on 1 July 1847 in three large blue-bound volumes. This report quickly became known in Wales as the Brad y Llyfrau Gleision (Treason of the Blue Books) since,[89] apart from documenting the state of education in Wales, the Commissioners were also free with their comments disparaging the language, nonconformity, and the morals of the Welsh people in general. An immediate effect of the report was that ordinary Welsh people began to believe that the only way to get on in the world was through the medium of English, and an inferiority complex developed about the Welsh language whose effects have not yet been completely eradicated. The historian Professor Kenneth O. Morgan referred to the significance of the report and its consequences as \"the Glencoe and the Amritsar of Welsh history\".[90]  In the later 19th century, the teaching of English in Welsh schools was generally supported by the Welsh public and parents who saw it as the language of economic advancement.[91]:\u200a453,\u200a457\u200a Virtually all teaching in the schools of Wales was in English, even in areas where the pupils barely understood English. Some schools used the Welsh Not, a piece of wood, often bearing the letters \"WN\", which was hung around the neck of any pupil caught speaking Welsh. The pupil could pass it on to any schoolmate heard speaking Welsh, with the pupil wearing it at the end of the day being punished. One of the most famous Welsh-born pioneers of higher education in Wales was Sir Hugh Owen. He made great progress in the cause of education, and more especially the University College of Wales at Aberystwyth, of which he was chief founder. He has been credited [by whom?] with the Welsh Intermediate Education Act 1889 (52 & 53 Vict c 40), following which several new Welsh schools were built. The first was completed in 1894 and named Ysgol Syr Hugh Owen.  Towards the beginning of the 20th century this policy slowly began to change, partly owing to the efforts of O.M. Edwards when he became chief inspector of schools for Wales in 1907.  The Ysgol Gymraeg Aberystwyth ('Aberystwyth Welsh School') was founded in 1939 by Sir Ifan ap Owen Edwards, the son of O.M. Edwards, as the first Welsh Primary School.[92] The headteacher was Norah Isaac. Ysgol Gymraeg Aberystwyth is still a very successful school, and now there are Welsh-language primary schools all over the country. Ysgol Glan Clwyd was established in Rhyl in 1956 as the first Welsh-medium secondary school.[93]  Welsh is now widely used in education, with 101,345 children and young people in Wales receiving their education in Welsh medium schools in 2014\/15, 65,460 in primary and 35,885 in secondary.[94] 26 per cent of all schools in Wales are defined as Welsh medium schools, with a further 7.3 per cent offering some Welsh-medium instruction to pupils.[95] 22 per cent of pupils are in schools in which Welsh is the primary language of instruction. Under the National Curriculum, it is compulsory that all students study Welsh up to the age of 16 as either a first or a second language.[96] Some students choose to continue with their studies through the medium of Welsh for the completion of their A-levels as well as during their college years. All local education authorities in Wales have schools providing bilingual or Welsh-medium education.[97] The remainder study Welsh as a second language in English-medium schools. Specialist teachers of Welsh called Athrawon Bro support the teaching of Welsh in the National Curriculum. Welsh is also taught in adult education classes. The Welsh Government has recently set up six centres of excellence in the teaching of Welsh for Adults, with centres in North Wales,[98] Mid Wales, South West, Glamorgan, Gwent, and Cardiff.  The ability to speak Welsh or to have Welsh as a qualification is desirable for certain career choices in Wales, such as teaching or customer service.[99] All universities in Wales teach courses in the language, with many undergraduate and post-graduate degree programmes offered in the medium of Welsh, ranging from law, modern languages, social sciences, and also other sciences such as biological sciences. Aberystwyth, Cardiff, Bangor, and Swansea have all had chairs in Welsh since their virtual establishment, and all their schools of Welsh are successful centres for the study of the Welsh language and its literature, offering a BA in Welsh as well as post-graduate courses. At all Welsh universities and the Open University, students have the right to submit assessed work and sit exams in Welsh even if the course was taught in English (usually the only exception is where the course requires demonstrating proficiency in another language). Following a commitment made in the One Wales coalition government between Labour and Plaid Cymru, the Coleg Cymraeg Cenedlaethol (Welsh Language National College) was established. The purpose of the federal structured college, spread out between all the universities of Wales, is to provide and also advance Welsh medium courses and Welsh medium scholarship and research in Welsh universities. There is also a Welsh-medium academic journal called Gwerddo ('Oasis'), which is a platform for academic research in Welsh and is published quarterly. There have been calls for more teaching of Welsh in English-medium schools.  When conducting applicants' professional reviews for Chartered Engineer status, the Institution of Engineering and Technology accepts applications in Welsh and will conduct face-to-face interviews in Welsh if requested to do so. One of the requirements for Chartered Engineer is also to be able to communicate effectively in English.  Like many of the world's languages, the Welsh language has seen an increased use and presence on the internet, ranging from formal lists of terminology in a variety of fields[100] to Welsh language interfaces for Microsoft Windows XP and up, Microsoft Office, LibreOffice, OpenOffice.org, Mozilla Firefox and a variety of Linux distributions, and on-line services to blogs kept in Welsh.[101] Wikipedia has had a Welsh version since July 2003 and Facebook since 2009.  In 2006 the Welsh Language Board launched a free software pack which enabled the use of SMS predictive text in Welsh.[102] At the National Eisteddfod of Wales 2009, a further announcement was made by the Welsh Language Board that the mobile phone company Samsung was to work with the network provider Orange to provide the first mobile phone in the Welsh language,[103] with the interface and the T9 dictionary on the Samsung S5600 available in the Welsh language. The model, available with the Welsh language interface, has been available since 1 September 2009, with plans to introduce it on other networks.[104]  On Android devices, both the built-in Google Keyboard and user-created keyboards can be used.[105] iOS devices have fully supported the Welsh language since the release of iOS 8 in September 2014. Users can switch their device to Welsh to access apps that are available in Welsh. Date and time on iOS is also localised, as shown by the built-in Calendar application, as well as certain third-party apps that have been localised.[106][107]  Secure communications are often difficult to achieve in wartime. Just as Navajo code talkers were used by the United States military during World War II, the Royal Welch Fusiliers, a Welsh regiment serving in Bosnia, used Welsh for emergency communications that needed to be secure.[108]  In 2017, parliamentary rules were amended to allow the use of Welsh when the Welsh Grand Committee meets at Westminster. The change did not alter the rules about debates within the House of Commons, where only English can be used.[109]  In February 2018, Welsh was first used when the Welsh Secretary, Alun Cairns, delivered his welcoming speech at a sitting of the committee. He said, \"I am proud to be using the language I grew up speaking, which is not only important to me, my family and the communities Welsh MPs represent, but is also an integral part of Welsh history and culture\".[110][111][112]  In November 2008, the Welsh language was used at a meeting of the European Union's Council of Ministers for the first time. The Heritage Minister Alun Ffred Jones addressed his audience in Welsh and his words were interpreted into the EU's 23 official languages. The official use of the language followed years of campaigning. Jones said \"In the UK we have one of the world's major languages, English, as the mother tongue of many. But there is a diversity of languages within our islands. I am proud to be speaking to you in one of the oldest of these, Welsh, the language of Wales.\" He described the breakthrough as \"more than [merely] symbolic\" saying \"Welsh might be one of the oldest languages to be used in the UK, but it remains one of the most vibrant. Our literature, our arts, our festivals, our great tradition of song all find expression through our language. And this is a powerful demonstration of how our culture, the very essence of who we are, is expressed through language.\"[113]  Jill Evans MEP used Welsh in a number of speeches in the European Parliament. In 2004, her using Welsh was the first use of the language in the European Parliament.[114] The last time Welsh was spoken in the European Parliament was during Evans' last speech shortly before Brexit.[115]  A greeting in Welsh is one of the 55 languages included on the Voyager Golden Record chosen to be representative of Earth in NASA's Voyager programme launched in 1977.[116] The greetings are unique to each language, with the Welsh greeting being Iechyd da i chwi yn awr ac yn oesoedd, which translates into English as \"Good health to you now and forever\".[117][118]  Welsh supplements its core Brittonic vocabulary (words such as wy \"egg\", carreg \"stone\") with hundreds of word lemmas borrowed from Latin,[119] such as (ffenestr 'window' < Latin fenestra, gwin 'wine' < Latin vinum). It also borrows words from English, such as (silff 'shelf', gi\u00e2t 'gate').  The phonology of Welsh includes a number of sounds that do not occur in English and are typologically rare in European languages. The voiceless alveolar lateral fricative [\u026c], the voiceless nasals [m\u0325], [n\u0325] and [\u014b\u030a], and the voiceless alveolar trill [r\u0325] are distinctive features of the Welsh language. Stress usually falls on the penultimate syllable in polysyllabic words, and the word-final unstressed syllable receives a higher pitch than the stressed syllable.  Symbols in parentheses are either allophones, or found only in loanwords.  The vowels \/\u0268\u031e\/ and \/\u0268\/ are only found in Northern varieties of Welsh. In the South these have merged with \/\u026a\/ and \/i\/ in all cases.  Welsh is written in a Latin alphabet of 29 letters, of which eight are digraphs treated as single letters for collation, for example fy comes before ffrwyth in the dictionary:  In contrast to English practice, \u27e8w\u27e9 and \u27e8y\u27e9 are considered vowel letters in Welsh along with \u27e8a, e, i, o, u\u27e9.  \u27e8j\u27e9 was not used traditionally, but is now used in many everyday words borrowed from English, like jam ('jam'), j\u00f4c ('joke') and garej ('garage'). \u27e8k, q, v, x, z\u27e9 are used in some technical terms, like kilogram, volt and zero, but in all cases can be, and often are, replaced by Welsh letters (same pronunciation): cilogram, folt and sero.[120] \u27e8k\u27e9 was in common use until the 16th century, but was dropped at the time of the publication of the New Testament in Welsh, as William Salesbury explained: \"\u27e8c\u27e9 for \u27e8k\u27e9, because the printers have not so many as the Welsh requireth\". This change was not popular at the time.[121]  The most common diacritic is the circumflex (called to bach in Welsh, lit. 'little roof'),[122] which usually disambiguates long vowels, most often in the case of homographs, where the vowel is short in one word and long in the other: e.g. man ('place') vs m\u00e2n ('fine, small').   Welsh morphology has much in common with that of the other modern Insular Celtic languages, such as the use of initial consonant mutations and of so-called \"conjugated prepositions\" (prepositions that fuse with the personal pronouns that are their object). Welsh nouns belong to one of two grammatical genders, masculine and feminine, but they are not inflected for case. Welsh has a variety of different endings and other methods to indicate the plural, and two endings to indicate the singular (technically the singulative) of some nouns. In spoken Welsh, verbal features are indicated primarily by the use of auxiliary verbs rather than by the inflection of the main verb. In literary Welsh, on the other hand, inflection of the main verb is usual.  The canonical word order in Welsh is verb\u2013subject\u2013object (VSO).  Colloquial Welsh inclines very strongly towards the use of auxiliaries with its verbs, as in English. The present tense is constructed with bod ('to be') as an auxiliary verb, with the main verb appearing as a verbnoun (used in a way loosely equivalent to an infinitive) after the particle yn:  There, mae is a third-person singular present indicative form of bod, and mynd is the verb-noun meaning \"to go\". The imperfect is constructed in a similar manner, as are the periphrastic forms of the future and conditional tenses.  In the preterite, future and conditional mood tenses, there are inflected forms of all verbs, which are used in the written language. However, speech now more commonly uses the verbnoun together with an inflected form of gwneud ('do'), so \"I went\" can be Mi es i or Mi wnes i fynd ('I did go'). Mi is an example of a preverbal particle; such particles are common in Welsh, though less so in the spoken language.  Welsh lacks separate pronouns for constructing subordinate clauses; instead, special verb forms or relative pronouns that appear identical to some preverbal particles are used.  The Welsh for \"I like Rhodri\" is Dw i'n hoffi Rhodri (word for word, \"am I [the] liking [of] Rhodri\"), with Rhodri in a possessive relationship with hoffi. With personal pronouns, the possessive form of the personal pronoun is used, as in \"I like him\": [Dw i'n ei hoffi], literally, \"am I his liking\" \u2013 \"I like you\" is [Dw i'n dy hoffi] ('am I your liking'). Very informally, the pronouns are often heard in their normal subject\/object form and aping English word order: Dw i'n hoffi ti ('Am I liking you').  In colloquial Welsh, possessive pronouns, whether they are used to mean \"my\", \"your\", etc. or to indicate the direct object of a verbnoun, are commonly reinforced by the use of the corresponding personal pronoun after the noun or verbnoun: ei d\u0177 e \"his house\" (literally \"his house of him\"), Dw i'n dy hoffi di \"I like you\" ('I am [engaged in the action of] your liking of you'), etc. The \"reinforcement\" (or, simply, \"redoubling\") adds no emphasis in the colloquial register. While the possessive pronoun alone may be used, especially in more formal registers, as shown above, it is considered incorrect to use only the personal pronoun. Such usage is nevertheless sometimes heard in very colloquial speech, mainly among young speakers: Ble 'dyn ni'n mynd? T\u0177 ti neu d\u0177 fi? ('Where are we going? Your house or my house?').  Welsh is a moderately inflecting language. Verbs inflect at least for person, number and mood, whilst nouns do for number and there is a masculine feminine distinction, of which the latter is marked via consonant mutation.  Colloquial and literary grammar show more differences than in English.  The traditional counting system used in the Welsh language is vigesimal, i.e. it is based on twenties, as in standard French numbers 70 (soixante-dix, literally \"sixty-ten\") to 99 (quatre-vingt-dix-neuf, literally \"four twenty nineteen\"). Welsh numbers from 11 to 14 are \"x on ten\" (e.g. un ar ddeg: 11), 16 to 19 are \"x on fifteen\" (e.g. un ar bymtheg: 16), though 18 is deunaw, \"two nines\"; numbers from 21 to 39 are \"1\u201319 on twenty\"(e.g. deg ar hugain: 30), 40 is deugain \"two twenties\", 60 is trigain \"three twenties\", etc. This form continues to be used, especially by older people, and it is obligatory in certain circumstances (such as telling the time, and in ordinal numbers).[123]  There is also a decimal counting system, which has become relatively widely used, though less so in giving the time, ages, and dates (it features no ordinal numbers). This system originated in Patagonian Welsh and was subsequently introduced to Wales in the 1940s.[124] Whereas 39 in the vigesimal system is pedwar ar bymtheg ar hugain ('four on fifteen on twenty') or even deugain namyn un ('two twenty minus one'), in the decimal system it is tri deg naw ('three tens nine').  Although there is only one word for \"one\" (un), it triggers the soft mutation[disambiguation needed] (treiglad meddal) of feminine nouns, where possible, other than those beginning with \"ll\" or \"rh\". There are separate masculine and feminine forms of the numbers 'two' (dau and dwy), 'three' (tri and tair) and 'four' (pedwar and pedair), which must agree with the grammatical gender of the objects being counted. The objects being counted appear in the singular, not plural form.  The differences between the dialects of modern colloquial Welsh are insignificant in comparison with the difference between the spoken and standard language. The latter is much more formal and is, among other things, the language of the Welsh translations of the Bible (but the Beibl Cymraeg Newydd \u2013 \"New Welsh Bible\" \u2013 is much less formal in language than the traditional 1588 Bible). Among the characteristics of the literary language, in comparison with the spoken language, are more frequent use of conjugated verb forms, a change in the use of certain tenses (for example, the literary imperfect in modern language has the meaning of the subjunctive mood), a reduction in the frequency of the use of pronouns (since the information they convey is usually conveyed by forms of inflected verbs and prepositions) and a more pronounced tendency to replace English borrowings with native Welsh words.[125]  For example: consider the question \"Do you want a cuppa [a cup of tea]?\" In Gwynedd this would typically be Dach chi isio paned? while in the south of Dyfed one would be more likely to hear Ych chi'n moyn dishgled? (though in other parts of the South one would not be surprised to hear Ych chi isie paned? as well, among other possibilities). An example of a pronunciation difference is the tendency in some southern dialects to palatalise the letter \"s\", e.g. mis (Welsh for 'month'), usually pronounced IPA: [mi\u02d0s], but as IPA: [mi\u02d0\u0283] in parts of the south. This normally occurs next to a high front vowel like \/i\/, although exceptions include the pronunciation of sut \"how\" as IPA: [\u0283\u028ad] in the southern dialects (compared with northern IPA: [s\u0268t]).  Although modern understanding often splits Welsh into northern (Gogledd) and southern (De) 'dialects', the traditional classification of four Welsh dialects remains the most academically useful:  A fifth dialect is Patagonian Welsh, which has developed since the start of Y Wladfa (the Welsh settlement in Argentina) in 1865; it includes Spanish loanwords and terms for local features, but a survey in the 1970s showed that the language in Patagonia is consistent throughout the lower Chubut Valley and in the Andes.  Subdialects exist within the main dialects (such as the Cofi dialect). The 1989 book Cymraeg, Cymr\u00e2g, Cymr\u00eag: Cyflwyno'r Tafodieithoedd (Welsh for 'Welsh, Welsh, Welsh: Introducing the Dialects')[127] was accompanied by a cassette containing recordings of 14 different speakers demonstrating aspects of different regional dialects. The book also refers to the earlier Linguistic Geography of Wales (1973)[128] as describing six different regions which could be identified as having words specific to those regions.  In the 1970s, there was an attempt to standardise the Welsh language by teaching Cymraeg Byw ('Living Welsh') \u2013 a colloquially-based generic form of Welsh,[129] but the attempt largely failed because it did not encompass the regional differences used by Welsh-speakers.  Modern Welsh can be considered to fall broadly into two main registers\u2014Colloquial Welsh (Cymraeg llafar) and Literary Welsh (Cymraeg llenyddol). Colloquial Welsh is used in most speech and informal writing. Literary Welsh is closer to the form of Welsh standardised by the 1588 translation of the Bible and is found in official documents and other formal registers, including much literature. As a standardised form, literary Welsh shows little if any of the dialectal variation found in colloquial Welsh. Some differences include:  Amongst the characteristics of the literary, as against the spoken language are a higher dependence on inflected verb forms, different usage of some of the tenses, less frequent use of pronouns (since the information is usually conveyed in the verb\/preposition inflections) and a much lesser tendency to substitute English loanwords for native Welsh words. In addition, more archaic pronouns and forms of mutation may be observed in Literary Welsh.  The differences between dialects of modern spoken Welsh pale into insignificance compared to the difference between some forms of the spoken language and the most formal constructions of the literary language. The latter is considerably more conservative and is the language used in Welsh translations of the Bible, amongst other things \u2013 although the 2004 Beibl Cymraeg Newydd (Welsh for 'New Welsh Bible') is significantly less formal than the traditional 1588 Bible. Gareth King, author of a popular Welsh grammar, observes, \"The difference between these two is much greater than between the virtually identical colloquial and literary forms of English.\"[131] A grammar of Literary Welsh can be found in A Grammar of Welsh by Stephen J. Williams[132] or more completely in Gramadeg y Gymraeg by Peter Wynn Thomas.[133] (No comprehensive grammar of formal literary Welsh exists in English.) An English-language guide to colloquial Welsh forms and register and dialect differences is Dweud Eich Dweud by Ceri Jones.[134]  Article 1 of the Universal Declaration of Human Rights:  Genir pawb yn rhydd ac yn gydradd \u00e2'i gilydd mewn urddas a hawliau. Fe'u cynysgaeddir \u00e2 rheswm a chydwybod, a dylai pawb ymddwyn y naill at y llall mewn ysbryd cymodlon.[135]  All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood.[136] "},{"title":"Supermajority","content":"  A supermajority (also called supra-majority, supramajority, qualified majority, or special majority) is a requirement for a proposal to gain a specified level of support which is greater than the threshold of more than one-half used for a simple majority. Supermajority rules in a democracy can help to prevent a majority from eroding fundamental rights of a minority, but they can also hamper efforts to respond to problems and encourage corrupt compromises at times when action is taken. Changes to constitutions, especially those with entrenched clauses, commonly require supermajority support in a legislature. Parliamentary procedure requires that any action of a deliberative assembly that may alter the rights of a minority have a supermajority requirement, such as a two-thirds vote. In consensus democracy the supermajority rule is applied in most cases.  Related concepts regarding alternatives to the majority vote requirement include a majority of the entire membership and a majority of the fixed membership. A supermajority can also be specified based on the entire membership or fixed membership rather than on those present and voting.  The first known use of a supermajority rule was in the 100s BC in ancient Rome.[1][how?]  Pope Alexander III introduced the use of supermajority rule for papal elections at the Third Lateran Council in 1179.[2]  In the Democratic Party of the United States, a rule requiring the determination of a presidential nominee required the votes of two-thirds of delegates to the Democratic National Convention was adopted at the party's first presidential nominating convention in 1832.[3] The two-thirds rule gave southern Democrats a de facto veto over any presidential nominee after the Civil War, which lasted until the rule was abolished in 1936.[4]  In the Federalist Papers, Alexander Hamilton and James Madison were critical of supermajority requirements. In Federalist 22, Hamilton wrote that while preventing harmful legislation from being passed, such requirements also prevented beneficial legislation from being passed, and \"its real operation is to embarrass the administration, to destroy the energy of government, and to substitute the pleasure, caprice or artifices of an insignificant, turbulent or corrupt junto, to the regular deliberations and decisions of a respectable majority.\" Hamilton also wrote that such a requirement would encourage \"contemptible compromises of the public good\".[5] In Federalist 58, Madison wrote that supermajority requirements might help impede the passage of \"hasty and partial measures\", but \"[i]n all cases where justice or the general good might require new laws to be passed, or active measures to be pursued, the fundamental principle of free government would be reversed. It would be no longer the majority that would rule; the power would be transferred to the minority.\" Madison also wrote that such requirements would encourage secession.[6]  A majority vote, or more than half the votes cast, is a common voting basis. Instead of the basis of a majority, a supermajority can be specified using any fraction or percentage which is greater than one-half.[7] It can also be called a qualified majority.[8] Common supermajorities include three-fifths (3\/5\u201360%), two-thirds (2\/3\u201366.66...%), and three-quarters (3\/4\u201375%).  A two-thirds vote, when unqualified, means two-thirds or more of the votes cast.[9][10][11] This voting basis is equivalent to the number of votes in favour being at least twice the number of votes against.[12] Abstentions and absences are excluded in calculating a two-thirds vote.[10]  The two-thirds requirement can be qualified to include the entire membership of a body instead of only those present and voting, but such a requirement must be explicitly stated (such as \"two-thirds of those members duly elected and sworn\").[9] In this case, abstentions and absences count as votes against the proposal. Alternatively, the voting requirement could be specified as \"two-thirds of those present\", which has the effect of counting abstentions but not absences as votes against the proposal.[13]  For example, if an organization has 150 members and at a meeting 30 members are present with 25 votes cast, a \"two-thirds vote\" would be 17. (\"Two-thirds of those present\" would be 20, and \"two-thirds of the entire membership\" would be 100.)[14]  Another type of supermajority is three-fifths (60 percent). This requirement could also be qualified to include the entire membership or to include those present.  In 2006, the Constitution of Florida was amended to require a 60% majority to pass new constitutional amendments by popular vote.[15]  In Poland, the Sejm (lower house of the bicameral parliament of Poland) requires a three-fifths majority of MPs to overturn a veto from the President of Poland.[16]  For the Montenegrin independence referendum held in 2006 the European Union envoy Miroslav Laj\u010d\u00e1k proposed independence if a 55% supermajority of votes are cast in favor with a minimum turnout of 50%. Such procedure, ultimately accepted by the government of Montenegro, was somewhat criticized as overriding the traditional practice of requiring a two-thirds supermajority, as practiced in all former Yugoslav countries before (including the previous referendum in Montenegro).  In 2016, the Constitution of Colorado was amended to require a 55% majority to pass new constitutional amendments by popular vote. It had previously been a simple majority.[17]  Related concepts regarding alternatives to the majority vote requirement include a \"majority of the entire membership\" and a \"majority of the fixed membership\".  A majority of the entire membership is a voting basis that requires that more than half of all the members of a body (including those absent and those present but not voting) vote in favor of a proposition in order for it to be passed.[14] In practical terms, it means an absence or an abstention from voting is equivalent to a \"no\" vote.[13] It may be contrasted with a majority vote which only requires more than half of those actually voting to approve a proposition for it to be enacted. An absolute majority may also be the same as a majority of the entire membership, although this usage is not consistent.[8][18]  A supermajority could be specified in this voting basis, such as a vote of \"two-thirds of the entire membership\". By way of illustration, in February 2007 the Italian Government fell after it lost a vote in the Italian Senate by 158 votes to 136 (with 24 abstentions). The government needed an absolute majority in the 318-member house but fell two votes short of the required 160 when two of its own supporters abstained.[19] In the United States Electoral College, an absolute majority of electoral votes are required for it to elect the US president and vice-president.  A majority of the fixed membership is based on the total number of the established fixed membership of the deliberative assembly.[14] It is used only when a specific number of seats or memberships is established in the rules governing the organization. A majority of the fixed membership would be different from a majority of the entire membership if there are vacancies.[14]  For example, say a board has 12 seats. If the board has the maximum number of members, or 12 members, a majority of the entire membership and a majority of the fixed membership would be seven members. However, if there are two vacancies (so that there are only ten members on the board), then a majority of the entire membership would be six members (more than half of ten), but a majority of the fixed membership would still be seven members.[14]  It is possible for organizations that use a majority of the fixed membership to be caught in a stalemate if at least half the membership consists of vacancies, making it impossible to perform any actions until those vacancies are filled.[14] The requirement for a minimum number of members to be present in order to conduct business, called a quorum, may be used to avoid such a possibility.  Similar to the voting basis for the entire membership, a supermajority could be specified for this basis, such as a vote of \"two-thirds of the fixed membership\".  Parliamentary procedure requires that any action that may alter the rights of a minority have a supermajority requirement. Robert's Rules of Order states:[10] As a compromise between the rights of the individual and the rights of the assembly, the principle has been established that a two-thirds vote is required to adopt any motion that: (a) suspends or modifies a rule of order previously adopted; (b) prevents the introduction of a question for consideration; (c) closes, limits, or extends the limits of debate; (d) closes nominations or the polls, or otherwise limits the freedom of nominating or voting; or (e) takes away membership. This book also states:[20] The vote of a majority of the entire membership is frequently an alternative to a requirement of previous notice, and is required in order to rescind and expunge from the minutes (see p. 310). Otherwise, prescribing such a requirement is generally unsatisfactory in an assembly of an ordinary society, since it is likely to be impossible to get a majority of the entire membership even to attend a given meeting, although in certain instances it may be appropriate in conventions or in permanent boards where the members are obligated to attend the meetings. To pass an amendment to the Australian Constitution, a referendum is required and must achieve a \"double majority\": a majority of those voting nationwide, as well as separate majorities in a majority of states (i.e., 4 out of 6 states).[21] Furthermore, in circumstances where a specific state is affected by a referendum, a majority of voters in that state must also agree to the change[22]\u2014referred to as a \"triple majority\".[citation needed]  Article 142 of the Constitution of Bangladesh stipulates a bill in the Jatiya Sangsad must expressly state in its short title its purpose is to amend a provision of the constitution. Constitutional amendments require a two-thirds majority in the unicameral Jatiya Sangsad to become effective.  In Canada, most constitutional amendments can be passed only if identical resolutions are adopted by the House of Commons, the Senate and two-thirds or more of the provincial legislative assemblies representing at least 50 percent of the national population.  Article 20 of the Constitution of Denmark states that if the government or parliament wants to cede parts of national sovereignty to an international body such as the European Union or the United Nations, it has to get a five-sixths majority in the Folketing (150 out of 179 seats).[23] If there is only a simple majority, a referendum must be held on the subject.[23]  The Council of the European Union uses 'Qualified majority voting' for the majority of issues brought before the institution. However, for matters of extreme importance for individual member states, unanimous voting is implemented.[24] An example of this is Article 7 of the Treaty on European Union, whereby a member state can have its rights suspended with the unanimous approval of all other member states.  After the accession of Croatia, on 1\u00a0July 2013, at least 260 votes out of a total of 352 by at least 15 member states were required for legislation to be adopted by qualified majority. From 1\u00a0July 2013, the pass condition translated into:  Requirements to reach an absolute majority is a common feature of voting in the European Parliament (EP) where under the ordinary legislative procedure the EP is required to act by an absolute majority if it is to either amend or reject proposed legislation.[25]  According to Finnish Law, when a new legislative proposal would in some way add, alter or remove a part of the Finnish constitution, a bill requires a 2\/3 majority in the Parliament of Finland. In other words, a legislative proposal that would modify, add or remove a part of the Finnish Constitution requires at least the approval of 134 out of 200 representatives in the Parliament of Finland  Article 368 of the Indian Constitution requires a supermajority of two-thirds of members present and voting in each house of the Indian Parliament, subject to at least by a majority of the total membership of each House of Parliament, to amend the constitution. In addition, in matters affecting the states and judiciary, at least above half of all the states need to ratify the amendment.  The President of Italy is elected by an electoral college consisting of both chambers of Parliament sitting in joint session with 58 electors from the country's 20 regions. In the first three rounds of voting, a candidate must get two-thirds of the votes to win, but from the fourth round onwards only an absolute majority is needed. Reforms to the Constitution need to achieve a supermajority of two-thirds of the votes both in the Chamber and in the Senate to avoid the possibility of being sent to popular vote in order to be confirmed through a referendum.  Amendments to the constitution require a two-thirds majority in both houses of the National Diet and a simple majority in a referendum.[26]  Section 268 of the Electoral Act sets out a number of 'reserved provisions'. These provisions include section 17(1) of the Constitution Act 1986 (regarding Parliament's term length), section 35 of the Electoral Act (regarding the drawing of electoral boundaries), and section 74 of the Electoral Act (designating 18 as the minimum voting age). For a 'reserved provision' to be amended or repealed, a three-quarters majority is required in the House of Representatives or a majority is needed in a national referendum.[27]  Under the Constitution of Nigeria a two-thirds majority is required in the National Assembly to alter the Constitution, enact legislation in a few areas, or remove office holders from some positions, such as Speaker. Legislative override or impeachment of the executive at either the state or federal government level also requires a two-thirds majority of the corresponding legislative assembly.[28]  Under the 1987 Constitution of the Philippines, a two-thirds majority of both chambers of the Congress of the Philippines (the House of Representatives and the Senate) meeting in joint session is required to declare war.[29] A two-thirds majority of both chambers is required to override a presidential veto.[29][30] A two-thirds vote of both chambers of Congress voting separately is required to designate the vice president as acting president in the event that a majority of the Cabinet certifies that the president is \"unable to discharge the powers and duties of his office\" but the president declares that no such inability exists.[29] A two-thirds vote of either chamber is required to suspend or expel a member from that chamber.[29]  Under the 1987 Constitution, \"The Congress may, by a vote of two-thirds of all its Members, call a constitutional convention, or by a majority vote of all its Members, submit to the electorate the question of calling such a convention.\"[29] A three-quarters vote of all the members of the Congress is required to propose an amendment to the Constitution; the proposed amendment is submitted to the people for ratification (by a majority of the votes cast) in a plebiscite.[29]  A two-thirds majority of the Senate is required to ratify treaties, and to remove an impeached official from office.[29] Impeachment by the House, which is the required first step in the removal process, only requires one-third of Representatives to sign a petition (specifically a verified complaint or resolution of impeachment).[29][31][32]  Different amendment procedures apply to different parts of the Constitution. Most of the Articles of the Constitution may be amended by a bill enacted by Parliament if there is at least a supermajority of two-thirds of all elected MPs voting in favour of the bill during its Second and Third Readings in Parliament.[33] This is in contrast to ordinary bills, which only need to be approved by at least a simple majority of all the MPs present and voting.[34]  However, the ruling People's Action Party (PAP) has commanded a majority of more than two-thirds of the seats in Parliament since 1968. Thus, the more stringent amendment requirement has not imposed any major limitation on Parliament's ability to amend the Constitution.[35][failed verification]  A three-fifths majority of legislators is required for a bill to be put to a vote in the National Assembly in order to prevent the ruling party from passing laws without the support of opposition parties.[36] However, if a bill does not achieve the required three-fifths majority at one session without also being rejected, it must then be voted on at the next session even if less than three-fifths of legislators agree to do so.[37]  Additionally, if the President vetoes a bill, the veto can be overridden by a two-thirds majority of legislators.[38]  According to Article 65 of the Constitution of South Korea, impeachment of the President requires a two-third majority of legislators to be effective.[38]  According to Article 113 of the Constitution of South Korea, the Constitutional Court requires a two-thirds majority of its judges to issue rulings nullifying laws, removing impeached officials or dissolving a political party.[38]  According to Article 130 of the Constitution of South Korea, amendments to the constitution must be passed by a two-thirds majority of legislators and then approved by voters at a referendum in order to become effective.[38]  The 1978 Constitution states that a three-fifths majority in both Congress of Deputies and Senate of Spain is needed to pass a constitutional reform, but if a two-thirds majority is reached in the Congress of Deputies, an absolute majority of senators is enough to pass the proposal.[39]  Nevertheless, when a new Constitution is proposed or the proposal's goal is to reform the Preliminary Title, the Chapter on Fundamental Rights and Freedoms or the Title on the Crown, the supermajority becomes significantly harder:  The first way has been used twice (1992 and 2011), but the second has never been used.  The Spanish Constitution states other supermajorities:  Each Spanish autonomous community has its own Statute of Autonomy, working like a local constitution that is subject to the 1978 Constitution and national powers.  The Statute of Autonomy of the Canary Islands states that its economic and fiscal regime and electoral law need a two-thirds majority of the Parliament to be modified.[43] On its behalf, the Ombudsman needs a three-fifths majority to be appointed. Also, if a two-thirds majority votes against a law project, it must be proposed to the following session.  Before the Additional Articles of the Constitution of the Republic of China in 2005, the constitution amendments need to be passed by the National Assembly. Since the Additional Articles ratified on June 7, 2005, the National Assembly was abolished. Amendments of the constitution need to be proposed by more than one-quarter of members of the Legislative Yuan, passed by three-quarters of those present in the meeting, the presence of which must surpass three-quarters of all members of Legislative Yuan, then followed by approval by more than half (50%) of all eligible voters in referendums.  In Turkey, constitutional amendments need a three fifths majority (360 votes) to be put forward to a referendum and a two-thirds majority (400 votes) to be ratified directly.  According to Article 155 of the Constitution of Ukraine, amendments to the constitution, except for Chapter I \u2014 \"General Principles,\" Chapter III \u2014 \"Elections. Referendum\", and Chapter XIII \u2014 \"Introducing Amendments to the Constitution of Ukraine\", must be previously approved by a simple majority of the constitutional composition of the Verkhovna Rada of Ukraine and then passed by a two-thirds majority of the constitutional composition of the Verkhovna Rada of Ukraine at the succeeding regular session of the Verkhovna Rada of Ukraine.  According to Article 156 of the Constitution of Ukraine, amendments to Chapter I \u2014 \"General Principles,\" Chapter III \u2014 \"Elections. Referendum\", and Chapter XIII \u2014 \"Introducing Amendments to the Constitution of Ukraine\" must be passed by a two-thirds majority of the constitutional composition of the Verkhovna Rada of Ukraine and then approved by voters at a referendum in order to become effective.  Prior to its repeal, the Fixed-term Parliaments Act 2011 provided that the United Kingdom House of Commons could be dissolved and an election held before the expiry of its 5-year term by a vote of two-thirds of the membership of the House of Commons. The Act's provision for an early dissolution vote was the only supermajority required in the British Constitution. The Act also provided that Parliament could alternatively be dissolved if the House of Commons passed a motion of no-confidence in the government and no new government were to win a motion of confidence within two weeks of the original vote of no-confidence.  The two-thirds supermajority provision for an early dissolution and election was triggered only once, resulting in the 2017 United Kingdom General Election. The previous election in 2015 had occurred due to the natural expiry of the 5-year term of the House of Commons.  Parliamentary supremacy meant that theoretically the Act could be circumvented by a government with a majority that wanted to bypass the requirement for a two-thirds vote by passing an act that stated, \"Notwithstanding the Fixed-term Parliaments Act 2011, a general election will be called on DATE\". This was precisely what was done to initiate the election in 2019, the final election held whilst the Fixed-term Parliaments Act was in effect.  During the 2019 election, both the governing Conservative Party and the opposition Labour Party expressed a desire to repeal the Fixed-term Parliaments Act and restore the traditional, centuries-old system under which elections could be held at any time, subject to the 5-year maximum term limit established by the Parliament Act 1911. Such a repeal would only require a simple majority.  Ultimately, the Fixed-term Parliaments Act was repealed by the Dissolution and Calling of Parliament Act 2022, thereby removing any supermajority requirement and restoring the previous royal prerogative power to dissolve the House of Commons at any time during its 5-year term.  Section 31A of the Scotland Act 1998[44] and Section 111A of the Government of Wales Act 2006[45] provide that certain provisions of those Acts relating to the functions of and elections to the respective Scottish and Welsh devolved legislatures are protected from amendment by those legislatures, unless a two-thirds supermajority of the total number of members votes in favour.  Regarding Scotland, the protected provisions are:[46]  The protected provisions regarding Wales are the same as those in Scotland; in addition, there are two Wales-specific provisions:[45]  The United Nations Security Council requires a supermajority of the fixed membership on substantive matters (procedural matters require a simple majority of those present and voting). According to Article 27 of the United Nations Charter, at least nine of the Security Council's 15 members (i.e., a three-fifths supermajority) must vote in favor of a draft resolution in order to achieve passage. Specifying the fixed membership has the effect of making abstentions count as votes against\u2014absences are not normal but would be treated the same way.  This is useful for the five permanent members of the council (China, France, the Russian Federation, the United Kingdom, and the United States) because a vote against from any one of them constitutes a veto, which cannot be overridden. Permanent members who do not support a measure but are unwilling to be seen to block it against the wishes of the majority of the council, tend to abstain; abstentions by veto powers are generally seen by close observers of the UN[according to whom?] as the equivalent of not vetoing votes against and have the same impact on the decision of the Security Council.  The Constitution of the United States requires supermajorities in order for certain significant actions to occur.[47]  Amendments to the Constitution may be proposed in one of two ways: a two-thirds supermajority votes of each body of United States Congress or a convention called by Congress on application of two-thirds (currently 34) of the states. Once proposed, the amendment must be ratified by three-quarters (currently 38) of the states (either through the state legislatures, or ratification conventions, whichever \"mode of ratification\" Congress selects).  Congress may pass bills by simple majority votes. If the president vetoes a bill, Congress may override the veto by a two-thirds supermajority of both houses.  A treaty must be ratified by a two-thirds supermajority of the Senate to enter into force and effect.  Section 4 of the Twenty-fifth Amendment to the United States Constitution gives Congress a role to play in the event of a presidential disability. If the vice president and a majority of the president's cabinet declare that the president is unable to serve in that role, the vice president becomes acting president. Within 21 days of such a declaration (or, if Congress is in recess when a president is disabled, 21 days after Congress reconvenes), Congress must vote by two-thirds supermajorities to continue the disability declaration; otherwise, such declaration expires after the 21 days and the president would at that time \"resume\" discharging all the powers and duties of the office. As of 2021, Section 4 has never been invoked.  The House may, by a simple majority vote, impeach a federal official (such as, but not limited to, the president, vice president, or a federal judge). Removal from office requires a two-thirds supermajority of the Senate. In 1842, the House failed to impeach president John Tyler. In 1868, the Senate fell one vote short of removing president Andrew Johnson following his impeachment. In 1999, efforts to remove Bill Clinton following his impeachment in 1998 fell just short of a simple majority, and 17 votes short of the two-thirds supermajority. The impeachment procedure was last used in 2021, when former president Donald Trump was impeached for a second time and subsequently acquitted. Each chamber may expel one of its own members by a two-thirds supermajority vote; this last happened when the House expelled George Santos in 2023.  The 14th Amendment (section 3) bars a person from federal or state office if, after having previously taken an oath to support the Constitution as a federal or state officer, \"shall have engaged in insurrection or rebellion against the same, or given aid or comfort to the enemies thereof\". However, both the House and Senate may jointly override this restriction with a two-thirds supermajority vote each.  A two-thirds supermajority in the Senate is 67 out of 100 senators, while a two-thirds supermajority in the House is 290 out of 435 representatives. However, since many votes take place without every seat in the House filled and representative participating, it does not often require 67 senators or 290 representatives to achieve this supermajority.  Apart from these constitutional requirements, a Senate rule (except in cases covered by the nuclear option, or of a rule change) requires an absolute supermajority of three-fifths to move to a vote through a cloture motion, which closes debate on a bill or nomination, thus ending a filibuster by a minority of members. In current practice, the mere threat of a filibuster prevents passing almost any measure that has less than three-fifths agreement in the Senate, 60 of the 100 senators if every seat is filled.  For state legislatures in the United States, Mason's Manual says, \"A deliberative body cannot by its own act or rule require a two-thirds vote to take any action where the constitution or controlling authority requires only a majority vote. To require a two-thirds vote, for example, to take any action would be to give to any number more than one-third of the members the power to defeat the action and amount to a delegation of the powers of the body to a minority.\"[48] Some states require a supermajority for passage of a constitutional amendment or statutory initiative.[49]  Many state constitutions allow or require amendments to their own constitutions to be proposed by supermajorities of the state legislature; these amendments must usually be approved by the voters at one or more subsequent elections. Michigan, for instance, allows the Legislature to propose an amendment to the Michigan Constitution; it must then be ratified by the voters at the next general election (unless a special election is called).[50]  In most states, the state legislature may override a governor's veto of legislation. In most states, a two-thirds supermajority of both chambers is required.[51] However, in some states (e.g., Illinois, Maryland and North Carolina), only a three-fifths supermajority is required,[52][53][54] while in Kentucky and West Virginia only a normal majority is needed.  One common provision of so-called \"taxpayer bill of rights\" laws (either in state statutes or state constitutions) is requirement of a supermajority vote in the state legislature to increase taxes. The National Conference of State Legislatures reported in 2010 that fifteen states required a supermajority vote (either a three-fifths, two-thirds or three-quarters majority vote in both chambers) to pass some or all tax increases.[55]  Supermajority requirements for tax increases have been criticized as \"deeply flawed\" by a report by the progressive Center on Budget and Policy Priorities because such requirements empower a minority of legislators, making it difficult to close tax loopholes or fund transportation infrastructure, and also may encourage pork-barrel spending as a trade-off to ensure passage of a tax increase (see logrolling).[56]  The Rome Statute requires a seven-eighths majority of participating states to be amended. "},{"title":"Vulcanization","content":"  Vulcanization (British English: Vulcanisation) is a range of processes for hardening rubbers.[1] The term originally referred exclusively to the treatment of natural rubber with sulfur, which remains the most common practice. It has also grown to include the hardening of other (synthetic) rubbers via various means. Examples include silicone rubber via room temperature vulcanizing and chloroprene rubber (neoprene) using metal oxides.   Vulcanization can be defined as the curing of elastomers, with the terms 'vulcanization' and 'curing' sometimes used interchangeably in this context. It works by forming cross-links between sections of the polymer chain which results in increased rigidity and durability, as well as other changes in the mechanical and electrical properties of the material.[2] Vulcanization, in common with the curing of other thermosetting polymers, is generally irreversible.  The word was suggested by William Brockedon (a friend of Thomas Hancock who attained the British patent for the process) coming from the god Vulcan who was associated with heat and sulfur in volcanoes.[3]  Rubber \u2013 latex \u2013 had been known for thousands of years in Mesoamerican cultures, used to make balls, sandal soles, rubber bands, and waterproof containers. Rubber was processed for specific applications within the Aztec Empire \u2013 rubber and latex goods were processed and constructed, and then shipped to the capital for use or further distribution.[4]  Early rubber tube tires in the 19th century would grow sticky on a hot road. Debris would get stuck in them and eventually the tires would burst.   Charles Goodyear, in the 1830s, was working to improve those tube tires. He tried heating up rubber in order to mix other chemicals with it. This seemed to harden and improve the rubber, though this was due to the heating itself and not the chemicals used. Not realizing this, he repeatedly ran into setbacks when his announced hardening formulas did not work consistently. One day in 1839, when trying to mix rubber with sulfur, Goodyear accidentally dropped the mixture in a hot frying pan. To his astonishment, instead of melting further or vaporizing, the rubber remained firm and, as he increased the heat, the rubber became harder. Goodyear worked out a consistent system for this hardening, and by 1844 was producing the rubber on an industrial scale.[citation needed]  There are many uses for vulcanized materials, some examples of which are rubber hoses, shoe soles, toys, erasers, hockey pucks, shock absorbers, conveyor belts,[5] vibration mounts\/dampers, insulation materials, tires, and bowling balls.[6] Most rubber products are vulcanized as this greatly improves their lifespan, function, and strength.  In contrast with thermoplastic processes (the melt-freeze process that characterize the behaviour of most modern polymers), vulcanization, in common with the curing of other thermosetting polymers, is generally irreversible. Five types of curing systems are in common use:  The most common vulcanizing methods depend on sulfur. Sulfur, by itself, is a slow vulcanizing agent and does not vulcanize synthetic polyolefins. Accelerated vulcanization is carried out using various compounds that modify the kinetics of crosslinking;[7] this mixture is often referred to as a cure package. The main polymers subjected to sulfur vulcanization are polyisoprene (natural  rubber) and styrene-butadiene rubber (SBR), which are used for most street-vehicle tires. The cure package is adjusted specifically for the substrate and the application. The reactive sites\u2014cure sites\u2014are allylic hydrogen atoms. These C-H bonds are adjacent to carbon-carbon double bonds (>C=C<). During vulcanization, some of these C-H bonds are replaced by chains of sulfur atoms that link with a cure site of another polymer chain. These bridges contain between one and several atoms. The number of sulfur atoms in the crosslink strongly influences the physical properties of the final rubber article. Short crosslinks give the rubber better heat resistance. Crosslinks with higher number of sulfur atoms give the rubber good dynamic properties but less heat resistance. Dynamic properties are important for flexing movements of the rubber article, e.g., the movement of a side-wall of a running tire. Without good flexing properties these movements rapidly form cracks, and ultimately will make the rubber article fail.  The vulcanization of neoprene or polychloroprene rubber (CR rubber) is carried out using metal oxides (specifically MgO and ZnO, sometimes Pb3O4) rather than sulfur compounds which are presently used with many natural and synthetic rubbers. In addition, because of various processing factors (principally scorch, this being the premature cross-linking of rubbers due to the influence of heat), the choice of accelerator is governed by different rules to other diene rubbers. Most conventionally used accelerators are problematic when CR rubbers are cured and the most important accelerant has been found to be ethylene thiourea (ETU), which, although being an excellent and proven accelerator for polychloroprene, has been classified as reprotoxic. The European rubber industry has started a research project SafeRubber[8] to develop a safer alternative to the use of ETU.  Room-temperature vulcanizing (RTV) silicone is constructed of reactive oil-based polymers combined with strengthening mineral fillers. There are two types of room-temperature vulcanizing silicone: "},{"title":"Association football","content":"  Association football, commonly known as football, or soccer,[a] is a team sport played between two teams of 11 players each, who primarily use their feet to propel a ball around a rectangular field called a pitch. The objective of the game is to score more goals than the opposing team by moving the ball beyond the goal line into a rectangular-framed goal defended by the opposing team. Traditionally, the game has been played over two 45-minute halves, for a total match time of 90 minutes. With an estimated 250 million players active in over 200 countries and territories, it is the world's most popular sport.  The game of association football is played in accordance with the Laws of the Game, a set of rules that has been in effect since 1863 and maintained by the IFAB since 1886. The game is played with a football that is 68\u201370\u00a0cm (27\u201328\u00a0in) in circumference. The two teams compete to get the ball into the other team's goal (between the posts, under the bar, and across the goal line), thereby scoring a goal. When the ball is in play, the players mainly use their feet, but may use any other part of their body, except for their hands or arms, to control, strike, or pass the ball. Only the goalkeepers may use their hands and arms, and only then within the penalty area. The team that has scored more goals at the end of the game is the winner. There are situations where a goal can be disallowed, such as an offside call or a foul in the build-up to the goal. Depending on the format of the competition, an equal number of goals scored may result in a draw being declared, or the game goes into extra time or a penalty shoot-out.[5]  Internationally, association football is governed by FIFA. Under FIFA, there are six continental confederations: AFC, CAF, CONCACAF, CONMEBOL, OFC, and UEFA. Of these confederations, CONMEBOL is the oldest one, being founded in 1916. National associations (e.g. The FA or JFA) are responsible for managing the game in their own countries both professionally and at an amateur level, and coordinating competitions in accordance with the Laws of the Game. The most senior and prestigious international competitions are the FIFA World Cup and the FIFA Women's World Cup. The men's World Cup is the most-viewed sporting event in the world, surpassing the Olympic Games.[6] The two most prestigious competitions in European club football are the UEFA Champions League and the UEFA Women's Champions League, which attract an extensive television audience throughout the world. Since 2009, the final of the men's tournament has been the most-watched annual sporting event in the world.[7]    Association football is one of a family of football codes that emerged from various ball games played worldwide since antiquity. Within the English-speaking world, the sport is now usually called \"football\" in Great Britain and most of Ulster in the north of Ireland, whereas people usually call it \"soccer\" in regions and countries where other codes of football are prevalent, such as Australia,[8] Canada, South Africa, most of Ireland (excluding Ulster),[9] and the United States. A notable exception is New Zealand, where in the first two decades of the 21st century, under the influence of international television, \"football\" has been gaining prevalence, despite the dominance of other codes of football, namely rugby union and rugby league.[10]  The term soccer comes from Oxford \"-er\" slang, which was prevalent at the University of Oxford in England from about 1875, and is thought to have been borrowed from the slang of Rugby School. Initially spelt assoccer (a shortening of \"association\"), it was later reduced to the modern spelling.[11][12] This form of slang also gave rise to rugger for rugby football, fiver and tenner for five pound and ten pound notes, and the now-archaic footer that was also a name for association football.[13] The word soccer arrived at its current form in 1895 and was first recorded in 1889 in the earlier form of socca.[14]  Kicking ball games arose independently multiple times across multiple cultures.[b] The Chinese competitive game cuju (\u8e74\u97a0, literally \"kick ball\"; also known as tsu chu) resembles modern association football.[16] This is the earliest form of the game for which there is scientific evidence, a military manual from the Han dynasty.[17] Cuju players could use any part of the body apart from hands and the intent was to kick a ball through an opening into a net. During the Han dynasty (206 BCE \u2013 220 CE), cuju games were standardised and rules were established.[18] The Silk Road facilitated the transmission of cuju, especially the game popular in the Tang dynasty, the period when the inflatable ball was invented and replaced the stuffed ball.[19] Other East Asian games included kemari in Japan and chuk-guk in Korea, both influenced by cuju.[20][21] Kemari originated after the year 600 during the Asuka period. It was a ceremonial rather than a competitive game, and involved the kicking of a mari, a ball made of animal skin.[22] In North America, pasuckuakohowog was a ball game played by the Algonquians; it was described as \"almost identical to the kind of folk football being played in Europe at the same time, in which the ball was kicked through goals\".[23]  Phaininda and episkyros were Greek ball games.[17][24] An image of an episkyros player depicted in low relief on a stele of c.\u2009375\u2013400 BCE in the National Archaeological Museum of Athens[15] appears on the UEFA European Championship trophy.[25] Athenaeus, writing in 228 CE, mentions the Roman ball game harpastum. Phaininda, episkyros and harpastum were played involving hands and violence. They all appear to have resembled rugby football, wrestling, and volleyball more than what is recognisable as modern football.[18][26][27][28][29][30] As with pre-codified mob football, the antecedent of all modern football codes, these three games involved more handling the ball than kicking it.[31][32]  Association football in itself does not have a classical history.[25] Notwithstanding any similarities to other ball games played around the world, FIFA has described that no historical connection exists with any game played in antiquity outside Europe.[33] The history of football in England dates back to at least the eighth century.[34] The modern rules of association football are based on the mid-19th century efforts to standardise the widely varying forms of football played in the public schools of England.  The Cambridge rules, first drawn up at the University of Cambridge in 1848, were particularly influential in the development of subsequent codes, including association football. The Cambridge rules were written at Trinity College, Cambridge, at a meeting attended by representatives from Eton, Harrow, Rugby, Winchester and Shrewsbury schools. They were not universally adopted. During the 1850s, many clubs unconnected to schools or universities were formed throughout the English-speaking world to play various forms of football. Some came up with their own distinct codes of rules, most notably the Sheffield Football Club, formed by former public school pupils in 1857,[35] which led to the formation of a Sheffield FA in 1867. In 1862, John Charles Thring of Uppingham School also devised an influential set of rules.[36]  These ongoing efforts contributed to the formation of The Football Association (The FA) in 1863, which first met on the morning of 26 October 1863 at the Freemasons' Tavern in Great Queen Street, London.[37] The only school to be represented on this occasion was Charterhouse. The Freemasons' Tavern was the setting for five more meetings of The FA between October and December 1863; the English FA eventually issued the first comprehensive set of rules named Laws of the Game, forming modern football.[38] The laws included bans on running with the ball in hand and hacking (kicking an opponent in the shins), tripping and holding.[39] Eleven clubs, under the charge of FA secretary Ebenezer Cobb Morley, ratified the original thirteen laws of the game.[37] The sticking point was hacking, which a twelfth club at the meeting, Blackheath FC, had wanted to keep, resulting in them withdrawing from the FA.[37] Other English rugby clubs followed this lead and did not join the FA, and instead in 1871, along with Blackheath, formed the Rugby Football Union. The FA rules included handling of the ball by \"marks\" and the lack of a crossbar, rules which made it remarkably similar to Victorian rules football being developed at that time in Australia. The Sheffield FA played by its own rules until the 1870s, with the FA absorbing some of its rules until there was little difference between the games.[40]  The world's oldest football competition is the FA Cup, which was founded by the footballer and cricketer Charles W. Alcock, and has been contested by English teams since 1872. The first official international football match also took place in 1872, between Scotland and England in Glasgow, again at the instigation of Alcock. England is also home to the world's first football league, which was founded in Birmingham in 1888 by Aston Villa director William McGregor.[41] The original format contained 12 clubs from the Midlands and Northern England.[42]  Laws of the Game are determined by the International Football Association Board (IFAB).[43] The board was formed in 1886[44] after a meeting in Manchester of the Football Association, the Scottish Football Association, the Football Association of Wales, and the Irish Football Association. FIFA, the international football body, was formed in Paris in 1904 and declared that they would adhere to the Laws of the Game of the Football Association.[45] The growing popularity of the international game led to the admittance of FIFA representatives to the IFAB in 1913. The board consists of four representatives from FIFA and one representative from each of the four British associations.[46]  For most of the 20th century, Europe and South America were the dominant regions in association football. The FIFA World Cup, inaugurated in 1930, became the main stage for players of both continents to show their worth and the strength of their national teams.[47] In the second half of the century, the European Cup and the Copa Libertadores were created, and the champions of these two club competitions would contest the Intercontinental Cup to prove which team was the best in the world.[48]  In the 21st century, South America has continued to produce some of the best footballers in the world,[49] but its clubs have fallen behind the still dominant European clubs, which often sign the best players from Latin America and elsewhere.[47][49] Meanwhile, football has improved in Africa, Asia and North America,[49] and nowadays, these regions are at least on equal grounds with South America in club football,[50] although countries in the Caribbean and Oceania regions (except Australia) have yet to make a mark in international football.[51][52] When it comes to men's national teams, Europeans and South Americans continue to dominate the FIFA World Cup, as no team from any other region has managed to even reach the final.[47][49] These regional trends do not hold true for the women's game, as the United States women's national team has won the FIFA Women's World Cup four times, more than any other women's team. [53]  Football is played at a professional level all over the world. Millions of people regularly go to football stadiums to follow their favourite teams,[54] while billions more watch the game on television or on the internet.[55][56] A very large number of people also play football at an amateur level. According to a survey conducted by FIFA published in 2001, over 240 million people from more than 200 countries regularly play football.[57] Football has the highest global television audience in sport.[58]  In many parts of the world, football evokes great passions and plays an important role in the life of individual fans, local communities, and even nations. Ryszard Kapu\u015bci\u0144ski says that Europeans who are polite, modest, or humble fall easily into rage when playing or watching football games.[59] The Ivory Coast national football team helped secure a truce to the nation's civil war in 2006[60] and it helped further reduce tensions between government and rebel forces in 2007 by playing a match in the rebel capital of Bouak\u00e9, an occasion that brought both armies together peacefully for the first time.[61] By contrast, football is widely considered to have been the final proximate cause for the Football War in June 1969 between El Salvador and Honduras.[62] The sport also exacerbated tensions at the beginning of the Croatian War of Independence of the 1990s, when a match between Dinamo Zagreb and Red Star Belgrade degenerated into rioting in May 1990.[63]  Women's association football has historically seen opposition, with national associations severely curbing its development and several outlawing it completely. Women may have been playing football for as long as the game has existed. Evidence shows that a similar ancient game (cuju, or tsu chu) was played by women during the Han dynasty (25\u2013220 CE), as female figures are depicted in frescoes of the period playing tsu chu.[64][65] There are also reports of annual football matches played by women in Midlothian, Scotland, during the 1790s.[66][67]  Association football, the modern game, has documented early involvement of women.[67] In 1863, football governing bodies introduced standardised rules to prohibit violence on the pitch, making it more socially acceptable for women to play.[68] The first match recorded by the Scottish Football Association took place in 1892 in Glasgow.[66] In England, the first recorded game of football between women took place in 1895.[68] Women's football has traditionally been associated with charity games and physical exercise, particularly in the United Kingdom.[69]  Association football continued to be played by women since the time of the first recorded women's games in the late 19th century.[69][70] The best-documented early European team was founded by activist Nettie Honeyball in England in 1894. It was named the British Ladies' Football Club. Honeyball is quoted as, \"I founded the association late last year [1894], with the fixed resolve of proving to the world that women are not the 'ornamental and useless' creatures men have pictured. I must confess, my convictions on all matters where the sexes are so widely divided are all on the side of emancipation, and I look forward to the time when ladies may sit in Parliament and have a voice in the direction of affairs, especially those which concern them most.\"[71] Honeyball and those like her paved the way for women's football. However, the women's game was frowned upon by the British football associations and continued without their support. It has been suggested that this was motivated by a perceived threat to the \"masculinity\" of the game.[72]  Women's football became popular on a large scale at the time of the First World War, when female employment in heavy industry spurred the growth of the game, much as it had done for men 50 years earlier. The most successful team of the era was Dick, Kerr Ladies F.C. of Preston, England. The team played in one of the first women's international matches against a French XI team in 1920,[73][74] and also made up most of the England team against a Scottish Ladies XI in the same year, winning 22\u20130.[66]  Despite being more popular than some men's football events, with one match seeing a 53,000 strong crowd in 1920,[75][76] women's football in England suffered a blow in 1921 when The Football Association outlawed the playing of the game on association members' pitches,[77] stating that \"the game of football is quite unsuitable for females and should not be encouraged.\"[78] Players and football writers have argued that this ban was, in fact, due to envy of the large crowds that women's matches attracted,[76] and because the FA had no control over the money made from the women's game.[78] The FA ban led to the formation of the short-lived English Ladies Football Association and play moved to rugby grounds.[79] Women's football also faced bans in several other countries, notably in Brazil from 1941 to 1979,[80] in France from 1941 to 1970,[81] and in Germany from 1955 to 1970.[82]  Restrictions began to be reduced in the 1960s and 1970s. The Italian women's football league was established in 1968.[83] In December 1969, the Women's Football Association was formed in England,[69][84] with the sport eventually becoming the most prominent team sport for women in the United Kingdom.[69] Two unofficial women's World Cups were organised by the FIEFF in 1970 and in 1971.  Also in 1971, Union of European Football Associations (UEFA) members voted to officially recognise women's football,[69] while The Football Association rescinded the ban that prohibited women from playing on association members' pitches in England.[84]  Women's football still faces many struggles, but its worldwide growth[85] has seen major competitions being launched at both the national and international levels, mirroring the men's competitions. The FIFA Women's World Cup was inaugurated in 1991: the first tournament was held in China, featuring 12 teams from the respective six confederations.  The World Cup has been held every four years since;[86] by the 2019 FIFA Women's World Cup in France, it had expanded to 24 national teams, and 1.12 billion viewers watched the competition.[87] Women's football has been an Olympic event since 1996.[88]  North America is the dominant region in women's football, with the United States winning most FIFA Women's World Cups and Olympic tournaments. Europe and Asia come second and third in terms of international success,[89][90] and the women's game has been improving in South America.[91]  Association football is played in accordance with a set of rules known as the Laws of the Game. The game is played using a spherical ball of 68\u201370\u00a0cm (27\u201328\u00a0in) circumference,[92] known as the football (or soccer ball). Two teams of eleven players each compete to get the ball into the other team's goal (between the posts and under the bar), thereby scoring a goal. The team that has scored more goals at the end of the game is the winner; if both teams have scored an equal number of goals then the game is a draw. Each team is led by a captain who has only one official responsibility as mandated by the Laws of the Game: to represent their team in the coin toss before kick-off or penalty kicks.[5]  The primary law is that players other than goalkeepers may not deliberately handle the ball with their hands or arms during play, though they must use both their hands during a throw-in restart. Although players usually use their feet to move the ball around, they may use any part of their body (notably, \"heading\" with the forehead)[93] other than their hands or arms.[94] Within normal play, all players are free to play the ball in any direction and move throughout the pitch, though players may not pass to teammates who are in an offside position.[95]  During gameplay, players attempt to create goal-scoring opportunities through individual control of the ball, such as by dribbling, passing the ball to a teammate, and by taking shots at the goal, which is guarded by the opposing goalkeeper. Opposing players may try to regain control of the ball by intercepting a pass or through tackling the opponent in possession of the ball; however, physical contact between opponents is restricted. Football is generally a free-flowing game, with play stopping only when the ball has left the field of play or when play is stopped by the referee for an infringement of the rules. After a stoppage, play recommences with a specified restart.[96]  At a professional level, most matches produce only a few goals. For example, the 2022\u201323 season of the English Premier League produced an average of 2.85 goals per match.[97] The Laws of the Game do not specify any player positions other than goalkeeper,[98] but a number of specialised roles have evolved.[99] Broadly, these include three main categories: strikers, or forwards, whose main task is to score goals; defenders, who specialise in preventing their opponents from scoring; and midfielders, who dispossess the opposition and keep possession of the ball to pass it to the forwards on their team. Players in these positions are referred to as outfield players, to distinguish them from the goalkeeper.  These positions are further subdivided according to the area of the field in which the player spends the most time. For example, there are central defenders and left and right midfielders. The ten outfield players may be arranged in any combination. The number of players in each position determines the style of the team's play; more forwards and fewer defenders creates a more aggressive and offensive-minded game, while the reverse creates a slower, more defensive style of play. While players typically spend most of the game in a specific position, there are few restrictions on player movement, and players can switch positions at any time.[100] The layout of a team's players is known as a formation. Defining the team's formation and tactics is usually the prerogative of the team's manager.[101]  There are 17 laws in the official Laws of the Game, each containing a collection of stipulations and guidelines. The same laws are designed to apply to all levels of football for both sexes, although certain modifications for groups such as juniors, seniors and people with physical disabilities are permitted.[c] The laws are often framed in broad terms, which allow flexibility in their application depending on the nature of the game. The Laws of the Game are published by FIFA, but are maintained by the IFAB.[102] In addition to the seventeen laws, numerous IFAB decisions and other directives contribute to the regulation of association football.[103][104] Within the United States, Major League Soccer used a distinct ruleset during the 1990s[105] and the National Federation of State High School Associations and National Collegiate Athletic Association still use rulesets that are comparable to, but different from, the IFAB Laws.  Each team consists of a maximum of eleven players (excluding substitutes), one of whom must be the goalkeeper. Competition rules may state a minimum number of players required to constitute a team, which is usually seven. Goalkeepers are the only players allowed to play the ball with their hands or arms, provided they do so within the penalty area in front of their own goal. Though there are a variety of positions in which the outfield (non-goalkeeper) players are strategically placed by a coach, these positions are not defined or required by the Laws.[98]  The basic equipment or kit players are required to wear includes a shirt, shorts, socks, footwear and adequate shin guards. An athletic supporter and protective cup is highly recommended for male players by medical experts and professionals.[106][107] Headgear is not a required piece of basic equipment, but players today may choose to wear it to protect themselves from head injury.[108] Players are forbidden to wear or use anything that is dangerous to themselves or another player, such as jewellery or watches. The goalkeeper must wear clothing that is easily distinguishable from that worn by the other players and the match officials.[109]  A number of players may be replaced by substitutes during the course of the game. The maximum number of substitutions permitted in most competitive international and domestic league games is five in 90 minutes,[110] with each team being allowed one more if the game should go into extra-time; the permitted number may vary in other competitions or in friendly matches. Common reasons for a substitution include injury, tiredness, ineffectiveness, a tactical switch, or timewasting at the end of a finely poised game. In standard adult matches, a player who has been substituted may not take further part in a match.[111] IFAB recommends \"that a match should not continue if there are fewer than seven players in either team\". Any decision regarding points awarded for abandoned games is left to the individual football associations.[112]   A game is officiated by a referee, who has \"full authority to enforce the Laws of the Game in connection with the match to which he has been appointed\" (Law 5), and whose decisions are final. The referee is assisted by two assistant referees. In many high-level games there is also a fourth official who assists the referee and may replace another official should the need arise.[113]  Goal line technology is used to measure if the whole ball has crossed the goal-line thereby determining whether a goal has been scored or not; this was brought in to prevent controversy. Video assistant referees (VAR) have also been increasingly introduced in high-level matches to assist officials through video replays to correct clear and obvious mistakes. There are four types of calls that can be reviewed: mistaken identity in awarding a red or yellow card, goals and whether there was a violation during the buildup, direct red card decisions, and penalty decisions.[114]  The ball is spherical with a circumference of between 68 and 70\u00a0cm (27 and 28\u00a0in), a weight in the range of 410 to 450\u00a0g (14 to 16\u00a0oz), and a pressure between 0.6 and 1.1 standard atmospheres (8.5 and 15.6 pounds per square inch) at sea level. In the past the ball was made up of leather panels sewn together, with a latex bladder for pressurisation, but modern balls at all levels of the game are now synthetic.[115][116]  As the Laws were formulated in England, and were initially administered solely by the four British football associations within IFAB, the standard dimensions of a football pitch were originally expressed in imperial units. The Laws now express dimensions with approximate metric equivalents (followed by traditional units in brackets), though use of imperial units remains popular in English-speaking countries with a relatively recent history of metrication (or only partial metrication), such as Britain.[117]  The length of the pitch, or field, for international adult matches is in the range of 100\u2013110\u00a0m (110\u2013120\u00a0yd) and the width is in the range of 64\u201375\u00a0m (70\u201380\u00a0yd). Fields for non-international matches may be 90\u2013120\u00a0m (100\u2013130\u00a0yd) in length and 45\u201390\u00a0m (50\u2013100\u00a0yd) in width, provided the pitch does not become square. In 2008, the IFAB initially approved a fixed size of 105\u00a0m (115\u00a0yd) long and 68\u00a0m (74\u00a0yd) wide as a standard pitch dimension for international matches;[118] however, this decision was later put on hold and was never actually implemented.[119]  The longer boundary lines are touchlines, while the shorter boundaries (on which the goals are placed) are goal lines. A rectangular goal is positioned on each goal line, midway between the two touchlines.[120] The inner edges of the vertical goal posts must be 7.32\u00a0m (24\u00a0ft) apart, and the lower edge of the horizontal crossbar supported by the goal posts must be 2.44\u00a0m (8\u00a0ft) above the ground. Nets are usually placed behind the goal, but are not required by the Laws.[121]  In front of the goal is the penalty area. This area is marked by the goal line, two lines starting on the goal line 16.5\u00a0m (18\u00a0yd) from the goalposts and extending 16.5\u00a0m (18\u00a0yd) into the pitch perpendicular to the goal line, and a line joining them. This area has a number of functions, the most prominent being to mark where the goalkeeper may handle the ball and where a penalty foul by a member of the defending team becomes punishable by a penalty kick. Other markings define the position of the ball or players at kick-offs, goal kicks, penalty kicks and corner kicks.[122]  A standard adult football match consists of two halves of 45 minutes each. Each half runs continuously, meaning that the clock is not stopped when the ball is out of play. There is usually a 15-minute half-time break between halves. The end of the match is known as full-time.[123] The referee is the official timekeeper for the match, and may make an allowance for time lost through substitutions, injured players requiring attention, or other stoppages. This added time is called \"additional time\" in FIFA documents,[124][125] but is most commonly referred to as stoppage time or injury time, while lost time can also be used as a synonym. The duration of stoppage time is at the sole discretion of the referee. Stoppage time does not fully compensate for the time in which the ball is out of play, and a 90-minute game typically involves about an hour of \"effective playing time\".[126][127] The referee alone signals the end of the match. In matches where a fourth official is appointed, towards the end of the half, the referee signals how many minutes of stoppage time they intend to add. The fourth official then informs the players and spectators by holding up a board showing this number. The signalled stoppage time may be further extended by the referee.[123] Added time was introduced because of an incident which happened in 1891 during a match between Stoke and Aston Villa. Trailing 1\u20130 with two minutes remaining, Stoke were awarded a penalty kick. Villa's goalkeeper deliberately kicked the ball out of play; by the time it was recovered, the clock had run out and the game was over, leaving Stoke unable to attempt the penalty.[128] The same law also states that the duration of either half is extended until a penalty kick to be taken or retaken is completed; thus, no game can end with an uncompleted penalty.[129]  In league competitions, games may end in a draw. In knockout competitions where a winner is required, various methods may be employed to break such a deadlock; some competitions may invoke replays.[130] A game tied at the end of regulation time may go into extra time, which consists of two further 15-minute periods. If the score is still tied after extra time, some competitions allow the use of penalty shoot-outs (known officially in the Laws of the Game as \"kicks from the penalty mark\") to determine which team will progress to the next stage of the tournament or be the champion. Goals scored during extra time periods count towards the final score of the game, but kicks from the penalty mark are only used to decide the team that progresses to the next part of the tournament, with goals scored in a penalty shoot-out not making up part of the final score.[5]  In competitions using two-legged matches, each team competes at home once, with an aggregate score from the two matches deciding which team progresses. Where aggregates are equal, the away goals rule may be used to determine the winners, in which case the winner is the team that scored the most goals in the leg they played away from home. If the result is still equal, extra time and potentially a penalty shoot-out are required.[5]  Under the Laws, the two basic states of play during a game are ball in play and ball out of play. From the beginning of each playing period with a kick-off until the end of the playing period, the ball is in play at all times, except when either the ball leaves the field of play, or play is stopped by the referee. When the ball becomes out of play, play is restarted by one of eight restart methods depending on how it went out of play:  A foul occurs when a player commits an offence listed in the Laws of the Game while the ball is in play. The offences that constitute a foul are listed in Law 12. Handling the ball deliberately, tripping an opponent, or pushing an opponent, are examples of \"penal fouls\", punishable by a direct free kick or penalty kick depending on where the offence occurred. Other fouls are punishable by an indirect free kick.[94]  The referee may punish a player's or substitute's misconduct by a caution (yellow card) or dismissal (red card). A second yellow card in the same game leads to a red card, which results in a dismissal. A player given a yellow card is said to have been \"booked\", the referee writing the player's name in their official notebook. If a player has been dismissed, no substitute can be brought on in their place and the player may not participate in further play. Misconduct may occur at any time, and while the offences that constitute misconduct are listed, the definitions are broad. In particular, the offence of \"unsporting behaviour\" may be used to deal with most events that violate the spirit of the game, even if they are not listed as specific offences. A referee can show a yellow or red card to a player, substitute, substituted player, and to non-players such as managers and support staff.[94][136]  Rather than stopping play, the referee may allow play to continue if doing so will benefit the team against which an offence has been committed. This is known as \"playing an advantage\".[137] The referee may \"call back\" play and penalise the original offence if the anticipated advantage does not ensue within \"a few seconds\". Even if an offence is not penalised due to advantage being played, the offender may still be sanctioned for misconduct at the next stoppage of play.[138]  The referee's decision in all on-pitch matters is considered final.[139] The score of a match cannot be altered after the game, even if later evidence shows that decisions (including awards\/non-awards of goals) were incorrect.  Along with the general administration of the sport, football associations and competition organisers also enforce good conduct in wider aspects of the game, dealing with issues such as comments to the press, clubs' financial management, doping, age fraud and match fixing. Most competitions enforce mandatory suspensions for players who are sent off in a game.[140] Some on-field incidents, if considered very serious (such as allegations of racial abuse), may result in competitions deciding to impose heavier sanctions than those normally associated with a red card.[d] Some associations allow for appeals against player suspensions incurred on-field if clubs feel a referee was incorrect or unduly harsh.[140]  Sanctions for such infractions may be levied on individuals or on clubs as a whole. Penalties may include fines, point deductions (in league competitions) or even expulsion from competitions. For example, the English Football League deduct 12 points from any team that enters financial administration.[141] Among other administrative sanctions are penalties against game forfeiture. Teams that had forfeited a game or had been forfeited against would be awarded a technical loss or win.  The recognised international governing body of football (and associated games, such as futsal and beach soccer)[c] is FIFA. The FIFA headquarters are located in Z\u00fcrich, Switzerland. Six regional confederations are associated with FIFA; these are:[142]  National associations (or national federations) oversee football within individual countries. These are generally synonymous with sovereign states (for example, the Cameroonian Football Federation in Cameroon), but also include a smaller number of associations responsible for sub-national entities or autonomous regions (for example, the Scottish Football Association in Scotland). 211 national associations are affiliated both with FIFA and with their respective continental confederations.[142] Other national associations may be members of continental confederations but otherwise not participate in FIFA competitions.[143]  While FIFA is responsible for arranging competitions and most rules related to international competition, the actual Laws of the Game are set by the IFAB, where each of the UK Associations has one vote, while FIFA collectively has four votes.[46]    International competitions in association football principally consist of two varieties: competitions involving representative national teams or those involving clubs based in multiple nations and national leagues. International football, without qualification, most often refers to the former. In the case of international club competition, it is the country of origin of the clubs involved, not the nationalities of their players, that renders the competition international in nature.  The major international competition in football is the World Cup, organised by FIFA. This competition has taken place every four years since 1930, with the exception of the 1942 and 1946 tournaments, which were cancelled because of World War II. As of 2022, over 200 national teams compete in qualifying tournaments within the scope of continental confederations for a place in the finals.[144] The finals tournament, held every four years, involved 32 national teams (expanding to 48 teams for the 2026 tournament) competing over a four-week period.[145][e] The World Cup is the most prestigious association football tournament as well as the most widely viewed and followed sporting event in the world, exceeding even the Olympic Games; the cumulative audience of all matches of the 2006 FIFA World Cup was estimated to be 26.29 billion with an estimated 715.1 million people watching the final match, one-ninth of the entire population of the planet.[146][147][148][149] The 1958 World Cup saw the emergence of Pel\u00e9 as a global sporting star, a period that coincided with \"the explosive spread of television, which massively amplified his presence everywhere\".[150] The current champions are Argentina, who won their third title at the 2022 tournament in Qatar.[151] The FIFA Women's World Cup has been held every four years since 1991. Under the tournament's current format that was expanded in 2023, national teams vie for 31 slots in a three-year qualification phase, while the host nation's team enters automatically as the 32nd slot.[152] The current champions are Spain, after winning their first title in the 2023 tournament.[153]  There has been a football tournament at every Summer Olympic Games since 1900, except at the 1932 games in Los Angeles when FIFA and the IOC had disagreed over the status of amateur players.[154][155] Before the inception of the World Cup, the Olympics (especially during the 1920s) were the most prestigious international event. Originally, the tournament was for amateurs only.[45] As professionalism spread around the world, the gap in quality between the World Cup and the Olympics widened. The countries that benefited most were the Soviet Bloc countries of Eastern Europe, where top athletes were state-sponsored while retaining their status as amateurs. Between 1948 and 1980, 23 out of 27 Olympic medals were won by Eastern Europe, with only Sweden (gold in 1948 and bronze in 1952), Denmark (bronze in 1948 and silver in 1960) and Japan (bronze in 1968) breaking their dominance. For the 1984 Los Angeles Games, the IOC allowed professional players to compete. Since 1992, male competitors must be under 23 years old, although since 1996, three players over the age of 23 have been allowed per squad.[156] A women's tournament was added in 1996; in contrast to the men's event, full international sides without age restrictions play the women's Olympic tournament.[157]  After the World Cup, the most important international football competitions are the continental championships, which are organised by each continental confederation and contested between national teams. These are the European Championship (UEFA), the Copa Am\u00e9rica (CONMEBOL), the African Cup of Nations (CAF), the Asian Cup (AFC), the CONCACAF Gold Cup (CONCACAF) and the OFC Men's Nations Cup (OFC).[158] These competitions are not strictly limited to members of the continental confederations, with guest teams from other continents sometimes invited to compete.[159] The FIFA Confederations Cup was contested by the winners of all six continental championships, the current FIFA World Cup champions, and the country which was hosting the next World Cup. This was generally regarded as a warm-up tournament for the upcoming FIFA World Cup and did not carry the same prestige as the World Cup itself.[158] The tournament was discontinued following the 2017 edition with its calendar slot replaced by an expanded FIFA Club World Cup.[160] The UEFA Nations League and the CONCACAF Nations League were introduced in the late 2010s to replace international friendlies during the two-year cycle between major tournaments.[161]  The most prestigious competitions in club football are the respective continental championships, which are generally contested between national champions, for example, the UEFA Champions League in Europe and the Copa Libertadores in South America. The winners of each continental competition contest the FIFA Club World Cup.[162]  The governing bodies in each country operate league systems in a domestic season, normally comprising several divisions, in which the teams gain points throughout the season depending on results. Teams are placed into tables, placing them in order according to points accrued. Most commonly, each team plays every other team in its league at home and away in each season, in a round-robin tournament. At the end of a season, the top team is declared the champion. The top few teams may be promoted to a higher division, and one or more of the teams finishing at the bottom are relegated to a lower division.[164]  The teams finishing at the top of a country's league may also be eligible to play in international club competitions in the following season. The main exceptions to this system occur in some Latin American leagues, which divide football championships into two sections named Apertura and Clausura (Spanish for Opening and Closing), awarding a champion for each.[165] Most countries supplement the league system with one or more \"cup\" competitions organised on a knock-out basis. These include the domestic cup, which may be open to all eligible teams in a country's league system\u2014both professional and amateur\u2014and is organised by the national federation.[166]  Some countries' top divisions feature highly-paid star players; in smaller countries, lower divisions, and many women's clubs, players may be part-timers with a second job, or amateurs. The five top European leagues \u2013 Premier League (England),[167] Bundesliga (Germany), La Liga (Spain), Serie A (Italy), and Ligue 1 (France) \u2013 attract most of the world's best players and, during the 2006\u201307 season, each of these leagues had a total wage cost in excess of \u20ac600 million.[168][needs update] These leagues also generated a combined \u20ac17.2\u00a0billion in revenue in the 2021\u201322 season from television contracts, matchday tickets, sponsorships, and other sources.[169] "},{"title":"Engineering","content":"  Engineering is the practice of using natural science, mathematics, and the engineering design process[1] to solve technical problems, increase efficiency and productivity, and improve systems. Modern engineering comprises many subfields which include designing and improving infrastructure, machinery, vehicles, electronics, materials, and energy systems.[2]  The discipline of engineering encompasses a broad range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, applied science, and types of application. See glossary of engineering.  The term engineering is derived from the Latin ingenium, meaning \"cleverness\" and ingeniare, meaning \"to contrive, devise\".[3]  The American Engineers' Council for Professional Development (ECPD, the predecessor of ABET)[4] has defined \"engineering\" as:  The creative application of scientific principles to design or develop structures, machines, apparatus, or manufacturing processes, or works utilizing them singly or in combination; or to construct or operate the same with full cognizance of their design; or to forecast their behavior under specific operating conditions; all as respects an intended function, economics of operation and safety to life and property.[5][6] Engineering has existed since ancient times, when humans devised inventions such as the wedge, lever, wheel and pulley, etc.  The term engineering is derived from the word engineer, which itself dates back to the 14th century when an engine'er (literally, one who builds or operates a siege engine) referred to \"a constructor of military engines\".[7] In this context, now obsolete, an \"engine\" referred to a military machine, i.e., a mechanical contraption used in war (for example, a catapult). Notable examples of the obsolete usage which have survived to the present day are military engineering corps, e.g., the U.S. Army Corps of Engineers.  The word \"engine\" itself is of even older origin, ultimately deriving from the Latin ingenium (c.\u20091250), meaning \"innate quality, especially mental power, hence a clever invention.\"[8]  Later, as the design of civilian structures, such as bridges and buildings, matured as a technical discipline, the term civil engineering[6] entered the lexicon as a way to distinguish between those specializing in the construction of such non-military projects and those involved in the discipline of military engineering.  The pyramids in ancient Egypt, ziggurats of Mesopotamia, the Acropolis and Parthenon in Greece, the Roman aqueducts, Via Appia and Colosseum, Teotihuac\u00e1n, and the Brihadeeswarar Temple of Thanjavur, among many others, stand as a testament to the ingenuity and skill of ancient civil and military engineers. Other monuments, no longer standing, such as the Hanging Gardens of Babylon and the Pharos of Alexandria, were important engineering achievements of their time and were considered among the Seven Wonders of the Ancient World.  The six classic simple machines were known in the ancient Near East. The wedge and the inclined plane (ramp) were known since prehistoric times.[9] The wheel, along with the wheel and axle mechanism, was invented in Mesopotamia (modern Iraq) during the 5th millennium BC.[10] The lever mechanism first appeared around 5,000 years ago in the Near East, where it was used in a simple balance scale,[11] and to move large objects in ancient Egyptian technology.[12] The lever was also used in the shadoof water-lifting device, the first crane machine, which appeared in Mesopotamia c.\u20093000 BC,[11] and then in ancient Egyptian technology c.\u20092000 BC.[13] The earliest evidence of pulleys date back to Mesopotamia in the early 2nd millennium BC,[14] and ancient Egypt during the Twelfth Dynasty (1991\u20131802 BC).[15] The screw, the last of the simple machines to be invented,[16] first appeared in Mesopotamia during the Neo-Assyrian period (911\u2013609) BC.[14] The Egyptian pyramids were built using three of the six simple machines, the inclined plane, the wedge, and the lever, to create structures like the Great Pyramid of Giza.[17]  The earliest civil engineer known by name is Imhotep.[6] As one of the officials of the Pharaoh, Djos\u00e8r, he probably designed and supervised the construction of the Pyramid of Djoser (the Step Pyramid) at Saqqara in Egypt around 2630\u20132611 BC.[18] The earliest practical water-powered machines, the water wheel and watermill, first appeared in the Persian Empire, in what are now Iraq and Iran, by the early 4th century BC.[19]  Kush developed the Sakia during the 4th century BC, which relied on animal power instead of human energy.[20]Hafirs were developed as a type of reservoir in Kush to store and contain water as well as boost irrigation.[21] Sappers were employed to build causeways during military campaigns.[22] Kushite ancestors built speos during the Bronze Age between 3700 and 3250 BC.[23]Bloomeries and blast furnaces were also created during the 7th centuries BC in Kush.[24][25][26][27]  Ancient Greece developed machines in both civilian and military domains. The Antikythera mechanism, an early known mechanical analog computer,[28][29] and the mechanical inventions of Archimedes, are examples of Greek mechanical engineering. Some of Archimedes' inventions, as well as the Antikythera mechanism, required sophisticated knowledge of differential gearing or epicyclic gearing, two key principles in machine theory that helped design the gear trains of the Industrial Revolution, and are widely used in fields such as robotics and automotive engineering.[30]  Ancient Chinese, Greek, Roman and Hunnic armies employed military machines and inventions such as artillery which was developed by the Greeks around the 4th century BC,[31] the trireme, the ballista and the catapult. In the Middle Ages, the trebuchet was developed.  The earliest practical wind-powered machines, the windmill and wind pump, first appeared in the Muslim world during the Islamic Golden Age, in what are now Iran, Afghanistan, and Pakistan, by the 9th century AD.[32][33][34][35] The earliest practical steam-powered machine was a steam jack driven by a steam turbine, described in 1551 by Taqi al-Din Muhammad ibn Ma'ruf in Ottoman Egypt.[36][37]  The cotton gin was invented in India by the 6th century AD,[38] and the spinning wheel was invented in the Islamic world by the early 11th century,[39] both of which were fundamental to the growth of the cotton industry. The spinning wheel was also a precursor to the spinning jenny, which was a key development during the early Industrial Revolution in the 18th century.[40]  The earliest programmable machines were developed in the Muslim world. A music sequencer, a programmable musical instrument, was the earliest type of programmable machine. The first music sequencer was an automated flute player invented by the Banu Musa brothers, described in their Book of Ingenious Devices, in the 9th century.[41][42] In 1206, Al-Jazari invented programmable automata\/robots. He described four automaton musicians, including drummers operated by a programmable drum machine, where they could be made to play different rhythms and different drum patterns.[43]  Before the development of modern engineering, mathematics was used by artisans and craftsmen, such as millwrights, clockmakers, instrument makers and surveyors. Aside from these professions, universities were not believed to have had much practical significance to technology.[44]:\u200a32\u200a  A standard reference for the state of mechanical arts during the Renaissance is given in the mining engineering treatise De re metallica (1556), which also contains sections on geology, mining, and chemistry. De re metallica was the standard chemistry reference for the next 180 years.[44]  The science of classical mechanics, sometimes called Newtonian mechanics, formed the scientific basis of much of modern engineering.[44] With the rise of engineering as a profession in the 18th century, the term became more narrowly applied to fields in which mathematics and science were applied to these ends. Similarly, in addition to military and civil engineering, the fields then known as the mechanic arts became incorporated into engineering.  Canal building was an important engineering work during the early phases of the Industrial Revolution.[45]  John Smeaton was the first self-proclaimed civil engineer and is often regarded as the \"father\" of civil engineering. He was an English civil engineer responsible for the design of bridges, canals, harbors, and lighthouses. He was also a capable mechanical engineer and an eminent physicist. Using a model water wheel, Smeaton conducted experiments for seven years, determining ways to increase efficiency.[46]:\u200a127\u200a   Smeaton introduced iron axles and gears to water wheels.[44]:\u200a69\u200a Smeaton also made mechanical improvements to the Newcomen steam engine. Smeaton designed the third Eddystone Lighthouse (1755\u201359) where he pioneered the use of 'hydraulic lime' (a form of mortar which will set under water) and developed a technique involving dovetailed blocks of granite in the building of the lighthouse. He is important in the history, rediscovery of, and development of modern cement, because he identified the compositional requirements needed to obtain \"hydraulicity\" in lime; work which led ultimately to the invention of Portland cement.  Applied science led to the development of the steam engine. The sequence of events began with the invention of the barometer and the measurement of atmospheric pressure by Evangelista Torricelli in 1643, demonstration of the force of atmospheric pressure by Otto von Guericke using the Magdeburg hemispheres in 1656, laboratory experiments by Denis Papin, who built experimental model steam engines and demonstrated the use of a piston, which he published in 1707. Edward Somerset, 2nd Marquess of Worcester published a book of 100 inventions containing a method for raising waters similar to a coffee percolator. Samuel Morland, a mathematician and inventor who worked on pumps, left notes at the Vauxhall Ordinance Office on a steam pump design that Thomas Savery read. In 1698 Savery built a steam pump called \"The Miner's Friend\". It employed both vacuum and pressure.[47] Iron merchant Thomas Newcomen, who built the first commercial piston steam engine in 1712, was not known to have any scientific training.[46]:\u200a32\u200a  The application of steam-powered cast iron blowing cylinders for providing pressurized air for blast furnaces lead to a large increase in iron production in the late 18th century. The higher furnace temperatures made possible with steam-powered blast allowed for the use of more lime in blast furnaces, which enabled the transition from charcoal to coke.[48] These innovations lowered the cost of iron, making horse railways and iron bridges practical. The puddling process, patented by Henry Cort in 1784 produced large scale quantities of wrought iron. Hot blast, patented by James Beaumont Neilson in 1828, greatly lowered the amount of fuel needed to smelt iron. With the development of the high pressure steam engine, the power to weight ratio of steam engines made practical steamboats and locomotives possible.[49] New steel making processes, such as the Bessemer process and the open hearth furnace, ushered in an area of heavy engineering in the late 19th century.  One of the most famous engineers of the mid-19th century was Isambard Kingdom Brunel, who built railroads, dockyards and steamships.  The Industrial Revolution created a demand for machinery with metal parts, which led to the development of several machine tools. Boring cast iron cylinders with precision was not possible until John Wilkinson invented his boring machine, which is considered the first machine tool.[50] Other machine tools included the screw cutting lathe, milling machine, turret lathe and the metal planer. Precision machining techniques were developed in the first half of the 19th century. These included the use of gigs to guide the machining tool over the work and fixtures to hold the work in the proper position. Machine tools and machining techniques capable of producing interchangeable parts lead to large scale factory production by the late 19th century.[51]  The United States Census of 1850 listed the occupation of \"engineer\" for the first time with a count of 2,000.[52] There were fewer than 50 engineering graduates in the U.S. before 1865. In 1870 there were a dozen U.S. mechanical engineering graduates, with that number increasing to 43 per year in 1875. In 1890, there were 6,000 engineers in civil, mining, mechanical and electrical.[49]  There was no chair of applied mechanism and applied mechanics at Cambridge until 1875, and no chair of engineering at Oxford until 1907. Germany established technical universities earlier.[53]  The foundations of electrical engineering in the 1800s included the experiments of Alessandro Volta, Michael Faraday, Georg Ohm and others and the invention of the electric telegraph in 1816 and the electric motor in 1872. The theoretical work of James Maxwell (see: Maxwell's equations) and Heinrich Hertz in the late 19th century gave rise to the field of electronics. The later inventions of the vacuum tube and the transistor further accelerated the development of electronics to such an extent that electrical and electronics engineers currently outnumber their colleagues of any other engineering specialty.[6] Chemical engineering developed in the late nineteenth century.[6] Industrial scale manufacturing demanded new materials and new processes and by 1880 the need for large scale production of chemicals was such that a new industry was created, dedicated to the development and large scale manufacturing of chemicals in new industrial plants.[6] The role of the chemical engineer was the design of these chemical plants and processes.[6]  Aeronautical engineering deals with aircraft design process design while aerospace engineering is a more modern term that expands the reach of the discipline by including spacecraft design. Its origins can be traced back to the aviation pioneers around the start of the 20th century although the work of Sir George Cayley has recently been dated as being from the last decade of the 18th century. Early knowledge of aeronautical engineering was largely empirical with some concepts and skills imported from other branches of engineering.[54]  The first PhD in engineering (technically, applied science and engineering) awarded in the United States went to Josiah Willard Gibbs at Yale University in 1863; it was also the second PhD awarded in science in the U.S.[55]  Only a decade after the successful flights by the Wright brothers, there was extensive development of aeronautical engineering through development of military aircraft that were used in World War I. Meanwhile, research to provide fundamental background science continued by combining theoretical physics with experiments.  Engineering is a broad discipline that is often broken down into several sub-disciplines. Although an engineer will usually be trained in a specific discipline, he or she may become multi-disciplined through experience. Engineering is often characterized as having four main branches:[56][57][58] chemical engineering, civil engineering, electrical engineering, and mechanical engineering.  Chemical engineering is the application of physics, chemistry, biology, and engineering principles in order to carry out chemical processes on a commercial scale, such as the manufacture of commodity chemicals, specialty chemicals, petroleum refining, microfabrication, fermentation, and biomolecule production.  Civil engineering is the design and construction of public and private works, such as infrastructure (airports, roads, railways, water supply, and treatment etc.), bridges, tunnels, dams, and buildings.[59][60] Civil engineering is traditionally broken into a number of sub-disciplines, including structural engineering, environmental engineering, and surveying. It is traditionally considered to be separate from military engineering.[61]  Electrical engineering is the design, study, and manufacture of various electrical and electronic systems, such as broadcast engineering, electrical circuits, generators, motors, electromagnetic\/electromechanical devices, electronic devices, electronic circuits, optical fibers, optoelectronic devices, computer systems, telecommunications, instrumentation, control systems, and electronics.  Mechanical engineering is the design and manufacture of physical or mechanical systems, such as power and energy systems, aerospace\/aircraft products, weapon systems, transportation products, engines, compressors, powertrains, kinematic chains, vacuum technology, vibration isolation equipment, manufacturing, robotics, turbines, audio equipments, and mechatronics.  Bioengineering is the engineering of biological systems for a useful purpose. Examples of bioengineering research include bacteria engineered to produce chemicals, new medical imaging technology, portable and rapid disease diagnostic devices, prosthetics, biopharmaceuticals, and tissue-engineered organs.  Interdisciplinary engineering draws from more than one of the principle branches of the practice. Historically, naval engineering and mining engineering were major branches. Other engineering fields are manufacturing engineering, acoustical engineering, corrosion engineering, instrumentation and control, aerospace, automotive, computer, electronic, information engineering, petroleum, environmental, systems, audio, software, architectural, agricultural, biosystems, biomedical,[62] geological, textile, industrial, materials,[63] and nuclear engineering.[64] These and other branches of engineering are represented in the 36 licensed member institutions of the UK Engineering Council.  New specialties sometimes combine with the traditional fields and form new branches \u2013 for example, Earth systems engineering and management involves a wide range of subject areas including engineering studies, environmental science, engineering ethics and philosophy of engineering.  Aerospace engineering covers the design, development, manufacture and operational behaviour of aircraft, satellites and rockets.  Marine engineering covers the design, development, manufacture and operational behaviour of watercraft and stationary structures like oil platforms and ports.  Computer engineering (CE) is a branch of engineering that integrates several fields of computer science and electronic engineering required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering.  Geological engineering is associated with anything constructed on or within the Earth. This discipline applies geological sciences and engineering principles to direct or support the work of other disciplines such as civil engineering, environmental engineering, and mining engineering. Geological engineers are involved with impact studies for facilities and operations that affect surface and subsurface environments, such as rock excavations (e.g. tunnels), building foundation consolidation, slope and fill stabilization, landslide risk assessment, groundwater monitoring, groundwater remediation, mining excavations, and natural resource exploration.  One who practices engineering is called an engineer, and those licensed to do so may have more formal designations such as Professional Engineer, Chartered Engineer, Incorporated Engineer, Ingenieur, European Engineer, or Designated Engineering Representative.  In the engineering design process, engineers apply mathematics and sciences such as physics to find novel solutions to problems or to improve existing solutions. Engineers need proficient knowledge of relevant sciences for their design projects. As a result, many engineers continue to learn new material throughout their careers.  If multiple solutions exist, engineers weigh each design choice based on their merit and choose the solution that best matches the requirements. The task of the engineer is to identify, understand, and interpret the constraints on a design in order to yield a successful result. It is generally insufficient to build a technically successful product, rather, it must also meet further requirements.  Constraints may include available resources, physical, imaginative or technical limitations, flexibility for future modifications and additions, and other factors, such as requirements for cost, safety, marketability, productivity, and serviceability. By understanding the constraints, engineers derive specifications for the limits within which a viable object or system may be produced and operated.  Engineers use their knowledge of science, mathematics, logic, economics, and appropriate experience or tacit knowledge to find suitable solutions to a particular problem. Creating an appropriate mathematical model of a problem often allows them to analyze it (sometimes definitively), and to test potential solutions.[65]  More than one solution to a design problem usually exists so the different design choices have to be evaluated on their merits before the one judged most suitable is chosen. Genrich Altshuller, after gathering statistics on a large number of patents, suggested that compromises are at the heart of \"low-level\" engineering designs, while at a higher level the best design is one which eliminates the core contradiction causing the problem.[66]  Engineers typically attempt to predict how well their designs will perform to their specifications prior to full-scale production. They use, among other things: prototypes, scale models, simulations, destructive tests, nondestructive tests, and stress tests. Testing ensures that products will perform as expected but only in so far as the testing has been representative of use in service. For products, such as aircraft, that are used differently by different users failures and unexpected shortcomings (and necessary design changes) can be expected throughout the operational life of the product.[67]  Engineers take on the responsibility of producing designs that will perform as well as expected and, except those employed in specific areas of the arms industry, will not harm people. Engineers typically include a factor of safety in their designs to reduce the risk of unexpected failure.  The study of failed products is known as forensic engineering. It attempts to identify the cause of failure to allow a redesign of the product and so prevent a re-occurrence. Careful analysis is needed to establish the cause of failure of a product. The consequences of a failure may vary in severity from the minor cost of a machine breakdown to large loss of life in the case of accidents involving aircraft and large stationary structures like buildings and dams.[68]  As with all modern scientific and technological endeavors, computers and software play an increasingly important role. As well as the typical business application software there are a number of computer aided applications (computer-aided technologies) specifically for engineering. Computers can be used to generate models of fundamental physical processes, which can be solved using numerical methods.  One of the most widely used design tools in the profession is computer-aided design (CAD) software. It enables engineers to create 3D models, 2D drawings, and schematics of their designs. CAD together with digital mockup (DMU) and CAE software such as finite element method analysis or analytic element method allows engineers to create models of designs that can be analyzed without having to make expensive and time-consuming physical prototypes.  These allow products and components to be checked for flaws; assess fit and assembly; study ergonomics; and to analyze static and dynamic characteristics of systems such as stresses, temperatures, electromagnetic emissions, electrical currents and voltages, digital logic levels, fluid flows, and kinematics. Access and distribution of all this information is generally organized with the use of product data management software.[69]  There are also many tools to support specific engineering tasks such as computer-aided manufacturing (CAM) software to generate CNC machining instructions; manufacturing process management software for production engineering; EDA for printed circuit board (PCB) and circuit schematics for electronic engineers; MRO applications for maintenance management; and Architecture, engineering and construction (AEC) software for civil engineering.  In recent years the use of computer software to aid the development of goods has collectively come to be known as product lifecycle management (PLM).[70]  The engineering profession engages in a range of activities, from collaboration at the societal level, and smaller individual projects. Almost all engineering projects are obligated to a funding source: a company, a set of investors, or a government. The types of engineering that are less constrained by such a funding source, are pro bono, and open-design engineering.  Engineering has interconnections with society, culture and human behavior. Most products and constructions used by modern society, are influenced by engineering. Engineering activities have an impact on the environment, society, economies, and public safety.  Engineering projects can be controversial. Examples from different engineering disciplines include: the development of nuclear weapons, the Three Gorges Dam, the design and use of sport utility vehicles and the extraction of oil. In response, some engineering companies have enacted serious corporate and social responsibility policies.  Engineering is a key driver of innovation and human development. Sub-Saharan Africa, in particular, has a small engineering capacity which results in many African nations being unable to develop crucial infrastructure without outside aid.[citation needed] The attainment of many of the Millennium Development Goals requires the achievement of sufficient engineering capacity to develop infrastructure and sustainable technological development.[71]  Overseas development and relief NGOs make considerable use of engineers, to apply solutions in disaster and development scenarios. Some charitable organizations use engineering directly for development:  Engineering companies in more developed economies face challenges with regard to the number of engineers being trained, compared with those retiring. This problem is prominent in the UK where engineering has a poor image and low status.[73] There are negative economic and political issues that this can cause, as well as ethical issues.[74] It is agreed the engineering profession faces an \"image crisis\".[75] The UK holds the most engineering companies compared to other European countries, together with the United States.[citation needed]  Many engineering societies have established codes of practice and codes of ethics to guide members and inform the public at large. The National Society of Professional Engineers code of ethics states:   Engineering is an important and learned profession. As members of this profession, engineers are expected to exhibit the highest standards of honesty and integrity. Engineering has a direct and vital impact on the quality of life for all people. Accordingly, the services provided by engineers require honesty, impartiality, fairness, and equity, and must be dedicated to the protection of the public health, safety, and welfare. Engineers must perform under a standard of professional behavior that requires adherence to the highest principles of ethical conduct.[76] In Canada, engineers wear the Iron Ring as a symbol and reminder of the obligations and ethics associated with their profession.[77]  Scientists study the world as it is; engineers create the world that has never been. There exists an overlap between the sciences and engineering practice; in engineering, one applies science. Both areas of endeavor rely on accurate observation of materials and phenomena. Both use mathematics and classification criteria to analyze and communicate observations.[citation needed]  Scientists may also have to complete engineering tasks, such as designing experimental apparatus or building prototypes. Conversely, in the process of developing technology, engineers sometimes find themselves exploring new phenomena, thus becoming, for the moment, scientists or more precisely \"engineering scientists\".[81]  In the book What Engineers Know and How They Know It,[82] Walter Vincenti asserts that engineering research has a character different from that of scientific research. First, it often deals with areas in which the basic physics or chemistry are well understood, but the problems themselves are too complex to solve in an exact manner.  There is a \"real and important\" difference between engineering and physics as similar to any science field has to do with technology.[83][84] Physics is an exploratory science that seeks knowledge of principles while engineering uses knowledge for practical applications of principles. The former equates an understanding into a mathematical principle while the latter measures variables involved and creates technology.[85][86][87] For technology, physics is an auxiliary and in a way technology is considered as applied physics.[88] Though physics and engineering are interrelated, it does not mean that a physicist is trained to do an engineer's job. A physicist would typically require additional and relevant training.[89] Physicists and engineers engage in different lines of work.[90] But PhD physicists who specialize in sectors of engineering physics and applied physics are titled as Technology officer, R&D Engineers and System Engineers.[91]  An example of this is the use of numerical approximations to the Navier\u2013Stokes equations to describe aerodynamic flow over an aircraft, or the use of the finite element method to calculate the stresses in complex components. Second, engineering research employs many semi-empirical methods that are foreign to pure scientific research, one example being the method of parameter variation.[92]  As stated by Fung et al. in the revision to the classic engineering text Foundations of Solid Mechanics:  Engineering is quite different from science. Scientists try to understand nature. Engineers try to make things that do not exist in nature. Engineers stress innovation and invention. To embody an invention the engineer must put his idea in concrete terms, and design something that people can use. That something can be a complex system, device, a gadget, a material, a method, a computing program, an innovative experiment, a new solution to a problem, or an improvement on what already exists. Since a design has to be realistic and functional, it must have its geometry, dimensions, and characteristics data defined. In the past engineers working on new designs found that they did not have all the required information to make design decisions. Most often, they were limited by insufficient scientific knowledge. Thus they studied mathematics, physics, chemistry, biology and mechanics. Often they had to add to the sciences relevant to their profession. Thus engineering sciences were born.[93] Although engineering solutions make use of scientific principles, engineers must also take into account safety, efficiency, economy, reliability, and constructability or ease of fabrication as well as the environment, ethical and legal considerations such as patent infringement or liability in the case of failure of the solution.[94]  The study of the human body, albeit from different directions and for different purposes, is an important common link between medicine and some engineering disciplines. Medicine aims to sustain, repair, enhance and even replace functions of the human body, if necessary, through the use of technology.  Modern medicine can replace several of the body's functions through the use of artificial organs and can significantly alter the function of the human body through artificial devices such as, for example, brain implants and pacemakers.[95][96] The fields of bionics and medical bionics are dedicated to the study of synthetic implants pertaining to natural systems.  Conversely, some engineering disciplines view the human body as a biological machine worth studying and are dedicated to emulating many of its functions by replacing biology with technology. This has led to fields such as artificial intelligence, neural networks, fuzzy logic, and robotics. There are also substantial interdisciplinary interactions between engineering and medicine.[97][98]  Both fields provide solutions to real world problems. This often requires moving forward before phenomena are completely understood in a more rigorous scientific sense and therefore experimentation and empirical knowledge is an integral part of both.  Medicine, in part, studies the function of the human body. The human body, as a biological machine, has many functions that can be modeled using engineering methods.[99]  The heart for example functions much like a pump,[100] the skeleton is like a linked structure with levers,[101] the brain produces electrical signals etc.[102] These similarities as well as the increasing importance and application of engineering principles in medicine, led to the development of the field of biomedical engineering that uses concepts developed in both disciplines.  Newly emerging branches of science, such as systems biology, are adapting analytical tools traditionally used for engineering, such as systems modeling and computational analysis, to the description of biological systems.[99]  There are connections between engineering and art, for example, architecture, landscape architecture and industrial design (even to the extent that these disciplines may sometimes be included in a university's Faculty of Engineering).[104][105][106]  The Art Institute of Chicago, for instance, held an exhibition about the art of NASA's aerospace design.[107] Robert Maillart's bridge design is perceived by some to have been deliberately artistic.[108] At the University of South Florida, an engineering professor, through a grant with the National Science Foundation, has developed a course that connects art and engineering.[104][109]  Among famous historical figures, Leonardo da Vinci is a well-known Renaissance artist and engineer, and a prime example of the nexus between art and engineering.[103][110]  Business engineering deals with the relationship between professional engineering, IT systems, business administration and change management. Engineering management or \"Management engineering\" is a specialized field of management concerned with engineering practice or the engineering industry sector. The demand for management-focused engineers (or from the opposite perspective, managers with an understanding of engineering), has resulted in the development of specialized engineering management degrees that develop the knowledge and skills needed for these roles. During an engineering management course, students will develop industrial engineering skills, knowledge, and expertise, alongside knowledge of business administration, management techniques, and strategic thinking. Engineers specializing in change management must have in-depth knowledge of the application of industrial and organizational psychology principles and methods. Professional engineers often train as certified management consultants in the very specialized field of management consulting applied to engineering practice or the engineering sector. This work often deals with large scale complex business transformation or business process management initiatives in aerospace and defence, automotive, oil and gas, machinery, pharmaceutical, food and beverage, electrical and electronics, power distribution and generation, utilities and transportation systems. This combination of technical engineering practice, management consulting practice, industry sector knowledge, and change management expertise enables professional engineers who are also qualified as management consultants to lead major business transformation initiatives. These initiatives are typically sponsored by C-level executives.  In political science, the term engineering has been borrowed for the study of the subjects of social engineering and political engineering, which deal with forming political and social structures using engineering methodology coupled with political science principles. Marketing engineering and financial engineering have similarly borrowed the term. "},{"title":"Scottish Gaelic","content":"  Scottish Gaelic (\/\u02c8\u0261\u00e6l\u026ak\/, GAL-ick; endonym: G\u00e0idhlig [\u02c8ka\u02d0l\u026ak\u02b2] \u24d8), also known as Scots Gaelic or simply Gaelic, is a Goidelic language (in the Celtic branch of the Indo-European language family) native to the Gaels of Scotland. As a Goidelic language, Scottish Gaelic, as well as both Irish and Manx, developed out of Old Irish.[3] It became a distinct spoken language sometime in the 13th century in the Middle Irish period, although a common literary language was shared by the Gaels of both Ireland and Scotland until well into the 17th century.[4] Most of modern Scotland was once Gaelic-speaking, as evidenced especially by Gaelic-language place names.[5][6]  In the 2011 census of Scotland, 57,375 people (1.1% of the Scottish population aged over three years old) reported being able to speak Gaelic, 1,275 fewer than in 2001. The highest percentages of Gaelic speakers were in the Outer Hebrides. Nevertheless, there is a language revival, and the number of speakers of the language under age 20 did not decrease between the 2001 and 2011 censuses.[7]  Outside of Scotland, a dialect known as Canadian Gaelic has been spoken in Canada since the 18th century. In the 2021 census, 2,170 Canadian residents claimed knowledge of Scottish Gaelic, a decline from 3,980 speakers in the 2016 census.[8][9] There exists a particular concentration of speakers in Nova Scotia, with historic communities in other parts of Canada having largely disappeared.[10]  The Scottish Government declares that it protects Scottish Gaelic \"as an official language of Scotland\",[11] however, this is disputed by others, who argue that Scottish Gaelic is not an official language of the United Kingdom or Scotland.[12][13] Scottish Gaelic is classed as an indigenous language under the European Charter for Regional or Minority Languages, which the UK Government has ratified, and the Gaelic Language (Scotland) Act 2005 established a language-development body, B\u00f2rd na G\u00e0idhlig.[14]  Aside from \"Scottish Gaelic\", the language may also be referred to simply as \"Gaelic\", pronounced \/\u02c8\u0261\u00e6l\u026ak\/ GAL-ick in English. However, \"Gaelic\" \/\u02c8\u0261e\u026al\u026ak\/ GAY-lik also refers to the Irish language (Gaeilge)[15] and the Manx language (Gaelg).  Scottish Gaelic is distinct from Scots, the Middle English-derived language which had come to be spoken in most of the Lowlands of Scotland by the early modern era. Prior to the 15th century, this language was known as Inglis (\"English\")[16] by its own speakers, with Gaelic being called Scottis (\"Scottish\"). Beginning in the late 15th century, it became increasingly common for such speakers to refer to Scottish Gaelic as Erse (\"Irish\") and the Lowland vernacular as Scottis.[17] Today, Scottish Gaelic is recognised as a separate language from Irish, so the word Erse in reference to Scottish Gaelic is no longer used.[18]  Based on medieval traditional accounts and the apparent evidence from linguistic geography, Gaelic has been commonly believed to have been brought to Scotland, in the 4th\u20135th centuries CE, by settlers from Ireland who founded the Gaelic kingdom of D\u00e1l Riata on Scotland's west coast in present-day Argyll.[19]:\u200a551\u200a[20]:\u200a66\u200a An alternative view has been voiced by archaeologist Ewan Campbell, who has argued that the putative migration or takeover is not reflected in archaeological or placename data (as pointed out earlier by Leslie Alcock). Campbell has also questioned the age and reliability of the medieval historical sources speaking of a conquest. Instead, he has inferred that Argyll formed part of a common Q-Celtic-speaking area with Ireland, connected rather than divided by the sea, since the Iron Age.[21] These arguments have been opposed by some scholars defending the early dating of the traditional accounts and arguing for other interpretations of the archaeological evidence.[22]  Regardless of how it came to be spoken in the region, Gaelic in Scotland was mostly confined to D\u00e1l Riata until the eighth century, when it began expanding into Pictish areas north of the Firth of Forth and the Firth of Clyde [citation needed]. During the reign of Caustant\u00edn mac \u00c1eda (Constantine II, 900\u2013943), outsiders began to refer to the region as the kingdom of Alba rather than as the kingdom of the Picts. However, though the Pictish language did not disappear suddenly, a process of Gaelicisation (which may have begun generations earlier) was clearly under way during the reigns of Caustant\u00edn and his successors. By a certain point, probably during the 11th century, all the inhabitants of Alba had become fully Gaelicised Scots, and Pictish identity was forgotten.[23] Bilingualism in Pictish and Gaelic, prior to the former's extinction, led to the presence of Pictish loanwords in Gaelic[24] and syntactic influence[25] which could be considered to constitute a Pictish substrate.[26]  In 1018, after the conquest of Lothian by the Kingdom of Scotland, Gaelic reached its social, cultural, political, and geographic zenith.[27]:\u200a16\u201318\u200a Colloquial speech in Scotland had been developing independently of that in Ireland since the eighth century.[28] For the first time, the entire region of modern-day Scotland was called Scotia in Latin, and Gaelic was the lingua Scotica.[29]:\u200a276\u200a[30]:\u200a554\u200a In southern Scotland, Gaelic was strong in Galloway, adjoining areas to the north and west, West Lothian, and parts of western Midlothian. It was spoken to a lesser degree in north Ayrshire, Renfrewshire, the Clyde Valley and eastern Dumfriesshire. In south-eastern Scotland, there is no evidence that Gaelic was ever widely spoken.[31]  Many historians mark the reign of King Malcolm Canmore (Malcolm III) between 1058 and 1093 as the beginning of Gaelic's eclipse in Scotland. His wife Margaret of Wessex spoke no Gaelic, gave her children Anglo-Saxon rather than Gaelic names, and brought many English bishops, priests, and monastics to Scotland.[27]:\u200a19\u200a When Malcolm and Margaret died in 1093, the Gaelic aristocracy rejected their anglicised sons and instead backed Malcolm's brother Domnall B\u00e1n (Donald III).[citation needed] Donald had spent 17 years in Gaelic Ireland and his power base was in the thoroughly Gaelic west of Scotland. He was the last Scottish monarch to be buried on Iona, the traditional burial place of the Gaelic Kings of D\u00e0l Riada and the Kingdom of Alba.[citation needed] However, during the reigns of Malcolm Canmore's sons, Edgar, Alexander I and David I (their successive reigns lasting 1097\u20131153), Anglo-Norman names and practices spread throughout Scotland south of the Forth\u2013Clyde line and along the northeastern coastal plain as far north as Moray. Norman French completely displaced Gaelic at court. The establishment of royal burghs throughout the same area, particularly under David I, attracted large numbers of foreigners speaking Old English. This was the beginning of Gaelic's status as a predominantly rural language in Scotland.[27]:\u200a19\u201323\u200a  Clan chiefs in the northern and western parts of Scotland continued to support Gaelic bards who remained a central feature of court life there. The semi-independent Lordship of the Isles in the Hebrides and western coastal mainland remained thoroughly Gaelic since the language's recovery there in the 12th century, providing a political foundation for cultural prestige down to the end of the 15th century.[30]:\u200a553\u20136\u200a  By the mid-14th century what eventually came to be called Scots (at that time termed Inglis) emerged as the official language of government and law.[32]:\u200a139\u200a Scotland's emergent nationalism in the era following the conclusion of the Wars of Scottish Independence was organized using Scots as well. For example, the nation's great patriotic literature including John Barbour's The Brus (1375) and Blind Harry's The Wallace (before 1488) was written in Scots, not Gaelic. By the end of the 15th century, English\/Scots speakers referred to Gaelic instead as 'Yrisch' or 'Erse', i.e. Irish and their own language as 'Scottis'.[27]:\u200a19\u201323\u200a  A steady shift away from Scottish Gaelic continued into and through the modern era. Some of this was driven by policy decisions by government or other organisations, while some originated from social changes. In the last quarter of the 20th century, efforts began to encourage use of the language.  The Statutes of Iona, enacted by James VI in 1609, was one piece of legislation that addressed, among other things, the Gaelic language. It required the heirs of clan chiefs to be educated in lowland, Protestant, English-speaking schools. James VI took several such measures to impose his rule on the Highland and Island region. In 1616, the Privy Council proclaimed that schools teaching in English should be established. Gaelic was seen, at this time, as one of the causes of the instability of the region. It was also associated with Catholicism.[33]:\u200a110\u2013113\u200a  The Society in Scotland for the Propagation of Christian Knowledge (SSPCK) was founded in 1709. They met in 1716, immediately after the failed Jacobite rising of 1715, to consider the reform and civilisation of the Highlands, which they sought to achieve by teaching English and the Protestant religion. Initially, their teaching was entirely in English, but soon the impracticality of educating Gaelic-speaking children in this way gave rise to a modest concession: In 1723, teachers were allowed to translate English words in the Bible into Gaelic to aid comprehension, but there was no further permitted use. Other less prominent schools worked in the Highlands at the same time, also teaching in English. This process of anglicisation paused when evangelical preachers arrived in the Highlands, convinced that people should be able to read religious texts in their own language. The first well known translation of the Bible into Scottish Gaelic was made in 1767, when James Stuart of Killin and Dugald Buchanan of Rannoch produced a translation of the New Testament. In 1798, four tracts in Gaelic were published by the Society for Propagating the Gospel at Home, with 5,000 copies of each printed. Other publications followed, with a full Gaelic Bible in 1801. The influential and effective Gaelic Schools Society was founded in 1811. Their purpose was to teach Gaels to read the Bible in their own language. In the first quarter of the 19th century, the SSPCK (despite their anti-Gaelic attitude in prior years) and the British and Foreign Bible Society distributed 60,000 Gaelic Bibles and 80,000 New Testaments.[34]:\u200a98\u200a It is estimated that this overall schooling and publishing effort gave some 300,000 people in the Highlands some basic literacy.[33]:\u200a110\u2013117\u200a Very few European languages have made the transition to a modern literary language without an early modern translation of the Bible; the lack of a well known translation may have contributed to the decline of Scottish Gaelic.[35]:\u200a168\u2013202\u200a  Counterintuitively, access to schooling in Gaelic increased knowledge of English. In 1829, the Gaelic Schools Society reported that parents were unconcerned about their children learning Gaelic, but were anxious to have them taught English. The SSPCK also found Highlanders to have significant prejudice against Gaelic. T. M. Devine attributes this to an association between English and the prosperity of employment: the Highland economy relied greatly on seasonal migrant workers travelling outside the G\u00e0idhealtachd. In 1863, an observer sympathetic to Gaelic stated that \"knowledge of English is indispensable to any poor islander who wishes to learn a trade or to earn his bread beyond the limits of his native Isle\". Generally, rather than Gaelic speakers, it was Celtic societies in the cities and professors of Celtic from universities who sought to preserve the language.[33]:\u200a116\u2013117\u200a  The Education (Scotland) Act 1872 provided universal education in Scotland, but completely ignored Gaelic in its plans. The mechanism for supporting Gaelic through the Education Codes issued by the Scottish Education Department were steadily used to overcome this omission, with many concessions in place by 1918. However, the members of Highland school boards tended to have anti-Gaelic attitudes and served as an obstacle to Gaelic education in the late 19th and early 20th century.[33]:\u200a110\u2013111\u200a  Loss of life due to World War I and the 1919 sinking of the HMY Iolaire, combined with emigration, resulted in the 1910s seeing unprecedented damage to the use of Scottish Gaelic, with a 46% fall in monolingual speakers and a 19% fall in bilingual speakers between the 1911 and 1921 Censuses.[36] Michelle MacLeod of Aberdeen University has said that there was no other period with such a high fall in the number of monolingual Gaelic speakers: \"Gaelic speakers became increasingly the exception from that point forward with bilingualism replacing monolingualism as the norm for Gaelic speakers.\"[36]  The Linguistic Survey of Scotland (1949\u20131997) surveyed both the dialect of the Scottish Gaelic language, and also mixed use of English and Gaelic across the Highlands and Islands.[37]  Dialects of Lowland Gaelic have been defunct since the 18th century. Gaelic in the Eastern and Southern Scottish Highlands, although alive until the mid-20th century, is now largely defunct. Although modern Scottish Gaelic is dominated by the dialects of the Outer Hebrides and Isle of Skye, there remain some speakers of the Inner Hebridean dialects of Tiree and Islay, and even a few native speakers from Western Highland areas including Wester Ross, northwest Sutherland, Lochaber and Argyll. Dialects on both sides of the Straits of Moyle (the North Channel) linking Scottish Gaelic with Irish are now extinct, though native speakers were still to be found on the Mull of Kintyre, on Rathlin and in North East Ireland as late as the mid-20th century. Records of their speech show that Irish and Scottish Gaelic existed in a dialect chain with no clear language boundary.[38] Some features of moribund dialects have been preserved in Nova Scotia, including the pronunciation of the broad or velarised l (l\u032a\u02e0) as [w], as in the Lochaber dialect.[39]:\u200a131\u200a    The Endangered Languages Project lists Gaelic's status as \"threatened\", with \"20,000 to 30,000 active users\".[40][41][better\u00a0source\u00a0needed] UNESCO classifies Gaelic as \"definitely endangered\".[42]  The 1755\u20132001 figures are census data quoted by MacAulay.[43]:\u200a141\u200a The 2011 Gaelic speakers figures come from table KS206SC of the 2011 Census. The 2011 total population figure comes from table KS101SC. The numbers of Gaelic speakers relate to the numbers aged 3 and over, and the percentages are calculated using those and the number of the total population aged 3 and over.   The 2011 UK Census showed a total of 57,375 Gaelic speakers in Scotland (1.1% of population over three years old), of whom only 32,400 could also read and write the language.[44] Compared with the 2001 Census, there has been a diminution of about 1300 people.[45] This is the smallest drop between censuses since the Gaelic-language question was first asked in 1881. The Scottish government's language minister and B\u00f2rd na G\u00e0idhlig took this as evidence that Gaelic's long decline has slowed.[46]  The main stronghold of the language continues to be the Outer Hebrides (Na h-Eileanan Siar), where the overall proportion of speakers is 52.2%. Important pockets of the language also exist in the Highlands (5.4%) and in Argyll and Bute (4.0%) and Inverness (4.9%). The locality with the largest absolute number is Glasgow with 5,878 such persons, who make up over 10% of all of Scotland's Gaelic speakers.  Gaelic continues to decline in its traditional heartland. Between 2001 and 2011, the absolute number of Gaelic speakers fell sharply in the Western Isles (\u22121,745), Argyll & Bute (\u2212694), and Highland (\u2212634). The drop in Stornoway, the largest parish in the Western Isles by population, was especially acute, from 57.5% of the population in 1991 to 43.4% in 2011.[47] The only parish outside the Western Isles over 40% Gaelic-speaking is Kilmuir in Northern Skye at 46%. The islands in the Inner Hebrides with significant percentages of Gaelic speakers are Tiree (38.3%), Raasay (30.4%), Skye (29.4%), Lismore (26.9%), Colonsay (20.2%), and Islay (19.0%).  Today, no civil parish in Scotland has a proportion of Gaelic speakers greater than 65% (the highest value is in Barvas, Lewis, with 64.1%). In addition, no civil parish on mainland Scotland has a proportion of Gaelic speakers greater than 20% (the highest is in Ardnamurchan, Highland, with 19.3%). Out of a total of 871 civil parishes in Scotland, the proportion of Gaelic speakers exceeds 50% in seven parishes, 25% in 14 parishes, and 10% in 35 parishes.   Decline in traditional areas has recently been balanced by growth in the Scottish Lowlands. Between the 2001 and 2011 censuses, the number of Gaelic speakers rose in nineteen of the country's 32 council areas. The largest absolute gains were in Aberdeenshire (+526), North Lanarkshire (+305), the Aberdeen City council area (+216), and East Ayrshire (+208). The largest relative gains were in Aberdeenshire (+0.19%), East Ayrshire (+0.18%), Moray (+0.16%), and Orkney (+0.13%).[citation needed]  In 2018, the census of pupils in Scotland showed 520 students in publicly funded schools had Gaelic as the main language at home, an increase of 5% from 497 in 2014. During the same period, Gaelic medium education in Scotland has grown, with 4,343 pupils (6.3 per 1000) being educated in a Gaelic-immersion environment in 2018, up from 3,583 pupils (5.3 per 1000) in 2014.[48] Data collected in 2007\u20132008 indicated that even among pupils enrolled in Gaelic medium schools, 81% of primary students and 74% of secondary students report using English more often than Gaelic when speaking with their mothers at home.[49] The effect on this of the significant increase in pupils in Gaelic-medium education since that time is unknown.  Gaelic Medium Education is one of the primary ways that the Scottish Government is addressing Gaelic language shift. Along with the B\u00f2rd na G\u00e0idhlig policies, preschool and daycare environments are also being used to create more opportunities for intergenerational language transmission in the Outer Hebrides.[50] \u00a0However, revitalization efforts are not unified within Scotland or Nova Scotia, Canada.[51] One can attend Sabhal M\u00f2r Ostaig, a national centre for Gaelic Language and Culture, based in Sleat, on the Isle of Skye. This institution is the only source for higher education which is conducted entirely in Scottish Gaelic.[52] They offer courses for Gaelic learners from beginners into fluency. They also offer regular bachelors and graduate programs delivered entirely in Gaelic. Concerns have been raised around the fluency achieved by learners within these language programs because they are disconnected from vernacular speech communities.[53][54] In regard to language revitalization planning efforts, many feel that the initiatives must come from within Gaelic speaking communities, be led by Gaelic speakers, and be designed to serve and increase fluency within the vernacular communities as the first and most viable resistance to total language shift from Gaelic to English.[51][53] Currently, language policies are focused on creating new language speakers through education, instead of focused on how to strengthen intergenerational transmission within existing Gaelic speaking communities.[51]  In the Outer Hebrides, accommodation ethics exist amongst native or local Gaelic speakers when engaging with new learners or non-locals.[53] Accommodation ethics, or ethics of accommodation, is a social practice where local or native speakers of Gaelic shift to speaking English when in the presence of non-Gaelic speakers out of a sense of courtesy or politeness. This accommodation ethic persists even in situations where new learners attempt to speak Gaelic with native speakers.[53] This creates a situation where new learners struggle to find opportunities to speak Gaelic with fluent speakers. Affect is the way people feel about something, or the emotional response to a particular situation or experience. For Gaelic speakers, there is a conditioned and socialized negative affect through a long history of negative Scottish media portrayal and public disrespect, state mandated restrictions on Gaelic usage, and highland clearances.[50][55][56] This negative affect towards speaking openly with non-native Gaelic speakers has led to a language ideology at odds with revitalization efforts on behalf of new speakers, state policies (such as the Gaelic Language Act), and family members reclaiming their lost mother tongue. New learners of Gaelic often have a positive affective stance to their language learning, and connect this learning journey towards Gaelic language revitalization.[57] The mismatch of these language ideologies, and differences in affective stance, has led to fewer speaking opportunities for adult language learners and therefore a challenge to revitalization efforts which occur outside the home. Positive engagements between language learners and native speakers of Gaelic through mentorship has proven to be productive in socializing new learners into fluency.[53][56]  Gaelic has long suffered from its lack of use in educational and administrative contexts and was long suppressed.[58]  The UK government has ratified the European Charter for Regional or Minority Languages in respect of Gaelic. Gaelic, along with Irish and Welsh, is designated under Part III of the Charter, which requires the UK Government to take a range of concrete measures in the fields of education, justice, public administration, broadcasting and culture. It has not received the same degree of official recognition from the UK Government as Welsh. With the advent of devolution, however, Scottish matters have begun to receive greater attention, and it achieved a degree of official recognition when the Gaelic Language (Scotland) Act was enacted by the Scottish Parliament on 21 April 2005.  The key provisions of the Act are:[59]  After its creation, B\u00f2rd na G\u00e0idhlig required a Gaelic Language Plan from the Scottish Government. This plan was accepted in 2008,[60] and some of its main commitments were: identity (signs, corporate identity); communications (reception, telephone, mailings, public meetings, complaint procedures); publications (PR and media, websites); staffing (language learning, training, recruitment).[60]  Following a consultation period, in which the government received many submissions, the majority of which asked that the bill be strengthened, a revised bill was published; the main alteration was that the guidance of the B\u00f2rd is now statutory (rather than advisory). In the committee stages in the Scottish Parliament, there was much debate over whether Gaelic should be given 'equal validity' with English. Due to executive concerns about resourcing implications if this wording was used, the Education Committee settled on the concept of 'equal respect'. It is not clear what the legal force of this wording is.  The Act was passed by the Scottish Parliament unanimously, with support from all sectors of the Scottish political spectrum, on 21 April 2005. Under the provisions of the Act, it will ultimately fall to BnG to secure the status of the Gaelic language as an official language of Scotland.  Some commentators, such as \u00c9amonn \u00d3 Grib\u00edn (2006) argue that the Gaelic Act falls so far short of the status accorded to Welsh that one would be foolish or na\u00efve to believe that any substantial change will occur in the fortunes of the language as a result of B\u00f2rd na G\u00e0idhlig's efforts.[61]  On 10 December 2008, to celebrate the 60th anniversary of the Universal Declaration of Human Rights, the Scottish Human Rights Commission had the UDHR translated into Gaelic for the first time.[62]  However, given there are no longer any monolingual Gaelic speakers,[63] following an appeal in the court case of Taylor v Haughney (1982), involving the status of Gaelic in judicial proceedings, the High Court ruled against a general right to use Gaelic in court proceedings.[64]  While the goal of the Gaelic Language Act was to aid in revitalization efforts through government mandated official language status, the outcome of the act is distanced from the actual minority language communities.[54] It helps to create visibility of the minority language in civil structures, but does not impact or address the lived experiences of the Gaelic speaker communities wherein the revitalization efforts may have a higher return of new Gaelic speakers. Efforts are being made to concentrate resources, language planning, and revitalization efforts towards vernacular communities in the Western Isles.[54]  The Scottish Qualifications Authority offer two streams of Gaelic examination across all levels of the syllabus: Gaelic for learners (equivalent to the modern foreign languages syllabus) and Gaelic for native speakers (equivalent to the English syllabus).[65][66]  An Comunn G\u00e0idhealach performs assessment of spoken Gaelic, resulting in the issue of a Bronze Card, Silver Card or Gold Card. Syllabus details are available on An Comunn's website. These are not widely recognised as qualifications, but are required for those taking part in certain competitions at the annual mods.[67]  In October 2009, a new agreement allowed Scottish Gaelic to be formally used between Scottish Government ministers and European Union officials. The deal was signed by Britain's representative to the EU, Sir Kim Darroch, and the Scottish government. This did not give Scottish Gaelic official status in the EU but gave it the right to be a means of formal communications in the EU's institutions. The Scottish government had to pay for the translation from Gaelic to other European languages. The deal was received positively in Scotland; Secretary of State for Scotland Jim Murphy said the move was a strong sign of the UK government's support for Gaelic. He said; \"Allowing Gaelic speakers to communicate with European institutions in their mother tongue is a progressive step forward and one which should be welcomed\".[citation needed] Culture Minister Mike Russell said; \"this is a significant step forward for the recognition of Gaelic both at home and abroad and I look forward to addressing the council in Gaelic very soon. Seeing Gaelic spoken in such a forum raises the profile of the language as we drive forward our commitment to creating a new generation of Gaelic speakers in Scotland.\"[68]  Bilingual road signs, street names, business and advertisement signage (in both Gaelic and English) are gradually being introduced throughout Gaelic-speaking regions in the Highlands and Islands, including Argyll. In many cases, this has simply meant re-adopting the traditional spelling of a name (such as R\u00e0tagan or Loch Ailleart rather than the anglicised forms Ratagan or Lochailort respectively).[69]  Some monolingual Gaelic road signs, particularly direction signs, are used on the Outer Hebrides, where a majority of the population can have a working knowledge of the language. These omit the English translation entirely.  Bilingual railway station signs are now more frequent than they used to be. Practically all the stations in the Highland area use both English and Gaelic, and the use of bilingual station signs has become more frequent in the Lowlands of Scotland, including areas where Gaelic has not been spoken for a long time.[citation needed]  This has been welcomed by many supporters of the language as a means of raising its profile as well as securing its future as a 'living language' (i.e. allowing people to use it to navigate from A to B in place of English) and creating a sense of place. However, in some places, such as Caithness, the Highland Council's intention to introduce bilingual signage has incited controversy.[70]  The Ordnance Survey has acted in recent years to correct many of the mistakes that appear on maps. They announced in 2004 that they intended to correct them and set up a committee to determine the correct forms of Gaelic place names for their maps.[69] Ainmean-\u00c0ite na h-Alba (\"Place names in Scotland\") is the national advisory partnership for Gaelic place names in Scotland.[71]  In the nineteenth century, Canadian Gaelic was the third-most widely spoken European language in British North America[72] and Gaelic-speaking immigrant communities could be found throughout what is modern-day Canada. Gaelic poets in Canada produced a significant literary tradition.[73] The number of Gaelic-speaking individuals and communities declined sharply, however, after the First World War.[74]  At the start of the 21st century, it was estimated that no more than 500 people in Nova Scotia still spoke Scottish Gaelic as a first language. In the 2011 census, 300 people claimed to have Gaelic as their first language (a figure that may include Irish Gaelic).[75] In the same 2011 census, 1,275 people claimed to speak Gaelic, a figure that not only included all Gaelic languages but also those people who are not first language speakers,[76] of whom 300 claim to have Gaelic as their \"mother tongue.\"[77][a]  The Nova Scotia government maintains the Office of Gaelic Affairs (Iomairtean na G\u00e0idhlig), which is dedicated to the development of Scottish Gaelic language, culture and tourism in Nova Scotia, and which estimates about 2,000 total Gaelic speakers to be in the province.[10] As in Scotland, areas of North-Eastern Nova Scotia and Cape Breton have bilingual street signs. Nova Scotia also has Comhairle na G\u00e0idhlig (The Gaelic Council of Nova Scotia), a non-profit society dedicated to the maintenance and promotion of the Gaelic language and culture in Maritime Canada. In 2018, the Nova Scotia government launched a new Gaelic vehicle licence plate to raise awareness of the language and help fund Gaelic language and culture initiatives.[79]  In September 2021, the first Gaelic-medium primary school outside of Scotland, named Taigh Sgoile na Drochaide, opened in Mabou, Nova Scotia.[80]  Maxville Public School in Maxville, Glengarry, Ontario, offers Scottish Gaelic lessons weekly.[81]  In Prince Edward Island, the Colonel Gray High School now offers both an introductory and an advanced course in Gaelic; both language and history are taught in these classes. This is the first recorded time that Gaelic has ever been taught as an official course on Prince Edward Island.[82]  The province of British Columbia is host to the Comunn G\u00e0idhlig Bhancoubhair (The Gaelic Society of Vancouver), the Vancouver Gaelic Choir, the Victoria Gaelic Choir, as well as the annual Gaelic festival M\u00f2d Vancouver. The city of Vancouver's Scottish Cultural Centre also holds seasonal Scottish Gaelic evening classes.  The BBC operates a Gaelic-language radio station Radio nan G\u00e0idheal as well as a television channel, BBC Alba. Launched on 19 September 2008, BBC Alba is widely available in the UK (on Freeview, Freesat, Sky and Virgin Media). It also broadcasts across Europe on the Astra 2 satellites.[83] The channel is being operated in partnership between BBC Scotland and MG Alba \u2013 an organisation funded by the Scottish Government, which works to promote the Gaelic language in broadcasting.[84] The ITV franchise in central Scotland, STV Central, has, in the past, produced a number of Scottish Gaelic programmes for both BBC Alba and its own main channel.[84]  Until BBC Alba was broadcast on Freeview, viewers were able to receive the channel TeleG, which broadcast for an hour every evening. Upon BBC Alba's launch on Freeview, it took the channel number that was previously assigned to TeleG.  There are also television programmes in the language on other BBC channels and on the independent commercial channels, usually subtitled in English. The ITV franchise in the north of Scotland, STV North (formerly Grampian Television) produces some non-news programming in Scottish Gaelic.  The Education (Scotland) Act 1872, which completely ignored Gaelic and led to generations of Gaels being forbidden to speak their native language in the classroom is now recognised as having dealt a major blow to the language. People still living in 2001 could recall being beaten for speaking Gaelic in school.[97] Even later, when these attitudes had changed, little provision was made for Gaelic medium education in Scottish schools. As late as 1958, even in Highland schools, only 20% of primary students were taught Gaelic as a subject, and only 5% were taught other subjects through the Gaelic language.[49]  Gaelic-medium playgroups for young children began to appear in Scotland during the late 1970s and early 1980s. Parent enthusiasm may have been a factor in the \"establishment of the first Gaelic medium primary school units in Glasgow and Inverness in 1985\".[98]  The first modern solely Gaelic-medium secondary school, Sgoil Gh\u00e0idhlig Ghlaschu (\"Glasgow Gaelic School\"), was opened at Woodside in Glasgow in 2006 (61 partially Gaelic-medium primary schools and approximately a dozen Gaelic-medium secondary schools also exist). According to B\u00f2rd na G\u00e0idhlig, a total of 2,092 primary pupils were enrolled in Gaelic-medium primary education in 2008\u201309, as opposed to 24 in 1985.[99]  The Columba Initiative, also known as colmcille (formerly Iomairt Cholm Cille), is a body that seeks to promote links between speakers of Scottish Gaelic and Irish.  In November 2019, the language-learning app Duolingo opened a beta course in Gaelic.[100][101][102]  Starting from summer 2020, children starting school in the Western Isles will be enrolled in GME (Gaelic-medium education) unless parents request differently. Children will be taught Scottish Gaelic from P1 to P4 and then English will be introduced to give them a bilingual education.[103]  In May 2004, the Nova Scotia government announced the funding of an initiative to support the language and its culture within the province. Several public schools in Northeastern Nova Scotia and Cape Breton offer Gaelic classes as part of the high-school curriculum.[104]  Maxville Public School in Maxville, Glengarry, Ontario, offers Scottish Gaelic lessons weekly. In Prince Edward Island, the Colonel Gray High School offer an introductory and an advanced course in Scottish Gaelic.[105]  A number of Scottish and some Irish universities offer full-time degrees including a Gaelic language element, usually graduating as Celtic Studies.  In Nova Scotia, Canada, St. Francis Xavier University, the Gaelic College of Celtic Arts and Crafts and Cape Breton University (formerly known as the \"University College of Cape Breton\") offer Celtic Studies degrees and\/or Gaelic language programs. The government's Office of Gaelic Affairs offers lunch-time lessons to public servants in Halifax.  In Russia the Moscow State University offers Gaelic language, history and culture courses.  The University of the Highlands and Islands offers a range of Gaelic language, history and culture courses at the National Certificate, Higher National Diploma, Bachelor of Arts (ordinary), Bachelor of Arts (Honours) and Master of Science levels. It offers opportunities for postgraduate research through the medium of Gaelic. Residential courses at Sabhal M\u00f2r Ostaig on the Isle of Skye offer adults the chance to become fluent in Gaelic in one year. Many continue to complete degrees, or to follow up as distance learners. A number of other colleges offer a one-year certificate course, which is also available online (pending accreditation).  Lews Castle College's Benbecula campus offers an independent 1-year course in Gaelic and Traditional Music (FE, SQF level 5\/6).  In the Western Isles, the isles of Lewis, Harris and North Uist have a Presbyterian majority (largely Church of Scotland \u2013 Eaglais na h-Alba in Gaelic, Free Church of Scotland and Free Presbyterian Church of Scotland). The isles of South Uist and Barra have a Catholic majority. All these churches have Gaelic-speaking congregations throughout the Western Isles. Notable city congregations with regular services in Gaelic are St Columba's Church, Glasgow and Greyfriars Tolbooth & Highland Kirk, Edinburgh. Leabhar Sheirbheisean\u2014a shorter Gaelic version of the English-language Book of Common Order\u2014was published in 1996 by the Church of Scotland.  The widespread use of English in worship has often been suggested as one of the historic reasons for the decline of Gaelic. The Church of Scotland is supportive today,[vague] but has a shortage of Gaelic-speaking ministers. The Free Church also recently announced plans to abolish Gaelic-language communion services, citing both a lack of ministers and a desire to have their congregations united at communion time.[106]  From the sixth century to the present day, Scottish Gaelic has been used as a literary language. Two prominent writers of the twentieth century are Anne Frater and Sorley MacLean.  Gaelic has its own version of European-wide names which also have English forms, for example: Iain (John), Alasdair (Alexander), Uilleam (William), Catr\u00econa (Catherine), Raibeart (Robert), Cairist\u00econa (Christina), Anna (Ann), M\u00e0iri (Mary), Seumas (James), P\u00e0draig (Patrick) and T\u00f2mas (Thomas). Not all traditional Gaelic names have direct equivalents in English: Oighrig, which is normally rendered as Euphemia (Effie) or Henrietta (Etta) (formerly also as Henny or even as Harriet), or, Diorbhal, which is \"matched\" with Dorothy, simply on the basis of a certain similarity in spelling. Many of these traditional Gaelic-only names are now regarded as old-fashioned, and hence are rarely or never used.  Some names have come into Gaelic from Old Norse; for example, Somhairle ( < Somarli\u00f0r), Tormod (< \u00de\u00f3rm\u00f3\u00f0r), Raghnall or Raonull (< R\u01ebgnvaldr), Torcuil (< \u00de\u00f3rkell, \u00de\u00f3rketill), \u00ccomhar (\u00cdvarr). These are conventionally rendered in English as Sorley (or, historically, Somerled), Norman, Ronald or Ranald, Torquil and Iver (or Evander).  Some Scottish names are Anglicized forms of Gaelic names: Aonghas \u2192 (Angus), D\u00f2mhnall\u2192 (Donald), for instance. Hamish, and the recently established Mhairi (pronounced [va\u02d0ri]) come from the Gaelic for, respectively, James, and Mary, but derive from the form of the names as they appear in the vocative case: Seumas (James) (nom.) \u2192 Sheumais (voc.) and M\u00e0iri (Mary) (nom.) \u2192 Mh\u00e0iri (voc.).  The most common class of Gaelic surnames are those beginning with mac (Gaelic for \"son\"), such as MacGillEathain\u2009\/\u2009MacIllEathain[107][108] (MacLean). The female form is nic (Gaelic for \"daughter\"), so Catherine MacPhee is properly called in Gaelic, Catr\u00econa Nic a' Ph\u00ec[109] (strictly, nic is a contraction of the Gaelic phrase nighean mhic, meaning \"daughter of the son\", thus NicDh\u00f2mhnaill[108] really means \"daughter of MacDonald\" rather than \"daughter of Donald\"). The \"of\" part actually comes from the genitive form of the patronymic that follows the prefix; in the case of MacDh\u00f2mhnaill, Dh\u00f2mhnaill (\"of Donald\") is the genitive form of D\u00f2mhnall (\"Donald\").[110]  Several colours give rise to common Scottish surnames: b\u00e0n (Bain \u2013 white), ruadh (Roy \u2013 red), dubh (Dow, Duff \u2013 black), donn (Dunn \u2013 brown), buidhe (Bowie \u2013 yellow) although in Gaelic these occur as part of a fuller form such as MacGille 'son of the servant of', i.e. MacGilleBh\u00e0in, MacGilleRuaidh, MacGilleDhuibh, MacGilleDhuinn, MacGilleBhuidhe.  Most varieties of Gaelic show either eight or nine vowel qualities (\/i e \u025b a \u0254 o u \u0264 \u026f\/) in their inventory of vowel phonemes, which can be either long or short. There are also two reduced vowels ([\u0259 \u026a]) which occur only in their short versions. Although some vowels are strongly nasal, instances of distinctive nasality are rare. There are about nine diphthongs and a few triphthongs.  Most consonants have both palatal and non-palatal counterparts, including a very rich system of liquids, nasals and trills (i.e. three contrasting \"l\" sounds, three contrasting \"n\" sounds and three contrasting \"r\" sounds). The historically voiced stops [b d\u032a \u0261] have lost their voicing, so the phonemic contrast today is between unaspirated [p t\u032a k] and aspirated [p\u02b0 t\u032a\u02b0 k\u02b0]. In many dialects, these stops may however gain voicing through secondary articulation through a preceding nasal, for examples doras [t\u032a\u0254\u027e\u0259s\u032a] \"door\" but an doras \"the door\" as [\u0259n\u032a\u02e0 d\u032a\u0254\u027e\u0259s\u032a] or [\u0259 n\u032a\u02e0\u0254\u027e\u0259s\u032a].  In some fixed phrases, these changes are shown permanently, as the link with the base words has been lost, as in an-dr\u00e0sta \"now\", from an tr\u00e0th-sa \"this time\/period\".  In medial and final position, the aspirated stops are preaspirated rather than postaspirated.  Scottish Gaelic is an Indo-European language with an inflecting morphology, verb\u2013subject\u2013object word order and two grammatical genders.  Gaelic nouns inflect for four cases (nominative\/accusative, vocative, genitive and dative) and three numbers (singular, dual and plural).  They are also normally classed as either masculine or feminine. A small number of words that used to belong to the neuter class show some degree of gender confusion. For example, in some dialects am muir \"the sea\" behaves as a masculine noun in the nominative case, but as a feminine noun in the genitive (na mara).  Nouns are marked for case in a number of ways, most commonly involving various combinations of lenition, palatalisation and suffixation.  There are 12 irregular verbs.[111] Most other verbs follow a fully predictable paradigm, although polysyllabic verbs ending in laterals can deviate from this paradigm as they show syncopation.  There are:  Word order is strictly verb\u2013subject\u2013object, including questions, negative questions and negatives. Only a restricted set of preverb particles may occur before the verb.  The majority of the vocabulary of Scottish Gaelic is of Celtic origin. However, Gaelic contains substantially more words of non-Goidelic extraction than Irish. The main sources of loanwords into Gaelic are the Germanic languages English, Scots and Norse. Other sources include Latin, French and the Brittonic languages.[112]  Many direct Latin loanwords in Scottish Gaelic were adopted during the Old and Middle Irish (600 AD-1200 AD) stages of the language and are often terms related to Christianity. Latin is also the source of the days of the week Diluain (\"Monday\"), Dim\u00e0irt (Tuesday), Disathairne (\"Saturday\") and Did\u00f2mhnaich (\"Sunday\").[112]  The Brittonic languages Cumbric and Pictish were spoken in Scotland during the Early to High Middle Ages, and Scottish Gaelic has many Brittonic influences. Scottish Gaelic contains a number of apparently P-Celtic loanwords, but it is not always possible to disentangle P and Q Celtic words. However, some common words such as d\u00ecleab (\"legacy\"), monadh (mynydd; \"mountain\") and preas (prys; \"bush\") are transparently Brittonic in origin.[24]  Scottish Gaelic contains a number of words, principally toponymic elements, that are more closely aligned in their usage and sense with their Brittonic cognates than their Irish. This is indicative of the operation of a Brittonic substrate influence. Such items include:[113][114]  In common with other Indo-European languages, the neologisms coined for modern concepts are typically based on Greek or Latin, although often coming through English; television, for instance, becomes telebhisean and computer becomes coimpi\u00f9tar. Some speakers use an English word even if there is a Gaelic equivalent, applying the rules of Gaelic grammar. With verbs, for instance, they will simply add the verbal suffix (-eadh, or, in Lewis, -igeadh, as in, \"Tha mi a' watch eadh (Lewis, \"watch igeadh\") an telly\" (I am watching the television), instead of \"Tha mi a' coimhead air an telebhisean\". This phenomenon was described over 170 years ago, by the minister who compiled the account covering the parish of Stornoway in the New Statistical Account of Scotland, and examples can be found dating to the eighteenth century.[115] However, as Gaelic medium education grows in popularity, a newer generation of literate Gaels has become more familiar with modern Gaelic vocabulary.[citation needed]  Scottish Gaelic has also influenced the Scots language and English, particularly Scottish Standard English. Loanwords include: whisky, slogan, brogue, jilt, clan, galore, trousers, gob, as well as familiar elements of Scottish geography like ben (beinn), glen (gleann) and loch. Irish has also influenced Lowland Scots and English in Scotland, but it is not always easy to distinguish its influence from that of Scottish Gaelic.[112][page\u00a0needed]  Scottish Gaelic orthography is fairly regular; its standard was set by the 1767 New Testament. The 1981 Scottish Examination Board recommendations for Scottish Gaelic, the Gaelic Orthographic Conventions, were adopted by most publishers and agencies, although they remain controversial among some academics, most notably Ronald Black.[116]  The quality of consonants (broad or slender) is indicated by the vowels surrounding them. Slender (palatalised) consonants are surrounded by slender vowels (\u27e8e, i\u27e9), while broad (neutral or velarised) consonants are surrounded by broad vowels (\u27e8a, o, u\u27e9). The spelling rule known as caol ri caol agus leathann ri leathann (\"slender to slender and broad to broad\") requires that a word-medial consonant or consonant group followed by \u27e8i, e\u27e9 is preceded by \u27e8i, e\u27e9 and similarly, if followed by \u27e8a, o, u\u27e9 is preceded by \u27e8a, o, u\u27e9.  This rule sometimes leads to the insertion of a silent written vowel. For example, plurals in Gaelic are often formed with the suffix -an [\u0259n], for example, br\u00f2g [pr\u0254\u02d0k] (\"shoe\") \/ br\u00f2gan [pr\u0254\u02d0k\u0259n] (\"shoes\"). But because of the spelling rule, the suffix is spelled -\u27e8ean\u27e9 (but pronounced the same, [\u0259n]) after a slender consonant, as in muinntir [m\u026fi\u032f\u0272t\u02b2\u026ar\u02b2] (\"[a] people\") \/ muinntirean [m\u026fi\u032f\u0272t\u02b2\u026ar\u02b2\u0259n] (\"peoples\") where \u27e8e\u27e9 is purely a graphic vowel inserted to conform with the spelling rule because \u27e8i\u27e9 precedes the \u27e8r\u27e9.  Unstressed vowels omitted in speech can be omitted in informal writing, e.g. Tha mi an d\u00f2chas. (\"I hope.\") > Tha mi 'n d\u00f2chas.  Scots English orthographic rules have also been used at various times in Gaelic writing. Notable examples of Gaelic verse composed in this manner are the Book of the Dean of Lismore and the Fernaig manuscript.  The Ogham writing system was used in Ireland to write Primitive Irish and Old Irish until it was supplanted by the Latin script in the 5th century CE in Ireland.[117] In Scotland, the majority of Ogham inscriptions are in Pictish but a number of Goidelic Ogham inscriptions also exist, such as the Giogha Stone which bears the inscription VICULA MAQ CUGINI 'Viqula, son of Comginus',[118] with Goidelic MAQ (modern mac 'son') rather than Brythonic MAB (cf. modern Welsh mab 'son').  The Insular script was used both in Ireland and Scotland but had largely disappeared in Scotland by the 16th century. It consisted of the same 18 letters still in modern use \u27e8a, b, c, d, e, f, g, h, i, l, m, n, o, p, r, s, t, u\u27e9.[119][120] and generally did not contain \u27e8j, k, q, v, w, x, y, z\u27e9.  In addition to the base letters, vowels in the Insular script could be accented with an acute accent (\u27e8\u00e1, \u00e9, \u00ed, \u00f3, \u00fa\u27e9 to indicate length. The overdot was used to indicate lenition of \u27e8\u1e1f, \u1e61\u27e9, while the following \u27e8h\u27e9 was used for \u27e8ch, ph, th\u27e9. The lenition of other letters was not generally indicated initially but eventually the two methods were used in parallel to represent the lenition of any consonant and competed with each other until the standard practice became to use the overdot in the Insular Script and the following \u27e8h\u27e9 in Roman type, i.e. \u27e8\u1e03, \u010b, \u1e0b, \u1e1f, \u0121, \u1e41, \u1e57, \u1e61, \u1e6b\u27e9 are equivalent to \u27e8bh, ch, dh, fh, gh, mh, ph, sh, th\u27e9. The use of Gaelic type and the overdot today is restricted to decorative usages.  Letters with an overdot have been available since Unicode 5.0 .[121]  The modern Scottish Gaelic alphabet has 18 letters: \u27e8a, b, c, d, e, f, g, h, i, l, m, n, o, p, r, s, t, u\u27e9. \u27e8h\u27e9 is mostly used to indicate lenition of a consonant. The letters of the alphabet were traditionally named after trees, but this custom has fallen out of use.  Long vowels are marked with a grave accent (\u27e8\u00e0, \u00e8, \u00ec, \u00f2, \u00f9\u27e9), indicated through digraphs (e.g. \u27e8ao\u27e9 for [\u026f\u02d0]) or conditioned by certain consonant environments (e.g. \u27e8u\u27e9 preceding a non-intervocalic \u27e8nn\u27e9 is [u\u02d0]). Traditionally the acute accent was used on \u27e8\u00e1, \u00e9, \u00f3\u27e9 to represent long close-mid vowels, but the spelling reforms replaced it with the grave accent.[108]  Certain 18th century sources used only an acute accent along the lines of Irish, such as in the writings of Alasdair mac Mhaighstir Alasdair (1741\u201351) and the earliest editions (1768\u201390) of Duncan Ban MacIntyre.[122]  Article 1 of the Universal Declaration of Human Rights in Scottish Gaelic:   Article 1 of the Universal Declaration of Human Rights in English:  Note: Items in brackets denote archaic, dialectal or regional variant forms "},{"title":"Democracy","content":"  List of forms of government  Democracy (from Ancient Greek: \u03b4\u03b7\u03bc\u03bf\u03ba\u03c1\u03b1\u03c4\u03af\u03b1, romanized:\u00a0d\u0113mokrat\u00eda, d\u0113mos 'people' and kratos 'rule')[1] is a system of government in which state power is vested in the people or the general population of a state.[2] Under a minimalist definition of democracy, rulers are elected through competitive elections while more expansive definitions link democracy to guarantees of civil liberties and human rights in addition to competitive elections.[3][4]  In a direct democracy, the people have the direct authority to deliberate and decide legislation. In a representative democracy, the people choose governing officials through elections to do so. Who is considered part of \"the people\" and how authority is shared among or delegated by the people has changed over time and at different rates in different countries. Features of democracy oftentimes include freedom of assembly, association, personal property, freedom of religion and speech, citizenship, consent of the governed, voting rights, freedom from unwarranted governmental deprivation of the right to life and liberty, and minority rights.  The notion of democracy has evolved over time considerably. Throughout history, one can find evidence of direct democracy, in which communities make decisions through popular assembly. Today, the dominant form of democracy is representative democracy, where citizens elect government officials to govern on their behalf such as in a parliamentary or presidential democracy. Most democracies apply in most cases majority rule,[5][6] but in some cases plurality rule, supermajority rule (e.g. constitution) or consensus rule (e.g. Switzerland) are applied. They serve the crucial purpose of inclusiveness and broader legitimacy on sensitive issues\u2014counterbalancing majoritarianism\u2014and therefore mostly take precedence on a constitutional level. In the common variant of liberal democracy, the powers of the majority are exercised within the framework of a representative democracy, but a constitution and supreme court limit the majority and protect the minority\u2014usually through securing the enjoyment by all of certain individual rights, such as freedom of speech or freedom of association.[7][8]  The term appeared in the 5th century BC in Greek city-states, notably Classical Athens, to mean \"rule of the people\", in contrast to aristocracy (\u1f00\u03c1\u03b9\u03c3\u03c4\u03bf\u03ba\u03c1\u03b1\u03c4\u03af\u03b1, aristokrat\u00eda), meaning \"rule of an elite\".[9] Western democracy, as distinct from that which existed in antiquity, is generally considered to have originated in city-states such as those in Classical Athens and the Roman Republic, where various degrees of enfranchisement of the free male population were observed. In virtually all democratic governments throughout ancient and modern history, democratic citizenship was initially restricted to an elite class, which was later extended to all adult citizens. In most modern democracies, this was achieved through the suffrage movements of the 19th and 20th centuries.  Democracy contrasts with forms of government where power is not vested in the general population of a state, such as authoritarian systems. World public opinion strongly favors democratic systems of government.[10] According to the V-Dem Democracy indices and The Economist Democracy Index, less than half the world's population lives in a democracy as of 2022[update].[11][12]  Although democracy is generally understood to be defined by voting,[1][8] no consensus exists on a precise definition of democracy.[13] Karl Popper says that the \"classical\" view of democracy is, \"in brief, the theory that democracy is the rule of the people, and that the people have a right to rule\".[14] One study identified 2,234 adjectives used to describe democracy in the English language.[15]  Democratic principles are reflected in all eligible citizens being equal before the law and having equal access to legislative processes.[16] For example, in a representative democracy, every vote has (in theory) equal weight, and the freedom of eligible citizens is secured by legitimised rights and liberties which are typically enshrined in a constitution,[17][18] while other uses of \"democracy\" may encompass direct democracy, in which citizens vote on issues directly. According to the United Nations, democracy \"provides an environment that respects human rights and fundamental freedoms, and in which the freely expressed will of people is exercised.\"[19]  One theory holds that democracy requires three fundamental principles: upward control (sovereignty residing at the lowest levels of authority), political equality, and social norms by which individuals and institutions only consider acceptable acts that reflect the first two principles of upward control and political equality.[20] Legal equality, political freedom and rule of law[21] are often identified by commentators as foundational characteristics for a well-functioning democracy.[13]  In some countries, notably in the United Kingdom (which originated the Westminster system), the dominant principle is that of parliamentary sovereignty, while maintaining judicial independence.[22][23] In India, parliamentary sovereignty is subject to the Constitution of India which includes judicial review.[24] Though the term \"democracy\" is typically used in the context of a  political state, the principles also are potentially applicable to private organisations, such as clubs, societies and firms.  Democracies may use many different decision-making methods, but majority rule is the dominant form. Without compensation, like legal protections of individual or group rights,  political minorities can be oppressed by the \"tyranny of the majority\". Majority rule involves a competitive approach, opposed to consensus democracy, creating the need that elections, and generally deliberation, be substantively and procedurally \"fair\",\" i.e. just and equitable. In some countries, freedom of political expression, freedom of speech, and freedom of the press are considered important to ensure that voters are well informed, enabling them to vote according to their own interests and beliefs.[25][26]  It has also been suggested that a basic feature of democracy is the capacity of all voters to participate freely and fully in the life of their society.[27] With its emphasis on notions of social contract and the  collective will of all the voters, democracy can also be characterised as a form of political  collectivism because it is defined as a form of government in which all eligible citizens have an equal say in lawmaking.[28]  Republics, though often popularly associated with democracy because of the shared principle of rule by consent of the governed, are not necessarily democracies, as republicanism does not specify how the people are to rule.[29] Classically the term \"republic\" encompassed both democracies and  aristocracies.[30][31] In a modern sense the republican form of government is a form of government without a monarch. Because of this, democracies can be republics or  constitutional monarchies, such as the United Kingdom.  Democratic assemblies are as old as the human species and are found throughout human history,[33] but up until the nineteenth century, major political figures have largely opposed democracy.[34] Republican theorists linked democracy to small size: as political units grew in size, the likelihood increased that the government would turn despotic.[35][36] At the same time, small political units were vulnerable to conquest.[35] Montesquieu wrote, \"If a republic be small, it is destroyed by a foreign force; if it be large, it is ruined by an internal imperfection.\"[37] According to Johns Hopkins University political scientist Daniel Deudney, the creation of the United States, with its large size and its system of checks and balances, was a solution to the dual problems of size.[35][pages\u00a0needed]  Retrospectively different polities, outside of declared democracies, have been described as proto-democratic.  Forms of democracy occurred organically in societies around the world that had no contact with each other.[38][39]  Vaishali, capital city of the Vajjika League (Vrijji mahajanapada) of India, is considered one of the first examples of a republic around the 6th century BC.[40][41][42]  The term democracy first appeared in ancient Greek political and philosophical thought in the city-state of Athens during classical antiquity.[43][44] The word comes from d\u00eamos '(common) people' and kr\u00e1tos 'force\/might'.[45] Under Cleisthenes, what is generally held as the first example of a type of democracy in 508\u2013507 BC was established in Athens. Cleisthenes is referred to as \"the father of Athenian democracy\".[46] The first attested use of the word democracy is found in prose works of the 430s BC, such as Herodotus' Histories, but its usage was older by several decades, as two Athenians born in the 470s were named Democrates, a new political name\u2014likely in support of democracy\u2014given at a time of debates over constitutional issues in Athens. Aeschylus also strongly alludes to the word in his play The Suppliants, staged in c.463 BC, where he mentions \"the demos's ruling hand\" [demou kratousa cheir]. Before that time, the word used to define the new political system of Cleisthenes was probably isonomia, meaning political equality.[47]  Athenian democracy took the form of a direct democracy, and it had two distinguishing features: the random selection of ordinary citizens to fill the few existing government administrative and judicial offices,[48] and a legislative assembly consisting of all Athenian citizens.[49] All eligible citizens were allowed to speak and vote in the assembly, which set the laws of the city state. However, Athenian citizenship excluded women, slaves, foreigners (\u03bc\u03ad\u03c4\u03bf\u03b9\u03ba\u03bf\u03b9 \/ m\u00e9toikoi), and youths below the age of military service.[50][51][contradictory] Effectively, only 1 in 4 residents in Athens qualified as citizens. Owning land was not a requirement for citizenship.[52] The exclusion of large parts of the population from the citizen body is closely related to the ancient understanding of citizenship. In most of antiquity the benefit of citizenship was tied to the obligation to fight war campaigns.[53]  Athenian democracy was not only direct in the sense that decisions were made by the assembled people, but also the most direct in the sense that the people through the assembly, boule and courts of law controlled the entire political process and a large proportion of citizens were involved constantly in the public business.[54] Even though the rights of the individual were not secured by the Athenian constitution in the modern sense (the ancient Greeks had no word for \"rights\"[55]), those who were citizens of Athens enjoyed their liberties not in opposition to the government but by living in a city that was not subject to another power and by not being subjects themselves to the rule of another person.[56]  Range voting appeared in Sparta as early as 700 BC. The Spartan ecclesia was an assembly of the people, held once a month, in which every male citizen of at least 20 years of age could participate. In the assembly, Spartans elected leaders and cast votes by range voting and shouting (the vote is then decided on how loudly the crowd shouts). Aristotle called this \"childish\", as compared with the stone voting ballots used by the Athenian citizenry. Sparta adopted it because of its simplicity, and to prevent any biased voting, buying, or cheating that was predominant in the early democratic elections.[57]  Even though the Roman Republic contributed significantly to many aspects of democracy, only a minority of Romans were citizens with votes in elections for representatives. The votes of the powerful were given more weight through a system of weighted voting, so most high officials, including members of the Senate, came from a few wealthy and noble families.[58] In addition, the overthrow of the Roman Kingdom was the first case in the Western world of a polity being formed with the explicit purpose of being a republic, although it didn't have much of a democracy. The Roman model of governance inspired many political thinkers over the centuries.[59]  Other cultures, such as the Iroquois Nation in the Americas also developed a form of democratic society between 1450 and 1660 (and possibly in 1142[60]), well before contact with the Europeans. This democracy continues to the present day and is the world's oldest standing representative democracy.[61][62]  While most regions in Europe during the Middle Ages were ruled by clergy or feudal lords, there existed various systems involving elections or assemblies, although often only involving a small part of the population. In Scandinavia, bodies known as things consisted of freemen presided by a lawspeaker. These deliberative bodies were responsible for settling political questions, and variants included the Althing in Iceland and the L\u00f8gting in the Faeroe Islands.[63][64] The veche, found in Eastern Europe, was a similar body to the Scandinavian thing. In the Roman Catholic Church, the pope has been elected by a papal conclave composed of cardinals since 1059. The first documented parliamentary body in Europe was the Cortes of Le\u00f3n. Established by Alfonso IX in 1188, the Cortes had authority over setting taxation, foreign affairs and legislating, though the exact nature of its role remains disputed.[65] The Republic of Ragusa, established in 1358 and centered around the city of Dubrovnik, provided representation and voting rights to its male aristocracy only. Various Italian city-states and polities had republic forms of government. For instance, the Republic of Florence, established in 1115, was led by the Signoria whose members were chosen by sortition. In 10th\u201315th century Frisia, a distinctly non-feudal society, the right to vote on local matters and on county officials was based on land size. The Kouroukan Fouga divided the Mali Empire into ruling clans (lineages) that were represented at a great assembly called the Gbara. However, the charter made Mali more similar to a constitutional monarchy than a democratic republic.  The Parliament of England had its roots in the restrictions on the power of kings written into Magna Carta (1215), which explicitly protected certain rights of the King's subjects and implicitly supported what became the English writ of habeas corpus, safeguarding individual freedom against unlawful imprisonment with right to appeal.[66][67] The first representative national assembly in England was Simon de Montfort's Parliament in 1265.[68][69] The emergence of petitioning is some of the earliest evidence of parliament being used as a forum to address the general grievances of ordinary people. However, the power to call parliament remained at the pleasure of the monarch.[70]  Studies have linked the emergence of parliamentary institutions in Europe during the medieval period to urban agglomeration and the creation of new classes, such as artisans,[71] as well as the presence of nobility and religious elites.[72] Scholars have also linked the emergence of representative government to Europe's relative political fragmentation.[73] Political scientist David Stasavage links the fragmentation of Europe, and its subsequent democratization, to the manner in which the Roman Empire collapsed: Roman territory was conquered by small fragmented groups of Germanic tribes, thus leading to the creation of small political units where rulers were relatively weak and needed the consent of the governed to ward off foreign threats.[74]  In Poland, noble democracy was characterized by an increase in the activity of the middle nobility, which wanted to increase their share in exercising power at the expense of the magnates. Magnates dominated the most important offices in the state (secular and ecclesiastical) and sat on the royal council, later the senate. The growing importance of the middle nobility had an impact on the establishment of the institution of the land sejmik (local assembly), which subsequently obtained more rights. During the fifteenth and first half of the sixteenth century, sejmiks received more and more powers and became the most important institutions of local power. In 1454, Casimir IV Jagiellon granted the sejmiks the right to decide on taxes and to convene a mass mobilization in the Nieszawa Statutes. He also pledged not to create new laws without their consent.[75]  In 17th century England, there was renewed interest in Magna Carta.[76] The Parliament of England passed the Petition of Right in 1628 which established certain liberties for subjects. The English Civil War (1642\u20131651) was fought between the King and an oligarchic but elected Parliament,[77][78] during which the idea of a political party took form with groups debating rights to political representation during the Putney Debates of 1647.[79] Subsequently, the Protectorate (1653\u201359) and the English Restoration (1660) restored more autocratic rule, although Parliament passed the Habeas Corpus Act in 1679 which strengthened the convention that forbade detention lacking sufficient cause or evidence. After the Glorious Revolution of 1688, the Bill of Rights was enacted in 1689 which codified certain rights and liberties and is still in effect. The Bill set out the requirement for regular elections, rules for freedom of speech in Parliament and limited the power of the monarch, ensuring that, unlike much of Europe at the time, royal absolutism would not prevail.[80][81] Economic historians Douglass North and Barry Weingast have characterized the institutions implemented in the Glorious Revolution as a resounding success in terms of restraining the government and ensuring protection for property rights.[82]  Renewed interest in the Magna Carta, the English Civil War, and the Glorious Revolution in the 17th century prompted the growth of political philosophy on the British Isles. Thomas Hobbes was the first philosopher to articulate a detailed social contract theory. Writing in the Leviathan (1651), Hobbes theorized that individuals living in the state of nature led lives that were \"solitary, poor, nasty, brutish and short\" and constantly waged a war of all against all. In order to prevent the occurrence of an anarchic state of nature, Hobbes reasoned that individuals ceded their rights to a strong, authoritarian power. In other words, Hobbes advocated for an absolute monarchy which, in his opinion, was the best form of government. Later, philosopher and physician John Locke would posit a different interpretation of social contract theory. Writing in his Two Treatises of Government (1689), Locke posited that all individuals possessed the inalienable rights to life, liberty and estate (property).[83] According to Locke, individuals would voluntarily come together to form a state for the purposes of defending their rights. Particularly important for Locke were property rights, whose protection Locke deemed to be a government's primary purpose.[84] Furthermore, Locke asserted that governments were legitimate only if they held the consent of the governed. For Locke, citizens had the right to revolt against a government that acted against their interest or became tyrannical. Although they were not widely read during his lifetime, Locke's works are considered the founding documents of liberal thought and profoundly influenced the leaders of the American Revolution and later the French Revolution.[85] His liberal democratic framework of governance remains the preeminent form of democracy in the world.  In the Cossack republics of Ukraine in the 16th and 17th centuries, the Cossack Hetmanate and Zaporizhian Sich, the holder of the highest post of Hetman was elected by the representatives from the country's districts.  In North America, representative government began in Jamestown, Virginia, with the election of the House of Burgesses (forerunner of the Virginia General Assembly) in 1619. English Puritans who migrated from 1620 established colonies in New England whose local governance was democratic;[86] although these local assemblies had some small amounts of devolved power, the ultimate authority was held by the Crown and the English Parliament. The Puritans (Pilgrim Fathers), Baptists, and Quakers who founded these colonies applied the democratic organisation of their congregations also to the administration of their communities in worldly matters.[87][88][89]  The first Parliament of Great Britain was established in 1707, after the merger of the Kingdom of England and the Kingdom of Scotland under the Acts of Union. Two key documents of the UK's uncodified constitution, the English Declaration of Right, 1689 (restated in the Bill of Rights 1689) and the Scottish Claim of Right 1689, had both cemented Parliament's position as the supreme law-making body, and said that the \"election of members of Parliament ought to be free\".[91] However, Parliament was only elected by male property owners, which amounted to 3% of the population in 1780.[92] The first known British person of African heritage to vote in a general election, Ignatius Sancho, voted in 1774 and 1780.[93]  During the Age of Liberty in Sweden (1718\u20131772), civil rights were expanded and power shifted from the monarch to parliament.[94] The taxed peasantry was represented in parliament, although with little influence, but commoners without taxed property had no suffrage.  The creation of the short-lived Corsican Republic in 1755 was an early attempt to adopt a democratic constitution (all men and women above age of 25 could vote).[95] This Corsican Constitution was the first based on Enlightenment principles and included female suffrage, something that was not included in most other democracies until the 20th century.  Colonial America had similar property qualifications as Britain, and in the period before 1776 the abundance and availability of land meant that large numbers of colonists met such requirements with at least 60 per cent of adult white males able to vote.[96] The great majority of white men were farmers who met the property ownership or taxpaying requirements. With few exceptions no blacks or women could vote. Vermont, which, on declaring independence of Great Britain in 1777, adopted a constitution modelled on Pennsylvania's with citizenship and democratic suffrage for males with or without property.[97] The United States Constitution of 1787 is the oldest surviving, still active, governmental codified constitution. The Constitution provided for an elected government and protected civil rights and liberties, but did not end slavery nor extend voting rights in the United States, instead leaving the issue of suffrage to the individual states.[98] Generally, states limited suffrage to white male property owners and taxpayers.[99] At the time of the first Presidential election in 1789, about 6% of the population was eligible to vote.[100] The Naturalization Act of 1790 limited U.S. citizenship to whites only.[101] The Bill of Rights in 1791 set limits on government power to protect personal freedoms but had little impact on judgements by the courts for the first 130 years after ratification.[102]  In 1789, Revolutionary France adopted the Declaration of the Rights of Man and of the Citizen and, although short-lived, the National Convention was elected by all men in 1792.[103] The Polish-Lithuanian Constitution of 3 May 1791 sought to implement a more effective constitutional monarchy, introduced political equality between townspeople and nobility, and placed the peasants under the protection of the government, mitigating the worst abuses of serfdom. In force for less than 19 months, it was declared null and void by the Grodno Sejm that met in 1793.[104][105] Nonetheless, the 1791 Constitution helped keep alive Polish aspirations for the eventual restoration of the country's sovereignty over a century later.  In the United States, the 1828 presidential election was the first in which non-property-holding white males could vote in the vast majority of states. Voter turnout soared during the 1830s, reaching about 80% of the adult white male population in the 1840 presidential election.[106] North Carolina was the last state to abolish property qualification in 1856 resulting in a close approximation to universal white male suffrage (however tax-paying requirements remained in five states in 1860 and survived in two states until the 20th century).[107][108][109] In the 1860 United States Census, the slave population had grown to four million,[110] and in Reconstruction after the Civil War, three constitutional amendments were passed: the 13th Amendment (1865) that ended slavery; the 14th Amendment (1869) that gave black people citizenship, and the 15th Amendment (1870) that gave black males a nominal right to vote.[111][112][nb 1] Full enfranchisement of citizens was not secured until after the civil rights movement gained passage by the US Congress of the Voting Rights Act of 1965.[113][114]  The voting franchise in the United Kingdom was expanded and made more uniform in a series of reforms that began with the Reform Act 1832 and continued into the 20th century, notably with the Representation of the People Act 1918 and the Equal Franchise Act 1928. Universal male suffrage was established in France in March 1848 in the wake of the French Revolution of 1848.[115] During that year, several revolutions broke out in Europe as rulers were confronted with popular demands for liberal constitutions and more democratic government.[116]  In 1876 the Ottoman Empire transitioned from an absolute monarchy to a constitutional one, and held two elections the next year to elect members to her newly formed parliament.[117] Provisional Electoral Regulations were issued, stating that the elected members of the Provincial Administrative Councils would elect members to the first Parliament. Later that year, a new constitution was promulgated, which provided for a bicameral Parliament with a Senate appointed by the Sultan and a popularly elected Chamber of Deputies. Only men above the age of 30 who were competent in Turkish and had full civil rights were allowed to stand for election. Reasons for disqualification included holding dual citizenship, being employed by a foreign government, being bankrupt, employed as a servant, or having \"notoriety for ill deeds\". Full universal suffrage was achieved in 1934.[118]  In 1893 the self-governing colony New Zealand became the first country in the world (except for the short-lived 18th-century Corsican Republic) to establish active universal suffrage by recognizing women as having the right to vote.[119]  20th-century transitions to liberal democracy have come in successive \"waves of democracy\", variously resulting from wars, revolutions, decolonisation, and religious and economic circumstances.[120] Global waves of \"democratic regression\" reversing democratization, have also occurred in the 1920s and 30s, in the 1960s and 1970s, and in the 2010s.[121][122]  World War I and the dissolution of the autocratic Ottoman and Austro-Hungarian empires resulted in the creation of new nation-states in Europe, most of them at least nominally democratic. In the 1920s democratic movements flourished and women's suffrage advanced, but the Great Depression brought disenchantment and most of the countries of Europe, Latin America, and Asia turned to strong-man rule or dictatorships. Fascism and dictatorships flourished in Nazi Germany, Italy, Spain and Portugal, as well as non-democratic governments in the Baltics, the Balkans, Brazil, Cuba, China, and Japan, among others.[123]  World War II brought a definitive reversal of this trend in western Europe. The democratisation of the American, British, and French sectors of occupied Germany (disputed[124]), Austria, Italy, and the occupied Japan served as a model for the later theory of government change. However, most of Eastern Europe, including the Soviet sector of Germany fell into the non-democratic Soviet-dominated bloc.  The war was followed by decolonisation, and again most of the new independent states had nominally democratic constitutions. India emerged as the world's largest democracy and continues to be so.[125] Countries that were once part of the British Empire often adopted the British Westminster system.[126][127] By 1960, the vast majority of country-states were nominally democracies, although most of the world's populations lived in nominal democracies that experienced sham elections, and other forms of subterfuge (particularly in \"Communist\" states and the former colonies.)  A subsequent wave of democratisation brought substantial gains toward true liberal democracy for many states, dubbed \"third wave of democracy\". Portugal, Spain, and several of the military dictatorships in South America returned to civilian rule in the 1970s and 1980s.[nb 2] This was followed by countries in East and South Asia by the mid-to-late 1980s. Economic malaise in the 1980s, along with resentment of Soviet oppression, contributed to the collapse of the Soviet Union, the associated end of the Cold War, and the democratisation and liberalisation of the former Eastern bloc countries. The most successful of the new democracies were those geographically and culturally closest to western Europe, and they are now either part of the European Union or candidate states. In 1986, after the toppling of the most prominent Asian dictatorship, the only democratic state of its kind at the time emerged in the Philippines with the rise of Corazon Aquino, who would later be known as the Mother of Asian Democracy.  The liberal trend spread to some states in Africa in the 1990s, most prominently in South Africa. Some recent examples of attempts of liberalisation include the Indonesian Revolution of 1998, the Bulldozer Revolution in Yugoslavia, the Rose Revolution in Georgia, the Orange Revolution in Ukraine, the Cedar Revolution in Lebanon, the Tulip Revolution in Kyrgyzstan, and the Jasmine Revolution in Tunisia.  According to Freedom House, in 2007 there were 123 electoral democracies (up from 40 in 1972).[129] According to World Forum on Democracy, electoral democracies now represent 120 of the 192 existing countries and constitute 58.2 per cent of the world's population. At the same time liberal democracies i.e. countries Freedom House regards as free and respectful of basic human rights and the rule of law are 85 in number and represent 38 per cent of the global population.[130] Also in 2007 the United Nations declared 15 September the International Day of Democracy.[131]  Many countries reduced their voting age to 18 years; the major democracies began to do so in the 1970s starting in Western Europe and North America.[132][failed verification][133][134] Most electoral democracies continue to exclude those younger than 18 from voting.[135] The voting age has been lowered to 16 for national elections in a number of countries, including Brazil, Austria, Cuba, and Nicaragua. In California, a 2004 proposal to permit a quarter vote at 14 and a half vote at 16 was ultimately defeated. In 2008, the German parliament proposed but shelved a bill that would grant the vote to each citizen at birth, to be used by a parent until the child claims it for themselves.  According to Freedom House, starting in 2005, there have been 17 consecutive years in which declines in political rights and civil liberties throughout the world have outnumbered improvements,[136][137] as populist and nationalist political forces have gained ground everywhere from Poland (under the Law and Justice Party) to the Philippines (under Rodrigo Duterte).[136][121] In a Freedom House report released in 2018, Democracy Scores for most countries declined for the 12th consecutive year.[138] The Christian Science Monitor reported that nationalist and populist political ideologies were gaining ground, at the expense of rule of law, in countries like Poland, Turkey and Hungary. For example, in Poland, the President appointed 27 new Supreme Court judges over legal objections from the European Commission. In Turkey, thousands of judges were removed from their positions following a failed coup attempt during a government crackdown .[139]  \"Democratic backsliding\" in the 2010s were attributed to economic inequality and social discontent,[141] personalism,[142] poor government's management of the COVID-19 pandemic,[143][144] as well as other factors such as manipulation of civil society, \"toxic polarization\", foreign disinformation campaigns,[145] racism and nativism, excessive executive power,[146][147][148] and decreased power of the opposition.[149] Within English-speaking Western democracies, \"protection-based\" attitudes combining cultural conservatism and leftist economic attitudes were the strongest predictor of support for authoritarian modes of governance.[150]  Aristotle contrasted rule by the many (democracy\/timocracy), with rule by the few (oligarchy\/aristocracy), and with rule by a single person (tyranny or today autocracy\/absolute monarchy). He also thought that there was a good and a bad variant of each system (he considered democracy to be the degenerate counterpart to timocracy).[151][152]  A common view among early and renaissance Republican theorists was that democracy could only survive in small political communities.[153] Heeding the lessons of the Roman Republic's shift to monarchism as it grew larger or smaller, these Republican theorists held that the expansion of territory and population inevitably led to tyranny.[153] Democracy was therefore highly fragile and rare historically, as it could only survive in small political units, which due to their size were vulnerable to conquest by larger political units.[153] Montesquieu famously said, \"if a republic is small, it is destroyed by an outside force; if it is large, it is destroyed by an internal vice.\"[153] Rousseau asserted, \"It is, therefore the natural property of small states to be governed as a republic, of middling ones to be subject to a monarch, and of large empires to be swayed by a despotic prince.\"[153]  Among modern political theorists, there are three contending conceptions of democracy: aggregative democracy, deliberative democracy, and radical democracy.[154]  The theory of aggregative democracy claims that the aim of the democratic processes is to solicit citizens' preferences and aggregate them together to determine what social policies society should adopt. Therefore, proponents of this view hold that democratic participation should primarily focus on voting, where the policy with the most votes gets implemented.  Different variants of aggregative democracy exist. Under minimalism, democracy is a system of government in which citizens have given teams of political leaders the right to rule in periodic elections. According to this minimalist conception, citizens cannot and should not \"rule\" because, for example, on most issues, most of the time, they have no clear views or their views are not well-founded. Joseph Schumpeter articulated this view most famously in his book Capitalism, Socialism, and Democracy.[155] Contemporary proponents of minimalism include William H. Riker, Adam Przeworski, Richard Posner.  According to the theory of direct democracy, on the other hand, citizens should vote directly, not through their representatives, on legislative proposals. Proponents of direct democracy offer varied reasons to support this view. Political activity can be valuable in itself, it socialises and educates citizens, and popular participation can check powerful elites. Most importantly, citizens do not rule themselves unless they directly decide laws and policies.  Governments will tend to produce laws and policies that are close to the views of the median voter\u2014with half to their left and the other half to their right. This is not a desirable outcome as it represents the action of self-interested and somewhat unaccountable political elites competing for votes. Anthony Downs suggests that ideological political parties are necessary to act as a mediating broker between individual and governments. Downs laid out this view in his 1957 book An Economic Theory of Democracy.[156]  Robert A. Dahl argues that the fundamental democratic principle is that, when it comes to binding collective decisions, each person in a political community is entitled to have his\/her interests be given equal consideration (not necessarily that all people are equally satisfied by the collective decision). He uses the term polyarchy to refer to societies in which there exists a certain set of institutions and procedures which are perceived as leading to such democracy. First and foremost among these institutions is the regular occurrence of free and open elections which are used to select representatives who then manage all or most of the public policy of the society. However, these polyarchic procedures may not create a full democracy if, for example, poverty prevents political participation.[157] Similarly, Ronald Dworkin argues that \"democracy is a substantive, not a merely procedural, ideal.\"[158]  Deliberative democracy is based on the notion that democracy is government by deliberation. Unlike aggregative democracy, deliberative democracy holds that, for a democratic decision to be legitimate, it must be preceded by authentic deliberation, not merely the aggregation of preferences that occurs in voting. Authentic deliberation is deliberation among decision-makers that is free from distortions of unequal political power, such as power a decision-maker obtained through economic wealth or the support of interest groups.[159][160][161] If the decision-makers cannot reach consensus after authentically deliberating on a proposal, then they vote on the proposal using a form of majority rule. Citizens assemblies are considered by many scholars as practical examples of deliberative democracy,[162][163][164] with a recent OECD report identifying citizens assemblies as an increasingly popular mechanism to involve citizens in governmental decision-making.[165]  Radical democracy is based on the idea that there are hierarchical and oppressive power relations that exist in society. Democracy's role is to make visible and challenge those relations by allowing for difference, dissent and antagonisms in decision-making processes.    Democracy indices are quantitative and comparative assessments of the state of democracy[166] for different countries according to various definitions of democracy.[167]  The democracies indices differ in whether they are categorical, such as classifying countries into democracies, hybrid regimes, and autocracies,[168][169] or continuous values.[170] The qualitative nature of democracy indices enables data analytical approaches for studying causal mechanisms of regime transformation processes.  Democracy has taken a number of forms, both in theory and practice. Some varieties of democracy provide better representation and more freedom for their citizens than others.[179][180] However, if any democracy is not structured to prohibit the government from excluding the people from the legislative process, or any branch of government from altering the separation of powers in its favour, then a branch of the system can accumulate too much power and destroy the democracy.[181][182][183]  The following kinds of democracy are not exclusive of one another: many specify details of aspects that are independent of one another and can co-exist in a single system.  Several variants of democracy exist, but there are two basic forms, both of which concern how the whole body of all eligible citizens executes its will. One form of democracy is direct democracy, in which all eligible citizens have active participation in the political decision making, for example voting on policy initiatives directly.[184] In most modern democracies, the whole body of eligible citizens remain the sovereign power but political power is exercised indirectly through elected representatives; this is called a representative democracy.  Direct democracy is a political system where the citizens participate in the decision-making personally, contrary to relying on intermediaries or representatives. A direct democracy gives the voting population the power to:  Within modern-day representative governments, certain electoral tools like referendums, citizens' initiatives and recall elections are referred to as forms of direct democracy.[185] However, some advocates of direct democracy argue for local assemblies of face-to-face discussion. Direct democracy as a government system currently exists in the Swiss cantons of Appenzell Innerrhoden and Glarus,[186] the Rebel Zapatista Autonomous Municipalities,[187] communities affiliated with the CIPO-RFM,[188] the Bolivian city councils of FEJUVE,[189] and Kurdish cantons of Rojava.[190]  Some modern democracies that are predominantly representative in nature also heavily rely upon forms of political action that are directly democratic. These democracies, which combine elements of representative democracy and direct democracy, are termed semi-direct democracies or participatory democracies. Examples include Switzerland and some U.S. states, where frequent use is made of referendums and initiatives.  The Swiss confederation is a semi-direct democracy.[186] At the federal level, citizens can propose changes to the constitution (federal popular initiative) or ask for a referendum to be held on any law voted by the parliament.[186] Between January 1995 and June 2005, Swiss citizens voted 31 times, to answer 103 questions (during the same period, French citizens participated in only two referendums).[186] Although in the past 120 years less than 250 initiatives have been put to referendum.[191]  Examples include the extensive use of referendums in the US state of California, which is a state that has more than 20 million voters.[192]  In New England, town meetings are often used, especially in rural areas, to manage local government. This creates a hybrid form of government, with a local direct democracy and a representative state government. For example, most Vermont towns hold annual town meetings in March in which town officers are elected, budgets for the town and schools are voted on, and citizens have the opportunity to speak and be heard on political matters.[193]  The use of a lot system, a characteristic of Athenian democracy, is a feature of some versions of direct democracies. In this system, important governmental and administrative tasks are performed by citizens picked from a lottery.[194]  Representative democracy involves the election of government officials by the people being represented. If the head of state is also democratically elected then it is called a democratic republic.[195] The most common mechanisms involve election of the candidate with a majority or a plurality of the votes. Most western countries have representative systems.[186]  Representatives may be elected or become diplomatic representatives by a particular district (or constituency), or represent the entire electorate through proportional systems, with some using a combination of the two. Some representative democracies also incorporate elements of direct democracy, such as referendums.[196] A characteristic of representative democracy is that while the representatives are elected by the people to act in the people's interest, they retain the freedom to exercise their own judgement as how best to do so. Such reasons have driven criticism upon representative democracy,[197][198] pointing out the contradictions of representation mechanisms with democracy[199][200]  Parliamentary democracy is a representative democracy where government is appointed by or can be dismissed by, representatives as opposed to a \"presidential rule\" wherein the president is both head of state and the head of government and is elected by the voters. Under a parliamentary democracy, government is exercised by delegation to an executive ministry and subject to ongoing review, checks and balances by the legislative parliament elected by the people.[201][202][203][204]  In a parliamentary system, the Prime Minister may be dismissed by the legislature at any point in time for not meeting the expectations of the legislature. This is done through a Vote of No Confidence where the legislature decides whether or not to remove the Prime Minister from office with majority support for dismissal.[205] In some countries, the Prime Minister can also call an election at any point in time, typically when the Prime Minister believes that they are in good favour with the public as to get re-elected. In other parliamentary democracies, extra elections are virtually never held, a minority government being preferred until the next ordinary elections. An important feature of the parliamentary democracy is the concept of the \"loyal opposition\". The essence of the concept is that the second largest political party (or opposition) opposes the governing party (or coalition), while still remaining loyal to the state and its democratic principles.  Presidential Democracy is a system where the public elects the president through an election. The president serves as both the head of state and head of government controlling most of the executive powers. The president serves for a specific term and cannot exceed that amount of time. The legislature often has limited ability to remove a president from office. Elections typically have a fixed date and aren't easily changed. The president has direct control over the cabinet, specifically appointing the cabinet members.[205]  The executive usually has the responsibility to execute or implement legislation and may have the limited legislative powers, such as a veto. However, a legislative branch passes legislation and budgets. This provides some measure of separation of powers. In consequence, however, the president and the legislature may end up in the control of separate parties, allowing one to block the other and thereby interfere with the orderly operation of the state. This may be the reason why presidential democracy is not very common outside the Americas, Africa, and Central and Southeast Asia.[205]  A semi-presidential system is a system of democracy in which the government includes both a prime minister and a president. The particular powers held by the prime minister and president vary by country.[205]  Many countries such as the United Kingdom, Spain, the Netherlands, Belgium, Scandinavian countries, Thailand, Japan and Bhutan turned powerful monarchs into constitutional monarchs (often gradually) with limited or symbolic roles. For example, in the predecessor states to the United Kingdom, constitutional monarchy began to emerge and has continued uninterrupted since the Glorious Revolution of 1688 and passage of the Bill of Rights 1689.[22][80] Strongly limited constitutional monarchies, such as the United Kingdom, have been referred to as crowned republics by writers such as H. G. Wells.[206]  In other countries, the monarchy was abolished along with the aristocratic system (as in France, China, Russia, Germany, Austria, Hungary, Italy, Greece and Egypt). An elected person, with or without significant powers, became the head of state in these countries.  Elite upper houses of legislatures, which often had lifetime or hereditary tenure, were common in many states. Over time, these either had their powers limited (as with the British House of Lords) or else became elective and remained powerful (as with the Australian Senate).  The term republic has many different meanings, but today often refers to a representative democracy with an elected head of state, such as a president, serving for a limited term, in contrast to states with a hereditary monarch as a head of state, even if these states also are representative democracies with an elected or appointed head of government such as a prime minister.[207]  The Founding Fathers of the United States often criticised direct democracy, which in their view often came without the protection of a constitution enshrining inalienable rights; James Madison argued, especially in The Federalist No. 10, that what distinguished a direct democracy from a republic was that the former became weaker as it got larger and suffered more violently from the effects of faction, whereas a republic could get stronger as it got larger and combats faction by its very structure.[208]  Professors Richard Ellis of Willamette University and Michael Nelson of Rhodes College argue that much constitutional thought, from Madison to Lincoln and beyond, has focused on \"the problem of majority tyranny\". They conclude, \"The principles of republican government embedded in the Constitution represent an effort by the framers to ensure that the inalienable rights of life, liberty, and the pursuit of happiness would not be trampled by majorities.\"[209] What was critical to American values, John Adams insisted,[210] was that the government be \"bound by fixed laws, which the people have a voice in making, and a right to defend.\" As Benjamin Franklin was exiting after writing the U.S. constitution, Elizabeth Willing Powel[211] asked him \"Well, Doctor, what have we got\u2014a republic or a monarchy?\". He replied \"A republic\u2014if you can keep it.\"[212]  A liberal democracy is a representative democracy in which the ability of the elected representatives to exercise decision-making power is subject to the rule of law, and moderated by a constitution or laws that emphasise the protection of the rights and freedoms of individuals, and which places constraints on the leaders and on the extent to which the will of the majority can be exercised against the rights of minorities (see civil liberties).  In a liberal democracy, it is possible for some large-scale decisions to emerge from the many individual decisions that citizens are free to make. In other words, citizens can \"vote with their feet\" or \"vote with their dollars\", resulting in significant informal government-by-the-masses that exercises many \"powers\" associated with formal government elsewhere.  Socialist thought has several different views on democracy. Social democracy, democratic socialism, and the dictatorship of the proletariat are some examples. Many democratic socialists and social democrats believe in a form of participatory, industrial, economic and\/or workplace democracy combined with a representative democracy.  Within Marxist orthodoxy there is a hostility to what is commonly called \"liberal democracy\", which is referred to as parliamentary democracy because of its centralised nature. Because of orthodox Marxists' desire to eliminate the political elitism they see in capitalism, Marxists, Leninists and Trotskyists believe in direct democracy implemented through a system of communes (which are sometimes called soviets). This system can begin with workplace democracy and ultimately manifests itself as council democracy.  Anarchists are split in this domain, depending on whether they believe that a majority-rule is tyrannic or not. To many anarchists, the only form of democracy considered acceptable is direct democracy. Pierre-Joseph Proudhon argued that the only acceptable form of direct democracy is one in which it is recognised that majority decisions are not binding on the minority, even when unanimous.[213] However, anarcho-communist Murray Bookchin criticised individualist anarchists for opposing democracy,[214] and says \"majority rule\" is consistent with anarchism.[215]  Some anarcho-communists oppose the majoritarian nature of direct democracy, feeling that it can impede individual liberty and opt-in favour of a non-majoritarian form of consensus democracy, similar to Proudhon's position on direct democracy.[216]  Sortition is the process of choosing decision-making bodies via a random selection. These bodies can be more representative of the opinions and interests of the people at large than an elected legislature or other decision-maker. The technique was in widespread use in Athenian Democracy and Renaissance Florence[217] and is still used in modern jury selection and citizens' assemblies.  Consociational democracy, also called consociationalism, is a form of democracy based on power-sharing formula between elites representing the social groups within the society. In 1969, Arendt Lijphart argued this would stabilize democracies with factions.[218] A consociational democracy allows for simultaneous majority votes in two or more ethno-religious constituencies, and policies are enacted only if they gain majority support from both or all of them. The Qualified majority voting rule in European Council of Ministers is a consociational democracy approach for supranational democracies. This system in Treaty of Rome allocates votes to member states in part according to their population, but heavily weighted in favour of the smaller states. A consociational democracy requires consensus of representatives, while consensus democracy requires consensus of electorate.[needs update]  Consensus democracy[219] requires consensus decision-making and supermajority to obtain a larger support than majority. In contrast, in majoritarian democracy minority opinions can potentially be ignored by vote-winning majorities.[220] Constitutions typically require consensus or supermajorities.[221]  Inclusive democracy is a political theory and political project that aims for direct democracy in all fields of social life: political democracy in the form of face-to-face assemblies which are confederated, economic democracy in a stateless, moneyless and marketless economy, democracy in the social realm, i.e. self-management in places of work and education, and ecological democracy which aims to reintegrate society and nature. The theoretical project of inclusive democracy emerged from the work of political philosopher Takis Fotopoulos in \"Towards An Inclusive Democracy\" and was further developed in the journal Democracy & Nature and its successor The International Journal of Inclusive Democracy.  A Parpolity or Participatory Polity is a theoretical form of democracy that is ruled by a Nested Council structure. The guiding philosophy is that people should have decision-making power in proportion to how much they are affected by the decision. Local councils of 25\u201350 people are completely autonomous on issues that affect only them, and these councils send delegates to higher level councils who are again autonomous regarding issues that affect only the population affected by that council.  A council court of randomly chosen citizens serves as a check on the tyranny of the majority, and rules on which body gets to vote on which issue. Delegates may vote differently from how their sending council might wish but are mandated to communicate the wishes of their sending council. Delegates are recallable at any time. Referendums are possible at any time via votes of lower-level councils, however, not everything is a referendum as this is most likely a waste of time. A parpolity is meant to work in tandem with a participatory economy.  Cosmopolitan democracy, also known as Global democracy or World Federalism, is a political system in which democracy is implemented on a global scale, either directly or through representatives. An important justification for this kind of system is that the decisions made in national or regional democracies often affect people outside the constituency who, by definition, cannot vote. By contrast, in a cosmopolitan democracy, the people who are affected by decisions also have a say in them.[222]  According to its supporters, any attempt to solve global problems is undemocratic without some form of cosmopolitan democracy. The general principle of cosmopolitan democracy is to expand some or all of the values and norms of democracy, including the rule of law; the non-violent resolution of conflicts; and equality among citizens, beyond the limits of the state. To be fully implemented, this would require reforming existing international organisations, e.g., the United Nations, as well as the creation of new institutions such as a World Parliament, which ideally would enhance public control over, and accountability in, international politics.  Cosmopolitan Democracy has been promoted, among others, by physicist Albert Einstein,[223] writer Kurt Vonnegut, columnist George Monbiot, and professors David Held and Daniele Archibugi.[224] The creation of the International Criminal Court in 2003 was seen as a major step forward by many supporters of this type of cosmopolitan democracy.  Creative Democracy is advocated by American philosopher John Dewey. The main idea about Creative Democracy is that democracy encourages individual capacity building and the interaction among the society. Dewey argues that democracy is a way of life in his work of \"Creative Democracy: The Task Before Us\"[225] and an experience built on faith in human nature, faith in human beings, and faith in working with others. Democracy, in Dewey's view, is a moral ideal requiring actual effort and work by people; it is not an institutional concept that exists outside of ourselves. \"The task of democracy\", Dewey concludes, \"is forever that of creation of a freer and more humane experience in which all share and to which all contribute\".  Guided democracy is a form of democracy that incorporates regular popular elections, but which often carefully \"guides\" the choices offered to the electorate in a manner that may reduce the ability of the electorate to truly determine the type of government exercised over them. Such democracies typically have only one central authority which is often not subject to meaningful public review by any other governmental authority. Russian-style democracy has often been referred to as a \"Guided democracy\".[226] Russian politicians have referred to their government as having only one center of power\/ authority, as opposed to most other forms of democracy which usually attempt to incorporate two or more naturally competing sources of authority within the same government.[227]  Aside from the public sphere, similar democratic principles and mechanisms of voting and representation have been used to govern other kinds of groups. Many non-governmental organisations decide policy and leadership by voting. Most trade unions and cooperatives are governed by democratic elections. Corporations are ultimately governed by their shareholders through shareholder democracy. Corporations may also employ systems such as workplace democracy to handle internal governance. Amitai Etzioni has postulated a system that fuses elements of democracy with sharia law, termed Islamocracy.[228] There is also a growing number of Democratic educational institutions such as Sudbury schools that are co-governed by students and staff.  Shareholder democracy is a concept relating to the governance of corporations by their shareholders. In the United States, shareholders are typically granted voting rights according to the one share, one vote principle. Shareholders may vote annually to elect the company's board of directors, who themselves may choose the company's executives. The shareholder democracy framework may be inaccurate for companies which have different classes of stock that further alter the distribution of voting rights.  Several justifications for democracy have been postulated.  Social contract theory argues that the legitimacy of government is based on consent of the governed, i.e. an election, and that political decisions must reflect the general will. Some proponents of the theory like Jean-Jacques Rousseau advocate for a direct democracy on this basis.[229]  Condorcet's jury theorem is logical proof that if each decision-maker has a better than chance probability of making the right decision, then having the largest number of decision-makers, i.e. a democracy, will result in the best decisions. This has also been argued by theories of the wisdom of the crowd.  In Why Nations Fail, economists Daron Acemoglu and James A. Robinson argue that democracies are more economically successful because undemocratic political systems tend to limit markets and favor monopolies at the expense of the creative destruction which is necessary for sustained economic growth.  A 2019 study by Acemoglu and others estimated that countries switching to democratic from authoritarian rule had on average a 20% higher GDP after 25 years than if they had remained authoritarian. The study examined 122 transitions to democracy and 71 transitions to authoritarian rule, occurring from 1960 to 2010.[230] Acemoglu said this was because democracies tended to invest more in health care and human capital, and reduce special treatment of regime allies.[231]  Democracy promotion, also referred to as democracy building, can be domestic policy to increase the quality of already existing democracy or a strand of foreign policy adopted by governments and international organizations that seek to support the spread of democracy as a system of government. Among the reasons for supporting democracy include the belief that countries with a democratic system of governance are less likely to go to war, are likely to be economically better off and socially more harmonious.[232] In democracy building, the process includes the building and strengthening of democracy, in particular the consolidation of democratic institutions, including courts of law, police forces, and constitutions.[233] Some critics have argued that the United States has used democracy promotion to justify military intervention abroad.[234][235]  Much experience was gained after the Revolutions of 1989 resulted in the fall of the Iron Curtain and a wave of democratic transitions in former Communist states, particularly in Central and Eastern Europe. According to Freedom House, the number of democracies increased from 41 of 150 existing states in 1974 to 123 of 192 states in 2006.[236] The pace of transition slowed considerably since the beginning of the twenty-first century, which encouraged discussion of whether democracy was under threat.[237] In the early twenty-first century, a democratic deficit was noticed in countries where democratic systems already existed, including Britain, the US and the European Union.[238] In the financial sense, democracy promotion grew from 2% of aid in 1990 to nearly 20% in 2005.[239]  Democracy promotion can increase the quality of already existing democracies, reduce political apathy, and the chance of democratic backsliding. Democracy promotion measures include voting advice applications,[241] participatory democracy,[242] increasing youth suffrage, increasing civic education,[243] reducing barriers to entry for new political parties,[244] increasing proportionality[245] and reducing presidentialism.[246]  A democratic transition describes a phase in a countries political system, often created as a result of an incomplete change from an authoritarian regime to a democratic one (or vice versa).[247][248]  Several philosophers and researchers have outlined historical and social factors seen as supporting the evolution of democracy. Other commentators have mentioned the influence of economic development.[251] In a related theory, Ronald Inglehart suggests that improved living-standards in modern developed countries can convince people that they can take their basic survival for granted, leading to increased emphasis on self-expression values, which correlates closely with democracy.[252][253]  Douglas M. Gibler and Andrew Owsiak in their study argued about the importance of peace and stable borders for the development of democracy. It has often been assumed that democracy causes peace, but this study shows that, historically, peace has almost always predated the establishment of democracy.[254]  Carroll Quigley concludes that the characteristics of weapons are the main predictor of democracy:[255][256] Democracy\u2014this scenario\u2014tends to emerge only when the best weapons available are easy for individuals to obtain and use.[257] By the 1800s, guns were the best personal weapons available, and in the United States of America (already nominally democratic), almost everyone could afford to buy a gun, and could learn how to use it fairly easily. Governments could not do any better: it became the age of mass armies of citizen soldiers with guns.[257] Similarly, Periclean Greece was an age of the citizen soldier and democracy.[258]  Other theories stressed the relevance of education and of human capital\u2014and within them of cognitive ability to increasing tolerance, rationality, political literacy and participation. Two effects of education and cognitive ability are distinguished:[259][need quotation to verify][260][261]  Evidence consistent with conventional theories of why democracy emerges and is sustained has been hard to come by. Statistical analyses have challenged modernisation theory by demonstrating that there is no reliable evidence for the claim that democracy is more likely to emerge when countries become wealthier, more educated, or less unequal.[262] In fact, empirical evidence shows that economic growth and education may not lead to increased demand for democratization as modernization theory suggests: historically, most countries attained high levels of access to primary education well before transitioning to democracy.[263] Rather than acting as a catalyst for democratization, in some situations education provision may instead be used by non-democratic regimes to indoctrinate their subjects and strengthen their power.[263]  The assumed link between education and economic growth is called into question when analyzing empirical evidence. Across different countries, the correlation between education attainment and math test scores is very weak (.07). A similarly weak relationship exists between per-pupil expenditures and math competency (.26). Additionally, historical evidence suggests that average human capital (measured using literacy rates) of the masses does not explain the onset of industrialization in France from 1750 to 1850 despite arguments to the contrary.[264] Together, these findings show that education does not always promote human capital and economic growth as is generally argued to be the case. Instead, the evidence implies that education provision often falls short of its expressed goals, or, alternatively, that political actors use education to promote goals other than economic growth and development.  Some scholars have searched for the \"deep\" determinants of contemporary political institutions, be they geographical or demographic.[265][266]  An example of this is the disease environment. Places with different mortality rates had different populations and productivity levels around the world. For example, in Africa, the tsetse fly\u2014which afflicts humans and livestock\u2014reduced the ability of Africans to plough the land. This made Africa less settled. As a consequence, political power was less concentrated.[267] This also affected the colonial institutions European countries established in Africa.[268] Whether colonial settlers could live or not in a place made them develop different institutions which led to different economic and social paths. This also affected the distribution of power and the collective actions people could take. As a result, some African countries ended up having democracies and others autocracies.  An example of geographical determinants for democracy is having access to coastal areas and rivers. This natural endowment has a positive relation with economic development thanks to the benefits of trade.[269] Trade brought economic development, which in turn, broadened power. Rulers wanting to increase revenues had to protect property-rights to create incentives for people to invest. As more people had more power, more concessions had to be made by the ruler and in many[quantify] places this process lead to democracy. These determinants defined the structure of the society moving the balance of political power.[270]  Robert Michels asserts that although democracy can never be fully realised, democracy may be developed automatically in the act of striving for democracy:  The peasant in the fable, when on his deathbed, tells his sons that a treasure is buried in the field. After the old man's death the sons dig everywhere in order to discover the treasure. They do not find it. But their indefatigable labor improves the soil and secures for them a comparative well-being. The treasure in the fable may well symbolise democracy.[271] Democracy in modern times has almost always faced opposition from the previously existing government, and many times it has faced opposition from social elites. The implementation of a democratic government from a non-democratic state is typically brought by peaceful or violent democratic revolution.  Some democratic governments have experienced sudden state collapse and regime change to an undemocratic form of government. Domestic military coups or rebellions are the most common means by which democratic governments have been overthrown.[285] (See List of coups and coup attempts by country and List of civil wars.) Examples include the Spanish Civil War, the Coup of 18 Brumaire that ended the First French Republic, and the 28 May 1926 coup d'\u00e9tat which ended the First Portuguese Republic. Some military coups are supported by foreign governments, such as the 1954 Guatemalan coup d'\u00e9tat and the 1953 Iranian coup d'\u00e9tat. Other types of a sudden end to democracy include:  Democratic backsliding can end democracy in a gradual manner, by increasing emphasis on national security and eroding free and fair elections, freedom of expression, independence of the judiciary, rule of law. A famous example is the Enabling Act of 1933, which lawfully ended democracy in Weimar Germany and marked the transition to Nazi Germany.[287]  Temporary or long-term political violence and government interference can prevent free and fair elections, which erode the democratic nature of governments. This has happened on a local level even in well-established democracies like the United States; for example, the Wilmington insurrection of 1898 and African-American disfranchisement after the Reconstruction era.  Criticism of democracy, or debate on democracy and the different aspects of how to implement democracy best have been widely discussed. There are both internal critics (those who call upon the constitutional regime to be true to its own highest principles) and external ones who reject the values promoted by constitutional democracy.[288]  Criticism of democracy has been a key part of democracy, its functions, and its development throughout history. Plato famously opposed democracy, arguing for a 'government of the best qualified'; James Madison extensively studied the historic attempts at and arguments on democracy in his preparation for the Constitutional Convention; and Winston Churchill remarked that \"No one pretends that democracy is perfect or all-wise. Indeed, it has been said that democracy is the worst form of government except all those other forms that have been tried from time to time.\"[289]  The theory of democracy relies on the implicit assumption that voters are well informed about social issues, policies, and candidates so that they can make a truly informed decision. Since the late 20'th century there has been a growing concern that voters may be poorly informed because the news media are focusing more on entertainment and gossip and less on serious journalistic research on political issues.[293][294]  The media professors Michael Gurevitch and Jay Blumler have proposed a number of functions that the mass media are expected to fulfill in a democracy:[295]  This proposal has inspired a lot of discussions over whether the news media are actually fulfilling the requirements that a well functioning democracy requires.[296] Commercial mass media are generally not accountable to anybody but their owners, and they have no obligation to serve a democratic function.[296][297] They are controlled mainly by economic market forces. Fierce economic competition may force the mass media to divert themselves from any democratic ideals and focus entirely on how to survive the competition.[298][299]  The tabloidization and popularization of the news media is seen in an increasing focus on human examples rather than statistics and principles. There is more focus on politicians as personalities and less focus on political issues in the popular media. Election campaigns are covered more as horse races and less as debates about ideologies and issues. The dominating media focus on spin, conflict, and competitive strategies has made voters perceive the politicians as egoists rather than idealists. This fosters mistrust and a cynical attitude to politics, less civic engagement, and less interest in voting.[300][301][302] The ability to find effective political solutions to social problems is hampered when problems tend to be blamed on individuals rather than on structural causes.[301] This person-centered focus may have far-reaching consequences not only for domestic problems but also for foreign policy when international conflicts are blamed on foreign heads of state rather than on political and economic structures.[303][304] A strong media focus on fear and terrorism has allowed military logic to penetrate public institutions, leading to increased surveillance and the erosion of civil rights.[305]  The responsiveness[306] and accountability of the democratic system is compromised when lack of access to substantive, diverse, and undistorted information is handicapping the citizens' capability of evaluating the political process.[297][302] The fast pace and trivialization in the competitive news media is dumbing down the political debate. Thorough and balanced investigation of complex political issues does not fit into this format. The political communication is characterized by short time horizons, short slogans, simple explanations, and simple solutions. This is conducive to political populism rather than serious deliberation.[297][305]  Commercial mass media are often differentiated along the political spectrum so that people can hear mainly opinions that they already agree with. Too much controversy and diverse opinions are not always profitable for the commercial news media.[307] Political polarization is emerging when different people read different news and watch different TV channels. This polarization has been worsened by the emergence of the social media that allow people to communicate mainly with groups of like-minded people, the so-called echo chambers.[308] Extreme political polarization may undermine the trust in democratic institutions, leading to erosion of civil rights and free speech and in some cases even reversion to autocracy.[309]  Many media scholars have discussed non-commercial news media with public service obligations as a means to improve the democratic process by providing the kind of political contents that a free market does not provide.[310][311] The World Bank has recommended public service broadcasting in order to strengthen democracy in developing countries. These broadcasting services should be accountable to an independent regulatory body that is adequately protected from interference from political and economic interests.[312] Public service media have an obligation to provide reliable information to voters. Many countries have publicly funded radio and television stations with public service obligations, especially in Europe and Japan,[313] while such media are weak or non-existent in other countries including the US.[314] Several studies have shown that the stronger the dominance of commercial broadcast media over public service media, the less the amount of policy-relevant information in the media and the more focus on horse race journalism, personalities, and the pecadillos of politicians. Public service broadcasters are characterized by more policy-relevant information and more respect for journalistic norms and impartiality than the commercial media. However, the trend of deregulation has put the public service model under increased pressure from competition with commercial media.[313][315][316]  The emergence of the internet and the social media has profoundly altered the conditions for political communication. The social media have given ordinary citizens easy access to voice their opinion and share information while bypassing the filters of the large news media. This is often seen as an advantage for democracy.[317] The new possibilities for communication have fundamentally changed the way social movements and protest movements operate and organize. The internet and social media have provided powerful new tools for democracy movements in developing countries and emerging democracies, enabling them to bypass censorship, voice their opinions, and organize protests.[318][319]  A serious problem with the social media is that they have no truth filters. The established news media have to guard their reputation as trustworthy, while ordinary citizens may post unreliable information.[318] In fact, studies show that false stories are going more viral than true stories.[320][321] The proliferation of false stories and conspiracy theories may undermine public trust in the political system and public officials.[321][309]  Reliable information sources are essential for the democratic process. Less democratic governments rely heavily on censorship, propaganda, and misinformation in order to stay in power, while independent sources of information are able to undermine their legitimacy.[322] "},{"title":"Sphere","content":"  A sphere (from Greek \u03c3\u03c6\u03b1\u1fd6\u03c1\u03b1, spha\u00eera)[1] is a geometrical object that is a three-dimensional analogue to a two-dimensional circle. Formally, a sphere is the set of points that are all at the same distance r from a given point in three-dimensional space.[2] That given point is the center of the sphere, and r is the sphere's radius. The earliest known mentions of spheres appear in the work of the ancient Greek mathematicians.  The sphere is a fundamental object in many fields of mathematics. Spheres and nearly-spherical shapes also appear in nature and industry. Bubbles such as soap bubbles take a spherical shape in equilibrium. The Earth is often approximated as a sphere in geography, and the celestial sphere is an important concept in astronomy. Manufactured items including pressure vessels and most curved mirrors and lenses are based on spheres. Spheres roll smoothly in any direction, so most balls used in sports and toys are spherical, as are ball bearings.  As mentioned earlier r is the sphere's radius; any line from the center to a point on the sphere is also called a radius.[3]  If a radius is extended through the center to the opposite side of the sphere, it creates a diameter. Like the radius, the length of a diameter is also called the diameter, and denoted d. Diameters are the longest line segments that can be drawn between two points on the sphere: their length is twice the radius, d = 2r. Two points on the sphere connected by a diameter are antipodal points of each other.[3]  A unit sphere is a sphere with unit radius (r = 1). For convenience, spheres are often taken to have their center at the origin of the coordinate system, and spheres in this article have their center at the origin unless a center is mentioned.   A great circle on the sphere has the same center and radius as the sphere, and divides it into two equal hemispheres.  Although the figure of Earth is not perfectly spherical, terms borrowed from geography are convenient to apply to the sphere. A particular line passing through its center defines an axis (as in Earth's axis of rotation). The sphere-axis intersection defines two antipodal poles (north pole and south pole). The great circle equidistant to the poles is called the equator. Great circles through the poles are called lines of longitude or meridians. Small circles on the sphere that are parallel to the equator are circles of latitude (or parallels). In geometry unrelated to astronomical bodies, geocentric terminology should be used only for illustration and noted as such, unless there is no chance of misunderstanding.[3]  Mathematicians consider a sphere to be a two-dimensional closed surface embedded in three-dimensional Euclidean space. They draw a distinction between a sphere and a ball, which is a three-dimensional manifold with boundary that includes the volume contained by the sphere. An open ball excludes the sphere itself, while a closed ball includes the sphere: a closed ball is the union of the open ball and the sphere, and a sphere is the boundary of a (closed or open) ball. The distinction between ball and sphere has not always been maintained and especially older mathematical references talk about a sphere as a solid. The distinction between \"circle\" and \"disk\" in the plane is similar.  Small spheres or balls are sometimes called spherules, e.g. in Martian spherules.  In analytic geometry, a sphere with center (x0, y0, z0) and radius r is the locus of all points (x, y, z) such that  Since it can be expressed as a quadratic polynomial, a sphere is a quadric surface, a type of algebraic surface.[3]  Let a, b, c, d, e be real numbers with a \u2260 0 and put  Then the equation  has no real points as solutions if     \u03c1 < 0   {\\displaystyle \\rho <0}   and is called the equation of an imaginary sphere. If     \u03c1 = 0   {\\displaystyle \\rho =0}  , the only solution of     f ( x , y , z ) = 0   {\\displaystyle f(x,y,z)=0}   is the point      P  0   = (  x  0   ,  y  0   ,  z  0   )   {\\displaystyle P_{0}=(x_{0},y_{0},z_{0})}   and the equation is said to be the equation of a point sphere. Finally, in the case     \u03c1 > 0   {\\displaystyle \\rho >0}  ,     f ( x , y , z ) = 0   {\\displaystyle f(x,y,z)=0}   is an equation of a sphere whose center is      P  0     {\\displaystyle P_{0}}   and whose radius is       \u03c1     {\\displaystyle {\\sqrt {\\rho }}}  .[2]  If a in the above equation is zero then f(x, y, z) = 0 is the equation of a plane. Thus, a plane may be thought of as a sphere of infinite radius whose center is a point at infinity.[4]  A parametric equation for the sphere with radius     r > 0   {\\displaystyle r>0}   and center     (  x  0   ,  y  0   ,  z  0   )   {\\displaystyle (x_{0},y_{0},z_{0})}   can be parameterized using trigonometric functions.  The symbols used here are the same as those used in spherical coordinates. r is constant, while \u03b8 varies from 0 to \u03c0 and     \u03c6   {\\displaystyle \\varphi }   varies from 0 to 2\u03c0.  In three dimensions, the volume inside a sphere (that is, the volume of a ball, but classically referred to as the volume of a sphere) is  where r is the radius and d is the diameter of the sphere. Archimedes first derived this formula by showing that the volume inside a sphere is twice the volume between the sphere and the circumscribed cylinder of that sphere (having the height and diameter equal to the diameter of the sphere).[6] This may be proved by inscribing a cone upside down into semi-sphere, noting that the area of a cross section of the cone plus the area of a cross section of the sphere is the same as the area of the cross section of the circumscribing cylinder, and applying Cavalieri's principle.[7] This formula can also be derived using integral calculus, i.e. disk integration to sum the volumes of an infinite number of circular disks of infinitesimally small thickness stacked side by side and centered along the x-axis from x = \u2212r to x = r, assuming the sphere of radius r is centered at the origin.  At any given x, the incremental volume (\u03b4V) equals the product of the cross-sectional area of the disk at x and its thickness (\u03b4x):  The total volume is the summation of all incremental volumes:  In the limit as \u03b4x approaches zero,[8] this equation becomes:  At any given x, a right-angled triangle connects x, y and r to the origin; hence, applying the Pythagorean theorem yields:  Using this substitution gives  which can be evaluated to give the result  An alternative formula is found using spherical coordinates, with volume element  so  For most practical purposes, the volume inside a sphere inscribed in a cube can be approximated as 52.4% of the volume of the cube, since V = \u03c0\/6 d3, where d is the diameter of the sphere and also the length of a side of the cube and \u03c0\/6\u00a0\u2248\u00a00.5236. For example, a sphere with diameter 1\u00a0m has 52.4% the volume of a cube with edge length 1\u00a0m, or about 0.524\u00a0m3.  The surface area of a sphere of radius r is:  Archimedes first derived this formula[9] from the fact that the projection to the lateral surface of a circumscribed cylinder is area-preserving.[10] Another approach to obtaining the formula comes from the fact that it equals the derivative of the formula for the volume with respect to r because the total volume inside a sphere of radius r can be thought of as the summation of the surface area of an infinite number of spherical shells of infinitesimal thickness concentrically stacked inside one another from radius 0 to radius r. At infinitesimal thickness the discrepancy between the inner and outer surface area of any given shell is infinitesimal, and the elemental volume at radius r is simply the product of the surface area at radius r and the infinitesimal thickness.  At any given radius r,[note 1] the incremental volume (\u03b4V) equals the product of the surface area at radius r (A(r)) and the thickness of a shell (\u03b4r):  The total volume is the summation of all shell volumes:  In the limit as \u03b4r approaches zero[8] this equation becomes:  Substitute V:  Differentiating both sides of this equation with respect to r yields A as a function of r:  This is generally abbreviated as:  where r is now considered to be the fixed radius of the sphere.  Alternatively, the area element on the sphere is given in spherical coordinates by dA = r2 sin \u03b8 d\u03b8 d\u03c6. The total area can thus be obtained by integration:  The sphere has the smallest surface area of all surfaces that enclose a given volume, and it encloses the largest volume among all closed surfaces with a given surface area.[11] The sphere therefore appears in nature: for example, bubbles and small water drops are roughly spherical because the surface tension locally minimizes surface area.  The surface area relative to the mass of a ball is called the specific surface area and can be expressed from the above stated equations as  where \u03c1 is the density (the ratio of mass to volume).  A sphere can be constructed as the surface formed by rotating a circle one half revolution about any of its diameters; this is very similar to the traditional definition of a sphere as given in Euclid's Elements. Since a circle is a special type of ellipse, a sphere is a special type of ellipsoid of revolution. Replacing the circle with an ellipse rotated about its major axis, the shape becomes a prolate spheroid; rotated about the minor axis, an oblate spheroid.[12]  A sphere is uniquely determined by four points that are not coplanar. More generally, a sphere is uniquely determined by four conditions such as passing through a point, being tangent to a plane, etc.[13] This property is analogous to the property that three non-collinear points determine a unique circle in a plane.  Consequently, a sphere is uniquely determined by (that is, passes through) a circle and a point not in the plane of that circle.  By examining the common solutions of the equations of two spheres, it can be seen that two spheres intersect in a circle and the plane containing that circle is called the radical plane of the intersecting spheres.[14] Although the radical plane is a real plane, the circle may be imaginary (the spheres have no real point in common) or consist of a single point (the spheres are tangent at that point).[15]  The angle between two spheres at a real point of intersection is the dihedral angle determined by the tangent planes to the spheres at that point. Two spheres intersect at the same angle at all points of their circle of intersection.[16] They intersect at right angles (are orthogonal) if and only if the square of the distance between their centers is equal to the sum of the squares of their radii.[4]  If f(x, y, z) = 0 and g(x, y, z) = 0 are the equations of two distinct spheres then  is also the equation of a sphere for arbitrary values of the parameters s and t. The set of all spheres satisfying this equation is called a pencil of spheres determined by the original two spheres. In this definition a sphere is allowed to be a plane (infinite radius, center at infinity) and if both the original spheres are planes then all the spheres of the pencil are planes, otherwise there is only one plane (the radical plane) in the pencil.[4]  In their book Geometry and the Imagination, David Hilbert and Stephan Cohn-Vossen describe eleven properties of the sphere and discuss whether these properties uniquely determine the sphere.[17] Several properties hold for the plane, which can be thought of as a sphere with infinite radius. These properties are:  The basic elements of Euclidean plane geometry are points and lines. On the sphere, points are defined in the usual sense. The analogue of the \"line\" is the geodesic, which is a great circle; the defining characteristic of a great circle is that the plane containing all its points also passes through the center of the sphere. Measuring by arc length shows that the shortest path between two points lying on the sphere is the shorter segment of the great circle that includes the points.  Many theorems from classical geometry hold true for spherical geometry as well, but not all do because the sphere fails to satisfy some of classical geometry's postulates, including the parallel postulate. In spherical trigonometry, angles are defined between great circles. Spherical trigonometry differs from ordinary trigonometry in many respects. For example, the sum of the interior angles of a spherical triangle always exceeds 180\u00a0degrees. Also, any two similar spherical triangles are congruent.  Any pair of points on a sphere that lie on a straight line through the sphere's center (i.e. the diameter) are called antipodal points\u2014on the sphere, the distance between them is exactly half the length of the circumference.[note 2] Any other (i.e. not antipodal) pair of distinct points on a sphere  Spherical geometry is a form of elliptic geometry, which together with hyperbolic geometry makes up non-Euclidean geometry.  The sphere is a smooth surface with constant Gaussian curvature at each point equal to 1\/r2.[9] As per Gauss's Theorema Egregium, this curvature is independent of the sphere's embedding in 3-dimensional space. Also following from Gauss, a sphere cannot be mapped to a plane while maintaining both areas and angles. Therefore, any map projection introduces some form of distortion.  A sphere of radius r has area element     d A =  r  2   sin \u2061 \u03b8  d \u03b8  d \u03c6   {\\displaystyle dA=r^{2}\\sin \\theta \\,d\\theta \\,d\\varphi }  . This can be found from the volume element in spherical coordinates with r held constant.[9]  A sphere of any radius centered at zero is an integral surface of the following differential form:  This equation reflects that the position vector and tangent plane at a point are always orthogonal to each other. Furthermore, the outward-facing normal vector is equal to the position vector scaled by 1\/r.  In Riemannian geometry, the filling area conjecture states that the hemisphere is the optimal (least area) isometric filling of the Riemannian circle.  Remarkably, it is possible to turn an ordinary sphere inside out in a three-dimensional space with possible self-intersections but without creating any creases, in a process called sphere eversion.  The antipodal quotient of the sphere is the surface called the real projective plane, which can also be thought of as the Northern Hemisphere with antipodal points of the equator identified.  Circles on the sphere are, like circles in the plane, made up of all points a certain distance from a fixed point on the sphere. The intersection of a sphere and a plane is a circle, a point, or empty.[18] Great circles are the intersection of the sphere with a plane passing through the center of a sphere: others are called small circles.  More complicated surfaces may intersect a sphere in circles, too: the intersection of a sphere with a surface of revolution whose axis contains the center of the sphere (are coaxial) consists of circles and\/or points if not empty. For example, the diagram to the right shows the intersection of a sphere and a cylinder, which consists of two circles. If the cylinder radius were that of the sphere, the intersection would be a single circle. If the cylinder radius were larger than that of the sphere, the intersection would be empty.  In navigation, a rhumb line or loxodrome is an arc crossing all meridians of longitude at the same angle. Loxodromes are the same as straight lines in the Mercator projection. A rhumb line is not a spherical spiral. Except for some simple cases, the formula of a rhumb line is complicated.  A Clelia curve is a curve on a sphere for which the longitude     \u03c6   {\\displaystyle \\varphi }   and the colatitude     \u03b8   {\\displaystyle \\theta }   satisfy the equation  Special cases are: Viviani's curve (    c = 1   {\\displaystyle c=1}  ) and spherical spirals (    c > 2   {\\displaystyle c>2}  ) such as Seiffert's spiral. Clelia curves approximate the ground track of satellites in polar orbit.  The analog of a conic section on the sphere is a spherical conic, a quartic curve which can be defined in several equivalent ways, including:  Many theorems relating to planar conic sections also extend to spherical conics.  If a sphere is intersected by another surface, there may be more complicated spherical curves.  The intersection of the sphere with equation       x  2   +  y  2   +  z  2   =  r  2      {\\displaystyle \\;x^{2}+y^{2}+z^{2}=r^{2}\\;}   and the cylinder with equation      ( y \u2212  y  0    )  2   +  z  2   =  a  2   ,   y  0   \u2260 0    {\\displaystyle \\;(y-y_{0})^{2}+z^{2}=a^{2},\\;y_{0}\\neq 0\\;}   is not just one or two circles. It is the solution of the non-linear system of equations  (see implicit curve and the diagram)  An ellipsoid is a sphere that has been stretched or compressed in one or more directions. More exactly, it is the image of a sphere under an affine transformation. An ellipsoid bears the same relationship to the sphere that an ellipse does to a circle.  Spheres can be generalized to spaces of any number of dimensions. For any natural number n, an n-sphere, often denoted S\u200dn, is the set of points in (n + 1)-dimensional Euclidean space that are at a fixed distance r from a central point of that space, where r is, as before, a positive real number. In particular:  Spheres for n > 2 are sometimes called hyperspheres.  The n-sphere of unit radius centered at the origin is denoted S\u200dn and is often referred to as \"the\" n-sphere. The ordinary sphere is a 2-sphere, because it is a 2-dimensional surface which is embedded in 3-dimensional space.  In topology, the n-sphere is an example of a compact topological manifold without boundary. A topological sphere need not be smooth; if it is smooth, it need not be diffeomorphic to the Euclidean sphere (an exotic sphere).  The sphere is the inverse image of a one-point set under the continuous function \u2016x\u2016, so it is closed; Sn is also bounded, so it is compact by the Heine\u2013Borel theorem.  More generally, in a metric space (E,d), the sphere of center x and radius r > 0 is the set of points y such that d(x,y) = r.  If the center is a distinguished point that is considered to be the origin of E, as in a normed space, it is not mentioned in the definition and notation. The same applies for the radius if it is taken to equal one, as in the case of a unit sphere.  Unlike a ball, even a large sphere may be an empty set. For example, in Zn with Euclidean metric, a sphere of radius r is nonempty only if r2 can be written as sum of n squares of integers.  An octahedron is a sphere in taxicab geometry, and a cube is a sphere in geometry using the Chebyshev distance.  The geometry of the sphere was studied by the Greeks. Euclid's Elements defines the sphere in book XI, discusses various properties of the sphere in book XII, and shows how to inscribe the five regular polyhedra within a sphere in book XIII. Euclid does not include the area and volume of a sphere, only a theorem that the volume of a sphere varies as the third power of its diameter, probably due to Eudoxus of Cnidus. The volume and area formulas were first determined in Archimedes's On the Sphere and Cylinder by the method of exhaustion. Zenodorus was the first to state that, for a given surface area, the sphere is the solid of maximum volume.[3]  Archimedes wrote about the problem of dividing a sphere into segments whose volumes are in a given ratio, but did not solve it. A solution by means of the parabola and hyperbola was given by Dionysodorus.[19] A similar problem \u2014 to construct a segment equal in volume to a given segment, and in surface to another segment \u2014 was solved later by al-Quhi.[3] "},{"title":"North Sea","content":"    Download coordinates as:  The North Sea lies between Great Britain, Denmark, Norway, Germany, the Netherlands, Belgium and France. An epeiric sea on the European continental shelf, it connects to the Atlantic Ocean through the English Channel in the south and the Norwegian Sea in the north. It is more than 970 kilometres (600\u00a0mi) long and 580 kilometres (360\u00a0mi) wide, covering 570,000 square kilometres (220,000\u00a0sq\u00a0mi).  It hosts key north European shipping lanes and is a major fishery. The coast is a popular destination for recreation and tourism in bordering countries, and a rich source of energy resources, including wind and wave power.  The North Sea has featured prominently in geopolitical and military affairs, particularly in Northern Europe, from the Middle Ages to the modern era. It was also important globally through the power northern Europeans projected worldwide during much of the Middle Ages and into the modern era. The North Sea was the centre of the Vikings' rise. The Hanseatic League, the Dutch Republic, and the British each sought to gain command of the North Sea and access to the world's markets and resources. As Germany's only outlet to the ocean, the North Sea was strategically important through both world wars.  The coast has diverse geology and geography. In the north, deep fjords and sheer cliffs mark much of its Norwegian and Scottish coastlines respectively, whereas in the south, the coast consists mainly of sandy beaches, estuaries of long rivers and wide mudflats. Due to the dense population, heavy industrialisation, and intense use of the sea and the area surrounding it, various environmental issues affect the sea's ecosystems. Adverse environmental issues\u00a0\u2013 commonly including overfishing, industrial and agricultural runoff, dredging, and dumping, among others\u00a0\u2013  have led to several efforts to prevent degradation and to safeguard long-term economic benefits.  The North Sea is bounded by the Orkney Islands and east coast of Great Britain to the west[1] and the northern and central European mainland to the east and south, including Norway, Denmark, Germany, the Netherlands, Belgium, and France.[2] In the southwest, beyond the Straits of Dover, the North Sea becomes the English Channel connecting to the Atlantic Ocean.[1][2] In the east, it connects to the Baltic Sea via the Skagerrak and Kattegat,[2] narrow straits that separate Denmark from Norway and Sweden respectively.[1] In the north it is bordered by the Shetland Islands, and connects with the Norwegian Sea, which is a marginal sea in the Arctic Ocean.[1][3]  The North Sea is more than 970 kilometres (600\u00a0mi) long and 580 kilometres (360\u00a0mi) wide, with an area of 750,000 square kilometres (290,000\u00a0sq\u00a0mi) and a volume of 54,000 cubic kilometres (13,000\u00a0cu\u00a0mi).[4] Around the edges of the North Sea are sizeable islands and archipelagos, including Shetland, Orkney, and the Frisian Islands.[2] The North Sea receives freshwater from a number of European continental watersheds, as well as the British Isles. A large part of the European drainage basin empties into the North Sea, including water from the Baltic Sea. The largest and most important rivers flowing into the North Sea are the Elbe and the Rhine \u2013 Meuse.[5] Around 185\u00a0million people live in the catchment area of the rivers discharging into the North Sea encompassing some highly industrialized areas.[6]  For the most part, the sea lies on the European continental shelf with a mean depth of 90 metres (300\u00a0ft).[1][7] The only exception is the Norwegian trench, which extends parallel to the Norwegian shoreline from Oslo to an area north of Bergen.[1] It is between 20 and 30 kilometres (12 and 19\u00a0mi) wide and has a maximum depth of 725 metres (2,379\u00a0ft).[8]  The Dogger Bank, a vast moraine, or accumulation of unconsolidated glacial debris, rises to a mere 15 to 30\u00a0m (50 to 100\u00a0ft) below the surface.[9][10] This feature has produced the finest fishing location of the North Sea.[1] The Long Forties and the Broad Fourteens are large areas with roughly uniform depth in fathoms (forty fathoms and fourteen fathoms or 73 and 26\u00a0m or 240 and 85\u00a0ft deep, respectively). These great banks and others make the North Sea particularly hazardous to navigate,[11] which has been alleviated by the implementation of satellite navigation systems.[12] The Devil's Hole lies 320 kilometres (200\u00a0mi) east of Dundee, Scotland. The feature is a series of asymmetrical trenches between 20 and 30 kilometres (12 and 19\u00a0mi) long, one and two kilometres (0.6 and 1.2\u00a0mi) wide and up to 230 metres (750\u00a0ft) deep.[13]  Other areas which are less deep are Cleaver Bank, Fisher Bank and Noordhinder Bank.  The International Hydrographic Organization defines the limits of the North Sea as follows:[14]  On the Southwest. A line joining the Phare de Walde (Walde Lighthouse, in France, 50\u00b059'37\"N, 1\u00b054'53\"E) and Leathercoat Point (England, 51\u00b010'01.4\"N 1\u00b024'07.8\").[15] northeast of Dover.  On the Northwest. From Dunnet Head (58\u00b040'20\"N, 3\u00b022'30\"W) in Scotland to Tor Ness (58\u00b047'N) in the Island of Hoy, thence through this island to the Kame of Hoy (58\u00b055'N) on to Breck Ness on Mainland (58\u00b058'N) through this island to Costa Head (3\u00b014'W) and Inga Ness (59'17'N) in Westray through Westray, to Bow Head, across to Mull Head (North point of Papa Westray) and on to Seal Skerry (North point of North Ronaldsay) and thence to Horse Island (South point of the Shetland Islands).  On the North. From the North point (Fethaland Point) of the Mainland of the Shetland Islands, across to Graveland Ness (60\u00b039'N) in the Island of Yell, through Yell to Gloup Ness (1\u00b004'W) and across to Spoo Ness (60\u00b045'N) in Unst island, through Unst to Herma Ness (60\u00b051'N), on to the SW point of the Rumblings and to Muckle Flugga (60\u00b051\u2032N 0\u00b053\u2032W\ufeff \/ \ufeff60.850\u00b0N 0.883\u00b0W\ufeff \/ 60.850; -0.883) all these being included in the North Sea area; thence up the meridian of 0\u00b053' West to the parallel of 61\u00b000' North and eastward along this parallel to the coast of Norway, the whole of Viking Bank is thus included in the North Sea.  On the East. The Western limit of the Skagerrak [A line joining Hanstholm (57\u00b007\u2032N 8\u00b036\u2032E\ufeff \/ \ufeff57.117\u00b0N 8.600\u00b0E\ufeff \/ 57.117; 8.600) and the Naze (Lindesnes, 58\u00b0N 7\u00b0E\ufeff \/ \ufeff58\u00b0N 7\u00b0E\ufeff \/ 58; 7)]. The average temperature is 17\u00a0\u00b0C (63\u00a0\u00b0F) in the summer and 6\u00a0\u00b0C (43\u00a0\u00b0F) in the winter.[4] The average temperatures have been trending higher since 1988, which has been attributed to climate change.[16][17] Air temperatures in January range on average between 0 and 4\u00a0\u00b0C (32 and 39\u00a0\u00b0F) and in July between 13 and 18\u00a0\u00b0C (55 and 64\u00a0\u00b0F). The winter months see frequent gales and storms.[1]  The salinity averages between 34 and 35 grams per litre (129 and 132\u00a0g\/US\u00a0gal) of water.[4] The salinity has the highest variability where there is fresh water inflow, such as at the Rhine and Elbe estuaries, the Baltic Sea exit and along the coast of Norway.[18]  The main pattern to the flow of water in the North Sea is an anti-clockwise rotation along the edges.[19]  The North Sea is an arm of the Atlantic Ocean receiving the majority of ocean current from the northwest opening, and a lesser portion of warm current from the smaller opening at the English Channel. These tidal currents leave along the Norwegian coast.[20] Surface and deep water currents may move in different directions. Low salinity surface coastal waters move offshore, and deeper, denser high salinity waters move inshore.[21]  The North Sea located on the continental shelf has different waves from those in deep ocean water. The wave speeds are diminished and the wave amplitudes are increased. In the North Sea there are two amphidromic systems and a third incomplete amphidromic system.[22][23] In the North Sea the average tide difference in wave amplitude is between zero and eight metres (26\u00a0ft).[An average is a single figure, not a range.][4] The presence of fixed-foundation wind turbines in the North Sea was created by action of the tide large visible sea plumes, as photographed by NASA.[24]  The Kelvin tide of the Atlantic Ocean is a semidiurnal wave that travels northward. Some of the energy from this wave travels through the English Channel into the North Sea. The wave continues to travel northward in the Atlantic Ocean, and once past the northern tip of Great Britain, the Kelvin wave turns east and south and once again enters the North Sea.[25]  The eastern and western coasts of the North Sea are jagged, formed by glaciers during the ice ages. The coastlines along the southernmost part are covered with the remains of deposited glacial sediment.[1] The Norwegian mountains plunge into the sea creating deep fjords and archipelagos. South of Stavanger, the coast softens, the islands become fewer.[1] The eastern Scottish coast is similar, though less severe than Norway. From north east of England, the cliffs become lower and are composed of less resistant moraine, which erodes more easily, so that the coasts have more rounded contours.[60][61] In the Netherlands, Belgium and in East Anglia the littoral is low and marshy.[1] The east coast and south-east of the North Sea (Wadden Sea) have coastlines that are mainly sandy and straight owing to longshore drift, particularly along Belgium and Denmark.[62]  The southern coastal areas were originally flood plains and swampy land. In areas especially vulnerable to storm surges, people settled behind elevated levees and on natural areas of high ground such as spits and geestland.[63]:\u200a[302,\u200a303]\u200a As early as 500 BC, people were constructing artificial dwelling hills higher than the prevailing flood levels.[63]:\u200a[306,\u200a308]\u200a It was only around the beginning of the High Middle Ages, in 1200 AD, that inhabitants began to connect single ring dikes into a dike line along the entire coast, thereby turning amphibious regions between the land and the sea into permanent solid ground.[63]  The modern form of the dikes supplemented by overflow and lateral diversion channels, began to appear in the 17th and 18th centuries, built in the Netherlands.[64] The North Sea Floods of 1953 and 1962 were the impetus for further raising of the dikes as well as the shortening of the coast line so as to present as little surface area as possible to the punishment of the sea and the storms.[65] Currently, 27% of the Netherlands is below sea level protected by dikes, dunes, and beach flats.[66]  Coastal management today consists of several levels.[67] The dike slope reduces the energy of the incoming sea, so that the dike itself does not receive the full impact.[67] Dikes that lie directly on the sea are especially reinforced.[67] The dikes have, over the years, been repeatedly raised, sometimes up to 9 metres (30\u00a0ft) and have been made flatter to better reduce wave erosion.[68] Where the dunes are sufficient to protect the land behind them from the sea, these dunes are planted with beach grass (Ammophila arenaria) to protect them from erosion by wind, water, and foot traffic.[69]  Storm surges threaten, in particular, the coasts of the Netherlands, Belgium, Germany, and Denmark and low-lying areas of eastern England particularly around The Wash and Fens.[62] Storm surges are caused by changes in barometric pressure combined with strong wind created wave action.[70]  The first recorded storm tide flood was the Julianenflut, on 17 February 1164. In its wake, the Jadebusen, (a bay on the coast of Germany), began to form. A storm tide in 1228 is recorded to have killed more than 100,000 people.[71] In 1362, the Second Marcellus Flood, also known as the Grote Manndrenke, hit the entire southern coast of the North Sea. Chronicles of the time again record more than 100,000 deaths, large parts of the coast were lost permanently to the sea, including the now legendary lost city of Rungholt.[72] In the 20th century, the North Sea flood of 1953 flooded several nations' coasts and cost more than 2,000 lives.[73] 315 citizens of Hamburg died in the North Sea flood of 1962.[74]:\u200a[79,\u200a86]\u200a  Though rare, the North Sea has been the site of a number of historically documented tsunamis. The Storegga Slides were a series of underwater landslides, in which a piece of the Norwegian continental shelf slid into the Norwegian Sea. The immense landslips occurred between 8150 BCE and 6000 BCE, and caused a tsunami up to 20 metres (66\u00a0ft) high that swept through the North Sea, having the greatest effect on Scotland and the Faeroe Islands.[75][76] The Dover Straits earthquake of 1580 is among the first recorded earthquakes in the North Sea measuring between 5.6 and 5.9 on the Richter scale. This event caused extensive damage in Calais both through its tremors and possibly triggered a tsunami, though this has never been confirmed. The theory is a vast underwater landslide in the English Channel was triggered by the earthquake, which in turn caused a tsunami.[77] The tsunami triggered by the 1755 Lisbon earthquake reached Holland, although the waves had lost their destructive power. The largest earthquake ever recorded in the United Kingdom was the 1931 Dogger Bank earthquake, which measured 6.1 on the Richter magnitude scale and caused a small tsunami that flooded parts of the British coast.[77]  Shallow epicontinental seas like the current North Sea have since long existed on the European continental shelf. The rifting that formed the northern part of the Atlantic Ocean during the Jurassic and Cretaceous periods, from about 150\u00a0million years ago, caused tectonic uplift in the British Isles.[78] Since then, a shallow sea has almost continuously existed between the uplands of the Fennoscandian Shield and the British Isles.[79] This precursor of the current North Sea has grown and shrunk with the rise and fall of the eustatic sea level during geologic time. Sometimes it was connected with other shallow seas, such as the sea above the Paris Basin to the south-west, the Paratethys Sea to the south-east, or the Tethys Ocean to the south.[80]  During the Late Cretaceous, about 85\u00a0million years ago, all of modern mainland Europe except for Scandinavia was a scattering of islands.[81] By the Early Oligocene, 34\u00a0to\u00a028 million years ago, the emergence of Western and Central Europe had almost completely separated the North Sea from the Tethys Ocean, which gradually shrank to become the Mediterranean as Southern Europe and South West Asia became dry land.[82] The North Sea was cut off from the English Channel by a narrow land bridge until that was breached by at least two catastrophic floods between 450,000 and 180,000 years ago.[83][84] Since the start of the Quaternary period about 2.6\u00a0million years ago, the eustatic sea level has fallen during each glacial period and then risen again. Every time the ice sheet reached its greatest extent, the North Sea became almost completely dry, the dry landmass being known as Doggerland, whose northern regions were themselves known to have been glaciated.[85] The present-day coastline formed after the Last Glacial Maximum when the sea began to flood the European continental shelf.[86]  In 2006 a bone fragment was found while drilling for oil in the North Sea. Analysis indicated that it was a Plateosaurus from 199 to 216\u00a0million years ago. This was the deepest dinosaur fossil ever found and the first find for Norway.[87]  Copepods and other zooplankton are plentiful in the North Sea. These tiny organisms are crucial elements of the food chain supporting many species of fish.[88] Over 230 species of fish live in the North Sea. Cod, haddock, whiting, saithe, plaice, sole, mackerel, herring, pouting, sprat, and sandeel are all very common and are fished commercially.[88][89] Due to the various depths of the North Sea trenches and differences in salinity, temperature, and water movement, some fish such as blue-mouth redfish and rabbitfish reside only in small areas of the North Sea.[90]  Crustaceans are also commonly found throughout the sea. Norway lobster, deep-water prawns, and brown shrimp are all commercially fished, but other species of lobster, shrimp, oyster, mussels and clams all live in the North Sea.[88] Recently non-indigenous species have become established including the Pacific oyster and Atlantic jackknife clam.[89]  The coasts of the North Sea are home to nature reserves including the Ythan Estuary, Fowlsheugh Nature Preserve, and Farne Islands in the UK and the Wadden Sea National Parks in Denmark, Germany and the Netherlands.[88] These locations provide breeding habitat for dozens of bird species. Tens of millions of birds make use of the North Sea for breeding, feeding, or migratory stopovers every year. Populations of black-legged kittiwakes, Atlantic puffins, northern gannets, northern fulmars, and species of petrels, seaducks, loons (divers), cormorants, gulls, auks, and terns, and many other seabirds make these coasts popular for birdwatching.[88][89]  The North Sea is also home to marine mammals. Common seals, grey seals, and harbour porpoises can be found along the coasts, at marine installations, and on islands. The very northern North Sea islands such as the Shetland Islands are occasionally home to a larger variety of pinnipeds including bearded, harp, hooded and ringed seals, and even walrus.[91] North Sea cetaceans include various porpoise, dolphin and whale species.[89][92]  Plant species in the North Sea include species of wrack, among them bladder wrack, knotted wrack, and serrated wrack. Algae, macroalgal, and kelp, such as oarweed and laminaria hyperboria, and species of maerl are found as well.[89] Eelgrass, formerly common in the entirety of the Wadden Sea, was nearly wiped out in the 20th century by a disease.[93] Similarly, sea grass used to coat huge tracts of ocean floor, but have been damaged by trawling and dredging have diminished its habitat and prevented its return.[94] Invasive Japanese seaweed has spread along the shores of the sea clogging harbours and inlets and has become a nuisance.[95]  Due to the heavy human populations and high level of industrialization along its shores, the wildlife of the North Sea has suffered from pollution, overhunting, and overfishing. Flamingos and pelicans were once found along the southern shores of the North Sea, but became extinct over the second millennium.[96] Walruses frequented the Orkney Islands through the mid-16th\u00a0century, as both Sable Island and Orkney Islands lay within their normal range.[97] Grey whales also resided in the North Sea but were driven to extinction in the Atlantic in the 17th\u00a0century[98] Other species have dramatically declined in population, though they are still found. North Atlantic right whales, sturgeon, shad, rays, skates, salmon, and other species were common in the North Sea until the 20th\u00a0century, when numbers declined due to overfishing.[99][100]  Other factors like the introduction of non-indigenous species, industrial and agricultural pollution, trawling and dredging, human-induced eutrophication, construction on coastal breeding and feeding grounds, sand and gravel extraction, offshore construction, and heavy shipping traffic have also contributed to the decline.[89] For example, a resident orca pod was lost in the 1960s, presumably due to the peak in PCB pollution in this time period.[101]  The OSPAR commission manages the OSPAR convention to counteract the harmful effects of human activity on wildlife in the North Sea, preserve endangered species, and provide environmental protection.[102] All North Sea border states are signatories of the MARPOL 73\/78 Accords, which preserve the marine environment by preventing pollution from ships.[103] Germany, Denmark, and the Netherlands also have a trilateral agreement for the protection of the Wadden Sea, or mudflats, which run along the coasts of the three countries on the southern edge of the North Sea.[104]  The North Sea has had various names throughout history. One of the earliest recorded names was Septentrionalis Oceanus, or \"Northern Ocean\", which was cited by Pliny.[105] He also noted that the Cimbri called it Morimarusa - \"Dead Sea\".[106] The name \"North Sea\" probably came into English, however, via the Dutch \"Noordzee\", who named it thus either in contrast with the Zuiderzee (\"South Sea\"), located south of Frisia, or because the sea is generally to the north of the Netherlands. Before the adoption of \"North Sea\", the names used in English were \"German Sea\" or \"German Ocean\", referred to as the Latin names \"Mare Germanicum\" and \"Oceanus Germanicus\",[107] and these persisted in use until the First World War.[108] Other common names in use for long periods were the Latin terms \"Mare Frisicum\", as well as the English equivalent, \"Frisian Sea\".[109][110] The modern names of the sea in the other local languages are: Danish: Vesterhavet [\u02c8vest\u0250\u02cch\u025b\u02c0v\u00f0\u0329] (\"West Sea\") or Nords\u00f8en [\u02c8no\u0250\u032f\u02ccs\u00f8\u02c0n\u0329], Dutch: Noordzee, Dutch Low Saxon: Noordzee, French: Mer du Nord, West Frisian: Noardsee, German: Nordsee, Low German: Noordsee, Northern Frisian: Weestsiie (\"West Sea\"), Swedish: Nordsj\u00f6n, Bokm\u00e5l: Nordsj\u00f8en [\u02c8n\u00fb\u02d0r\u02cc\u0282\u00f8\u02d0n], Nynorsk: Nordsj\u00f8en, Scots: North Sea and Scottish Gaelic: An Cuan a Tuath.  The North Sea has provided waterway access for commerce and conquest. Many areas have access to the North Sea because of its long coastline and the European rivers that empty it.[1] There is little documentary evidence concerning the North Sea before the Roman conquest of Britain in 43 CE, however, archaeological evidence reveals the diffusion of cultures and technologies from across or along the North Sea to Great Britain and Scandinavia and reliance by some prehistoric cultures on fishing, whaling, and seaborne trade on the North Sea. The Romans established organised ports in Britain, which increased shipping and began sustained trade[111] the diffusion of cultures and technologies from across or along the North Sea to Great Britain and Scandinavia and reliance by some prehistoric cultures on fishing, whaling, and seaborne trade on the North Sea. The Romans established organised ports in Britain, which increased shipping and began sustained trade[111] and many Scandinavian tribes participated in raids and wars against the Romans and Roman coinage and manufacturing were important trade goods. When the Romans abandoned Britain in 410, the Germanic Angles, Frisians, Saxons, and Jutes began the next great migration across the North Sea during the Migration Period. They made successive invasions of the island from what is now the Netherlands, Denmark, and Germany.[112]  The Viking Age began in 793 with the attack on Lindisfarne; for the next quarter-millennium, the Vikings ruled the North Sea. In their superior longships, they raided, traded, and established colonies and outposts along the coasts of the sea. From the Middle Ages through the 15th century, the northern European coastal ports exported domestic goods, dyes, linen, salt, metal goods and wine. The Scandinavian and Baltic areas shipped grain, fish, naval necessities, and timber. In turn, the North Sea countries imported high-grade cloths, spices, and fruits from the Mediterranean region.[113] Commerce during this era was mainly conducted by maritime trade due to underdeveloped roadways.[113]  In the 13th century the Hanseatic League, though centred on the Baltic Sea, started to control most of the trade through important members and outposts on the North Sea.[114] The League lost its dominance in the 16th century, as neighbouring states took control of former Hanseatic cities and outposts. Their internal conflict prevented effective cooperation and defence.[115] As the League lost control of its maritime cities, new trade routes emerged that provided Europe with Asian, American, and African goods.[116][117]  The 17th century Dutch Golden Age saw Dutch maritime power at its zenith.[118][119] Important overseas colonies, a vast merchant marine, a large fishing fleet,[113] powerful navy, and sophisticated financial markets made the Dutch the ascendant power in the North Sea, to be challenged by an ambitious England. This rivalry led to the first three Anglo-Dutch Wars between 1652 and 1673, which ended with Dutch victories.[119] After the Glorious Revolution in 1688, the Dutch prince William ascended to the English throne. With unified leadership, commercial, military, and political power began to shift from Amsterdam to London.[120] The British did not face a challenge to their dominance of the North Sea until the 20th century.[121]  Tensions in the North Sea were again heightened in 1904 by the Dogger Bank incident. During the Russo-Japanese War, several ships of the Russian Baltic Fleet, which was on its way to the Far East, mistook British fishing boats for Japanese ships and fired on them, and then upon each other, near the Dogger Bank, nearly causing Britain to enter the war on the side of Japan.  During the First World War, Great Britain's Grand Fleet and Germany's Kaiserliche Marine faced each other in the North Sea,[122] which became the main theatre of the war for surface action.[122] Britain's larger fleet and North Sea Mine Barrage were able to establish an effective blockade for most of the war, which restricted the Central Powers' access to many crucial resources.[123] Major battles included the Battle of Heligoland Bight,[124] the Battle of the Dogger Bank,[125] and the Battle of Jutland.[125] World War I also brought the first extensive use of submarine warfare, and a number of submarine actions occurred in the North Sea.[126]  The Second World War also saw action in the North Sea, though it was restricted more to aircraft reconnaissance and action by fighter\/bomber aircraft, submarines and smaller vessels such as minesweepers and torpedo boats.[127][128]  After the war, hundreds of thousands of tons of chemical weapons were disposed of by being dumped in the North Sea.[129]  After the war, the North Sea lost much of its military significance because it is bordered only by NATO member-states. However, it gained significant economic importance in the 1960s as the states around the North Sea began full-scale exploitation of its oil and gas resources.[130] The North Sea continues to be an active trade route.[131]  Countries that border the North Sea all claim the 12 nautical miles (22\u00a0km; 14\u00a0mi) of territorial waters, within which they have exclusive fishing rights.[132] The Common Fisheries Policy of the European Union (EU) exists to coordinate fishing rights and assist with disputes between EU states and the EU border state of Norway.[133]  After the discovery of mineral resources in the North Sea during the early 1960s, the Convention on the Continental Shelf established country rights largely divided along the median line. The median line is defined as the line \"every point of which is equidistant from the nearest points of the baselines from which the breadth of the territorial sea of each State is measured\".[134] The ocean floor border between Germany, the Netherlands, and Denmark was only reapportioned in 1969 after protracted negotiations and a judgment of the International Court of Justice.[132][135]  As early as 1859, oil was discovered in onshore areas around the North Sea and natural gas as early as 1910.[81] Onshore resources, for example the K12-B field in the Netherlands continue to be exploited today.  Offshore test drilling began in 1966 and then, in 1969, Phillips Petroleum Company discovered the Ekofisk oil field[136] distinguished by valuable, low-sulphur oil.[137] Commercial exploitation began in 1971 with tankers and, after 1975, by a pipeline, first to Teesside, England and then, after 1977, also to Emden, Germany.[138]  The exploitation of the North Sea oil reserves began just before the 1973 oil crisis, and the climb of international oil prices made the large investments needed for extraction much more attractive.[139] The start in 1973 of the oil reserves by the UK allowed them to stop the declining position in international trade in 1974, and a huge increase after the discovery and exploitation of the huge oil field by Phillips group in 1977 as the Brae field.  Although the production costs are relatively high, the quality of the oil, the political stability of the region, and the proximity of important markets in western Europe have made the North Sea an important oil-producing region.[137] The largest single humanitarian catastrophe in the North Sea oil industry was the destruction of the offshore oil platform Piper Alpha in 1988 in which 167 people lost their lives.[140]  Besides the Ekofisk oil field, the Statfjord oil field is also notable as it was the cause of the first pipeline to span the Norwegian trench.[141] The largest natural gas field in the North Sea, Troll gas field, lies in the Norwegian trench, dropping over 300 metres (980\u00a0ft), requiring the construction of the enormous Troll A platform to access it.  The price of Brent Crude, one of the first types of oil extracted from the North Sea is used today as a standard price for comparison for crude oil from the rest of the world.[142] The North Sea contains western Europe's largest oil and natural gas reserves and is one of the world's key non-OPEC producing regions.[143]  In the UK sector of the North Sea, the oil industry invested \u00a314.4\u00a0billion in 2013 and was on track to spend \u00a313\u00a0billion in 2014. Industry body Oil & Gas UK put the decline down to rising costs, lower production, high tax rates, and less exploration.[144]  In January 2018, The North Sea region contained 184 offshore rigs, which made it the region with the highest number of offshore rigs in the world at the time.[145]  The North Sea is Europe's main fishery accounting for over 5% of international commercial fish caught.[1] Fishing in the North Sea is concentrated in the southern part of the coastal waters. The main method of fishing is trawling.[146] In 1995, the total volume of fish and shellfish caught in the North Sea was approximately 3.5\u00a0million tonnes.[147] Besides saleable fish, it is estimated that one million tonnes of unmarketable by-catch is caught and discarded to die each year.[148]  In recent decades, overfishing has left many fisheries unproductive, disturbing marine food chain dynamics and costing jobs in the fishing industry.[149] Herring, cod and plaice fisheries may soon face the same plight as mackerel fishing, which ceased in the 1970s due to overfishing.[150] The objective of the European Union Common Fisheries Policy is to minimize the environmental impact associated with resource use by reducing fish discards, increasing the productivity of fisheries, stabilising markets of fisheries and fish processing, and supplying fish at reasonable prices for the consumer.[151]  Whaling was an important economic activity from the 9th until the 13th century for Flemish whalers.[152] The medieval Flemish, Basque and Norwegian whalers who were replaced in the 16th century by Dutch, English, Danes, and Germans, took massive numbers of whales and dolphins and nearly depleted the right whales. This activity likely led to the extinction of the Atlantic population of the once common grey whale.[153] By 1902 the whaling had ended.[152] After being absent for 300 years a single grey whale returned in 2010,[154] it probably was the first of many more to find its way through the now ice-free Northwest Passage.  In addition to oil, gas, and fish, the states along the North Sea also take millions of cubic metres per year of sand and gravel from the ocean floor. These are used for beach nourishment, land reclamation and construction.[155] Rolled pieces of amber may be picked up on the east coast of England.[156]  Due to the strong prevailing winds, and shallow water, countries on the North Sea, particularly Germany and Denmark, have used the shore for wind power since the 1990s.[157] The North Sea is the home of one of the first large-scale offshore wind farms in the world, Horns Rev 1, completed in 2002. Since then many other wind farms have been commissioned in the North Sea (and elsewhere). As of 2013, the 630\u00a0megawatt (MW) London Array is the largest offshore wind farm in the world, with the 504 (MW) Greater Gabbard wind farm the second largest, followed by the 367\u00a0MW Walney Wind Farm. All are off the coast of the UK. These projects will be dwarfed by subsequent wind farms that are in the pipeline, including Dogger Bank at 4,800\u00a0MW, Norfolk Bank (7,200\u00a0MW), and Irish Sea (4,200\u00a0MW). At the end of June 2013 total European combined offshore wind energy capacity was 6,040\u00a0MW. The UK installed 513.5\u00a0MW of offshore wind power in the first half-year of 2013.[158] The development of the offshore wind industry in UK-controlled areas of the North Sea is traced to three phases: coastal, off-coastal and deep offshore in the period 2004 - 2021.[159]  The expansion of offshore wind farms has met with some resistance. Concerns have included shipping collisions[160] and environmental effects on ocean ecology and wildlife such as fish and migratory birds,[161] however, these concerns were found to be negligible in a long-term study in Denmark released in 2006 and again in a UK government study in 2009.[162][163] There are also concerns about reliability,[164] and the rising costs of constructing and maintaining offshore wind farms.[165] Despite these, development of North Sea wind power is continuing, with plans for additional wind farms off the coasts of Germany, the Netherlands, and the UK.[166] There have also been proposals for a transnational power grid in the North Sea[167][168] to connect new offshore wind farms.[169]  Energy production from tidal power is still in a pre-commercial stage. The European Marine Energy Centre has installed a wave testing system at Billia Croo on the Orkney mainland[170] and a tidal power testing station on the nearby island of Eday.[171] Since 2003, a prototype Wave Dragon energy converter has been in operation at Nissum Bredning fjord of northern Denmark.[172]  The beaches and coastal waters of the North Sea are destinations for tourists. The English, Belgian, Dutch, German and Danish coasts[173][174] are developed for tourism. The North Sea coast of the United Kingdom has tourist destinations with beach resorts and links golf courses; the coastal town of St. Andrews in Scotland is renowned as the \"Home of Golf\".[citation needed]  The North Sea Trail is a long-distance trail linking seven countries around the North Sea.[175] Windsurfing and sailing[176] are popular sports because of the strong winds. Mudflat hiking,[177] recreational fishing and birdwatching[174] are among other activities.  The climatic conditions on the North Sea coast have been claimed to be healthy. As early as the 19th century, travellers visited the North Sea coast for curative and restorative vacations. The sea air, temperature, wind, water, and sunshine are counted among the beneficial conditions that are said to activate the body's defences, improve circulation, strengthen the immune system, and have healing effects on the skin and the respiratory system.[178]  The Wadden Sea in Denmark, Germany and the Netherlands is an UNESCO World Heritage Site.  The North Sea is important for marine transport and its shipping lanes are among the busiest in the world.[132] Major ports are located along its coasts: Rotterdam, the busiest port in Europe and the fourth busiest port in the world by tonnage as of 2013[update], Antwerp (was 16th) and Hamburg (was 27th), Bremen\/Bremerhaven and Felixstowe, both in the top 30 busiest container seaports,[179] as well as the Port of Bruges-Zeebrugge, Europe's leading ro-ro port.[180]  Fishing boats, service boats for offshore industries, sport and pleasure craft, and merchant ships to and from North Sea ports and Baltic ports must share routes on the North Sea. The Dover Strait alone sees more than 400 commercial vessels a day.[181] Because of this volume, navigation in the North Sea can be difficult in high traffic zones, so ports have established elaborate vessel traffic services to monitor and direct ships into and out of port.[182]  The North Sea coasts are home to numerous canals and canal systems to facilitate traffic between and among rivers, artificial harbours, and the sea. The Kiel Canal, connecting the North Sea with the Baltic Sea, is the most heavily used artificial seaway in the world reporting an average of 89 ships per day not including sporting boats and other small watercraft in 2009.[183] It saves an average of 250 nautical miles (460\u00a0km; 290\u00a0mi), instead of the voyage around the Jutland peninsula.[184] The North Sea Canal connects Amsterdam with the North Sea. "},{"title":"Irish language","content":"  Irish (Standard Irish: Gaeilge), also known as Irish Gaelic or simply Gaelic (\/\u02c8\u0261e\u026al\u026ak\/ GAY-lik),[3][4][5][6][7][8] is a Goidelic language of the Insular Celtic branch of the Celtic language group, which is a part of the Indo-European language family.[7][4][9][10][6] Irish is indigenous to the island of Ireland[11] and was the population's first language until the 19th century, when English gradually became dominant, particularly in the last decades of the century. Today, Irish is still commonly spoken as a first language in areas of Ireland collectively known as the Gaeltacht, in which only 2% of Ireland's population lived in 2022.[12]  The total number of people (aged 3 and over) in Ireland who claimed they could speak Irish in April 2022 was 1,873,997, representing 40% of respondents, but of these, 472,887 said they never spoke it and a further 551,993 said they only spoke it within the education system.[12] Linguistic analyses of Irish speakers are therefore based primarily on the number of daily users in Ireland outside the education system, which in 2022 was 20,261 in the Gaeltacht and 51,707 outside it, totalling 71,968.[12] In response to the 2021 census of Northern Ireland, 43,557 individuals stated they spoke Irish on a daily basis, 26,286 spoke it on a weekly basis, 47,153 spoke it less often than weekly, and 9,758 said they could speak Irish, but never spoke it.[13] From 2006 to 2008, over 22,000 Irish Americans reported speaking Irish as their first language at home, with several times that number claiming \"some knowledge\" of the language.[14]  For most of recorded Irish history, Irish was the dominant language of the Irish people, who took it with them to other regions, such as Scotland and the Isle of Man, where Middle Irish gave rise to Scottish Gaelic and Manx. It was also, for a period, spoken widely across Canada, with an estimated 200,000\u2013250,000 daily Canadian speakers of Irish in 1890.[15] On the island of Newfoundland, a unique dialect of Irish developed before falling out of use in the early 20th century.  With a writing system, Ogham, dating back to at least the 4th century AD, which was gradually replaced by Latin script since the 5th century AD, Irish has one of the oldest vernacular literatures in Western Europe. On the island, the language has three major dialects: Connacht, Munster and Ulster Irish. All three have distinctions in their speech and orthography. There is also a \"standard written form\" devised by a parliamentary commission in the 1950s. The traditional Irish alphabet, a variant of the Latin alphabet with 18 letters, has been succeeded by the standard Latin alphabet (albeit with 7\u20138 letters used primarily in loanwords).  Irish has constitutional status as the national and first official language of the Republic of Ireland, and is also an official language of Northern Ireland and among the official languages of the European Union. The public body Foras na Gaeilge is responsible for the promotion of the language throughout the island. Irish has no regulatory body but the standard modern written form is guided by a parliamentary service and new vocabulary by a voluntary committee with university input.  In An Caighde\u00e1n Oifigi\u00fail (\"The Official [Written] Standard\") the name of the language is Gaeilge, from the South Connacht form, spelled Gaedhilge prior the spelling reform of 1948, which was originally the genitive of Gaedhealg, the form used in Classical Gaelic.[16] The modern spelling results from the deletion of the silent \u27e8dh\u27e9 in Gaedhilge. Older spellings include Gaoidhealg [\u02c8\u0261e\u02d0\u029d\u0259l\u02e0\u0261] in Classical Gaelic and Go\u00eddelc [\u02c8\u0261oi\u00f0el\u02e0\u0261] in Old Irish. Goidelic, used to refer to the language family, is derived from the Old Irish term.  Endonyms of the language in the various modern Irish dialects include: Gaeilge [\u02c8\u0261e\u02d0l\u02b2\u025f\u0259] in Galway, Gaeilg\/Gaeilic\/Gaeilig [\u02c8\u0261e\u02d0l\u02b2\u0259c] in Mayo and Ulster, Gaelainn\/Gaoluinn [\u02c8\u0261e\u02d0l\u032a\u02e0\u0259n\u0320\u02b2] in West\/Cork, Kerry Munster, as well as Gaedhealaing in mid and East Kerry\/Cork and Waterford Munster to reflect local pronunciation.[17][18]  Gaeilge also has a wider meaning, including the Gaelic of Scotland and the Isle of Man, as well as of Ireland. When required by the context, these are distinguished as Gaeilge na hAlban, Gaeilge Mhanann and Gaeilge na h\u00c9ireann respectively.[19]  In English (including Hiberno-English), the language is usually referred to as Irish, as well as Gaelic and Irish Gaelic.[20][21] The term Irish Gaelic may be seen when English speakers discuss the relationship between the three Goidelic languages (Irish, Scottish Gaelic and Manx).[22] Gaelic is a collective term for the Goidelic languages,[6][23][7][10][24] and when the context is clear it may be used without qualification to refer to each language individually. When the context is specific but unclear, the term may be qualified, as Irish Gaelic, Scottish Gaelic or Manx Gaelic. Historically the name \"Erse\" (\/\u025c\u02d0rs\/ URS) was also sometimes used in Scots and then in English to refer to Irish;[25] as well as Scottish Gaelic.  Written Irish is first attested in Ogham inscriptions from the 4th century AD,[26] a stage of the language known as Primitive Irish. These writings have been found throughout Ireland and the west coast of Great Britain. Primitive Irish underwent a change into Old Irish through the 5th century. Old Irish, dating from the 6th century, used the Latin alphabet and is attested primarily in marginalia to Latin manuscripts. During this time, the Irish language absorbed some Latin words, some via Old Welsh, including ecclesiastical terms: examples are easpag (bishop) from episcopus, and Domhnach (Sunday, from dominica).  By the 10th century, Old Irish had evolved into Middle Irish, which was spoken throughout Ireland, Isle of Man and parts of Scotland. It is the language of a large corpus of literature, including the Ulster Cycle. From the 12th century, Middle Irish began to evolve into modern Irish in Ireland, into Scottish Gaelic in Scotland, and into the Manx language in the Isle of Man.  Early Modern Irish, dating from the 13th century, was the basis of the literary language of both Ireland and Gaelic-speaking Scotland. Modern Irish, as attested in the work of such writers as Geoffrey Keating, may be said to date from the 17th century, and was the medium of popular literature from that time on.  From the 18th century on, the language lost ground in the east of the country. The reasons behind this shift were complex but came down to a number of factors:  The change was characterised by diglossia (two languages being used by the same community in different social and economic situations) and transitional bilingualism (monoglot Irish-speaking grandparents with bilingual children and monoglot English-speaking grandchildren). By the mid-18th century, English was becoming a language of the Catholic middle class, the Catholic Church and public intellectuals, especially in the east of the country. Increasingly, as the value of English became apparent, parents sanctioned the prohibition of Irish in schools.[28] Increasing interest in emigrating to the United States and Canada was also a driver, as fluency in English allowed the new immigrants to get jobs in areas other than farming. An estimated one quarter to one third of US immigrants during the Great Famine were Irish speakers.[29]  Irish was not marginal to Ireland's modernisation in the 19th century, as is often assumed. In the first half of the century there were still around three million people for whom Irish was the primary language, and their numbers alone made them a cultural and social force. Irish speakers often insisted on using the language in law courts (even when they knew English), and Irish was also common in commercial transactions. The language was heavily implicated in the \"devotional revolution\" which marked the standardisation of Catholic religious practice and was also widely used in a political context. Down to the time of the Great Famine and even afterwards, the language was in use by all classes, Irish being an urban as well as a rural language.[30]  This linguistic dynamism was reflected in the efforts of certain public intellectuals to counter the decline of the language. At the end of the 19th century, they launched the Gaelic revival in an attempt to encourage the learning and use of Irish, although few adult learners mastered the language.[31] The vehicle of the revival was the Gaelic League (Conradh na Gaeilge), and particular emphasis was placed on the folk tradition, which in Irish is particularly rich. Efforts were also made to develop journalism and a modern literature.  Although it has been noted that the Catholic Church played a role in the decline of the Irish language before the Gaelic Revival, the Protestant Church of Ireland also made only minor efforts to encourage use of Irish in a religious context. An Irish translation of the Old Testament by Leinsterman Muircheartach \u00d3 C\u00edonga, commissioned by Bishop Bedell, was published after 1685 along with a translation of the New Testament. Otherwise, Anglicisation was seen as synonymous with 'civilising' the native Irish. Currently, modern day Irish speakers in the church are pushing for language revival.[32]  It has been estimated that there were around 800,000 monoglot Irish speakers in 1800, which dropped to 320,000 by the end of the famine, and under 17,000 by 1911.[33]  Irish is recognised by the Constitution of Ireland as the national and first official language of Republic of Ireland (English being the other official language). Despite this, almost all government business and legislative debate is conducted in English.[34]  In 1938, the founder of Conradh na Gaeilge (Gaelic League), Douglas Hyde, was inaugurated as the first President of Ireland. The record of his delivering his inaugural Declaration of Office in Roscommon Irish is one of only a few recordings of that dialect.[35][36][37][38]  In the 2016 census, 10.5% of respondents stated that they spoke Irish, either daily or weekly, while over 70,000 people (4.2%) speak it as a habitual daily means of communication.[39]  From the foundation of the Irish Free State in 1922 (see History of the Republic of Ireland), new appointees to the Civil Service of the Republic of Ireland, including postal workers, tax collectors, agricultural inspectors, Garda S\u00edoch\u00e1na (police), etc., were required to have some proficiency in Irish. By law, a Garda who was addressed in Irish had to respond in Irish as well.[40]  In 1974, in part through the actions of protest organisations like the Language Freedom Movement, the requirement for entrance to the public service was changed to proficiency in just one official language.  Nevertheless, Irish remains a required subject of study in all schools in the Republic of Ireland that receive public money (see Education in the Republic of Ireland). Teachers in primary schools must also pass a compulsory examination called Scr\u00fad\u00fa C\u00e1il\u00edochta sa Ghaeilge. As of 2005, Garda S\u00edoch\u00e1na recruits need a pass in Leaving Certificate Irish or English, and receive lessons in Irish during their two years of training. Official documents of the Irish government must be published in both Irish and English or Irish alone (in accordance with the Official Languages Act 2003, enforced by An Coimisin\u00e9ir Teanga, the Irish language ombudsman).  The National University of Ireland requires all students wishing to embark on a degree course in the NUI federal system to pass the subject of Irish in the Leaving Certificate or GCE\/GCSE examinations.[41] Exemptions are made from this requirement for students who were born or completed primary education outside of Ireland, and students diagnosed with dyslexia.  NUI Galway is required to appoint people who are competent in the Irish language, as long as they are also competent in all other aspects of the vacancy to which they are appointed. This requirement is laid down by the University College Galway Act, 1929 (Section 3).[42] In 2016, the university faced controversy when it announced the appointment of a president who did not speak Irish. Misneach[further explanation needed] staged protests against this decision. The following year the university announced that Ciar\u00e1n \u00d3 h\u00d3gartaigh, a fluent Irish speaker, would be its 13th president.[citation needed]  For a number of years there has been vigorous debate in political, academic and other circles about the failure of most students in English-medium schools to achieve competence in Irish, even after fourteen years of teaching as one of the three main subjects.[43][44][45] The concomitant decline in the number of traditional native speakers has also been a cause of great concern.[46][47][48][49]  In 2007, filmmaker Manch\u00e1n Magan found few Irish speakers in Dublin, and faced incredulity when trying to get by speaking only Irish in Dublin. He was unable to accomplish some everyday tasks, as portrayed in his documentary No B\u00e9arla.[50]  There is, however, a growing body of Irish speakers in urban areas, particularly in Dublin. Many have been educated in schools in which Irish is the language of instruction. Such schools are known as Gaelscoileanna at primary level. These Irish-medium schools report some better outcomes for students than English-medium schools.[51] In 2009, a paper suggested that within a generation, non-Gaeltacht habitual users of Irish might typically be members of an urban, middle class, and highly educated minority.[52]  Parliamentary legislation is supposed to be available in both Irish and English but is frequently only available in English. This is notwithstanding that Article 25.4 of the Constitution of Ireland requires that an \"official translation\" of any law in one official language be provided immediately in the other official language, if not already passed in both official languages.[1]  In November 2016, RT\u00c9 reported that over 2.3 million people worldwide were learning Irish through the Duolingo app.[53] Irish president Michael Higgins officially honoured several volunteer translators for developing the Irish edition, and said the push for Irish language rights remains an \"unfinished project\".[54]  There are rural areas of Ireland where Irish is still spoken daily to some extent as a first language. These regions are known individually and collectively as the Gaeltacht (plural Gaeltachta\u00ed). While the fluent Irish speakers of these areas, whose numbers have been estimated at 20\u201330,000,[55] are a minority of the total number of fluent Irish speakers, they represent a higher concentration of Irish speakers than other parts of the country and it is only in Gaeltacht areas that Irish continues to be spoken as a community vernacular to some extent.  According to data compiled by the Department of Tourism, Culture, Arts, Gaeltacht, Sport and Media, only 1\/4 of households in Gaeltacht areas are fluent in Irish. The author of a detailed analysis of the survey, Donncha \u00d3 h\u00c9allaithe of the Galway-Mayo Institute of Technology, described the Irish language policy followed by Irish governments as a \"complete and absolute disaster\". The Irish Times, referring to his analysis published in the Irish language newspaper Foinse, quoted him as follows: \"It is an absolute indictment of successive Irish Governments that at the foundation of the Irish State there were 250,000 fluent Irish speakers living in Irish-speaking or semi Irish-speaking areas, but the number now is between 20,000 and 30,000.\"[55]  In the 1920s, when the Irish Free State was founded, Irish was still a vernacular in some western coastal areas.[56] In the 1930s, areas where more than 25% of the population spoke Irish were classified as Gaeltacht. Today, the strongest Gaeltacht areas, numerically and socially, are those of South Connemara, the west of the Dingle Peninsula, and northwest Donegal, where many residents still use Irish as their primary language. These areas are often referred to as the F\u00edor-Ghaeltacht (true Gaeltacht), a term originally officially applied to areas where over 50% of the population spoke Irish.  There are Gaeltacht regions in the following counties:[57][58]  Gweedore (Gaoth Dobhair), County Donegal, is the largest Gaeltacht parish in Ireland. Irish language summer colleges in the Gaeltacht are attended by tens of thousands of teenagers annually. Students live with Gaeltacht families, attend classes, participate in sports, go to c\u00e9ilithe and are obliged to speak Irish. All aspects of Irish culture and tradition are encouraged.  The Act was passed 14 July 2003 with the main purpose of improving the amount and quality of public services delivered in Irish by the government and other public bodies.[59] Compliance with the Act is monitored by the An Coimisin\u00e9ir Teanga (Irish Language Commissioner) which was established in 2004[60] and any complaints or concerns pertaining to the Act are brought to them.[59] There are 35 sections included in the Act all detailing different aspects of the use of Irish in official documentation and communication. Included in these sections are subjects such as Irish language use in official courts, official publications, and placenames.[61] The Act was recently amended in December 2019 in order to strengthen the already preexisting legislation.[62] All changes made took into account data collected from online surveys and written submissions.[63]  The Official Languages Scheme was enacted 1 July 2019 and is an 18-page document that adheres to the guidelines of the Official Languages Act 2003.[64] The purpose of the Scheme is to provide services through the mediums of Irish and\/or English. According to the Department of the Taoiseach, it is meant to \"develop a sustainable economy and a successful society, to pursue Ireland's interests abroad, to implement the Government's Programme and to build a better future for Ireland and all her citizens.\"[65]  The Strategy was produced on 21 December 2010 and will stay in action until 2030; it aims to target language vitality and revitalization of the Irish language.[66] The 30-page document published by the Government of Ireland details the objectives it plans to work towards in an attempt to preserve and promote both the Irish language and the Gaeltacht. It is divided into four separate phases with the intention of improving 9 main areas of action including:  The general goal for this strategy was to increase the amount of daily speakers from 83,000 to 250,000 by the end of its run.[68] By 2022, the number of such speakers had fallen to 71,968.[69]  Before the partition of Ireland in 1921, Irish was recognised as a school subject and as \"Celtic\" in some third level institutions. Between 1921 and 1972, Northern Ireland had devolved government. During those years the political party holding power in the Stormont Parliament, the Ulster Unionist Party (UUP), was hostile to the language. The context of this hostility was the use of the language by nationalists.[70] In broadcasting, there was an exclusion on the reporting of minority cultural issues, and Irish was excluded from radio and television for almost the first fifty years of the previous devolved government.[71] After the 1998 Good Friday Agreement, the language gradually received a degree of formal recognition in Northern Ireland from the United Kingdom,[72] and then, in 2003, by the British government's ratification in respect of the language of the European Charter for Regional or Minority Languages. In the 2006 St Andrews Agreement the British government promised to enact legislation to promote the language[73] and in 2022 it approved legislation to recognise Irish as an official language alongside English. The bill received royal assent on 6 December 2022.[74]  The Irish language has often been used as a bargaining chip during government formation in Northern Ireland, prompting protests from organisations and groups such as An Dream Dearg.[75]  Irish became an official language of the EU on 1 January 2007, meaning that MEPs with Irish fluency can now speak the language in the European Parliament and at committees, although in the case of the latter they have to give prior notice to a simultaneous interpreter in order to ensure that what they say can be interpreted into other languages.  While an official language of the European Union, only co-decision regulations were available until 2022, due to a five-year derogation, requested by the Irish Government when negotiating the language's new official status. The Irish government had committed itself to train the necessary number of translators and interpreters and to bear the related costs.[76] This derogation ultimately came to an end on 1 January 2022, making Irish a fully recognised EU language for the first time in the state's history.[77]  Before Irish became an official language it was afforded the status of treaty language and only the highest-level documents of the EU were made available in Irish.  The Irish language was carried abroad in the modern period by a vast diaspora, chiefly to Great Britain and North America, but also to Australia, New Zealand and Argentina. The first large movements began in the 17th century, largely as a result of the Cromwellian conquest of Ireland, which saw many Irish sent to the West Indies. Irish emigration to the United States was well established by the 18th century, and was reinforced in the 1840s by thousands fleeing from the Famine. This flight also affected Britain. Up until that time most emigrants spoke Irish as their first language, though English was establishing itself as the primary language. Irish speakers had first arrived in Australia in the late 18th century as convicts and soldiers, and many Irish-speaking settlers followed, particularly in the 1860s. New Zealand also received some of this influx. Argentina was the only non-English-speaking country to receive large numbers of Irish emigrants, and there were few Irish speakers among them.  Relatively few of the emigrants were literate in Irish, but manuscripts in the language were brought to both Australia and the United States, and it was in the United States that the first newspaper to make significant use of Irish was established: An Gaodhal. In Australia, too, the language found its way into print. The Gaelic revival, which started in Ireland in the 1890s, found a response abroad, with branches of Conradh na Gaeilge being established in all the countries to which Irish speakers had emigrated.  The decline of Irish in Ireland and a slowing of emigration helped to ensure a decline in the language abroad, along with natural attrition in the host countries. Despite this, small groups of enthusiasts continued to learn and cultivate Irish in diaspora countries and elsewhere, a trend which strengthened in the second half of the 20th century. Today the language is taught at tertiary level in North America, Australia and Europe, and Irish speakers outside Ireland contribute to journalism and literature in the language. There are significant Irish-speaking networks in the United States and Canada;[78] figures released for the period 2006\u20132008 show that 22,279 Irish Americans claimed to speak Irish at home.[14]  The Irish language is also one of the languages of the Celtic League, a non-governmental organisation that promotes self-determination, Celtic identity and culture in Ireland, Scotland, Wales, Brittany, Cornwall and the Isle of Man, known collectively as the Celtic nations.  Irish was spoken as a community language until the early 20th century on the island of Newfoundland, in a form known as Newfoundland Irish.[79] Certain Irish vocabulary, grammar, and pronunciation features are still used in modern Newfoundland English.[80]   The 2016 census data shows: The total number of people who answered 'yes' to being able to speak Irish in April 2016 was 1,761,420, a slight decrease (0.7 per cent) on the 2011 figure of 1,774,437. This represents 39.8 per cent of respondents compared with 41.4 in 2011... Of the 73,803 daily Irish speakers (outside the education system), 20,586 (27.9%) lived in Gaeltacht areas.[81] In 1996, the three electoral divisions in the State where Irish had the most daily speakers were An Turloch (91%+), Scainimh (89%+), Min an Chladaigh (88%+).[83]  Irish is represented by several traditional dialects and by various varieties of \"urban\" Irish. The latter have acquired lives of their own and a growing number of native speakers. Differences between the dialects make themselves felt in stress, intonation, vocabulary and structural features.  Roughly speaking, the three major dialect areas which survive coincide roughly with the provinces of Connacht (C\u00faige Chonnacht), Munster (C\u00faige Mumhan) and Ulster (C\u00faige Uladh). Records of some dialects of Leinster (C\u00faige Laighean) were made by the Irish Folklore Commission and others.[84] Newfoundland, in eastern Canada, had a form of Irish derived from the Munster Irish of the later 18th century (see Newfoundland Irish).  Historically, Connacht Irish represents the westernmost remnant of a dialect area which once stretched from east to west across the centre of Ireland. The strongest dialect of Connacht Irish is to be found in Connemara and the Aran Islands. Much closer to the larger Connacht Gaeltacht is the dialect spoken in the smaller region on the border between Galway (Gaillimh) and Mayo (Maigh Eo). There are a number of differences between the popular South Connemara form of Irish, the Mid-Connacht\/Joyce Country form (on the border between Mayo and Galway) and the Achill and Erris forms in the north of the province.  Features in Connacht Irish differing from the official standard include a preference for verbal nouns ending in -achan, e.g. lagachan instead of lag\u00fa, \"weakening\". The non-standard pronunciation of Cois Fharraige with lengthened vowels and heavily reduced endings gives it a distinct sound. Distinguishing features of Connacht and Ulster dialect include the pronunciation of word-final \/w\/ as [w], rather than as [v\u02e0] in Munster. For example, sliabh (\"mountain\") is [\u0283l\u02b2i\u0259w] in Connacht and Ulster as opposed to [\u0283l\u02b2i\u0259\u03b2] in the south. In addition Connacht and Ulster speakers tend to include the \"we\" pronoun rather than use the standard compound form used in Munster, e.g. bh\u00ed muid is used for \"we were\" instead of bh\u00edomar.  As in Munster Irish, some short vowels are lengthened and others diphthongised before \u27e8ll, m, nn, rr, rd\u27e9, in monosyllabic words and in the stressed syllable of multisyllabic words where the syllable is followed by a consonant. This can be seen in ceann [c\u0251\u02d0n\u032a\u02e0] \"head\", cam [k\u0251\u02d0m\u02e0] \"crooked\", gearr [\u025f\u0251\u02d0\u027e\u02e0] \"short\", ord [ou\u027e\u02e0d\u032a\u02e0] \"sledgehammer\", gall [g\u0251\u02d0l\u032a\u02e0] \"foreigner, non-Gael\", iontas [i\u02d0n\u032a\u02e0t\u032a\u02e0\u0259s\u02e0] \"a wonder, a marvel\", etc. The form \u27e8(a)ibh\u27e9, when occurring at the end of words like agaibh, tends to be pronounced as [i\u02d0].  In South Connemara, for example, there is a tendency to replace word-final \/v\u02b2\/ with \/b\u02b2\/, in word such as sibh, libh and d\u00f3ibh (pronounced respectively as \"shiv,\" \"liv\" and \"d\u00f3fa\" in the other areas). This placing of the B-sound is also present at the end of words ending in vowels, such as acu ([\u02c8ak\u0259b\u02e0]) and 'leo ([l\u02b2o\u02d0b\u02e0]). There is also a tendency to omit \/g\/ in agam, agat and againn, a characteristic also of other Connacht dialects. All these pronunciations are distinctively regional.  The pronunciation prevalent in the Joyce Country (the area around Lough Corrib and Lough Mask) is quite similar to that of South Connemara, with a similar approach to the words agam, agat and againn and a similar approach to pronunciation of vowels and consonants but there are noticeable differences in vocabulary, with certain words such as doiligh (difficult) and foscailte being preferred to the more usual deacair and oscailte. Another interesting aspect of this sub-dialect is that almost all vowels at the end of words tend to be pronounced as [i\u02d0]: eile (other), cosa (feet) and d\u00e9anta (done) tend to be pronounced as eil\u00ed, cosa\u00ed and d\u00e9anta\u00ed respectively.  The northern Mayo dialect of Erris (Iorras) and Achill (Acaill) is in grammar and morphology essentially a Connacht dialect but shows some similarities to Ulster Irish due to large-scale immigration of dispossessed people following the Plantation of Ulster. For example, words ending -\u27e8bh, mh\u27e9 have a much softer sound, with a tendency to terminate words such as leo and d\u00f3ibh with \u27e8f\u27e9, giving leofa and d\u00f3fa respectively. In addition to a vocabulary typical of other area of Connacht, one also finds Ulster words like amharc (meaning \"to look\"), nimhneach (painful or sore), druid (close), mothaigh (hear), doiligh (difficult), \u00far (new), and tig le (to be able to \u2013 i.e. a form similar to f\u00e9idir).  Irish President Douglas Hyde was possibly one of the last speakers of the Roscommon dialect of Irish.[36]  Munster Irish is the dialect spoken in the Gaeltacht areas of the counties of Cork (Contae Chorca\u00ed), Kerry (Contae Chiarra\u00ed), and Waterford (Contae Phort L\u00e1irge). The Gaeltacht areas of Cork can be found in Cape Clear Island (Oile\u00e1n Chl\u00e9ire) and Muskerry (M\u00fascra\u00ed); those of Kerry lie in Corca Dhuibhne and Iveragh Peninsula; and those of Waterford in Ring (An Rinn) and Old Parish (An Sean Phobal), both of which together form Gaeltacht na nD\u00e9ise. Of the three counties, the Irish spoken in Cork and Kerry is quite similar while that of Waterford is more distinct.  Some typical features of Munster Irish are:  Ulster Irish is the dialect spoken in the Gaeltacht regions of Donegal. These regions contain all of Ulster's communities where Irish has been spoken in an unbroken line back to when the language was the dominant language of Ireland. The Irish-speaking communities in other parts of Ulster are a result of language revival \u2013 English-speaking families deciding to learn Irish. Census data shows that 4,130 people speak it at home.  Linguistically, the most important of the Ulster dialects today is that which is spoken, with slight differences, in both Gweedore (Gaoth Dobhair = Inlet of Streaming Water) and The Rosses (na Rossa).  Ulster Irish sounds quite different from the other two main dialects. It shares several features with southern dialects of Scottish Gaelic and Manx, as well as having many characteristic words and shades of meanings. However, since the demise of those Irish dialects spoken natively in what is today Northern Ireland, it is probably an exaggeration to see present-day Ulster Irish as an intermediary form between Scottish Gaelic and the southern and western dialects of Irish. Northern Scottish Gaelic has many non-Ulster features in common with Munster Irish.  One noticeable trait of Ulster Irish, Scots Gaelic and Manx is the use of the negative particle cha(n) in place of the Munster and Connacht n\u00ed. Though southern Donegal Irish tends to use n\u00ed more than cha(n), cha(n) has almost ousted n\u00ed in northernmost dialects (e.g. Rosguill and Tory Island), though even in these areas n\u00edl \"is not\" is more common than chan fhuil or cha bhfuil.[85][86] Another noticeable trait is the pronunciation of the first person singular verb ending -(a)im as -(e)am, also common to the Isle of Man and Scotland (Munster\/Connacht si\u00falaim \"I walk\", Ulster si\u00falam).  Down to the early 19th century and even later, Irish was spoken in all twelve counties of Leinster. The evidence furnished by placenames, literary sources and recorded speech indicates that there was no Leinster dialect as such. Instead, the main dialect used in the province was represented by a broad central belt stretching from west Connacht eastwards to the Liffey estuary and southwards to Wexford, though with many local variations. Two smaller dialects were represented by the Ulster speech of counties Meath and Louth, which extended as far south as the Boyne valley, and a Munster dialect found in Kilkenny and south Laois.  The main dialect had characteristics which survive today only in the Irish of Connacht. It typically placed the stress on the first syllable of a word, and showed a preference (found in placenames) for the pronunciation \u27e8cr\u27e9 where the standard spelling is \u27e8cn\u27e9. The word cnoc (hill) would therefore be pronounced croc. Examples are the placenames Crooksling (Cnoc Slinne) in County Dublin and Crukeen (Cnoic\u00edn) in Carlow. East Leinster showed the same diphthongisation or vowel lengthening as in Munster and Connacht Irish in words like poll (hole), cill (monastery), coill (wood), ceann (head), cam (crooked) and dream (crowd). A feature of the dialect was the pronunciation of \u27e8ao\u27e9, which generally became [e\u02d0] in east Leinster (as in Munster), and [i\u02d0] in the west (as in Connacht).[87]  Early evidence regarding colloquial Irish in east Leinster is found in The Fyrst Boke of the Introduction of Knowledge (1547), by the English physician and traveller Andrew Borde.[88] The illustrative phrases he uses include the following:  The Pale (An Ph\u00e1il) was an area around late medieval Dublin under the control of the English government. By the late 15th century it consisted of an area along the coast from Dalkey, south of Dublin, to the garrison town of Dundalk, with an inland boundary encompassing Naas and Leixlip in the Earldom of Kildare and Trim and Kells in County Meath to the north. In this area of \"Englyshe tunge\" English had never actually been a dominant language \u2013 and was moreover a relatively late comer; the first colonisers were Normans who spoke Norman French, and before these Norse. The Irish language had always been the language of the bulk of the population. An English official remarked of the Pale in 1515 that \"all the common people of the said half counties that obeyeth the King's laws, for the most part be of Irish birth, of Irish habit and of Irish language\".[89]  With the strengthening of English cultural and political control, language change began to occur but this did not become clearly evident until the 18th century. Even then, in the decennial period 1771\u201381, the percentage of Irish speakers in Meath was at least 41%. By 1851 this had fallen to less than 3%.[90]  English expanded strongly in Leinster in the 18th century but Irish speakers were still numerous. In the decennial period 1771\u201381 certain counties had estimated percentages of Irish speakers as follows (though the estimates are likely to be too low):[90]  The language saw its most rapid initial decline in counties Dublin, Kildare, Laois, Wexford, and Wicklow. In recent years, County Wicklow has been noted as having the lowest percentage of Irish speakers of any county in Ireland, with only 0.14% of its population claiming to have passable knowledge of the language.[91] The proportion of Irish-speaking children in Leinster went down as follows: 17% in the 1700s, 11% in the 1800s, 3% in the 1830s, and virtually none in the 1860s.[92] The Irish census of 1851 showed that there were still a number of older speakers in County Dublin.[90] Sound recordings were made between 1928 and 1931 of some of the last speakers in Omeath, County Louth (now available in digital form).[93] The last known traditional native speaker in Omeath, and in Leinster as a whole, was Annie O'Hanlon (n\u00e9e Dobbin), who died in 1960.[28] Her dialect was, in fact, a branch of the Irish of south-east Ulster.[94]  Irish was spoken as a community language in Irish towns and cities down to the 19th century. In the 16th and 17th centuries it was widespread even in Dublin and the Pale. The English administrator William Gerard (1518\u20131581) commented as follows: \"All English, and the most part with delight, even in Dublin, speak Irish,\"[95] while the Old English historian Richard Stanihurst (1547\u20131618) lamented that \"When their posterity became not altogether so wary in keeping, as their ancestors were valiant in conquering, the Irish language was free dennized in the English Pale: this canker took such deep root, as the body that before was whole and sound, was by little and little festered, and in manner wholly putrified\".[96]  The Irish of Dublin, situated as it was between the east Ulster dialect of Meath and Louth to the north and the Leinster-Connacht dialect further south, may have reflected the characteristics of both in phonology and grammar. In County Dublin itself the general rule was to place the stress on the initial vowel of words. With time it appears that the forms of the dative case took over the other case endings in the plural (a tendency found to a lesser extent in other dialects). In a letter written in Dublin in 1691 we find such examples as the following: gn\u00f3thuimh (accusative case, the standard form being gn\u00f3tha\u00ed), t\u00edorthuibh (accusative case, the standard form being t\u00edortha) and leithsc\u00e9alaibh (genitive case, the standard form being leithsc\u00e9alta).[97]  English authorities of the Cromwellian period, aware that Irish was widely spoken in Dublin, arranged for its official use. In 1655 several local dignitaries were ordered to oversee a lecture in Irish to be given in Dublin. In March 1656 a converted Catholic priest, S\u00e9amas Corcy, was appointed to preach in Irish at Bride's parish every Sunday, and was also ordered to preach at Drogheda and Athy.[98] In 1657 the English colonists in Dublin presented a petition to the Municipal Council complaining that in Dublin itself \"there is Irish commonly and usually spoken\".[99]  There is contemporary evidence of the use of Irish in other urban areas at the time. In 1657 it was found necessary to have an Oath of Abjuration (rejecting the authority of the Pope) read in Irish in Cork so that people could understand it.[100]  Irish was sufficiently strong in early 18th century Dublin to be the language of a coterie of poets and scribes led by Se\u00e1n and Tadhg \u00d3 Neachtain, both poets of note.[101] Scribal activity in Irish persisted in Dublin right through the 18th century. An outstanding example was Muiris \u00d3 Gorm\u00e1in (Maurice Gorman), a prolific producer of manuscripts who advertised his services (in English) in Faulkner's Dublin Journal.[102] There were still an appreciable number of Irish speakers in County Dublin at the time of the 1851 census.[103]  In other urban centres the descendants of medieval Anglo-Norman settlers, the so-called Old English, were Irish-speaking or bilingual by the 16th century.[104] The English administrator and traveller Fynes Moryson, writing in the last years of the 16th century, said that \"the English Irish and the very citizens (excepting those of Dublin where the lord deputy resides) though they could speak English as well as we, yet commonly speak Irish among themselves, and were hardly induced by our familiar conversation to speak English with us\".[105] In Galway, a city dominated by Old English merchants and loyal to the Crown up to the Irish Confederate Wars (1641\u20131653), the use of the Irish language had already provoked the passing of an Act of Henry VIII (1536), ordaining as follows:  The demise of native cultural institutions in the seventeenth century saw the social prestige of Irish diminish, and the gradual Anglicisation of the middle classes followed.[107] The census of 1851 showed, however, that the towns and cities of Munster still had significant Irish-speaking populations. Much earlier, in 1819, James McQuige, a veteran Methodist lay preacher in Irish, wrote: \"In some of the largest southern towns, Cork, Kinsale and even the Protestant town of Bandon, provisions are sold in the markets, and cried in the streets, in Irish\".[108] Irish speakers constituted over 40% of the population of Cork even in 1851.[109]  The late 18th and 19th centuries saw a reduction in the number of Dublin's Irish speakers, in keeping with the trend elsewhere. This continued until the end of the 19th century, when the Gaelic revival saw the creation of a strong Irish\u2013speaking network, typically united by various branches of the Conradh na Gaeilge, and accompanied by renewed literary activity.[110] By the 1930s Dublin had a lively literary life in Irish.[111]  Urban Irish has been the beneficiary, from the last decades of the 20th century, of a rapidly expanding system of Gaelscoileanna, teaching entirely through Irish. As of 2019 there are 37 such primary schools in Dublin alone.[112]  It has been suggested that Ireland's towns and cities are acquiring a critical mass of Irish speakers, reflected in the expansion of Irish language media.[113] Many are younger speakers who, after encountering Irish at school, made an effort to acquire fluency, while others have been educated through Irish and some have been raised with Irish. Those from an English-speaking background are now often described as nuachainteoir\u00ed (\"new speakers\") and use whatever opportunities are available (festivals, \"pop-up\" events) to practise or improve their Irish.[114]  It has been suggested that the comparative standard is still the Irish of the Gaeltacht,[115] but other evidence suggests that young urban speakers take pride in having their own distinctive variety of the language.[116] A comparison of traditional Irish and urban Irish shows that the distinction between broad and slender consonants, which is fundamental to Irish phonology and grammar, is not fully or consistently observed in urban Irish. This and other changes make it possible that urban Irish will become a new dialect or even, over a long period, develop into a creole (i.e. a new language) distinct from Gaeltacht Irish.[113] It has also been argued that there is a certain elitism among Irish speakers, with most respect being given to the Irish of native Gaeltacht speakers and with \"Dublin\" (i.e. urban) Irish being under-represented in the media.[117] This, however, is paralleled by a failure among some urban Irish speakers to acknowledge grammatical and phonological features essential to the structure of the language.[113]  There is no single official standard for pronouncing the Irish language. Certain dictionaries, such as Focl\u00f3ir P\u00f3ca, provide a single pronunciation. Online dictionaries such as Focl\u00f3ir B\u00e9arla-Gaeilge[118] provide audio files in the three major dialects. The differences between dialects are considerable, and have led to recurrent difficulties in conceptualising a \"standard Irish.\" In recent decades contacts between speakers of different dialects have become more frequent and the differences between the dialects are less noticeable.[119]  An Caighde\u00e1n Oifigi\u00fail (\"The Official Standard\"), often shortened to An Caighde\u00e1n, is a standard for the spelling and grammar of written Irish, developed and used by the Irish government. Its rules are followed by most schools in Ireland, though schools in and near Irish-speaking regions also use the local dialect. It was published by the translation department of D\u00e1il \u00c9ireann in 1953[120] and updated in 2012[121] and 2017.  In pronunciation, Irish most closely resembles its nearest relatives, Scottish Gaelic and Manx. One notable feature is that consonants (except \/h\/) come in pairs, one \"broad\" (velarised, pronounced with the back of the tongue pulled back towards the soft palate) and one \"slender\" (palatalised, pronounced with the middle of the tongue pushed up towards the hard palate). While broad\u2013slender pairs are not unique to Irish (being found, for example, in Russian), in Irish they have a grammatical function.  The diphthongs of Irish are \/i\u0259, u\u0259, \u0259i, \u0259u\/.  Irish is a fusional, VSO, nominative-accusative language. It is neither verb nor satellite framed, and makes liberal use of deictic verbs.  Nouns decline for 3 numbers: singular, dual (only in conjunction with the number dh\u00e1 \"two\"), plural; 2 genders: masculine, feminine; and 4 cases: nomino-accusative (ainmneach), vocative (gairmeach), genitive (ginideach), and prepositional-locative (tabharthach), with fossilised traces of the older accusative (cusp\u00f3ireach). Adjectives agree with nouns in number, gender, and case. Adjectives generally follow nouns, though some precede or prefix nouns. Demonstrative adjectives have proximal, medial, and distal forms. The prepositional-locative case is called the dative by convention, though it originates in the Proto-Celtic ablative.  Verbs conjugate for 3 tenses: past, present, future; 2 aspects: perfective, imperfective; 2 numbers: singular, plural; 4 moods: indicative, subjunctive, conditional, imperative; 2 relative forms, the present and future relative; and in some verbs, independent and dependent forms. Verbs conjugate for 3 persons and an impersonal form which is actor-free; the 3rd person singular acts as a person-free personal form that can be followed or otherwise refer to any person or number.  There are two verbs for \"to be\", one for inherent qualities with only two forms, is \"present\" and ba \"past\" and \"conditional\", and one for transient qualities, with a full complement of forms except for the verbal adjective. The two verbs share the one verbal noun.  Irish verb formation employs a mixed system during conjugation, with both analytic and synthetic methods employed depending on tense, number, mood and person. For example, in the official standard, present tense verbs have conjugated forms only in the 1st person and autonomous forms (i.e. molaim 'I praise', molaimid 'we praise', moltar 'is praised, one praises' ), whereas all other persons are conveyed analytically (i.e. molann s\u00e9 'he praises', molann sibh 'you pl. praise'). The ratio of analytic to synthetic forms in a given verb paradigm varies between the various tenses and moods. The conditional, imperative and past habitual forms prefer synthetic forms in most persons and numbers, whereas the subjunctive, past, future and present forms prefer mostly analytical forms.  The meaning of the passive voice is largely conveyed through the autonomous verb form, however there also exist other structures analogous to the passival and resultative constructions. There are also a number of preverbal particles marking the negative, interrogative, subjunctive, relative clauses, etc. There is a verbal noun and verbal adjective. Verb forms are highly regular, many grammars recognise only 11 irregular verbs.  Prepositions inflect for person and number. Different prepositions govern different cases. In Old and Middle Irish, prepositions governed different cases depending on intended semantics; this has disappeared in Modern Irish except in fossilised form.  Irish has no verb to express having; instead, the word ag (\"at\", etc.) is used in conjunction with the transient \"be\" verb bheith:  Numerals have three forms: abstract, general and ordinal. The numbers from 2 to 10 (and these in combination with higher numbers) are rarely used for people, numeral nominals being used instead:  Irish has both decimal and vigesimal systems:  10: a deich  20: fiche  30: vigesimal \u2013 a deich is fiche; decimal \u2013 tr\u00edocha  40: v. daichead, d\u00e1 fhichead; d. ceathracha  50: v. a deich is daichead; d. caoga (also: leathch\u00e9ad \"half-hundred\")  60: v. tr\u00ed fichid; d. seasca  70: v. a deich is tr\u00ed fichid; d. seacht\u00f3  80: v. cheithre fichid; d. ocht\u00f3  90: v. a deich is cheithre fichid; d. n\u00f3cha  100: v. c\u00faig fichid; d. c\u00e9ad  A number such as 35 has various forms:  a c\u00faigd\u00e9ag is fichid \"15 and 20\"  a c\u00faig is tr\u00edocha \"5 and 30\"  a c\u00faigd\u00e9ag ar fhichid \"15 on 20\"  a c\u00faig ar thr\u00edochaid \"5 on 30\"  a c\u00faigd\u00e9ag fichead \"15 of 20 (genitive)\"  a c\u00faig tr\u00edochad \"5 of 30 (genitive)\"  fiche 's a c\u00faigd\u00e9ag \"20 and 15\"  tr\u00edocha 's a c\u00faig \"30 and 5\"  The latter is most commonly used in mathematics.  In Irish, there are two classes of initial consonant mutations, which express grammatical relationship and meaning in verbs, nouns and adjectives:  Mutations are often the only way to distinguish grammatical forms. For example, the only non-contextual way to distinguish possessive pronouns \"her\", \"his\" and \"their\", is through initial mutations since all meanings are represented by the same word a.  Due to initial mutation, prefixes, clitics, suffixes, root inflection, ending morphology, elision, sandhi, epenthesis, and assimilation; the beginning, core, and end of words can each change radically and even simultaneously depending on context.  A native writing system, Ogham, was used to write Primitive Irish and Old Irish until Latin script was introduced in the 5th century CE.[123] Since the introduction of Latin script, the main typeface used to write Irish was Gaelic type until it was replaced by Roman type during the mid-20th century.  The traditional Irish alphabet (\u00e1ib\u00edtir) consists of 18 letters: \u27e8a, b, c, d, e, f, g, h, i, l, m, n, o, p, r, s, t, u\u27e9; it does not contain \u27e8j, k, q, v, w, x, y, z\u27e9.[124][125] However contemporary Irish uses the full Latin alphabet, with the previously unused letter used in modern loanwords; \u27e8v\u27e9 occurs in a small number of (mainly onomatopoeic) native words and colloquialisms.  Vowels may be accented with an acute accent (\u27e8\u00e1, \u00e9, \u00ed, \u00f3, \u00fa\u27e9; Irish and Hiberno-English: (s\u00edneadh) fada \"long (sign)\"), but it is ignored for purposes of alphabetisation.[126] It is used, among other conventions, to mark long vowels, e.g. \u27e8e\u27e9 is \/\u025b\/ and \u27e8\u00e9\u27e9 is \/e\u02d0\/.  The overdot (ponc s\u00e9imhithe \"dot of lenition\") was used in traditional orthography to indicate lenition; An Caighde\u00e1n uses a following \u27e8h\u27e9 for this purpose, i.e. the dotted letters (litreacha buailte \"struck letters\") \u27e8\u1e03, \u010b, \u1e0b, \u1e1f, \u0121, \u1e41, \u1e57, \u1e61, \u1e6b\u27e9 are equivalent to \u27e8bh, ch, dh, fh, gh, mh, ph, sh, th\u27e9.  The use of Gaelic type and the overdot today is restricted to when a traditional style is consciously being used, e.g. \u00d3glai\u0121 na h-\u00c9ireann on the Irish Defence Forces cap badge (see above). Extending the use of the overdot to Roman type would theoretically have the advantage of making Irish texts significantly shorter, e.g. gheobhaidh sibh \"you (pl.) will get\" would become \u0121eo\u1e03ai\u1e0b si\u1e03.  Around the time of the Second World War, S\u00e9amas Dalt\u00fan, in charge of Rann\u00f3g an Aistri\u00fach\u00e1in\u00a0[ga] (The Translation Department of the Irish government), issued his own guidelines about how to standardise Irish spelling and grammar. This de facto standard was subsequently approved by the State and developed into an Caighde\u00e1n Oifigi\u00fail, which simplified and standardised the orthography and grammar by removing inter-dialectal silent letters and simplifying vowel combinations. Where multiple versions existed in different dialects for the same word, one was selected, for example:  An Caighde\u00e1n does not reflect all dialects to the same degree, e.g. cruaidh \/k\u027e\u02e0u\u0259j\/ \"hard\", leabaidh \/\u02c8l\u0320\u02b2ab\u02e0\u0259j\/ \"bed\", and tr\u00e1igh \/t\u032a\u02e0\u027e\u02e0a\u02d0j\/ \"beach\" were standardised as crua, leaba, and tr\u00e1 despite the reformed spellings only reflecting South Connacht realisations [k\u027e\u02e0u\u0259], [\u02c8l\u0320\u02b2ab\u02e0\u0259], and [t\u032a\u02e0\u027e\u02e0a\u02d0], failing to represent the other dialectal realisations [k\u027e\u02e0ui], [\u02c8l\u0320\u02b2ab\u02e0i], and [t\u032a\u02e0\u027e\u02e0a\u02d0i] (in Mayo and Ulster) or [k\u027e\u02e0u\u0259\u025f], [\u02c8l\u0320\u02b2ab\u02e0\u0259\u025f], and [t\u032a\u02e0\u027e\u02e0a\u02d0\u025f] (in Munster), which were previously represented by the pre-reformed spellings.[127] For this reason, the pre-reform spellings are used by some speakers to reflect the dialectal pronunciations.  Other examples include the genitive of bia \"food\" (\/b\u02b2i\u0259\/; pre-reform biadh) and saol \"life, world\" (\/s\u02e0e\u02d0l\u02e0\/; pre-reform saoghal), realised [b\u02b2i\u02d0\u025f] and [s\u02e0e\u02d0l\u02b2] in Munster, reflecting the pre-Caighde\u00e1n spellings b\u00eddh and saoghail, which were standardised as bia and saoil despite not representing the Munster pronunciations.[128][129]  Article 1 of the Universal Declaration of Human Rights "},{"title":"Scotland","content":"  \u2013\u00a0in Europe\u00a0(green &\u00a0dark grey)\u2013\u00a0in the United Kingdom\u00a0(green) Scotland (Scots: Scotland; Scottish Gaelic: Alba) is a country that is part of the United Kingdom. It contains nearly one-third of the United Kingdom's land area, consisting of the northern part of the island of Great Britain and more than 790 adjacent islands, principally in the archipelagos of the Hebrides and the Northern Isles. To the south-east, Scotland has its only land border, which is 96 miles (154\u00a0km) long and shared with England; the country is surrounded by the Atlantic Ocean to the north and west, the North Sea to the north-east and east, and the Irish Sea to the south. The population in 2022 was 5,436,600 and accounts for 8% of the population of the UK.[10] Edinburgh is the capital and Glasgow is the largest of the cities of Scotland.  The Kingdom of Scotland emerged in the 9th century. In 1603, James VI inherited England and Ireland, forming a personal union of the three kingdoms. On 1 May 1707 Scotland and England combined to create the new Kingdom of Great Britain,[11][12] with the Parliament of Scotland subsumed into the Parliament of Great Britain. In 1999 a Scottish Parliament was re-established, and has devolved authority over many areas of domestic policy.[13] The country has a distinct legal system, educational system, and religious history from the rest of the UK, which have all contributed to the continuation of Scottish culture and national identity.[14] Scottish English and Scots are the most widely spoken languages in the country, existing on a dialect continuum with each other.[15] Scottish Gaelic speakers can be found all over Scotland, however the language is largely spoken natively by communities within the Hebrides.[16] The number of Gaelic speakers numbers less than 2% of the total population, though state-sponsored revitalisation attempts have led to a growing community of second language speakers.[17]   The mainland of Scotland is broadly divided into three regions: the Highlands, a mountainous region in the north and north-west; the Lowlands, a flatter plain across the centre of the country; and the Southern Uplands, a hilly region along the southern border. The Highlands are the most mountainous region of the British Isles and contain its highest peak, Ben Nevis, at 4,413 feet (1,345\u00a0m).[10] The region also contains many lakes, called lochs; the term is also applied to the many saltwater inlets along the country's deeply indented western coastline. The geography of the many islands is varied. Some, such as Mull and Skye, are noted for their mountainous terrain, while the likes of Tiree and Coll are much flatter. Scotland comes from Scoti, the Latin name for the Gaels.[18] Philip Freeman has speculated on the likelihood of a group of raiders adopting a name from an Indo-European root, *skot, citing the parallel in Greek skotos (\u03c3\u03ba\u03cc\u03c4\u03bf\u03c2), meaning \"darkness, gloom\".[19] The Late Latin word Scotia (\"land of the Gaels\") was initially used to refer to Ireland,[20] and likewise in early Old English Scotland was used for Ireland.[21] By the 11th century at the latest, Scotia was being used to refer to (Gaelic-speaking) Scotland north of the River Forth, alongside Albania or Albany, both derived from the Gaelic Alba.[22] The use of the words Scots and Scotland to encompass all of what is now Scotland became common in the Late Middle Ages.[11]  Prehistoric Scotland, before the arrival of the Roman Empire, was culturally divergent.[23]  Repeated glaciations, which covered the entire land mass of modern Scotland, destroyed any traces of human habitation that may have existed before the Mesolithic period. It is believed the first post-glacial groups of hunter-gatherers arrived in Scotland around 12,800 years ago, as the ice sheet retreated after the last glaciation.[24] At the time, Scotland was covered in forests, had more bog-land, and the main form of transport was by water.[25]:\u200a9\u200a These settlers began building the first known permanent houses on Scottish soil around 9,500 years ago, and the first villages around 6,000 years ago. The well-preserved village of Skara Brae on the mainland of Orkney dates from this period. Neolithic habitation, burial, and ritual sites are particularly common and well preserved in the Northern Isles and Western Isles, where a lack of trees led to most structures being built of local stone.[26] Evidence of sophisticated pre-Christian belief systems is demonstrated by sites such as the Callanish Stones on Lewis and the Maes Howe on Orkney, which were built in the third millennium BC.[27]:\u200a38\u200a  The first written reference to Scotland was in 320 BC by Greek sailor Pytheas, who called the northern tip of Britain \"Orcas\", the source of the name of the Orkney islands.[25]:\u200a10\u200a  Most of modern Scotland was not incorporated into the Roman Empire, and Roman control over parts of the area fluctuated over a rather short period. The first Roman incursion into Scotland was in 79 AD, when Agricola invaded Scotland; he defeated a Caledonian army at the Battle of Mons Graupius in 83 AD.[25]:\u200a12\u200a After the Roman victory, Roman forts were briefly set along the Gask Ridge close to the Highland line, but by three years after the battle, the Roman armies had withdrawn to the Southern Uplands.[28] Remains of Roman forts established in the 1st century have been found as far north as the Moray Firth.[29] By the reign of the Roman emperor Trajan (r.\u200998\u2013117), Roman control had lapsed to Britain south of a line between the River Tyne and the Solway Firth.[30] Along this line, Trajan's successor Hadrian (r.\u2009117\u2013138) erected Hadrian's Wall in northern England[25]:\u200a12\u200a and the Limes Britannicus became the northern border of the Roman Empire.[31][32] The Roman influence on the southern part of the country was considerable, and they introduced Christianity to Scotland.[25]:\u200a13\u201314\u200a[27]:\u200a38\u200a  The Antonine Wall was built from 142 at the order of Hadrian's successor Antoninus Pius (r.\u2009138\u2013161), defending the Roman part of Scotland from the unadministered part of the island, north of a line between the Firth of Clyde and the Firth of Forth.[33] The Roman invasion of Caledonia 208\u2013210 was undertaken by emperors of the imperial Severan dynasty in response to the breaking of a treaty by the Caledonians in 197,[29] but permanent conquest of the whole of Great Britain was forestalled by Roman forces becoming bogged down in punishing guerrilla warfare and the death of the senior emperor Septimius Severus (r.\u2009193\u2013211) at Eboracum (York) after he was taken ill while on campaign. Although forts erected by the Roman army in the Severan campaign were placed near those established by Agricola and were clustered at the mouths of the glens in the Highlands, the Caledonians were again in revolt in 210\u2013211 and these were overrun.[29]  To the Roman historians Tacitus and Cassius Dio, the Scottish Highlands and the area north of the River Forth was called Caledonia.[29] According to Cassius Dio, the inhabitants of Caledonia were the Caledonians and the Maeatae.[29] Other ancient authors used the adjective \"Caledonian\" to mean anywhere in northern or inland Britain, often mentioning the region's people and animals, its cold climate, its pearls, and a noteworthy region of wooded hills (Latin: saltus) which the 2nd century AD Roman philosopher Ptolemy, in his Geography, described as being south-west of the Beauly Firth.[29] The name Caledonia is echoed in the place names of Dunkeld, Rohallion, and Schiehallion.[29]  The Great Conspiracy constituted a seemingly coordinated invasion against Roman rule in Britain in the later 4th century, which included the participation of the Gaelic Scoti and the Caledonians, who were then known as Picts by the Romans. This was defeated by the comes Theodosius; but Roman military government was withdrawn from the island altogether by the early 5th century, resulting in the Anglo-Saxon settlement of Britain and the immigration of the Saxons to southeastern Scotland and the rest of eastern Great Britain.[30]  Beginning in the sixth century, the area that is now Scotland was divided into three areas: Pictland, a patchwork of small lordships in central Scotland;[25]:\u200a25\u201326\u200a the Anglo-Saxon Kingdom of Northumbria, which had conquered southeastern Scotland;[25]:\u200a18\u201320\u200a and D\u00e1l Riata, which included territory in western Scotland and northern Ireland, and spread Gaelic language and culture into Scotland.[34] These societies were based on the family unit and had sharp divisions in wealth, although the vast majority were poor and worked full-time in subsistence agriculture. The Picts kept slaves (mostly captured in war) through the ninth century.[25]:\u200a26\u201327\u200a  Gaelic influence over Pictland and Northumbria was facilitated by the large number of Gaelic-speaking clerics working as missionaries.[25]:\u200a23\u201324\u200a Operating in the sixth century on the island of Iona, Saint Columba was one of the earliest and best-known missionaries.[27]:\u200a39\u200a The Vikings began to raid Scotland in the eighth century. Although the raiders sought slaves and luxury items, their main motivation was to acquire land. The oldest Norse settlements were in northwest Scotland, but they eventually conquered many areas along the coast. Old Norse entirely displaced Pictish in the Northern Isles.[35]  In the ninth century, the Norse threat allowed a Gael named Kenneth I (Cin\u00e1ed mac Ailp\u00edn) to seize power over Pictland, establishing a royal dynasty to which the modern monarchs trace their lineage, and marking the beginning of the end of Pictish culture.[25]:\u200a31\u201332\u200a[36] The kingdom of Cin\u00e1ed and his descendants, called Alba, was Gaelic in character but existed on the same area as Pictland. By the end of the tenth century, the Pictish language went extinct as its speakers shifted to Gaelic.[25]:\u200a32\u201333\u200a From a base in eastern Scotland north of the River Forth and south of the River Spey, the kingdom expanded first southwards, into the former Northumbrian lands, and northwards into Moray.[25]:\u200a34\u201335\u200a Around the turn of the millennium, there was a centralization in agricultural lands and the first towns began to be established.[25]:\u200a36\u201337\u200a  In the twelfth and thirteenth centuries, much of Scotland was under the control of a single ruler. Initially, Gaelic culture predominated, but immigrants from France, England and Flanders steadily created a more diverse society, with the Gaelic language starting to be replaced by Scots; and a modern nation-state emerged from this. At the end of this period, war against England started the growth of a Scottish national consciousness.[37]:\u200a37-39\u200a[38]:\u200ach 1\u200a David I (1124\u20131153) and his successors centralised royal power[37]:\u200a41\u201342\u200a and united mainland Scotland, capturing regions such as Moray, Galloway, and Caithness, although he could not extend his power over the Hebrides, which had been ruled by various Scottish clans following the death of Somerled in 1164.[37]:\u200a48\u201349\u200a In 1266, Scotland fought the short but consequential Scottish-Norwegian War which saw the reclamation of the Hebrides after the strong defeat of King Haakon IV and his forces at the Battle of Largs.[39] Up until that point, the Hebrides had been under Norwegian Viking control for roughly 400 years and had developed a distinctive Norse\u2013Gaelic culture that saw many Old Norse loanwords enter the Scottish Gaelic spoken by islanders, and through successive generations the Norse would become almost completely assimilated into Gaelic culture and the Scottish clan system. After the conflict, Scotland had to affirm Norwegian sovereignty of the Northern Isles, but they were later integrated into Scotland in the 15th century. Scandinavian culture in the form of the Norn language survived for a lot longer than in the Hebrides, and would strongly influence the local Scots dialect on Shetland and Orkney.[40] Later, a system of feudalism was consolidated, with both Anglo-Norman incomers and native Gaelic chieftains being granted land in exchange for serving the king.[37]:\u200a53\u201354\u200a The relationship with England was complex during this period: Scottish kings tried several times, sometimes with success, to exploit English political turmoil, followed by the longest period of peace between Scotland and England in the mediaeval period: from 1217\u20131296.[37]:\u200a45-46\u200a  The death of Alexander III in March 1286 broke the succession line of Scotland's kings. Edward I of England arbitrated between various claimants for the Scottish crown. In return for surrendering Scotland's nominal independence, John Balliol was pronounced king in 1292.[37]:\u200a47\u200a[41] In 1294, Balliol and other Scottish lords refused Edward's demands to serve in his army against the French. Scotland and France sealed a treaty on 23 October 1295, known as the Auld Alliance. War ensued, and John was deposed by Edward who took personal control of Scotland. Andrew Moray and William Wallace initially emerged as the principal leaders of the resistance to English rule in the Wars of Scottish Independence,[42] until Robert the Bruce was crowned king of Scotland in 1306.[43] Victory at the Battle of Bannockburn in 1314 proved the Scots had regained control of their kingdom. In 1320 the world's first documented declaration of independence, the Declaration of Arbroath, won the support of Pope John XXII, leading to the legal recognition of Scottish sovereignty by the English Crown. [44]:\u200a70,\u200a72\u200a  A civil war between the Bruce dynasty and their long-term rivals of the House of Comyn and House of Balliol lasted until the middle of the 14th century. Although the Bruce faction was successful, David II's lack of an heir allowed his half-nephew Robert II, the Lord High Steward of Scotland, to come to the throne and establish the House of Stewart.[44]:\u200a77\u200a The Stewarts ruled Scotland for the remainder of the Middle Ages. The country they ruled experienced greater prosperity from the end of the 14th century through the Scottish Renaissance to the Reformation,[45]:\u200a93\u200a despite the effects of the Black Death in 1349[44]:\u200a76\u200a and increasing division between Highlands and Lowlands.[44]:\u200a78\u200a Multiple truces reduced warfare on the southern border.[44]:\u200a76,\u200a83\u200a  The Treaty of Perpetual Peace was signed in 1502 by James IV of Scotland and Henry VII of England. James married Henry's daughter, Margaret Tudor.[46] James invaded England in support of France under the terms of the Auld Alliance and became the last monarch in Great Britain to die in battle, at Flodden in 1513.[47] The war with England during the minority years of Mary, Queen of Scots between 1543 and 1551 is known as the Rough Wooing.[48] In 1560, the Treaty of Edinburgh brought an end to the Siege of Leith and recognized the Protestant Elizabeth I as Queen of England.[45]:\u200a112\u200a The Parliament of Scotland met and immediately adopted the Scots Confession, which signalled the Scottish Reformation's sharp break from papal authority and Roman Catholic teaching.[27]:\u200a44\u200a The Catholic Mary, Queen of Scots, was forced to abdicate in 1567.[49]  In 1603, James VI, King of Scots inherited the thrones of the Kingdom of England and the Kingdom of Ireland in the Union of the Crowns, and moved to London.[50] This was a personal union as despite having the same monarch the kingdoms retained their separate parliaments, laws and other institutions. The first Union Jack was designed at James's behest, to be flown in addition to the St Andrew's Cross on Scots vessels at sea. James VI and I intended to create a single kingdom of Great Britain, but was thwarted in his attempt to do so by the Parliament of England, which supported the wrecking proposal that a full legal union be sought instead, a proposal to which the Scots Parliament would not assent, causing the king to withdraw the plan.[51]  Except for a short period under the Protectorate, Scotland remained a separate state in the 17th century, but there was considerable conflict between the crown and the Covenanters over the form of church government.[52]:\u200a124\u200a The military was strengthened, allowing the imposition of royal authority on the western Highland clans. The 1609 Statutes of Iona compelled the cultural integration of Hebridean clan leaders.[53]:\u200a37\u201340\u200a In 1641 and again in 1643, the Parliament of Scotland unsuccessfully sought a union with England which was \"federative\" and not \"incorporating\", in which Scotland would retain a separate parliament.[54] The issue of union split the parliament in 1648.[54]  After the execution of the Scottish king at Whitehall in 1649, amid the Wars of the Three Kingdoms and its events in Scotland, Oliver Cromwell, the victorious Lord Protector, imposed the British Isles' first written constitution \u2013 the Instrument of Government \u2013 on Scotland in 1652 as part of the republican Commonwealth of England, Scotland, and Ireland.[54] The Protectorate Parliament was the first Westminster parliament to include representatives nominally from Scotland. The monarchy of the House of Stuart was resumed with the Restoration in Scotland in 1660. The Parliament of Scotland sought a commercial union with England in 1664; the proposal was rejected in 1668.[54] In 1670 the Parliament of England rejected a proposed political union with Scotland.[54] English proposals along the same lines were abandoned in 1674 and in 1685.[54] The Scots Parliament rejected proposals for a political union with England in 1689.[54] Jacobitism, the political support for the exiled Catholic Stuart dynasty, remained a threat to the security of the British state under the Protestant House of Orange and the succeeding House of Hanover until the defeat of the Jacobite rising of 1745.[54] In 1698, the Company of Scotland attempted a project to secure a trading colony on the Isthmus of Panama. Almost every Scottish landowner who had money to spare is said to have invested in the Darien scheme.[55][56]  After another proposal from the English House of Lords was rejected in 1695, and a further Lords motion was voted down in the House of Commons in 1700, the Parliament of Scotland again rejected union in 1702.[54] The failure of the Darien Scheme bankrupted the landowners who had invested, though not the burghs. Nevertheless, the nobles' bankruptcy, along with the threat of an English invasion, played a leading role in convincing the Scots elite to back a union with England.[55][56] On 22 July 1706, the Treaty of Union was agreed between representatives of the Scots Parliament and the Parliament of England. The following year, twin Acts of Union were passed by both parliaments to create the united Kingdom of Great Britain with effect from 1 May 1707[57] with popular opposition and anti-union riots in Edinburgh, Glasgow, and elsewhere.[58][59] The union also created the Parliament of Great Britain, which succeeded both the Parliament of Scotland and the Parliament of England, which rejected proposals from the Parliament of Ireland that the third kingdom be incorporated in the union.[54]  With trade tariffs with England abolished, trade blossomed, especially with Colonial America. The clippers belonging to the Glasgow Tobacco Lords were the fastest ships on the route to Virginia. Until the American War of Independence in 1776, Glasgow was the world's premier tobacco port, dominating world trade.[60] The disparity between the wealth of the merchant classes of the Scottish Lowlands and the ancient clans of the Scottish Highlands grew, amplifying centuries of division.  The deposed Jacobite Stuart claimants had remained popular in the Highlands and north-east, particularly among non-Presbyterians, including Roman Catholics and Episcopalian Protestants. Two major Jacobite risings launched in 1715 and 1745 failed to remove the House of Hanover from the British throne. The threat of the Jacobite movement to the United Kingdom and its monarchs effectively ended at the Battle of Culloden, Great Britain's last pitched battle.  In the Highlands, clan chiefs gradually started to think of themselves more as commercial landlords than leaders of their people. These social and economic changes included the first phase of the Highland Clearances and, ultimately, the demise of clanship.[61]:\u200a32\u201353,\u200apassim\u200a  The Scottish Enlightenment and the Industrial Revolution turned Scotland into an intellectual, commercial and industrial powerhouse[62] \u2014 so much so Voltaire said \"We look to Scotland for all our ideas of civilisation.\"[63] With the demise of Jacobitism and the advent of the Union, thousands of Scots, mainly Lowlanders, took up numerous positions of power in politics, civil service, the army and navy, trade, economics, colonial enterprises and other areas across the nascent British Empire. Historian Neil Davidson notes \"after 1746 there was an entirely new level of participation by Scots in political life, particularly outside Scotland.\" Davidson also states \"far from being 'peripheral' to the British economy, Scotland \u2013 or more precisely, the Lowlands \u2013 lay at its core.\"[64]  The Scottish Reform Act 1832 increased the number of Scottish MPs and widened the franchise to include more of the middle classes.[65] From the mid-century, there were increasing calls for Home Rule for Scotland and the post of Secretary of State for Scotland was revived.[66] Towards the end of the century Prime Ministers of Scottish descent included William Gladstone,[67] and the Earl of Rosebery.[68] In the late 19th century the growing importance of the working classes was marked by Keir Hardie's success in the Mid Lanarkshire by-election, 1888, leading to the foundation of the Scottish Labour Party, which was absorbed into the Independent Labour Party in 1895, with Hardie as its first leader.[69] Glasgow became one of the largest cities in the world and known as \"the Second City of the Empire\" after London.[70] After 1860, the Clydeside shipyards specialised in steamships made of iron (after 1870, made of steel), which rapidly replaced the wooden sailing vessels of both the merchant fleets and the battle fleets of the world. It became the world's pre-eminent shipbuilding centre.[71] The industrial developments, while they brought work and wealth, were so rapid that housing, town planning, and provision for public health did not keep pace with them, and for a time living conditions in some of the towns and cities were notoriously bad, with overcrowding, high infant mortality, and growing rates of tuberculosis.[72]  While the Scottish Enlightenment is traditionally considered to have concluded toward the end of the 18th century,[73] disproportionately large Scottish contributions to British science and letters continued for another 50 years or more, thanks to such figures as the physicists James Clerk Maxwell and Lord Kelvin, and the engineers and inventors James Watt and William Murdoch, whose work was critical to the technological developments of the Industrial Revolution throughout Britain.[74] In literature, the most successful figure of the mid-19th century was Walter Scott. His first prose work, Waverley in 1814, is often called the first historical novel.[75] It launched a highly successful career that probably more than any other helped define and popularise Scottish cultural identity.[76] In the late 19th century, a number of Scottish-born authors achieved international reputations, such as Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald.[77] Scotland also played a major part in the development of art and architecture. The Glasgow School, which developed in the late 19th century, and flourished in the early 20th century, produced a distinctive blend of influences including the Celtic Revival the Arts and Crafts movement, and Japonism, which found favour throughout the modern art world of continental Europe and helped define the Art Nouveau style. Proponents included architect and artist Charles Rennie Mackintosh.[78]  Scotland played a major role in the British effort in the First World War. It especially provided manpower, ships, machinery, fish and money.[79] With a population of 4.8\u00a0million in 1911, Scotland sent over half a million men to the war, of whom over a quarter died in combat or from disease, and 150,000 were seriously wounded.[80] Field Marshal Sir Douglas Haig was Britain's commander on the Western Front. The war saw the emergence of a radical movement called \"Red Clydeside\" led by militant trades unionists. Formerly a Liberal stronghold, the industrial districts switched to Labour by 1922, with a base among the Irish Catholic working-class districts. Women were especially active in building neighbourhood solidarity on housing issues. The \"Reds\" operated within the Labour Party with little influence in Parliament and the mood changed to passive despair by the late 1920s.[81]  During the Second World War, Scotland was targeted by Nazi Germany largely due to its factories, shipyards, and coal mines.[82] Cities such as Glasgow and Edinburgh were targeted by German bombers, as were smaller towns mostly located in the central belt of the country.[82] Perhaps the most significant air raid in Scotland was the Clydebank Blitz of March 1941, which intended to destroy naval shipbuilding in the area.[83] 528 people were killed and 4,000 homes totally destroyed.[83] Perhaps Scotland's most unusual wartime episode occurred in 1941 when Rudolf Hess flew to Renfrewshire, possibly intending to broker a peace deal through the Duke of Hamilton.[84] Before his departure from Germany, Hess had given his adjutant, Karlheinz Pintsch, a letter addressed to Adolf Hitler that detailed his intentions to open peace negotiations with the British. Pintsch delivered the letter to Hitler at the Berghof around noon on 11 May.[85] Albert Speer later said Hitler described Hess's departure as one of the worst personal blows of his life, as he considered it a personal betrayal.[86] Hitler worried that his allies, Italy and Japan, would perceive Hess's act as an attempt by Hitler to secretly open peace negotiations with the British.  After 1945, Scotland's economic situation worsened due to overseas competition, inefficient industry, and industrial disputes.[87] Only in recent decades has the country enjoyed something of a cultural and economic renaissance. Economic factors contributing to this recovery included a resurgent financial services industry, electronics manufacturing, (see Silicon Glen),[88] and the North Sea oil and gas industry.[89] The introduction in 1989 by Margaret Thatcher's government of the Community Charge (widely known as the Poll Tax) one year before the rest of Great Britain,[90] contributed to a growing movement for Scottish control over domestic affairs.[91]  Following a referendum on devolution proposals in 1997, the Scotland Act 1998[92] was passed by the British Parliament, which established a devolved Scottish Parliament and Scottish Government with responsibility for most laws specific to Scotland.[93] The Scottish Parliament was reconvened in Edinburgh on 4 July 1999.[94] The first to hold the office of first minister of Scotland was Donald Dewar, who served until his sudden death in 2000.[95]  The Scottish Parliament Building at Holyrood opened in October 2004 after lengthy construction delays and running over budget.[96] The Scottish Parliament's form of proportional representation (the additional member system) resulted in no one party having an overall majority for the first three Scottish parliament elections.  The pro-independence Scottish National Party led by Alex Salmond achieved an overall majority in the 2011 election, winning 69 of the 129 seats available.[97] The success of the SNP in achieving a majority in the Scottish Parliament paved the way for the September 2014 referendum on Scottish independence. The majority voted against the proposition, with 55% voting no to independence.[98] More powers, particularly concerning taxation, were devolved to the Scottish Parliament after the referendum, following cross-party talks in the Smith Commission.  Since the 2014 referendum, events such as the UK leaving the European Union, despite a majority of voters in Scotland voting to remain a member, have led to calls for a second independence referendum. In 2022, the Lord Advocate Dorothy Bain argued the case for the Scottish Government to hold another referendum on the issue, with the Supreme Court later ruling against the argument.[99] Following the Supreme Court decision, the Scottish Government stated that it wished to make amendments to the Scotland Act 1998 that would allow a referendum to be held in 2023.[100]  The mainland of Scotland comprises the northern third of the land mass of the island of Great Britain, which lies off the northwest coast of Continental Europe. The total area is 30,977 square miles (80,231\u00a0km2) with a land area of 30,078 square miles (77,901\u00a0km2),[4] comparable to the size of the Czech Republic. Scotland's only land border is with England, and runs for 96 miles (154\u00a0km) between the basin of the River Tweed on the east coast and the Solway Firth in the west. The Atlantic Ocean borders the west coast and the North Sea is to the east. The island of Ireland lies only 13 miles (21\u00a0km) from the south-western peninsula of Kintyre;[101] Norway is 190 miles (305\u00a0km) to the northeast and the Faroe Islands, 168 miles (270\u00a0km) to the north.  The territorial extent of Scotland is generally that established by the 1237 Treaty of York between Scotland and the Kingdom of England[102] and the 1266 Treaty of Perth between Scotland and Norway.[12] Important exceptions include the Isle of Man, which having been lost to England in the 14th century is now a crown dependency outside of the United Kingdom; the island groups Orkney and Shetland, which were acquired from Norway in 1472;[103] and Berwick-upon-Tweed, lost to England in 1482  The geographical centre of Scotland lies a few miles from the village of Newtonmore in Badenoch.[104] Rising to 4,413 feet (1,345\u00a0m) above sea level, Scotland's highest point is the summit of Ben Nevis, in Lochaber, while Scotland's longest river, the River Tay, flows for a distance of 117 miles (188\u00a0km).[10]  The whole of Scotland was covered by ice sheets during the Pleistocene ice ages and the landscape is much affected by glaciation. From a geological perspective, the country has three main sub-divisions: the Highlands and Islands, the Central Lowlands, and the Southern Uplands.  The Highlands and Islands lie to the north and west of the Highland Boundary Fault, which runs from Arran to Stonehaven. This part of Scotland largely comprises ancient rocks from the Cambrian and Precambrian, which were uplifted during the later Caledonian orogeny. It is interspersed with igneous intrusions of a more recent age, remnants of which formed mountain massifs such as the Cairngorms and Skye Cuillins.[105] In north-eastern mainland Scotland weathering of rock that occurred before the Last Ice Age has shaped much of the landscape.[106]  A significant exception to the above are the fossil-bearing beds of Old Red Sandstones found principally along the Moray Firth coast. The Highlands are generally mountainous and the highest elevations in the British Isles are found here. Scotland has over 790 islands divided into four main groups: Shetland, Orkney, and the Inner Hebrides and Outer Hebrides. There are numerous bodies of freshwater including Loch Lomond and Loch Ness. Some parts of the coastline consist of machair, a low-lying dune pasture land.  The Central Lowlands is a rift valley mainly comprising Paleozoic formations. Many of these sediments have economic significance for it is here that the coal and iron-bearing rocks that fuelled Scotland's industrial revolution are found. This area has also experienced intense volcanism, Arthur's Seat in Edinburgh being the remnant of a once much larger volcano. This area is relatively low-lying, although even here hills such as the Ochils and Campsie Fells are rarely far from view.  The Southern Uplands is a range of hills almost 125 miles (200\u00a0km) long, interspersed with broad valleys. They lie south of a second fault line (the Southern Uplands fault) that runs from Girvan to Dunbar.[107][108][109] The geological foundations largely comprise Silurian deposits laid down some 400 to 500\u00a0million years ago. The high point of the Southern Uplands is Merrick with an elevation of 843\u00a0m (2,766\u00a0ft).[11][110][111][112] The Southern Uplands is home to Scotland's highest village, Wanlockhead (430\u00a0m or 1,411\u00a0ft above sea level).[109]  The climate of most of Scotland is temperate and oceanic, and tends to be very changeable. As it is warmed by the Gulf Stream from the Atlantic, it has much milder winters (but cooler, wetter summers) than areas on similar latitudes, such as Labrador, southern Scandinavia, the Moscow region in Russia, and the Kamchatka Peninsula on the opposite side of Eurasia. Temperatures are generally lower than in the rest of the UK, with the temperature of \u221227.2\u00a0\u00b0C (\u221217.0\u00a0\u00b0F) recorded at Braemar in the Grampian Mountains, on 11 February 1895, the coldest ever recorded anywhere in the UK.[113] Winter maxima average 6\u00a0\u00b0C (43\u00a0\u00b0F) in the Lowlands, with summer maxima averaging 18\u00a0\u00b0C (64\u00a0\u00b0F). The highest temperature recorded was 35.1\u00a0\u00b0C (95.2\u00a0\u00b0F) at Floors Castle, Scottish Borders on 19 July 2022.[114]  The west of Scotland is usually warmer than the east, owing to the influence of Atlantic ocean currents and the colder surface temperatures of the North Sea. Tiree, in the Inner Hebrides, is one of the sunniest places in the country: it had more than 300 hours of sunshine in May 1975.[115] Rainfall varies widely across Scotland. The western highlands of Scotland are the wettest, with annual rainfall in a few places exceeding 3,000\u00a0mm (120\u00a0in).[116] In comparison, much of lowland Scotland receives less than 800\u00a0mm (31\u00a0in) annually.[117] Heavy snowfall is not common in the lowlands, but becomes more common with altitude. Braemar has an average of 59 snow days per year,[118] while many coastal areas average fewer than 10 days of lying snow per year.[117]  Scotland's wildlife is typical of the north-west of Europe, although several of the larger mammals such as the lynx, brown bear, wolf, elk and walrus were hunted to extinction in historic times. There are important populations of seals and internationally significant nesting grounds for a variety of seabirds such as gannets.[119] The golden eagle is something of a national icon.[120]  On the high mountain tops, species including ptarmigan, mountain hare and stoat can be seen in their white colour phase during winter months.[121] Remnants of the native Scots pine forest exist[122] and within these areas the Scottish crossbill, the UK's only endemic bird species and vertebrate, can be found alongside capercaillie, Scottish wildcat, red squirrel and pine marten.[123][124][125] Various animals have been re-introduced, including the white-tailed eagle in 1975, the red kite in the 1980s,[126][127] and there have been experimental projects involving the beaver and wild boar. Today, much of the remaining native Caledonian Forest lies within the Cairngorms National Park and remnants of the forest remain at 84 locations across Scotland. On the west coast, remnants of ancient Celtic Rainforest remain, particularly on the Taynish peninsula in Argyll, these forests are particularly rare due to high rates of deforestation throughout Scottish history.[128][129]  The flora of the country is varied incorporating both deciduous and coniferous woodland as well as moorland and tundra species. Large-scale commercial tree planting and management of upland moorland habitat for the grazing of sheep and field sport activities like deer stalking and driven grouse shooting impacts the distribution of indigenous plants and animals.[130] The UK's tallest tree is a grand fir planted beside Loch Fyne, Argyll in the 1870s, and the Fortingall Yew may be 5,000 years old and is probably the oldest living thing in Europe.[131][132][133] Although the number of native vascular plants is low by world standards, Scotland's substantial bryophyte flora is of global importance.[134][135]  During the 1820s, many Scots migrated from Scotland to countries such as Australia, the United States and Canada, principally from the Highlands which remained poor in comparison to elsewhere in Scotland.[136] The Highlands was the only part of mainland Britain with a recurrent famine.[137] A small range of products were exported from the region, which had negligible industrial production and a continued population growth that tested the subsistence agriculture. These problems, and the desire to improve agriculture and profits were the driving forces of the ongoing Highland Clearances, in which many of the population of the Highlands suffered eviction as lands were enclosed, principally so that they could be used for sheep farming. The first phase of the clearances followed patterns of agricultural change throughout Britain. The second phase was driven by overpopulation, the Highland Potato Famine and the collapse of industries that had relied on the wartime economy of the Napoleonic Wars.[138]  The population of Scotland grew steadily in the 19th century, from 1,608,000 in the census of 1801 to 2,889,000 in 1851 and 4,472,000 in 1901.[139] Even with the development of industry, there were not enough good jobs. As a result, during the period 1841\u20131931, about 2 million Scots migrated to North America and Australia, and another 750,000 Scots relocated to England.[140] Caused by the advent of refrigeration and imports of lamb, mutton and wool from overseas, the 1870s brought with them a collapse of sheep prices and an abrupt halt in the previous sheep farming boom.[141]  In August 2012, the Scottish population reached an all-time high of 5.25\u00a0million people.[142] The reasons given were that, in Scotland, births were outnumbering the number of deaths, and immigrants were moving to Scotland from overseas. In 2011, 43,700 people moved from Wales, Northern Ireland or England to live in Scotland.[142] The most recent census in Scotland was conducted by the Scottish Government and the National Records of Scotland in March 2022.[143] The population of Scotland at the 2022 Census was 5,436,600, the highest ever,[144] beating the previous record of 5,295,400 at the 2011 Census. It was 5,062,011 at the 2001 Census.[145] An ONS estimate for mid-2021 was 5,480,000.[146] In the 2011 Census, 62% of Scotland's population stated their national identity as 'Scottish only', 18% as 'Scottish and British', 8% as 'British only', and 4% chose 'other identity only'.[147]  Throughout its history, Scotland has long had a tradition of migration from Scotland and immigration into Scotland. In 2021, the Scottish Government released figures showing that an estimated 41,000 people had immigrated from other international countries into Scotland, while an average of 22,100 people had migrated from Scotland.[148] Scottish Government data from 2002 shows that by 2021, there had been a sharp increase in immigration to Scotland, with 2002 estimates standing at 27,800 immigrants. While immigration had increased from 2002, migration from Scotland had dropped, with 2002 estimates standing at 26,200 people migrating from Scotland.[149]  Although Edinburgh is the capital of Scotland, the largest city is Glasgow, which has just over 584,000 inhabitants. The Greater Glasgow conurbation, with a population of almost 1.2\u00a0million, is home to nearly a quarter of Scotland's population.[150] The Central Belt is where most of the main towns and cities of Scotland are located, including Glasgow, Edinburgh, Dundee, and Perth. Scotland's only major city outside the Central Belt is Aberdeen. The Scottish Lowlands host 80% of the total population, where the Central Belt accounts for 3.5\u00a0million people.  In general, only the more accessible and larger islands remain inhabited. Currently, fewer than 90 remain inhabited. The Southern Uplands is essentially rural and dominated by agriculture and forestry.[151][152] Because of housing problems in Glasgow and Edinburgh, five new towns were designated between 1947 and 1966. They are East Kilbride, Glenrothes, Cumbernauld, Livingston, and Irvine.[153]  The largest council area by population is Glasgow City, with Highland being the largest in terms of geographical area.  Scotland has three officially recognised languages: English, Scots, and Scottish Gaelic.[155][156] Scottish Standard English, a variety of English as spoken in Scotland, is at one end of a bipolar linguistic continuum, with broad Scots at the other.[157] Scottish Standard English may have been influenced to varying degrees by Scots.[158][159] The 2011 census indicated that 63% of the population had \"no skills in Scots\".[160] Others speak Highland English. Gaelic is mostly spoken in the Western Isles, where a large proportion of people still speak it. Nationally, its use is confined to 1% of the population.[161] The number of Gaelic speakers in Scotland dropped from 250,000 in 1881 to 60,000 in 2008.[162]  Immigration since World War II has given Glasgow, Edinburgh, and Dundee small South Asian communities.[163] In 2011, there were an estimated 49,000 ethnically Pakistani people living in Scotland, making them the largest non-White ethnic group.[164] Since the enlargement of the European Union more people from Central and Eastern Europe have moved to Scotland, and the 2011 census indicated that 61,000 Poles live there.[164][165]  There are many more people with Scottish ancestry living abroad than the total population of Scotland. In the 2000 Census, 9.2\u00a0million Americans self-reported some degree of Scottish descent.[166] Ulster's Protestant population is mainly of lowland Scottish descent,[167] and it is estimated that there are more than 27\u00a0million descendants of the Scots-Irish migration now living in the US.[168][169] In Canada, the Scottish-Canadian community accounts for 4.7\u00a0million people.[170] About 20% of the original European settler population of New Zealand came from Scotland.[171]  Forms of Christianity have dominated religious life in what is now Scotland for more than 1,400 years.[172][173] In 2011 just over half (54%) of the Scottish population reported being a Christian while nearly 37% reported not having a religion.[174] Since the Scottish Reformation of 1560, the national church (the Church of Scotland, also known as The Kirk) has been Protestant in classification and Reformed in theology. Since 1689 it has had a Presbyterian system of church government independent from the state.[11] Its membership dropped just below 300,000 in 2020 (5% of the total population)[175][176][177] The Church operates a territorial parish structure, with every community in Scotland having a local congregation.  Scotland also has a significant Roman Catholic population, 19% professing that faith, particularly in Greater Glasgow and the north-west.[178] After the Reformation, Roman Catholicism in Scotland continued in the Highlands and some western islands like Uist and Barra, and it was strengthened during the 19th century by immigration from Ireland. Other Christian denominations in Scotland include the Free Church of Scotland, and various other Presbyterian offshoots. Scotland's third largest church is the Scottish Episcopal Church.[179]  There are an estimated 75,000 Muslims in Scotland (about 1.4% of the population),[174][180] and significant but smaller Jewish, Hindu and Sikh communities, especially in Glasgow.[180] The Samy\u00e9 Ling monastery near Eskdalemuir, which celebrated its 40th anniversary in 2007, is the first Buddhist monastery in western Europe.[181]  The Scottish education system has always had a characteristic emphasis on a broad education.[183] In the 15th century, the Humanist emphasis on education cumulated with the passing of the Education Act 1496, which decreed that all sons of barons and freeholders of substance should attend grammar schools to learn \"perfyct Latyne\", resulting in an increase in literacy among a male and wealthy elite.[184] In the Reformation, the 1560 First Book of Discipline set out a plan for a school in every parish, but this proved financially impossible.[185] In 1616 an act in Privy council commanded every parish to establish a school.[186] By the late seventeenth century there was a largely complete network of parish schools in the lowlands, but in the Highlands basic education was still lacking in many areas.[187] Education remained a matter for the church rather than the state until the Education (Scotland) Act 1872.[188]  Education in Scotland is the responsibility of the Scottish Government and is overseen by its executive agency Education Scotland.[189] The Curriculum for Excellence, Scotland's national school curriculum, presently provides the curricular framework for children and young people from age 3 to 18.[190] All 3- and 4-year-old children in Scotland are entitled to a free nursery place. Formal primary education begins at approximately 5 years old and lasts for 7 years (P1\u2013P7); children in Scotland study National Qualifications of the Curriculum for Excellence between the ages of 14 and 18. The school leaving age is 16, after which students may choose to remain at school and study further qualifications. A small number of students at certain private schools may follow the English system and study towards GCSEs and A and AS-Levels instead.[191]  There are fifteen Scottish universities, some of which are among the oldest in the world.[192][193] The four universities founded before the end of the 16th century \u2013 the University of St Andrews, the University of Glasgow, the University of Aberdeen and the University of Edinburgh \u2013 are collectively known as the ancient universities of Scotland, all of which rank among the 200 best universities in the world in the THE rankings, with Edinburgh placing in the top 50.[194] Scotland had more universities per capita in QS' World University Rankings' top 100 in 2012 than any other nation.[195] The country produces 1% of the world's published research with less than 0.1% of the world's population, and higher education institutions account for 9% of Scotland's service sector exports.[196][197] Scotland's University Courts are the only bodies in Scotland authorised to award degrees.  Health care in Scotland is mainly provided by NHS Scotland, Scotland's public health care system. This was founded by the National Health Service (Scotland) Act 1947 (later repealed by the National Health Service (Scotland) Act 1978) that took effect on 5 July 1948 to coincide with the launch of the NHS in England and Wales. Prior to 1948, half of Scotland's landmass was already covered by state-funded health care, provided by the Highlands and Islands Medical Service.[199] Healthcare policy and funding is the responsibility of the Scottish Government's Health Directorates. In 2014, the NHS in Scotland had around 140,000 staff.[200]  The total fertility rate (TFR) in Scotland is below the replacement rate of 2.1 (the TFR was 1.73 in 2011[201]). The majority of births are to unmarried women (51.3% of births were outside of marriage in 2012[202]).  Life expectancy for those born in Scotland between 2012 and 2014 is 77.1 years for males and 81.1 years for females.[203] This is the lowest of any of the four countries of the UK.[203] The number of hospital admissions in Scotland for diseases such as cancer was 2,528 in 2002. Over the next ten years, by 2012, this had increased to 2,669.[204] Hospital admissions for other diseases, such as coronary heart disease (CHD) were lower, with 727 admissions in 2002, and decreasing to 489 in 2012.[204]  Scotland is part of the United Kingdom, a constitutional monarchy whose current sovereign is Charles III.[205] The monarchy uses a variety of styles, titles and other symbols specific to Scotland, most of which originated in the pre-Union Kingdom of Scotland. These include the Royal Standard of Scotland, the royal coat of arms, and the title Duke of Rothesay, which is traditionally given to the heir apparent. There are also distinct Scottish Officers of State and Officers of the Crown, and the Order of the Thistle, a chivalric order, is specific to the country.[206]  The Parliament of the United Kingdom and the Parliament of Scotland are the country's primary legislative bodies. The UK Parliament is sovereign and therefore has supremacy over the Scottish Parliament,[207] but generally restricts itself to legislating over reserved matters: primarily taxes, social security, defence, international relations, and broadcasting.[208] There is a convention the UK Parliament will not legislate over devolved matters without the Scottish Parliament's consent.[209] Scotland is represented in the House of Commons, the lower chamber of the UK Parliament, by 59 Members of Parliament (out of a total of 650).[210] They are elected to single-member constituencies under the first-past-the-post system of voting. The Scotland Office represents the British government in Scotland and represents Scottish interests within the government.[211] The Scotland Office is led by the Secretary of State for Scotland, who sits in the Cabinet of the United Kingdom.[212] The Conservative MP Alister Jack has held the position since July 2019.[212]  The Scottish Parliament is a unicameral legislature with 129 members (MSPs): 73 of them represent individual constituencies and are elected on a first-past-the-post system, and the other 56 are elected in eight different electoral regions by the additional member system. MSPs normally serve for a five-year period.[213] The largest party since the 2021 Scottish Parliament election, has been the Scottish National Party (SNP), which won 64 of the 129 seats.[214] The Scottish Conservatives, Scottish Labour, the Scottish Liberal Democrats and the Scottish Greens also have representation in the current Parliament.[214] The next Scottish Parliament election is due to be held on 7 May 2026.[215] The Scottish Government is led by the First Minister, who is nominated by MSPs and is typically the leader of the largest party in the Parliament. Other ministers are appointed by the first minister and serve at their discretion.[216] Since March 2023 the first minister has been Humza Yousaf, the leader of the SNP.  Within the UK, the First Minister is a member of the Heads of Government Council, the body which facilitates intergovernmental relations between the Scottish Government, UK Government, Welsh Government, and Northern Ireland Executive.[217] Foreign policy is a reserved matter and primarily the responsibility of the Foreign Office, a department of the UK Government.[218] Nevertheless, the Scottish Government may promote Scottish interests abroad and encourage foreign investment in Scotland.[219] The First Minister, Cabinet Secretary for Culture, Tourism and External Affairs,[220] and the Minister for International Development and Europe all have portfolios which include foreign affairs.[221][222]  Scotland's international network consists of two Scotland Houses, one in Brussels and the other in London, seven Scottish Government international offices, and over thirty Scottish Development International offices in other countries globally. Both Scotland Houses are independent Scottish Government establishments, whilst the seven Scottish Government international offices are based in British embassies or British High Commission offices.[223] The Scottish Government, along with the other devolved governments of the United Kingdom, pay the Foreign, Commonwealth and Development Office an annual charge to be able to access facilities and support in the Embassy or High Commission in which the Scottish international offices are based. The Scottish Government's international network allows Scottish Government ministers to engage with other international governments and bodies in relation to the government's policy objectives as well as that of Scottish businesses. Additionally, the international network of the Scottish Government acts as a mechanism to promote and strengthen the Scottish economy by creating opportunities for Scottish businesses to increase export sales of Scottish products, whilst working with their current, and any future, foreign investors to establish and maintain Scottish jobs in the goods sector.[223]  Scotland is a member of the British\u2013Irish Council and the British\u2013Irish Parliamentary Assembly, both of which are intended to foster collaboration between the legislative bodies of the United Kingdom and the Republic of Ireland.[224][225] The Scottish Government has a network of offices in Beijing, Berlin, Brussels, Copenhagen, Dublin, London, Ottawa, Paris, and Washington, D.C, which promote Scottish interests in their respective areas.[226] The nation has historic ties to France as a result of the 'Auld Alliance', a treaty signed between the Kingdom of Scotland and Kingdom of France in 1295 to discourage an English invasion of either country.[227] The alliance effectively ended in the sixteenth century, but the two countries continue to have a close relationship, with a Statement of Intent being signed in 2013 between the Scottish Government and the Government of France.[228] In 2004 the Scotland Malawi Partnership was established, which co-ordinates Scottish activities to strengthen existing links with Malawi, and in 2021, the Scottish Government and Government of Ireland signed the Ireland-Scotland Bilateral Review, committing both governments to increased levels of co\u2013operation on areas such as diplomacy, economy and business.[223][229][230] Scotland also has historical and cultural ties with the Scandinavian countries.[231][232] Scottish Government policy advocates for stronger political relations with the Nordic and Baltic countries, which has resulted in some Nordic-inspired policies being adopted such as baby boxes.[233][234] Representatives from the Scottish Parliament attended the Nordic Council for the first time in 2022.[235]  Devolution\u2014the granting of central government powers to a regional government[236]\u2013 gained increasing popularity as a policy in the United Kingdom the late twentieth century; it was described by John Smith, then Leader of the Labour Party, as the \"settled will of the Scottish people\".[237] The Scottish Parliament and Scottish Government were subsequently established under the Scotland Act 1998; the Act followed a successful referendum in 1997 which found majority support for both creating the Parliament and granting it limited powers to vary income tax.[238] The Act enabled the new institutions to legislate in all areas not explicitly reserved by the UK Parliament.[239]  Two more pieces of legislation, the Scotland Acts of 2012 and 2016, gave the Scottish Parliament further powers to legislate on taxation and social security;[240] the 2016 Act also gave the Scottish Government powers to manage the affairs of the Crown Estate in Scotland.[241] Conversely, the United Kingdom Internal Market Act 2020 constrains the Scottish Parliament's autonomy to regulate goods and services,[242][243] and the academic view is that this undermines devolution.[249]  The 2007 Scottish Parliament elections led to the Scottish National Party (SNP), which supports Scottish independence, forming a minority government. The new government established a \"National Conversation\" on constitutional issues, proposing a number of options such as increasing the powers of the Scottish Parliament, federalism, or a referendum on Scottish independence from the United Kingdom. The three main unionist opposition parties\u2013Scottish Labour, the Scottish Conservatives, and the Scottish Liberal Democrats\u2013created a separate commission to investigate the distribution of powers between devolved Scottish and UK-wide bodies while not considering independence.[250] In August 2009 the SNP proposed a bill to hold a referendum on independence in November 2010, but was defeated by opposition from all other major parties.[251][252][253]  The 2011 Scottish Parliament election resulted in an SNP overall majority in the Scottish Parliament, and on 18 September 2014 a referendum on Scottish independence was held.[254] The referendum resulted in a rejection of independence, by 55.3% to 44.7%.[255][256] During the campaign, the three main parties in the British Parliament\u2013the Conservatives, Labour, and the Liberal Democrats\u2013pledged to extend the powers of the Scottish Parliament.[257][258] An all-party commission chaired by Robert Smith, Baron Smith of Kelvin was formed,[258] which led to the Scotland Act 2016.[259]  Following the European Union Referendum Act 2015, the 2016 United Kingdom European Union membership referendum was held on 23 June 2016 on Britain's membership of the European Union. A majority in the United Kingdom voted to withdraw from the EU, while a majority within Scotland voted to remain a member.[260] The first minister, Nicola Sturgeon, announced the following day that as a result a new independence referendum was \"highly likely\".[261][260] On 31 January 2020, the United Kingdom formally withdrew from the European Union. Because constitutional affairs are reserved matters under the Scotland Act, the Scottish Parliament would again have to be granted temporary additional powers under Section 30 to hold a legally binding vote.[262][263][264]  For local government purposes Scotland is subdivided into 32 single-tier council areas.[265] The areas were established in 1996, and their councils are responsible for the provision of all local government services. Decisions are made by councillors, who are elected at local elections every five years. The leader of the council is typically a councillor from the party with the most seats; councils also have a civic head, typically called the provost or lord provost, who represents the council on ceremonial occasions and chairs council meetings.[266] Community Councils are informal organisations that represent smaller subdivisions within each council area.[267]  Police Scotland and the Scottish Fire and Rescue Service cover the entire country. For healthcare and postal districts, and a number of other governmental and non-governmental organisations such as the churches, there are other long-standing methods of subdividing Scotland for the purposes of administration.  There are eight cities in Scotland: Aberdeen, Dundee, Dunfermline, Edinburgh, Glasgow, Inverness, Stirling and Perth.[268] City status in the United Kingdom is conferred by the monarch through letters patent.[269]  As one of the countries of the United Kingdom, the British Armed Forces are the armed forces of Scotland. Of the money spent on UK defence, about \u00a33.3\u00a0billion can be attributed to Scotland as of 2018\/2019.[270] Scotland had a long military tradition predating the Treaty of Union with England. Following the Treaty of Union in 1707, the Scots Army and Royal Scots Navy merged with their English counterparts to form the Royal Navy and the British Army, which together form part of the British Armed Forces.[271][272] The Atholl Highlanders, Europe's only remaining legal private army, did not join the Scots Army or Royal Scots Navy in merging with English armed forces, remaining a private army not under the command of the British Armed Forces.[273]   Numerous Scottish regiments have at various times existed in the British Army. Distinctively Scottish regiments in the British Army include the Scots Guards, the Royal Scots Dragoon Guards and the 154 (Scottish) Regiment RLC, an Army Reserve regiment of the Royal Logistic Corps. In 2006, as a result of the Delivering Security in a Changing World white paper, the Scottish infantry regiments in the Scottish Division were amalgamated to form the Royal Regiment of Scotland.[274]  As a result of the Cameron\u2013Clegg coalition's Strategic Defence and Security Review 2010, the Scottish regiments of the line in the British Army infantry, having previously formed the Scottish Division, were reorganised into the Scottish, Welsh and Irish Division in 2017. Before the formation of the Scottish Division, the Scottish infantry was organised into a Lowland Brigade and Highland Brigade.[275] Because of their topography and perceived remoteness, parts of Scotland have housed many sensitive defence establishments.[276][277][278] Between 1960 and 1991, the Holy Loch was a base for the US fleet of Polaris ballistic missile submarines.[279] Today, Her Majesty's Naval Base Clyde, 25 miles (40 kilometres) north-west of Glasgow, is the base for the four Trident-armed Vanguard-class ballistic missile submarines that comprise the Britain's nuclear deterrent.  Scotland's Scapa Flow was the main base for the Royal Navy in the 20th century.[280] As the Cold War intensified in 1961, the United States deployed Polaris ballistic missiles, and submarines, in the Firth of Clyde's Holy Loch. Public protests from CND campaigners proved futile. The Royal Navy successfully convinced the government to allow the base because it wanted its own Polaris submarines, and it obtained them in 1963. The RN's nuclear submarine base opened with four Resolution-class Polaris submarines at the expanded Faslane Naval Base on the Gare Loch. The first patrol of a Trident-armed submarine occurred in 1994, although the US base was closed at the end of the Cold War.[281]  A single front-line Royal Air Force base is located in Scotland. RAF Lossiemouth, located in Moray, is the most northerly air defence fighter base in the United Kingdom and is home to four Eurofighter Typhoon combat aircraft squadrons, three Poseidon MRA1 squadrons, and a full\u2013time, permanently based RAF Regiment squadron.[282]  Scots law has a basis derived from Roman law,[283] combining features of both uncodified civil law, dating back to the Corpus Juris Civilis, and common law with medieval sources. The terms of the Treaty of Union with England in 1707 guaranteed the continued existence of a separate legal system in Scotland from that of England and Wales.[284] Prior to 1611, there were several regional law systems in Scotland, most notably Udal law in Orkney and Shetland, based on old Norse law. Various other systems derived from common Celtic or Brehon laws survived in the Highlands until the 1800s.[285] Scots law provides for three types of courts responsible for the administration of justice: civil, criminal and heraldic. The supreme civil court is the Court of Session, although civil appeals can be taken to the Supreme Court of the United Kingdom (or before 1 October 2009, the House of Lords). The High Court of Justiciary is the supreme criminal court in Scotland. The Court of Session is housed at Parliament House, in Edinburgh, which was the home of the pre-Union Parliament of Scotland with the High Court of Justiciary and the Supreme Court of Appeal currently located at the Lawnmarket. The sheriff court is the main criminal and civil court, hearing most cases. There are 49 sheriff courts throughout the country.[286] District courts were introduced in 1975 for minor offences and small claims. These were gradually replaced by Justice of the Peace Courts from 2008 to 2010.  For three centuries the Scots legal system was unique for being the only national legal system without a parliament. This ended with the advent of the Scottish Parliament in 1999, which legislates for devolved matters.[287] Many features within the system have been preserved. Within criminal law, the Scots legal system is unique in having three possible verdicts: \"guilty\", \"not guilty\" and \"not proven\".[288] Both \"not guilty\" and \"not proven\" result in an acquittal, typically with no possibility of retrial per the rule of double jeopardy. A retrial can hear new evidence at a later date that might have proven conclusive in the earlier trial at first instance, where the person acquitted subsequently admits the offence or where it can be proved that the acquittal was tainted by an attempt to pervert the course of justice. Scots juries, sitting in criminal cases, consist of fifteen jurors, which is three more than is typical in many countries.[289]  The Lord Advocate is the chief legal officer of the Scottish Government and the Crown in Scotland. The Lord Advocate is the head of the systems in Scotland for the investigation and prosecution of crime, the investigation of deaths as well as serving as the principal legal adviser to the Scottish Government and representing the government in legal proceedings.[290] They are the chief public prosecutor for Scotland and all prosecutions on indictment are conducted by the Crown Office and Procurator Fiscal Service in the Lord Advocate's name on behalf of the Monarch.[290] The officeholder is one of the Great Officers of State of Scotland. The current Lord Advocate is Dorothy Bain, who was nominated by First Minister Nicola Sturgeon and appointed in June 2021.[291] The Lord Advocate is supported by the Solicitor General for Scotland.[292]  Since 2013, Scotland has had a unified police force known as Police Scotland. The Scottish Prison Service (SPS) manages the prisons in Scotland, which collectively house over 8,500 prisoners.[293] The Cabinet Secretary for Justice and Home Affairs is responsible for the Scottish Prison Service within the Scottish Government.  Scotland has a Western-style open mixed economy closely linked with the rest of the UK and the wider world. Scotland is one of the leading financial centres in Europe, and is the largest financial centre in the United Kingdom outside of London.[295] Edinburgh is the financial services centre of Scotland, with many large finance firms based there, including: Lloyds Banking Group, the Bank of Scotland, the Government-owned Royal Bank of Scotland and Standard Life.[296] Edinburgh was ranked 15th in the list of world financial centres in 2007, but fell to 37th in 2012, following damage to its reputation,[297] and in 2016 was ranked 56th out of 86.[298] Its status had returned to 17th by 2020.[299] Traditionally, the Scottish economy was dominated by heavy industry underpinned by shipbuilding in Glasgow, coal mining and steel industries. Petroleum-related industries associated with the extraction of North Sea oil have also been important employers from the 1970s, especially in the north-east of Scotland. De-industrialisation during the 1970s and 1980s saw a shift from a manufacturing focus towards a more service-oriented economy. The Scottish National Investment Bank was established by the Scottish Government in 2020, which uses public money to fund commercial projects across Scotland with the hope that this seed capital will encourage further private investment, to help develop a fairer, more sustainable economy. \u00a32\u00a0billion of taxpayers money was earmarked for the bank.[300]  In 2022, Scotland's gross domestic product (GDP), including offshore oil and gas, was estimated at \u00a3211.7\u00a0billion.[7] In 2021, Scottish exports in goods and services (excluding intra-UK trade) were estimated to be \u00a350.1 billion.[301] Scotland's primary goods exports are mineral fuels, machinery and transport, and beverages and tobacco.[302] The country's largest export markets in goods are the European Union, Asia and Oceania, and North America.[302] Whisky is one of Scotland's more known goods of economic activity. Exports increased by 87% in the decade to 2012[303] and were valued at \u00a34.3\u00a0billion in 2013, which was 85% of Scotland's food and drink exports.[304] It supports around 10,000 jobs directly and 25,000 indirectly.[305] It may contribute \u00a3400\u2013682\u00a0million to Scotland, rather than several billion pounds, as more than 80% of whisky produced is owned by non-Scottish companies.[306] A briefing published in 2002 by the Scottish Parliament Information Centre (SPICe) for the Scottish Parliament's Enterprise and Life Long Learning Committee stated that tourism accounted for up to 5% of GDP and 7.5% of employment.[307]  Scotland was one of the industrial powerhouses of Europe from the time of the Industrial Revolution onwards, being a world leader in manufacturing.[308] This left a legacy in the diversity of goods and services which Scotland produces, from textiles, whisky and shortbread to jet engines, buses, computer software, investment management and other related financial services.[309] In common with most other advanced industrialised economies, Scotland has seen a decline in the importance of both manufacturing industries and primary-based extractive industries. This has been combined with a rise in the service sector of the economy, which has grown to be the largest sector in Scotland.[310]  The average weekly income for workplace-based employees in Scotland is \u00a3573,[311] and \u00a3576 for residence based employees.[311] Scotland has the third highest median gross salary in the United Kingdom at \u00a326,007 and is higher than the overall UK average annual salary of \u00a325,971.[312] With an average of \u00a314.28, Scotland has the third highest median hourly rate (excluding overtime working hours) of any of the countries of the United Kingdom, and like the annual salary, is higher than the average UK figure as a whole.[312] The highest paid industries in Scotland tend of be in the utility electricity, gas and air conditioning sectors,[312] with industries like tourism, accommodation and food and drink tend to be the lowest paid.[312] The top local authority for pay by where people live is East Renfrewshire (\u00a320.87 per hour).[312]  The top local authority for pay based on where people work is East Ayrshire (\u00a316.92 per hour). Scotland's cities commonly have the largest salaries in Scotland for where people work.[312] 2021\/2022 date indicates that there were 2.6 million dwellings across Scotland, with 318,369 local authority dwellings.[313] Typical prices for a house in Scotland was \u00a3195,391 in August 2022.[314]  Between 2016 and 2020, the Scottish Government estimated that 10% of people in Scotland were in persistent poverty following housing costs, with similar rates of persistent poverty for children (10%), working-age adults (10%) and pensioners (11%).[315] Persistent child poverty rates had seen a relatively sharp drop, however, the accuracy of this was deemed to be questionable due to a number of various factors such as households re-entering the longitudinal sample allowing data gaps to be filled.[315] The Scottish Government introduced the Scottish Child Payment in 2021 for low-income families with children under six years of age in an attempt to reduce child poverty rates, with families receiving a payment of roughly \u00a31,040 per year.[316] As of October 2023, 10% of the Scottish population were estimated to be living in poverty.[317]  Although the Bank of England is the central bank for the UK, three Scottish clearing banks issue Sterling banknotes: the Bank of Scotland, the Royal Bank of Scotland and the Clydesdale Bank. The issuing of banknotes by retail banks in Scotland is subject to the Banking Act 2009, which repealed all earlier legislation under which banknote issuance was regulated, and the Scottish and Northern Ireland Banknote Regulations 2009.[318]  The value of the Scottish banknotes in circulation in 2013 was \u00a33.8\u00a0billion, underwritten by the Bank of England using funds deposited by each clearing bank, under the Banking Act 2009, to cover the total value of such notes in circulation.[319]  Scotland has five international airports operating scheduled services to Europe, North America and Asia, as well as domestic services to England, Northern Ireland and Wales.[320] Highlands and Islands Airports operates eleven airports across the Highlands, Orkney, Shetland and the Western Isles, which are primarily used for short distance, public service operations, although Inverness Airport has a number of scheduled flights to destinations across the UK and mainland Europe.[321] Edinburgh Airport is currently Scotland's busiest airport handling over 13 million passengers in 2017.[322] It is also the UK's 6th busiest airport. The airline Loganair has its headquarters at Glasgow Airport and markets itself as Scotland's Airline.[323]  Network Rail owns and operates the fixed infrastructure assets of the railway system in Scotland, while the Scottish Government retains overall responsibility for rail strategy and funding in Scotland.[324] Scotland's rail network has 359 railway stations and around 1,710 miles (2,760\u00a0km) of track.[325] In 2018\u201319 there were 102\u00a0million passenger journeys on Scottish railways.[326] On 1 January 2006, Transport Scotland was established, which would oversee the regulation of railways in Scotland and administer major rail projects.[327] Since April 2022, Transport Scotland has taken ScotRail back into public ownership via its operator of last resort, Scottish Rail Holdings.[328] It did the same with the Caledonian Sleeper service in June 2023.[329]  The Glasgow Subway is the only underground system in Scotland. It opened on 14 December 1896, making it the third-oldest underground network in the world after the Budapest Metro and the London Underground. It is owned and operated by Strathclyde Partnership for Transport.[330]  The Scottish motorways and major trunk roads are managed by Transport Scotland. The remainder of the road network is managed by the Scottish local authorities in each of their areas.  Regular ferry services operate between the Scottish mainland and outlying islands. Ferries serving both the inner and outer Hebrides are principally operated by the state-owned enterprise Caledonian MacBrayne.[331][332] Services to the Northern Isles are operated by Serco. Other routes, such as southwest Scotland to Northern Ireland, are served by multiple companies.[333] DFDS Seaways operated a freight-only Rosyth \u2013 Zeebrugge ferry service, until a fire damaged the vessel DFDS were using.[334] A passenger service was also operated between 2002 and 2010.[335]  Scotland's primary sources of energy are provided through renewable energy (61.8%), nuclear (25.7%) and fossil fuel generation (10.9%).[337] Whitelee Wind Farm is the largest onshore wind farm in the United Kingdom, and was Europe's largest onshore wind farm for some time.[338] Tidal power is an emerging source of energy in Scotland. The MeyGen tidal stream energy plant in the north of the country is claimed to be the largest tidal stream energy project in the world.[339] In Scotland, 98.6% of all electricity used was from renewable sources. This is minus net exports.[337] Between October 2021 and September 2022 63.1% of all electricity generated in Scotland was from renewable sources, 83.6% was classed as low carbon and 14.5% was from fossil fuels.[340] The Scottish Government has a target to have the equivalent of 50% of the energy for Scotland's heat, transport and electricity consumption to be supplied from renewable sources by 2030.[341] They have stated that, in 2022, the equivalent of 113% of the country's overall electrical consumption was produced by renewable energy, making it the highest recorded figure of renewable energy generated to date.[342]  Scotland's inventions and discoveries are said to have revolutionised human technology and have played a major role in the creation of the modern world. Such inventions \u2013 the television, the telephone, refrigerators, the MRI scanner, flushing toilets and the steam engine \u2013 are said to have been possible by Scotland's universities and parish schools, together with the commitment Scots had to education during the Scottish Enlightenment.[343] Alexander Fleming is responsible for the discovery of the world's first broadly effective antibiotic substance, which he named penicillin, earning him a Nobel Prize in Physiology or Medicine in 1945.[344][345][346] Modern Scottish inventions \u2013 the Falkirk Wheel and the Glasgow Tower \u2013 hold world records for being the only rotating boat lift and the tallest fully rotating freestanding structure in the world respectively.[347][348]  Scotland's space industry is a world leader in sustainable space technology,[349][350] and, according to the UK Space Agency, there are 173 space companies currently operating in Scotland as of May 2021.[351] These include spacecraft manufacturers, launch providers, downstream data analyzers, and research organisations.[352] The space industry in Scotland is projected to generate \u00a32billion in income for Scotland's space cluster by 2030.[349] Scottish space industry jobs represent almost 1 in 5 of all UK space industry employment.[353] In addition to its space industry, Scotland is home to two planned spaceports \u2013 Sutherland spaceport and SaxaVord Spaceport \u2013 with launch vehicles such as the Orbex Prime from Scottish\u2013based aerospace company Orbex expected to be launched from Sutherland.[354]  Scottish music is a significant aspect of the nation's culture, with both traditional and modern influences. A famous traditional Scottish instrument is the Great Highland bagpipe, a woodwind reed instrument consisting of three drones and a melody pipe (called the chanter), which are fed continuously by a reservoir of air in a bag. The popularity of pipe bands\u2014primarily featuring bagpipes, various types of snares and drums, and showcasing Scottish traditional dress and music\u2014has spread throughout the world. Bagpipes are featured in holiday celebrations, parades, funerals, weddings, and other events internationally. Many military regiments have a pipe band of their own. In addition to the Great Highland pipes, several smaller, somewhat quieter bellows-blown varieties of bagpipe are played in Scotland, including the smallpipes and the Border pipes.  Scottish popular music has gained an international following, with artists such as Lewis Capaldi, Amy Macdonald, KT Tunstall, Nina Nesbitt, Chvrches, Gerry Cinnamon and Paolo Nutini gaining international success. DJ Calvin Harris was one of the most streamed artists on Spotify in 2023,[355][356] whilst Susan Boyle's debut album was one of the best-selling albums of the 21st century, and was the best-selling album internationally in 2009.[357] Musical talent in Scotland is recognised via the Scottish Music Awards, Scottish Album of the Year Award, the Scots Trad Music Awards and the BBC Radio Scotland Young Traditional Musician award.  Scotland has a literary heritage dating back to the early Middle Ages. The earliest extant literature composed in what is now Scotland was in Brythonic speech in the 6th century, but is preserved as part of Welsh literature.[358] Later medieval literature included works in Latin,[359] Gaelic,[360] Old English[361] and French.[362] The first surviving major text in Early Scots is the 14th-century poet John Barbour's epic Brus, focusing on the life of Robert I,[363] and was soon followed by a series of vernacular romances and prose works.[364] In the 16th century, the crown's patronage helped the development of Scots drama and poetry,[365] but the accession of James VI to the English throne removed a major centre of literary patronage and Scots was sidelined as a literary language.[366] Interest in Scots literature was revived in the 18th century by figures including James Macpherson, whose Ossian Cycle made him the first Scottish poet to gain an international reputation and was a major influence on the European Enlightenment.[367] It was also a major influence on Robert Burns, whom many consider the national poet,[368] and Walter Scott, whose Waverley Novels did much to define Scottish identity in the 19th century.[369] Towards the end of the Victorian era a number of Scottish-born authors achieved international reputations as writers in English, including Robert Louis Stevenson, Arthur Conan Doyle, J. M. Barrie and George MacDonald.[370]  In the 20th century the Scottish Renaissance saw a surge of literary activity and attempts to reclaim the Scots language as a medium for serious literature.[371] Members of the movement were followed by a new generation of post-war poets including Edwin Morgan, who would be appointed the first Scots Makar by the inaugural Scottish government in 2004.[372] Sorley MacLean was described by the Scottish Poetry Library as \"one of the major Scottish poets of the modern era\" because of his \"mastery of his chosen medium and his engagement with the European poetic tradition and European politics\".[373] Nobel Prize Laureate Seamus Heaney credited MacLean with saving Scottish Gaelic poetry.[374] From the 1980s Scottish literature enjoyed another major revival, particularly associated with a group of writers including Irvine Welsh.[371] Scottish poets who emerged in the same period included Carol Ann Duffy, who, in May 2009, was the first Scot named the monarch's Poet Laureate.[375]  National newspapers such as the Daily Record, The Herald, The Scotsman and The National are all produced in Scotland.[376] Important regional dailies include the Evening News in Edinburgh, The Courier in Dundee in the east, and The Press and Journal serving Aberdeen and the north.[376] Scotland is represented at the Celtic Media Festival, which showcases film and television from the Celtic countries. Scottish entrants have won many awards since the festival began in 1980.[377]  Scotland's national broadcaster is BBC Scotland, a division of the BBC, which runs three national television stations BBC One Scotland, BBC Scotland channel and the Gaelic-language broadcaster BBC Alba, and the national radio stations, BBC Radio Scotland and BBC Radio nan G\u00e0idheal, among others. The main Scottish commercial television station is STV which broadcasts on two of the three ITV regions of Scotland.[378]  As one of the Celtic nations, Scotland and Scottish culture are represented at inter-Celtic events at home and over the world. Scotland hosts several music festivals including Celtic Connections (Glasgow), and the Hebridean Celtic Festival (Stornoway). Festivals celebrating Celtic culture, such as Festival Interceltique de Lorient (Brittany), the Pan Celtic Festival (Ireland), and the National Celtic Festival (Portarlington, Australia), feature elements of Scottish culture such as language, music and dance.[379][380][381][382]  The image of St. Andrew, martyred while bound to an X-shaped cross, first appeared in the Kingdom of Scotland during the reign of William I.[383] Following the death of King Alexander III in 1286 an image of Andrew was used on the seal of the Guardians of Scotland who assumed control of the kingdom during the subsequent interregnum.[384] Use of a simplified symbol associated with Saint Andrew, the saltire, has its origins in the late 14th century; the Parliament of Scotland decreeing in 1385 that Scottish soldiers should wear a white Saint Andrew's Cross on the front and back of their tunics.[385] Use of a blue background for the Saint Andrew's Cross is said to date from at least the 15th century.[386] Since 1606 the saltire has also formed part of the design of the Union Flag. There are numerous other symbols and symbolic artefacts, both official and unofficial, including the thistle, the nation's floral emblem (celebrated in the song, The Thistle o' Scotland), the Declaration of Arbroath, incorporating a statement of political independence made on 6 April 1320, the textile pattern tartan that often signifies a particular Scottish clan and the royal Lion Rampant flag.[387][388][389] Highlanders can thank James Graham, 3rd Duke of Montrose, for the repeal in 1782 of the Act of 1747 prohibiting the wearing of tartans.[390]  Although there is no official national anthem of Scotland,[391] Flower of Scotland is played on special occasions and sporting events such as football and rugby matches involving the Scotland national teams and since 2010 is also played at the Commonwealth Games after it was voted the overwhelming favourite by participating Scottish athletes.[392] Other currently less popular candidates for the National Anthem of Scotland include Scotland the Brave, Highland Cathedral, Scots Wha Hae and A Man's A Man for A' That.[393]  St Andrew's Day, 30 November, is the national day, although Burns' Night tends to be more widely observed, particularly outside Scotland. In 2006, the Scottish Parliament passed the St Andrew's Day Bank Holiday (Scotland) Act 2007, designating the day an official bank holiday.[394] Tartan Day is a recent innovation from Canada.[395]  The national animal of Scotland is the unicorn, which has been a Scottish heraldic symbol since the 12th century.[396] The Court of the Lord Lyon regulates Scottish heraldry and the Public Register of All Armorial Bearings in Scotland.[397]  Scottish cuisine has distinctive attributes and recipes of its own but shares much with wider British and European cuisine as a result of local and foreign influences, both ancient and modern. Traditional Scottish dishes exist alongside international foodstuffs brought about by migration. Scotland's natural larder of game, dairy products, fish, fruit, and vegetables is the chief factor in traditional Scots cooking, with a high reliance on simplicity and a lack of spices from abroad, as these were historically rare and expensive.[398]  Irn-Bru is the most common Scottish carbonated soft drink, often described as \"Scotland's other national drink\" (after whisky).[399] During the Late Middle Ages and early modern era, French cuisine played a role in Scottish cookery due to cultural exchanges brought about by the \"Auld Alliance\",[400] especially during the reign of Mary, Queen of Scots. Mary, on her return to Scotland, brought an entourage of French staff who are considered responsible for revolutionising Scots cooking and for some of Scotland's unique food terminology.[401]  Scotland hosts its own national sporting competitions and has independent representation at several international sporting events, including the FIFA World Cup, the UEFA Nations League, the UEFA European Championship, the Rugby Union World Cup, the Rugby League World Cup, the Cricket World Cup, the Netball World Cup and the Commonwealth Games. Scotland has its own national governing bodies, such as the Scottish Football Association (the second oldest national football association in the world)[402] and the Scottish Rugby Union. Variations of football have been played in Scotland for centuries, with the earliest reference dating back to 1424.[403]  The world's first official international association football match, between Scotland and England was held in Glasgow on 30 November 1872, and resulted in a 0\u20130 draw.[404] The Scottish Cup was first contested in 1873, and is the oldest trophy in association football.[405] The Scottish Football Association (SFA) is the main governing body for Scottish association football, and a founding member of the International Football Association Board (IFAB) which governs the Laws of the Game. Scotland is one of only four countries to have a permanent representative on the IFAB; the other four representatives being appointed for set periods by FIFA.[406][407] The SFA has responsibility for the Scotland national football team and the Scotland women's team.  With the modern game of golf originating in 15th-century Scotland, the country is promoted as the home of golf.[408][409][410] To many golfers the Old Course in the Fife town of St Andrews, an ancient links course dating to before 1552,[411] is considered a site of pilgrimage.[412] In 1764, the standard 18-hole golf course was created at St Andrews when members modified the course from 22 to 18 holes.[413] The world's oldest golf tournament, and golf's first major, is The Open Championship, which was first played on 17 October 1860 at Prestwick Golf Club, in Ayrshire, Scotland, with Scottish golfers winning the earliest majors.[414] There are many other famous golf courses in Scotland, including Carnoustie, Gleneagles, Muirfield, and Royal Troon.  The Scottish Rugby Union is the second oldest rugby union in the world. Murrayfield Stadium in Edinburgh is the national stadium of the Scottish national rugby team. The Scotland rugby team played their first official test match, winning 1\u20130 against England at Raeburn Place in 1871. Scotland has competed in the Six Nations from the inaugural tournament in 1883, winning it 14 times outright\u2014including the last Five Nations in 1999\u2014and sharing it another 8. The Rugby World Cup was introduced in 1987 and Scotland have competed in all nine competitions, the most recent being in the 2023 Rugby World Cup. Scotland competes with the England rugby team annually for the Calcutta Cup. Each year, this fixture is played out as part of the Six Nations, with Scotland having last won in 2023.[415]  Other distinctive features of the national sporting culture include the Highland games, curling and shinty. In boxing, Scotland has had 13 world champions, including Ken Buchanan, Benny Lynch and Jim Watt. Scotland has also been successful in motorsport, particularly in Formula One. Notable drivers include; David Coulthard, Jim Clark, Paul Di Resta, and Jackie Stewart.[416] In IndyCar, Dario Franchitti has won 4 consecutive IndyCar world championships.[417]  Scotland has competed at every Commonwealth Games since 1930 and has won 356 medals in total\u201491 Gold, 104 Silver and 161 Bronze.[418] Edinburgh played host to the Commonwealth Games in 1970 and 1986, and most recently Glasgow in 2014.[419]  57\u00b0N 4\u00b0W\ufeff \/ \ufeff57\u00b0N 4\u00b0W\ufeff \/ 57; -4 "},{"title":"Running bounce","content":"  A running bounce, or simply bounce, is a skill in the sport of Australian rules football (necessitated by the Laws of the Game) and some variants where a player bounces (or touches) the ball on the ground in order to run more than the maximum distance with the ball (currently 15 metres\/16 yards\/50 feet in most competitions).  The earliest record of the running bounce is its use by the Geelong Football Club in 1862, as a means of slowing down the player in possession of the ball and to create more opportunities for a turn over. It became an official part of the Laws of the Game in 1866. The bounce is regarded as a distinctive feature, and one of the most difficult skills to master, of the sport. Observers sometimes compare it to dribbling in basketball which appeared in the 1890s[1] or bouncing in Gaelic football which appeared in the 1900s.[2]).   The feature of the game led to the sport early on being referred to as \"bouncing football\" in some places in the early 20th Century (such as Western Australia, the United States and Canada) to distinguish it from other variations of football.  The origins of the running bounce are unknown. Anecdotally it had been practiced by footballers during the Victorian gold rush who had been playing under a variety of rules as early as the 1850s.  Historians infer that the Geelong Football Club had, sometime prior to 1862, introduced a rule to touch or bounce the ball on the ground every few yards. The club had been playing under rules which historian Graeme Atkinson considered likely to have been drawn up prior to the Melbourne Football Club's first rules in 17 May 1859.[3] Unlike Melbourne's, Geelong's first rules appear to have never been published[3] and though believed to have been written down are believed to have been lost completely. A reprint of what were believed to have been the Geelong's eleven 1859 rules appeared in the Geelong Advertiser in 1923 courtesy of Fred Blackham from an old folded card, which appeared to differ only slightly from Melbourne Football Club's rules and do not mention a requirement to bounce the ball.[4] These reprinted rules were not dated and likely to be from a later period. The Geelong Advertiser appears to indicate that Geelong had Saturday football teams which regularly \"hacked shins\" in March and April prior to the formation of the Melbourne Football Club and that the formation of the Melbourne FC spurred Geelong to incorporate its own club.[5] The Melbourne Football Club from its formation until its first matches against Geelong in 1860 is not known to have either played with or enforced such a rule. Mangan (1992) states that the bounce was introduced due to an ongoing dispute between Geelong and Melbourne which came to a head during a match in 1862. Melbourne members familiar with the Rugby school rules were regularly flaunting their own rules of not running with the ball (particularly H. C. A. Harrison but also Tom Wills) carrying it great distances while not being penalised by the umpires. The rules at the time were written in such a way as it could be interpreted by the umpire that the players were allowed sufficient time (to continue to run) for as long as they needed to prepare an effective kick, that is, virtually indefinitely. Geelong, asserting that the game was not meant to be played like rugby, began to enforce its rule of bouncing for matches between the two clubs.[6] An early version of the Geelong-Melbourne rule had stipulated that \"no player shall run with the ball unless he strikes it against the ground every five of six yards\".[7]  Another early mention of such a rule comes from the Christchurch Football Club in New Zealand, which drafted its own rules in 1863 (prior to adopting rugby).[8].  This club was known to have initially played with a rule to bounce the ball every 4 yards.[9][10] This was a time when the football codes were still being established and regularly exchanged rules and ideas around the world. According to some, it may have come from an Australian club as at least one was known at the time to have had a bouncing rule. The club believes without stating a source that it was more likely to have been influenced by the rules of the Blackheath F.C. in England. Blackheath's 1862 rules include rule 12 \"When a player running with the ball grounds it, it cannot be touched by anyone until he lifts his hand from it\".[11] Touching the ball on the ground while running may have found its way into common practice for some early football clubs. However the club believes that its rules differed from Blackheath's in that it specifically required the ball to be bounced and 22 players per side, though were otherwise similar.  Nevertheless Geelong and other Victorian clubs continued to agitate for the rules and by 1866 there were moves to standardise it. The rules committee chaired by H. C. A. Harrison in 8 May 1866 sought to pacify them. Melbourne was determined to increase this distance and proposed rule 6. \"Ball must be bounced every 10 or 20 yards if carried\". Harrison requested Geelong ratify change before publishing the new rules which became known as the Victorian football rules in May 1866. The new rule was promoted as a way to slow down the player in possession of the ball and to create more opportunities for a turn over, thus helping to increase the number of disposals and encourage more dynamic team play. Harrison himself was one of the fastest runners in the game, known for his ability to evade opponents while running the length of the field ball-in-hand. Arthur Conan Doyle considered it \"very sporting of [Harrison] to introduce the bouncing rule, which robbed him of his advantage.\"[12]  The rule was well received by players and spectators alike, and considered attractive to watch.[citation needed]  Football is played with an ellipsoidal (oval-shaped) ball, rather than a spherical one, so the technique for bouncing one back to oneself while running requires practice. To execute a running bounce, a player should:  Executed properly by a player running at a normal pace, the ball should bounce directly back into their waiting hands.  Players need to readjust the distance of their bounces when running at different paces. When running faster, the ball must be bounced further in front of the player, and when running slower, the ball must be bounced closer. At very slow or stationary paces, this correction is more difficult, because it is difficult to correctly angle the ball for the return bounce at such a short distance.  Australian children (in Australian rules football states) generally learn how to execute running bounces over a few years while they play at school and in junior levels, so to top-level players, the running bounce is a natural skill.  Nevertheless, bouncing an oval-shaped ball is still a volatile skill. Even top level players will occasionally lose the ball while bouncing it, by accidentally bouncing the ball on its point, only to see it quickly skid away from them.  The rules of football state that a player running on the field with the ball must take a running bounce at least once every fifteen metres. If they run too far without taking a running bounce, the umpire pays a free kick for running too far to the opposition at the position where the player oversteps their limit. The umpire signals running too far by rolling their clenched fists around each other\u00a0\u2013 similar to false starts in American football, or traveling in basketball.  While the distance of 15 metres (50\u00a0ft) is explicit in the rules, the lack of markings on the ground makes it impossible for umpires to accurately judge these free kicks. Regular watchers of football generally have a feel for the average time between running bounces which feels right, and umpires usually penalise players when they exceed this by more than a few steps.  Instead of executing a running bounce, players may bend over and touch the ball onto the ground. It must be touched with both hands or a free kick will be rewarded to the opposing team. This has the disadvantage of taking much longer, increasing the risk of being tackled by an opponent, but it has the advantage of reducing the risk of making a bad bounce and dropping the ball. This technique is often used on rainy days when the mud or water on the ground makes a regulation bounce much more difficult, but is also used by some players, particularly in lower levels, who have yet to master the running bounce.  The bounce is not considered a correct disposal as throwing is not allowed under the rules, and a player who bounces is considered still to be in possession of the football while it is out of his hands. Under the holding the ball rule, bouncing the ball while being tackled results in the tackler being rewarded with a free kick.   Running bounces are most commonly made by attacking half-back flankers, also known as link-men, or by outside\/receiving midfielders. They generally accept the ball from a rebound, and have wide space in front of them to run into, giving teammates time to create options at half-forward.   Brent Harvey holds the AFL career record for the most bounces with 1055 while David Rodan had the highest average of more than 3 a game.  Mick McGuane set an Australian Football League record of 7 consecutive bounces from the centre bounce resulting in the 1994 Goal of the Year (Video on YouTube).[13] Nathan Bock, currently holds the AFL record for running bounces with 20 in a game in 2009[14] and Heath Shaw holds the record for an AFL season with 167 in 2009.[15]  The requirement that a player performs a specialist skill in order to be allowed to run with the ball is common and necessary in many sports. Introducing these skills prevents players from taking the ball in hand and running the length of the field unchallenged. In this way, the running bounce is related to:  The running bounce should not be confused with the ball-up, also often referred to as a bounce. The ball-up is an unrelated umpiring skill used to restart play from a neutral contest. "},{"title":"Oval","content":"An oval (from Latin  ovum\u00a0'egg') is a closed curve in a plane which resembles the outline of an egg. The term is not very specific, but in some areas (projective geometry, technical drawing, etc.) it is given a more precise definition, which may include either one or two axes of symmetry of an ellipse. In common English, the term is used in a broader sense: any shape which reminds one of an egg. The three-dimensional version of an oval is called an ovoid.  The term oval when used to describe curves in geometry is not well-defined, except in the context of projective geometry. Many distinct curves are commonly called ovals or are said to have an \"oval shape\". Generally, to be called an oval, a plane curve should resemble the outline of an egg or an ellipse. In particular, these are common traits of ovals:  Here are examples of ovals described elsewhere:  An ovoid is the surface in 3-dimensional space generated by rotating an oval curve about one of its axes of symmetry. The adjectives ovoidal and ovate mean having the characteristic of being an ovoid, and are often used as synonyms for \"egg-shaped\".  For finite planes (i.e. the set of points is finite) there is a more convenient characterization:[2]  An ovoid in a projective space is a set  \u03a9 of points such that:  In the finite case only for dimension 3 there exist ovoids. A convenient characterization is:  The shape of an egg is approximated by the \"long\" half of a prolate spheroid, joined to a \"short\" half of a roughly spherical ellipsoid, or even a slightly oblate spheroid. These are joined at the equator and share a principal axis of rotational symmetry, as illustrated above.  Although the term egg-shaped usually implies a lack of reflection symmetry across the equatorial plane, it may also refer to true prolate ellipsoids.  It can also be used to describe the 2-dimensional figure that, if revolved around its major axis, produces the 3-dimensional surface.  In technical drawing, an oval is a figure that is constructed from two pairs of arcs, with two different radii (see image on the right). The arcs are joined at a point in which lines tangential to both joining arcs lie on the same line, thus making the joint smooth. Any point of an oval belongs to an arc with a constant radius (shorter or longer), but in an ellipse, the radius is continuously changing.  In common speech, \"oval\" means a shape rather like an egg or an ellipse, which may be two-dimensional or three-dimensional. It also often refers to a figure that resembles two semicircles joined by a rectangle, like a cricket infield, speed skating rink or an athletics track. However, this is most correctly called a stadium.  The term \"ellipse\" is often used interchangeably with oval, despite not being a precise synonym.[4] The term \"oblong\" is often used incorrectly to describe an elongated oval or 'stadium' shape.[5] However, in geometry, an oblong is a rectangle with unequal adjacent sides (i.e., not a square).[6] "}]